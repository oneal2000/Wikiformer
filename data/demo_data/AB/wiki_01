<doc id="11924" url="https://en.wikipedia.org/wiki?curid=11924" title="Game theory">
Game theory

Game theory is the study of mathematical models of strategic interactions among rational agents. It has applications in all fields of social science, as well as in logic, systems science and computer science. Originally, it addressed two-person zero-sum games, in which each participant's gains or losses are exactly balanced by those of other participants. In the 21st century, game theory applies to a wide range of behavioral relations, and is now an umbrella term for the science of logical decision making in humans, animals, and computers.
Modern game theory began with the idea of mixed-strategy equilibria in two-person zero-sum game and its proof by John von Neumann. Von Neumann's original proof used the Brouwer fixed-point theorem on continuous mappings into compact convex sets, which became a standard method in game theory and mathematical economics. His paper was followed by the 1944 book "Theory of Games and Economic Behavior", co-written with Oskar Morgenstern, which considered cooperative games of several players. The second edition of this book provided an axiomatic theory of expected utility, which allowed mathematical statisticians and economists to treat decision-making under uncertainty.
Game theory was developed extensively in the 1950s by many scholars. It was explicitly applied to evolution in the 1970s, although similar developments go back at least as far as the 1930s. Game theory has been widely recognized as an important tool in many fields. , with the Nobel Memorial Prize in Economic Sciences going to game theorist Jean Tirole, eleven game theorists have won the economics Nobel Prize. John Maynard Smith was awarded the Crafoord Prize for his application of evolutionary game theory.
## History.
### Precursors.
Discussions on the mathematics of games began long before the rise of modern mathematical game theory. Cardano's work on games of chance in "Liber de ludo aleae" ("Book on Games of Chance"), which was written around 1564 but published posthumously in 1663, formulated some of the field's basic ideas. In the 1650s, Pascal and Huygens developed the concept of expectation on reasoning about the structure of games of chance, and Huygens published his gambling calculus in "De ratiociniis in ludo aleæ" ("On Reasoning in Games of Chance") in 1657.
In 1713, a letter attributed to Charles Waldegrave analyzed a game called "le Her". He was an active Jacobite and uncle to James Waldegrave, a British diplomat. In this letter, Waldegrave provided a minimax mixed strategy solution to a two-person version of the card game le Her, and the problem is now known as Waldegrave problem. In his 1838 "Recherches sur les principes mathématiques de la théorie des richesses" ("Researches into the Mathematical Principles of the Theory of Wealth"), Antoine Augustin Cournot considered a duopoly and presented a solution that is the Nash equilibrium of the game.
In 1913, Ernst Zermelo published "Über eine Anwendung der Mengenlehre auf die Theorie des Schachspiels" ("On an Application of Set Theory to the Theory of the Game of Chess"), which proved that the optimal chess strategy is strictly determined. This paved the way for more general theorems.
In 1938, the Danish mathematical economist Frederik Zeuthen proved that the mathematical model had a winning strategy by using Brouwer's fixed point theorem. In his 1938 book "Applications aux Jeux de Hasard" and earlier notes, Émile Borel proved a minimax theorem for two-person zero-sum matrix games only when the pay-off matrix is symmetric and provided a solution to a non-trivial infinite game (known in English as Blotto game). Borel conjectured the non-existence of mixed-strategy equilibria in finite two-person zero-sum games, a conjecture that was proved false by von Neumann.
### Birth and early developments.
Game theory did not really exist as a unique field until John von Neumann published the paper "On the Theory of Games of Strategy" in 1928. Von Neumann's original proof used Brouwer's fixed-point theorem on continuous mappings into compact convex sets, which became a standard method in game theory and mathematical economics. His paper was followed by his 1944 book "Theory of Games and Economic Behavior" co-authored with Oskar Morgenstern. The second edition of this book provided an axiomatic theory of utility, which reincarnated Daniel Bernoulli's old theory of utility (of money) as an independent discipline. Von Neumann's work in game theory culminated in this 1944 book. This foundational work contains the method for finding mutually consistent solutions for two-person zero-sum games. Subsequent work focused primarily on cooperative game theory, which analyzes optimal strategies for groups of individuals, presuming that they can enforce agreements between them about proper strategies.
In 1950, the first mathematical discussion of the prisoner's dilemma appeared, and an experiment was undertaken by notable mathematicians Merrill M. Flood and Melvin Dresher, as part of the RAND Corporation's investigations into game theory. RAND pursued the studies because of possible applications to global nuclear strategy. Around this same time, John Nash developed a criterion for mutual consistency of players' strategies known as the Nash equilibrium, applicable to a wider variety of games than the criterion proposed by von Neumann and Morgenstern. Nash proved that every finite n-player, non-zero-sum (not just two-player zero-sum) non-cooperative game has what is now known as a Nash equilibrium in mixed strategies.
Game theory experienced a flurry of activity in the 1950s, during which the concepts of the core, the extensive form game, fictitious play, repeated games, and the Shapley value were developed. The 1950s also saw the first applications of game theory to philosophy and political science.
### Prize-winning achievements.
In 1965, Reinhard Selten introduced his solution concept of subgame perfect equilibria, which further refined the Nash equilibrium. Later he would introduce trembling hand perfection as well. In 1994 Nash, Selten and Harsanyi became Economics Nobel Laureates for their contributions to economic game theory.
In the 1970s, game theory was extensively applied in biology, largely as a result of the work of John Maynard Smith and his evolutionarily stable strategy. In addition, the concepts of correlated equilibrium, trembling hand perfection, and common knowledge were introduced and analyzed.
In 2005, game theorists Thomas Schelling and Robert Aumann followed Nash, Selten, and Harsanyi as Nobel Laureates. Schelling worked on dynamic models, early examples of evolutionary game theory. Aumann contributed more to the equilibrium school, introducing equilibrium coarsening and correlated equilibria, and developing an extensive formal analysis of the assumption of common knowledge and of its consequences.
In 2007, Leonid Hurwicz, Eric Maskin, and Roger Myerson were awarded the Nobel Prize in Economics "for having laid the foundations of mechanism design theory". Myerson's contributions include the notion of proper equilibrium, and an important graduate text: "Game Theory, Analysis of Conflict". Hurwicz introduced and formalized the concept of incentive compatibility.
In 2012, Alvin E. Roth and Lloyd S. Shapley were awarded the Nobel Prize in Economics "for the theory of stable allocations and the practice of market design". In 2014, the Nobel went to game theorist Jean Tirole.
## Game types.
### Cooperative / non-cooperative.
A game is "cooperative" if the players are able to form binding commitments externally enforced (e.g. through contract law). A game is "non-cooperative" if players cannot form alliances or if all agreements need to be self-enforcing (e.g. through credible threats).
Cooperative games are often analyzed through the framework of "cooperative game theory", which focuses on predicting which coalitions will form, the joint actions that groups take, and the resulting collective payoffs. It is opposed to the traditional "non-cooperative game theory" which focuses on predicting individual players' actions and payoffs and analyzing Nash equilibria. The focus on individual payoff can result in a phenomenon known as Tragedy of the Commons, where resources are used to a collectively inefficient level. The lack of formal negotiation leads to the deterioration of public goods through over-use and under provision that stems from private incentives.
Cooperative game theory provides a high-level approach as it describes only the structure, strategies, and payoffs of coalitions, whereas non-cooperative game theory also looks at how bargaining procedures will affect the distribution of payoffs within each coalition. As non-cooperative game theory is more general, cooperative games can be analyzed through the approach of non-cooperative game theory (the converse does not hold) provided that sufficient assumptions are made to encompass all the possible strategies available to players due to the possibility of external enforcement of cooperation. While using a single theory may be desirable, in many instances insufficient information is available to accurately model the formal procedures available during the strategic bargaining process, or the resulting model would be too complex to offer a practical tool in the real world. In such cases, cooperative game theory provides a simplified approach that allows analysis of the game at large without having to make any assumption about bargaining powers.
### Symmetric / asymmetric.
A symmetric game is a game where the payoffs for playing a particular strategy depend only on the other strategies employed, not on who is playing them. That is, if the identities of the players can be changed without changing the payoff to the strategies, then a game is symmetric. Many of the commonly studied 2×2 games are symmetric. The standard representations of chicken, the prisoner's dilemma, and the stag hunt are all symmetric games. Some scholars would consider certain asymmetric games as examples of these games as well. However, the most common payoffs for each of these games are symmetric.
The most commonly studied asymmetric games are games where there are not identical strategy sets for both players. For instance, the ultimatum game and similarly the dictator game have different strategies for each player. It is possible, however, for a game to have identical strategies for both players, yet be asymmetric. For example, the game pictured in this section's graphic is asymmetric despite having identical strategy sets for both players.
### Zero-sum / non-zero-sum.
Zero-sum games are a special case of constant-sum games in which choices by players can neither increase nor decrease the available resources. In zero-sum games, the total benefit goes to all players in a game, for every combination of strategies, always adds to zero (more informally, a player benefits only at the equal expense of others). Poker exemplifies a zero-sum game (ignoring the possibility of the house's cut), because one wins exactly the amount one's opponents lose. Other zero-sum games include matching pennies and most classical board games including Go and chess.
Many games studied by game theorists (including the famed prisoner's dilemma) are non-zero-sum games, because the outcome has net results greater or less than zero. Informally, in non-zero-sum games, a gain by one player does not necessarily correspond with a loss by another.
Constant-sum games correspond to activities like theft and gambling, but not to the fundamental economic situation in which there are potential gains from trade. It is possible to transform any game into a (possibly asymmetric) zero-sum game by adding a dummy player (often called "the board") whose losses compensate the players' net winnings.
### Simultaneous / sequential.
Simultaneous games are games where both players move simultaneously, or instead the later players are unaware of the earlier players' actions (making them "effectively" simultaneous). Sequential games (or dynamic games) are games where later players have some knowledge about earlier actions. This need not be perfect information about every action of earlier players; it might be very little knowledge. For instance, a player may know that an earlier player did not perform one particular action, while they do not know which of the other available actions the first player actually performed.
The difference between simultaneous and sequential games is captured in the different representations discussed above. Often, normal form is used to represent simultaneous games, while extensive form is used to represent sequential ones. The transformation of extensive to normal form is one way, meaning that multiple extensive form games correspond to the same normal form. Consequently, notions of equilibrium for simultaneous games are insufficient for reasoning about sequential games; see subgame perfection.
In short, the differences between sequential and simultaneous games are as follows:
#### Cournot Competition.
The Cournot competition model involves players choosing quantity of a homogenous product to produce independently and simultaneously, where marginal cost can be different for each firm and the firm's payoff is profit. The production costs are public information and the firm aims to find their profit-maximising quantity based on what they believe the other firm will produce and behave like monopolies. In this game firms want to produce at the monopoly quantity but there is a high incentive to deviate and produce more, which decreases the market-clearing price. For example, firms may be tempted to deviate from the monopoly quantity if there is a low monopoly quantity and high price, with the aim of increasing production to maximise profit. However this option does not provide the highest payoff, as a firm's ability to maximise profits depends on its market share and the elasticity of the market demand. The Cournot equilibrium is reached when each firm operates on their reaction function with no incentive to deviate, as they have the best response based on the other firms output. Within the game, firms reach the Nash equilibrium when the Cournot equilibrium is achieved. 
#### Bertrand Competition.
The Bertrand competition, assumes homogenous products and a constant marginal cost and players choose the prices. The equilibrium of price competition is where the price is equal to marginal costs, assuming complete information about the competitors' costs. Therefore, the firms have an incentive to deviate from the equilibrium because a homogenous product with a lower price will gain all of the market share, known as a cost advantage.
### Perfect information and imperfect information.
An important subset of sequential games consists of games of perfect information. A game is one of perfect information if all players, at every move in the game, know the moves previously made by all other players. In reality, this can be applied to firms and consumers having information about price and quality of all the available goods in a market. An imperfect information game is played when the players do not know all moves already made by the opponent such as a simultaneous move game. Most games studied in game theory are imperfect-information games. Examples of perfect-information games include tic-tac-toe, checkers, infinite chess, and Go.
Many card games are games of imperfect information, such as poker and bridge. Perfect information is often confused with complete information, which is a similar concept. Complete information requires that every player know the strategies and payoffs available to the other players but not necessarily the actions taken, whereas perfect information is knowledge of all aspects of the game and players. Games of incomplete information can be reduced, however, to games of imperfect information by introducing "moves by nature".
#### Bayesian game.
For one of the assumptions behind the concept of Nash equilibrium, every player has right beliefs about the actions of the other players. In game theory, there are many situations where participants do not fully understand the characteristics of their opponents. Negotiators may be unaware of their opponent's valuation of the object of negotiation, companies may be unaware of their opponent's cost functions, combatants may be unaware of their opponent's strengths, and jurors may be unaware of their colleague's interpretation of the evidence at trial. In some cases, participants may know the character of their opponent well, but may not know how well their opponent knows his or her own character.
Bayesian game means a strategic game with incomplete information. For a strategic game, decision makers are players, and every player has a group of actions. A core part of the imperfect information specification is the set of states. Every state completely describes a collection of characteristics relevant to the player such as their preferences and details about them. There must be a state for every set of features that some player believes may exist.
For example, where Player 1 is unsure whether Player 2 would rather date her or get away from her, while Player 2 understands Player 1's preferences as before. To be specific, supposing that Player 1 believes that Player 2 wants to date her under a probability of 1/2 and get away from her under a probability of 1/2 (this evaluation comes from Player 1's experience probably: she faces players who want to date her half of the time in such a case and players who want to avoid her half of the time). Due to the probability involved, the analysis of this situation requires to understand the player's preference for the draw, even though people are only interested in pure strategic equilibrium.
Games in which the difficulty of finding an optimal strategy stems from the multiplicity of possible moves are called combinatorial games. Examples include chess and go. Games that involve imperfect information may also have a strong combinatorial character, for instance backgammon. There is no unified theory addressing combinatorial elements in games. There are, however, mathematical tools that can solve particular problems and answer general questions.
Games of perfect information have been studied in combinatorial game theory, which has developed novel representations, e.g. surreal numbers, as well as combinatorial and algebraic (and sometimes non-constructive) proof methods to solve games of certain types, including "loopy" games that may result in infinitely long sequences of moves. These methods address games with higher combinatorial complexity than those usually considered in traditional (or "economic") game theory. A typical game that has been solved this way is Hex. A related field of study, drawing from computational complexity theory, is game complexity, which is concerned with estimating the computational difficulty of finding optimal strategies.
Research in artificial intelligence has addressed both perfect and imperfect information games that have very complex combinatorial structures (like chess, go, or backgammon) for which no provable optimal strategies have been found. The practical solutions involve computational heuristics, like alpha–beta pruning or use of artificial neural networks trained by reinforcement learning, which make games more tractable in computing practice.
### Infinitely long games.
Games, as studied by economists and real-world game players, are generally finished in finitely many moves. Pure mathematicians are not so constrained, and set theorists in particular study games that last for infinitely many moves, with the winner (or other payoff) not known until "after" all those moves are completed.
The focus of attention is usually not so much on the best way to play such a game, but whether one player has a winning strategy. (It can be proven, using the axiom of choice, that there are gameseven with perfect information and where the only outcomes are "win" or "lose"for which "neither" player has a winning strategy.) The existence of such strategies, for cleverly designed games, has important consequences in descriptive set theory.
### Discrete and continuous games.
Much of game theory is concerned with finite, discrete games that have a finite number of players, moves, events, outcomes, etc. Many concepts can be extended, however. Continuous games allow players to choose a strategy from a continuous strategy set. For instance, Cournot competition is typically modeled with players' strategies being any non-negative quantities, including fractional quantities.
### Differential games.
Differential games such as the continuous pursuit and evasion game are continuous games where the evolution of the players' state variables is governed by differential equations. The problem of finding an optimal strategy in a differential game is closely related to the optimal control theory. In particular, there are two types of strategies: the open-loop strategies are found using the Pontryagin maximum principle while the closed-loop strategies are found using Bellman's Dynamic Programming method.
A particular case of differential games are the games with a random time horizon. In such games, the terminal time is a random variable with a given probability distribution function. Therefore, the players maximize the mathematical expectation of the cost function. It was shown that the modified optimization problem can be reformulated as a discounted differential game over an infinite time interval.
### Evolutionary game theory.
Evolutionary game theory studies players who adjust their strategies over time according to rules that are not necessarily rational or farsighted. In general, the evolution of strategies over time according to such rules is modeled as a Markov chain with a state variable such as the current strategy profile or how the game has been played in the recent past. Such rules may feature imitation, optimization, or survival of the fittest.
In biology, such models can represent evolution, in which offspring adopt their parents' strategies and parents who play more successful strategies (i.e. corresponding to higher payoffs) have a greater number of offspring. In the social sciences, such models typically represent strategic adjustment by players who play a game many times within their lifetime and, consciously or unconsciously, occasionally adjust their strategies.
### Stochastic outcomes (and relation to other fields).
Individual decision problems with stochastic outcomes are sometimes considered "one-player games". These situations are not considered game theoretical by some authors. They may be modeled using similar tools within the related disciplines of decision theory, operations research, and areas of artificial intelligence, particularly AI planning (with uncertainty) and multi-agent system. Although these fields may have different motivators, the mathematics involved are substantially the same, e.g. using Markov decision processes (MDP).
Stochastic outcomes can also be modeled in terms of game theory by adding a randomly acting player who makes "chance moves" ("moves by nature"). This player is not typically considered a third player in what is otherwise a two-player game, but merely serves to provide a roll of the dice where required by the game.
For some problems, different approaches to modeling stochastic outcomes may lead to different solutions. For example, the difference in approach between MDPs and the minimax solution is that the latter considers the worst-case over a set of adversarial moves, rather than reasoning in expectation about these moves given a fixed probability distribution. The minimax approach may be advantageous where stochastic models of uncertainty are not available, but may also be overestimating extremely unlikely (but costly) events, dramatically swaying the strategy in such scenarios if it is assumed that an adversary can force such an event to happen. (See Black swan theory for more discussion on this kind of modeling issue, particularly as it relates to predicting and limiting losses in investment banking.)
General models that include all elements of stochastic outcomes, adversaries, and partial or noisy observability (of moves by other players) have also been studied. The "gold standard" is considered to be partially observable stochastic game (POSG), but few realistic problems are computationally feasible in POSG representation.
### Metagames.
These are games the play of which is the development of the rules for another game, the target or subject game. Metagames seek to maximize the utility value of the rule set developed. The theory of metagames is related to mechanism design theory.
The term metagame analysis is also used to refer to a practical approach developed by Nigel Howard. whereby a situation is framed as a strategic game in which stakeholders try to realize their objectives by means of the options available to them. Subsequent developments have led to the formulation of confrontation analysis.
### Pooling games.
These are games prevailing over all forms of society. Pooling games are repeated plays with changing payoff table in general over an experienced path, and their equilibrium strategies usually take a form of evolutionary social convention and economic convention. Pooling game theory emerges to formally recognize the interaction between optimal choice in one play and the emergence of forthcoming payoff table update path, identify the invariance existence and robustness, and predict variance over time. The theory is based upon topological transformation classification of payoff table update over time to predict variance and invariance, and is also within the jurisdiction of the computational law of reachable optimality for ordered system.
### Mean field game theory.
Mean field game theory is the study of strategic decision making in very large populations of small interacting agents. This class of problems was considered in the economics literature by Boyan Jovanovic and Robert W. Rosenthal, in the engineering literature by Peter E. Caines, and by mathematician Pierre-Louis Lions and Jean-Michel Lasry.
## Representation of games.
The games studied in game theory are well-defined mathematical objects. To be fully defined, a game must specify the following elements: the "players" of the game, the "information" and "actions" available to each player at each decision point, and the "payoffs" for each outcome. (Eric Rasmusen refers to these four "essential elements" by the acronym "PAPI".) A game theorist typically uses these elements, along with a solution concept of their choosing, to deduce a set of equilibrium strategies for each player such that, when these strategies are employed, no player can profit by unilaterally deviating from their strategy. These equilibrium strategies determine an equilibrium to the game—a stable state in which either one outcome occurs or a set of outcomes occur with known probability.
Most cooperative games are presented in the characteristic function form, while the extensive and the normal forms are used to define noncooperative games.
### Extensive form.
The extensive form can be used to formalize games with a time sequencing of moves. Games here are played on trees (as pictured here). Here each vertex (or node) represents a point of choice for a player. The player is specified by a number listed by the vertex. The lines out of the vertex represent a possible action for that player. The payoffs are specified at the bottom of the tree. The extensive form can be viewed as a multi-player generalization of a decision tree. To solve any extensive form game, backward induction must be used. It involves working backward up the game tree to determine what a rational player would do at the last vertex of the tree, what the player with the previous move would do given that the player with the last move is rational, and so on until the first vertex of the tree is reached.
The game pictured consists of two players. The way this particular game is structured (i.e., with sequential decision making and perfect information), "Player 1" "moves" first by choosing either or (fair or unfair). Next in the sequence, "Player 2", who has now seen "Player 1"s move, chooses to play either or . Once "Player 2" has made their choice, the game is considered finished and each player gets their respective payoff. Suppose that "Player 1" chooses and then "Player 2" chooses : "Player 1" then gets a payoff of "eight" (which in real-world terms can be interpreted in many ways, the simplest of which is in terms of money but could mean things such as eight days of vacation or eight countries conquered or even eight more opportunities to play the same game against other players) and "Player 2" gets a payoff of "two".
The extensive form can also capture simultaneous-move games and games with imperfect information. To represent it, either a dotted line connects different vertices to represent them as being part of the same information set (i.e. the players do not know at which point they are), or a closed line is drawn around them. (See example in the imperfect information section.)
### Normal form.
The normal (or strategic form) game is usually represented by a matrix which shows the players, strategies, and payoffs (see the example to the right). More generally it can be represented by any function that associates a payoff for each player with every possible combination of actions. In the accompanying example there are two players; one chooses the row and the other chooses the column. Each player has two strategies, which are specified by the number of rows and the number of columns. The payoffs are provided in the interior. The first number is the payoff received by the row player (Player 1 in our example); the second is the payoff for the column player (Player 2 in our example). Suppose that Player 1 plays "Up" and that Player 2 plays "Left". Then Player 1 gets a payoff of 4, and Player 2 gets 3.
When a game is presented in normal form, it is presumed that each player acts simultaneously or, at least, without knowing the actions of the other. If players have some information about the choices of other players, the game is usually presented in extensive form.
Every extensive-form game has an equivalent normal-form game, however, the transformation to normal form may result in an exponential blowup in the size of the representation, making it computationally impractical.
### Characteristic function form.
In games that possess removable utility, separate rewards are not given; rather, the characteristic function decides the payoff of each unity. The idea is that the unity that is 'empty', so to speak, does not receive a reward at all.
The origin of this form is to be found in John von Neumann and Oskar Morgenstern's book; when looking at these instances, they guessed that when a union formula_1 appears, it works against the fraction
formula_2
as if two individuals were playing a normal game. The balanced payoff of C is a basic function. Although there are differing examples that help determine coalitional amounts from normal games, not all appear that in their function form can be derived from such.
Formally, a characteristic function is seen as: (N,v), where N represents the group of people and formula_3 is a normal utility.
Such characteristic functions have expanded to describe games where there is no removable utility.
### Alternative game representations.
Alternative game representation forms exist and are used for some subclasses of games or adjusted to the needs of interdisciplinary research. In addition to classical game representations, some of the alternative representations also encode time related aspects.
## General and applied uses.
As a method of applied mathematics, game theory has been used to study a wide variety of human and animal behaviors. It was initially developed in economics to understand a large collection of economic behaviors, including behaviors of firms, markets, and consumers. The first use of game-theoretic analysis was by Antoine Augustin Cournot in 1838 with his solution of the Cournot duopoly. The use of game theory in the social sciences has expanded, and game theory has been applied to political, sociological, and psychological behaviors as well. 
Although pre-twentieth-century naturalists such as Charles Darwin made game-theoretic kinds of statements, the use of game-theoretic analysis in biology began with Ronald Fisher's studies of animal behavior during the 1930s. This work predates the name "game theory", but it shares many important features with this field. The developments in economics were later applied to biology largely by John Maynard Smith in his 1982 book "Evolution and the Theory of Games".
In addition to being used to describe, predict, and explain behavior, game theory has also been used to develop theories of ethical or normative behavior and to prescribe such behavior. In economics and philosophy, scholars have applied game theory to help in the understanding of good or proper behavior. Game-theoretic arguments of this type can be found as far back as Plato. An alternative version of game theory, called chemical game theory, represents the player's choices as metaphorical chemical reactant molecules called "knowlecules".  Chemical game theory then calculates the outcomes as equilibrium solutions to a system of chemical reactions.
### Description and modeling.
The primary use of game theory is to describe and model how human populations behave. Some scholars believe that by finding the equilibria of games they can predict how actual human populations will behave when confronted with situations analogous to the game being studied. This particular view of game theory has been criticized. It is argued that the assumptions made by game theorists are often violated when applied to real-world situations. Game theorists usually assume players act rationally, but in practice, human behavior often deviates from this model. Game theorists respond by comparing their assumptions to those used in physics. Thus while their assumptions do not always hold, they can treat game theory as a reasonable scientific ideal akin to the models used by physicists. However, empirical work has shown that in some classic games, such as the centipede game, guess 2/3 of the average game, and the dictator game, people regularly do not play Nash equilibria. There is an ongoing debate regarding the importance of these experiments and whether the analysis of the experiments fully captures all aspects of the relevant situation.
Some game theorists, following the work of John Maynard Smith and George R. Price, have turned to evolutionary game theory in order to resolve these issues. These models presume either no rationality or bounded rationality on the part of players. Despite the name, evolutionary game theory does not necessarily presume natural selection in the biological sense. Evolutionary game theory includes both biological as well as cultural evolution and also models of individual learning (for example, fictitious play dynamics).
### Prescriptive or normative analysis.
Some scholars see game theory not as a predictive tool for the behavior of human beings, but as a suggestion for how people ought to behave. Since a strategy, corresponding to a Nash equilibrium of a game constitutes one's best response to the actions of the other players – provided they are in (the same) Nash equilibrium – playing a strategy that is part of a Nash equilibrium seems appropriate. This normative use of game theory has also come under criticism.
### Economics and business.
Game theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents. Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers and acquisitions pricing, fair division, duopolies, oligopolies, social network formation, agent-based computational economics, general equilibrium, mechanism design, and voting systems; and across such broad areas as experimental economics, behavioral economics, information economics, industrial organization, and political economy.
This research usually focuses on particular sets of strategies known as "solution concepts" or "equilibria". A common assumption is that players act rationally. In non-cooperative games, the most famous of these is the Nash equilibrium. A set of strategies is a Nash equilibrium if each represents a best response to the other strategies. If all the players are playing the strategies in a Nash equilibrium, they have no unilateral incentive to deviate, since their strategy is the best they can do given what others are doing.
The payoffs of the game are generally taken to represent the utility of individual players.
A prototypical paper on game theory in economics begins by presenting a game that is an abstraction of a particular economic situation. One or more solution concepts are chosen, and the author demonstrates which strategy sets in the presented game are equilibria of the appropriate type. Economists and business professors suggest two primary uses (noted above): "descriptive" and "prescriptive".
The Chartered Institute of Procurement &amp; Supply (CIPS) promotes knowledge and use of game theory within the context of business procurement. CIPS and TWS Partners have conducted a series of surveys designed to explore the understanding, awareness and application of game theory among procurement professionals. Some of the main findings in their third annual survey (2019) include:
### Project management.
Sensible decision-making is critical for the success of projects. In project management, game theory is used to model the decision-making process of players, such as investors, project managers, contractors, sub-contractors, governments and customers. Quite often, these players have competing interests, and sometimes their interests are directly detrimental to other players, making project management scenarios well-suited to be modeled by game theory.
Piraveenan (2019) in his review provides several examples where game theory is used to model project management scenarios. For instance, an investor typically has several investment options, and each option will likely result in a different project, and thus one of the investment options has to be chosen before the project charter can be produced. Similarly, any large project involving subcontractors, for instance, a construction project, has a complex interplay between the main contractor (the project manager) and subcontractors, or among the subcontractors themselves, which typically has several decision points. For example, if there is an ambiguity in the contract between the contractor and subcontractor, each must decide how hard to push their case without jeopardizing the whole project, and thus their own stake in it. Similarly, when projects from competing organizations are launched, the marketing personnel have to decide what is the best timing and strategy to market the project, or its resultant product or service, so that it can gain maximum traction in the face of competition. In each of these scenarios, the required decisions depend on the decisions of other players who, in some way, have competing interests to the interests of the decision-maker, and thus can ideally be modeled using game theory.
Piraveenan summarises that two-player games are predominantly used to model project management scenarios, and based on the identity of these players, five distinct types of games are used in project management.
In terms of types of games, both cooperative as well as non-cooperative, normal-form as well as extensive-form, and zero-sum as well as non-zero-sum are used to model various project management scenarios.
### Political science.
The application of game theory to political science is focused in the overlapping areas of fair division, political economy, public choice, war bargaining, positive political theory, and social choice theory. In each of these areas, researchers have developed game-theoretic models in which the players are often voters, states, special interest groups, and politicians.
Early examples of game theory applied to political science are provided by Anthony Downs. In his 1957 book "An Economic Theory of Democracy", he applies the Hotelling firm location model to the political process. In the Downsian model, political candidates commit to ideologies on a one-dimensional policy space. Downs first shows how the political candidates will converge to the ideology preferred by the median voter if voters are fully informed, but then argues that voters choose to remain rationally ignorant which allows for candidate divergence. Game theory was applied in 1962 to the Cuban Missile Crisis during the presidency of John F. Kennedy.
It has also been proposed that game theory explains the stability of any form of political government. Taking the simplest case of a monarchy, for example, the king, being only one person, does not and cannot maintain his authority by personally exercising physical control over all or even any significant number of his subjects. Sovereign control is instead explained by the recognition by each citizen that all other citizens expect each other to view the king (or other established government) as the person whose orders will be followed. Coordinating communication among citizens to replace the sovereign is effectively barred, since conspiracy to replace the sovereign is generally punishable as a crime. Thus, in a process that can be modeled by variants of the prisoner's dilemma, during periods of stability no citizen will find it rational to move to replace the sovereign, even if all the citizens know they would be better off if they were all to act collectively.
A game-theoretic explanation for democratic peace is that public and open debate in democracies sends clear and reliable information regarding their intentions to other states. In contrast, it is difficult to know the intentions of nondemocratic leaders, what effect concessions will have, and if promises will be kept. Thus there will be mistrust and unwillingness to make concessions if at least one of the parties in a dispute is a non-democracy.
However, game theory predicts that two countries may still go to war even if their leaders are cognizant of the costs of fighting. War may result from asymmetric information; two countries may have incentives to mis-represent the amount of military resources they have on hand, rendering them unable to settle disputes agreeably without resorting to fighting. Moreover, war may arise because of commitment problems: if two countries wish to settle a dispute via peaceful means, but each wishes to go back on the terms of that settlement, they may have no choice but to resort to warfare. Finally, war may result from issue indivisibilities.
Game theory could also help predict a nation's responses when there is a new rule or law to be applied to that nation. One example is Peter John Wood's (2013) research looking into what nations could do to help reduce climate change. Wood thought this could be accomplished by making treaties with other nations to reduce greenhouse gas emissions. However, he concluded that this idea could not work because it would create a prisoner's dilemma for the nations.
### Biology.
Unlike those in economics, the payoffs for games in biology are often interpreted as corresponding to fitness. In addition, the focus has been less on equilibria that correspond to a notion of rationality and more on ones that would be maintained by evolutionary forces. The best-known equilibrium in biology is known as the "evolutionarily stable strategy" (ESS), first introduced in . Although its initial motivation did not involve any of the mental requirements of the Nash equilibrium, every ESS is a Nash equilibrium.
In biology, game theory has been used as a model to understand many different phenomena. It was first used to explain the evolution (and stability) of the approximate 1:1 sex ratios. suggested that the 1:1 sex ratios are a result of evolutionary forces acting on individuals who could be seen as trying to maximize their number of grandchildren.
Additionally, biologists have used evolutionary game theory and the ESS to explain the emergence of animal communication. The analysis of signaling games and other communication games has provided insight into the evolution of communication among animals. For example, the mobbing behavior of many species, in which a large number of prey animals attack a larger predator, seems to be an example of spontaneous emergent organization. Ants have also been shown to exhibit feed-forward behavior akin to fashion (see Paul Ormerod's "Butterfly Economics").
Biologists have used the game of chicken to analyze fighting behavior and territoriality.
According to Maynard Smith, in the preface to "Evolution and the Theory of Games", "paradoxically, it has turned out that game theory is more readily applied to biology than to the field of economic behaviour for which it was originally designed". Evolutionary game theory has been used to explain many seemingly incongruous phenomena in nature.
One such phenomenon is known as biological altruism. This is a situation in which an organism appears to act in a way that benefits other organisms and is detrimental to itself. This is distinct from traditional notions of altruism because such actions are not conscious, but appear to be evolutionary adaptations to increase overall fitness. Examples can be found in species ranging from vampire bats that regurgitate blood they have obtained from a night's hunting and give it to group members who have failed to feed, to worker bees that care for the queen bee for their entire lives and never mate, to vervet monkeys that warn group members of a predator's approach, even when it endangers that individual's chance of survival. All of these actions increase the overall fitness of a group, but occur at a cost to the individual.
Evolutionary game theory explains this altruism with the idea of kin selection. Altruists discriminate between the individuals they help and favor relatives. Hamilton's rule explains the evolutionary rationale behind this selection with the equation , where the cost to the altruist must be less than the benefit to the recipient multiplied by the coefficient of relatedness . The more closely related two organisms are causes the incidences of altruism to increase because they share many of the same alleles. This means that the altruistic individual, by ensuring that the alleles of its close relative are passed on through survival of its offspring, can forgo the option of having offspring itself because the same number of alleles are passed on. For example, helping a sibling (in diploid animals) has a coefficient of , because (on average) an individual shares half of the alleles in its sibling's offspring. Ensuring that enough of a sibling's offspring survive to adulthood precludes the necessity of the altruistic individual producing offspring. The coefficient values depend heavily on the scope of the playing field; for example if the choice of whom to favor includes all genetic living things, not just all relatives, we assume the discrepancy between all humans only accounts for approximately 1% of the diversity in the playing field, a coefficient that was in the smaller field becomes 0.995. Similarly if it is considered that information other than that of a genetic nature (e.g. epigenetics, religion, science, etc.) persisted through time the playing field becomes larger still, and the discrepancies smaller.
### Computer science and logic.
Game theory has come to play an increasingly important role in logic and in computer science. Several logical theories have a basis in game semantics. In addition, computer scientists have used games to model interactive computations. Also, game theory provides a theoretical basis to the field of multi-agent systems.
Separately, game theory has played a role in online algorithms; in particular, the -server problem, which has in the past been referred to as "games with moving costs" and "request-answer games". Yao's principle is a game-theoretic technique for proving lower bounds on the computational complexity of randomized algorithms, especially online algorithms.
The emergence of the Internet has motivated the development of algorithms for finding equilibria in games, markets, computational auctions, peer-to-peer systems, and security and information markets. Algorithmic game theory and within it algorithmic mechanism design combine computational algorithm design and analysis of complex systems with economic theory.
### Philosophy.
Game theory has been put to several uses in philosophy. Responding to two papers by , used game theory to develop a philosophical account of convention. In so doing, he provided the first analysis of common knowledge and employed it in analyzing play in coordination games. In addition, he first suggested that one can understand meaning in terms of signaling games. This later suggestion has been pursued by several philosophers since Lewis. Following game-theoretic account of conventions, Edna Ullmann-Margalit (1977) and Bicchieri (2006) have developed theories of social norms that define them as Nash equilibria that result from transforming a mixed-motive game into a coordination game.
Game theory has also challenged philosophers to think in terms of interactive epistemology: what it means for a collective to have common beliefs or knowledge, and what are the consequences of this knowledge for the social outcomes resulting from the interactions of agents. Philosophers who have worked in this area include Bicchieri (1989, 1993), Skyrms (1990), and Stalnaker (1999).
In ethics, some (most notably David Gauthier, Gregory Kavka, and Jean Hampton) authors have attempted to pursue Thomas Hobbes' project of deriving morality from self-interest. Since games like the prisoner's dilemma present an apparent conflict between morality and self-interest, explaining why cooperation is required by self-interest is an important component of this project. This general strategy is a component of the general social contract view in political philosophy (for examples, see and ).
Other authors have attempted to use evolutionary game theory in order to explain the emergence of human attitudes about morality and corresponding animal behaviors. These authors look at several games including the prisoner's dilemma, stag hunt, and the Nash bargaining game as providing an explanation for the emergence of attitudes about morality (see, e.g., and ).
### Retail and consumer product pricing.
Game theory applications are used heavily in the pricing strategies of retail and consumer markets, particularly for the sale of inelastic goods. With retailers constantly competing against one another for consumer market share, it has become a fairly common practice for retailers to discount certain goods, intermittently, in the hopes of increasing foot-traffic in brick and mortar locations (websites visits for e-commerce retailers) or increasing sales of ancillary or complimentary products.
Black Friday, a popular shopping holiday in the US, is when many retailers focus on optimal pricing strategies to capture the holiday shopping market. In the Black Friday scenario, retailers using game theory applications typically ask "what is the dominant competitor's reaction to me?" In such a scenario, the game has two players: the retailer, and the consumer. The retailer is focused on an optimal pricing strategy, while the consumer is focused on the best deal. In this closed system, there often is no dominant strategy as both players have alternative options. That is, retailers can find a different customer, and consumers can shop at a different retailer. Given the market competition that day, however, the dominant strategy for retailers lies in outperforming competitors. The open system assumes multiple retailers selling similar goods, and a finite number of consumers demanding the goods at an optimal price. A blog by a Cornell University professor provided an example of such a strategy, when Amazon priced a Samsung TV $100 below retail value, effectively undercutting competitors. Amazon made up part of the difference by increasing the price of HDMI cables, as it has been found that consumers are less price discriminatory when it comes to the sale of secondary items.
Retail markets continue to evolve strategies and applications of game theory when it comes to pricing consumer goods. The key insights found between simulations in a controlled environment and real-world retail experiences show that the applications of such strategies are more complex, as each retailer has to find an optimal balance between pricing, supplier relations, brand image, and the potential to cannibalize the sale of more profitable items.
### Epidemiology.
Since the decision to take a vaccine for a particular disease is often made by individuals, who may consider a range of factors and parameters in making this decision (such as the incidence and prevalence of the disease, perceived and real risks associated with contracting the disease, mortality rate, perceived and real risks associated with vaccination, and financial cost of vaccination), game theory has been used to model and predict vaccination uptake in a society.
## See also.
Lists

</doc>
<doc id="11927" url="https://en.wikipedia.org/wiki?curid=11927" title="Germany/politics">
Germany/politics



</doc>
<doc id="11929" url="https://en.wikipedia.org/wiki?curid=11929" title="Demographics of Germany">
Demographics of Germany

The demography of Germany is monitored by the "Statistisches Bundesamt" (Federal Statistical Office of Germany). According to the most recent data, Germany's population is 83,129,285 (30 June 2021), making it the second-most populous country in Europe after Russia, and the nineteenth-most populous country in the world. The total fertility rate was rated at 1.53 in 2020, which is far below the replacement rate of 2.1. For a long time Germany had one of the world's lowest fertility rates of around 1.3 to 1.4 however there has been a small increase in recent years. Due to the low birth rate there have been more death than births in Germany in every year since 1972, which means 2020 was the 49th consecutive year the German population would have decreased without immigration. It is the only country in the world to have such a long-term natural population decline. The decline has been somewhat mitigated by immigration: in 2019 the number of people with a foreign background was 26%. Under this category there are counted foreigners, naturalized citizens, ethnic German repatriates from east Europe and their children. Until the early 20th century Germany was also a large emigrant nation with 5 million people emigrating to the US alone from Germany in the Kaiserreich boundaries in the 19th century and more than two million in the 20th century plus additional emigrants to Latin America, Canada and eastern Europe. However after World War II immigration began to outweigh emigration, as around 14 million ethnic Germans were expelled from the former eastern Provinces of the Reich and other areas in eastern Europe of whom around 12 million made their way to present day Germany and several hundred thousand to Austria and other countries while several hundred died. Some additional 4.5 million ethnic Germans from eastern Europe repatriated after 1950, especially around the end of the Eastern Bloc and mostly from the former Soviet Union, Poland and Romania.
Large scale immigration to the BRD began during the time of the Wirtschaftswunder from the 1950s to early 1970s when Germany had a shortage of workers and let in Southern Europeans from countries like Turkey, Italy and Spain on a temporary basis as guest workers. The liberalisation of guest worker legislation allowed many to stay and build a life in the BRD. Another large wave of immigration happened around reunification when a large group of German repatriates but also many refugees arrived mostly from former Yugoslavia due to the Yugoslav War and Bosnian War and from Turkey seeking asylum in Germany. The next large immigration wave began after eastern Expansion of the European Union in 2011 as Eastern Europeans were now allowed to live and work in Germany without a visa. In 2015 Germany took in what was, in EU terms, a relatively large number of refugees fleeing the Syrian civil war but also other conflicts in Iraq and Afghanistan: 476,649 asylum seekers in 2015, 745,545 in 2016 and declining numbers after that.
Germany has one of the world's highest levels of education, technological development, and economic productivity. Since the end of World War II, the number of students entering university has more than tripled, and the trade and technical schools are among the world's best. With a per capita income of about €40,883 in 2018, Germany is a broadly middle-class society. However, there has been a strong increase in the number of children living in poverty. In 1965, one in 75 children was on the welfare rolls; but by 2007 this had increased to one child in six. These children live in relative poverty, but not necessarily in absolute poverty. Germans are typically well-travelled, with millions travelling overseas each year. The social welfare system provides for universal health care, unemployment compensation, child benefits and other social programmes. Germany's ageing population and struggling economy strained the welfare system in the 1990s, so the government adopted a wide-ranging programme of - still controversial - belt-tightening reforms, Agenda 2010, including the labour-market reforms known as Hartz concept.
## History.
The contemporary demographics of Germany are also measured by a series of full censuses, with the most recent held in 1987. Since reunification, German authorities rely on a "micro census".
### Total Fertility Rate from 1800 to 1899.
The total fertility rate is the number of children born per woman. It is based on fairly good data for the entire period. Sources: Our World In Data and Gapminder Foundation.
### Life expectancy from 1875 to 2015.
Sources: Our World In Data and the United Nations.
1875-1950
1950-2015
Source: "UN World Population Prospects"
### Statistics since 1817.
Population statistics since 1817.Territorial changes of Germany occurred in 1866 (establishment of North German Confederation, 1871 (German unification and annexation of Alsace-Lorraine), 1918/1919, 1921/1922, 1945/1946 and in 1990.
In 2020, 586,421 (75.8%) children were born to mothers with German citizenship, while 186,723 (24.2%) children were born to mothers with foreign citizenship.
### 1945–1990.
After the World War II border shifts and expulsions, the Germans from Central and Eastern Europe and the former eastern territories moved westward to post-war Germany. During the partition of Germany, many Germans from East Germany fled to West Germany for political and economic reasons. Since Germany's reunification, there are ongoing migrations from the eastern "New Länder" to the western "Old Länder" for economic reasons.
The Federal Republic of Germany and the German Democratic Republic followed different paths when it came to demographics. The politics of the German Democratic Republic was pronatalistic while that of the Federal Republic was compensatory.
Fertility in the GDR was higher than that in the FRG. Demographic politics was only one of the reasons. Women in the GDR had fewer "biographic options", young motherhood was expected of them. State funded costfree childcare was available to all mothers.
Note: Berlin is included into East Germany for the year 2002 and 2008. Source: Kreyenfeld (2002); Kreyenfeld et al. (2010); HFD Germany (2010)
### 1990–today.
About 1.7 million people have left the new federal states (the East) since the fall of the Berlin Wall, or 12% of the population; a disproportionately high number of them were women under 35.
After 1990, the total fertility rate (TFR) in the East dropped to 0.772 in 1994. This has been attributed to a "demographic shock": people not only had fewer children, they were also less likely to marry or divorce after the end of the GDR; the biographic options of the citizens of the former GDR had increased. Young motherhood seemed to be less attractive and the age of the first birth rose sharply.
In the following years, the TFR in the East started to rise again, surpassing 1.0 in 1997 and 1.3 in 2004, and reaching the West's TFR (1.37) in 2007. In 2010, the East's fertility rate (1.459) clearly exceeded that of the West (1.385), while Germany's overall TFR had risen to 1.393, the highest value since 1990, which was still far below the natural replacement rate of 2.1 and the birth rates seen under communism. In 2016, the TFR was 1.64 in the East and 1.60 in the West.
Between 1989 and 2009, about 2,000 schools closed because there were fewer children.
In some regions the number of women between the ages of 20 and 30 has dropped by more than 30%. In 2004, in the age group 18-29 (statistically important for starting families) there were only 90 women for every 100 men in the new federal states (the East, including Berlin).
Until 2007 family politics in the federal republic was compensatory, which means that poor families received more family benefits (such as the "Erziehungsgeld") than rich ones. In 2007 the so-called "Elterngeld" was introduced. According to Christoph Butterwegge the Elterngeld was meant to "motivate highly educated women to have more children"; the poor on the other hand were disadvantaged by the "Elterngeld", and now received lower child benefits than the middle classes. The very well-off (who earn more than 250.000 Euro per annum) and those on welfare receive no Elterngeld payments.
In 2013 the following most recent developments were noticed:
In the new federal states the fertility rate of college-educated women is now higher than that of those without college degrees. Differences in value priorities and the better availability of childcare in the eastern states are discussed as possible reasons.
In 2019, the non-profit Austrian Institute of Economic Research and the Bertelsmann Stiftung published a study about the economic impact of demographics. The researchers assume a reduction in the per capita income of €3,700 until 2040.
## Demographic statistics.
Demographic statistics according to the World Population Review.
Demographic statistics according to the CIA World Factbook, unless otherwise indicated.
Most childbirths in Germany happen within marriage. Out of 778,080 births in 2019 258,835 were to unmarried parents, which means that around 33% or one third of the children are born out of wedlock, while two thirds are within. This percentage of unmarried birth has long been growing and reached 33% in 2010, more than twice of what it was in 1990. However in recent years it has started to stagnate or even decrease.
The Mikrozensus done in 2008 revealed that the number of children a German woman aged 40 to 75 had, was closely linked to her educational achievement.
In Western Germany the most educated women were the most likely to be childless. 26% of those groups stated they were childless, while 16% of those having an intermediate education, and 11% of those having compulsory education, stated the same.
In Eastern Germany however, 9% of the most educated women of that age group and 7% of those who had an intermediary education were childless, while 12% of those having only compulsory education were childless.
The reason for that east-western difference is that the GDR had an "educated mother scheme" and actively tried to encourage first births among the more educated. It did so by propagandizing the opinion that every educated woman should "present at least one child to socialism" and also by financially rewarding its more educated citizen to become parents. The government especially tried to persuade students to become parents while still in college and it was quite successful in doing so. In 1986 38% of all women, who were about to graduate from college, were mothers of at least one child and additional 14% were pregnant and 43% of all men, who were about to graduate from college, were fathers of at least one child. There was a sharp decline in the birth rate and especially in the birth rate of the educated after the fall of the Berlin wall. Nowadays, 5% of those about to graduate from college are parents.
The more educated a Western German mother aged 40 to 75 was in 2008, the less likely she was to have a big family.
The same was true for a mother living in Eastern Germany in 2008.
In 2011, this trend was reversed in Eastern Germany, where more highly educated women now had a somewhat higher fertility rate than the rest of the population. 
Persons who said they had no religion tend to have fewer children than those who identify as Christians, and studies also found that conservative-leaning Christians had more children compared to liberal-leaning Christians. 
A study done in 2005 in the western German state of Nordrhein-Westfalen by the HDZ revealed that childlessness was especially widespread among scientists. It showed that 78% of the women scientists and 71% of the male scientists working in that state were childless.
## Ethnic minorities and migrant background ("Migrationshintergrund").
The Federal Statistical Office defines persons with a migrant background as all persons who migrated to the present area of the Federal Republic of Germany after 1949, plus all foreign nationals born in Germany and all persons born in Germany as German nationals with at least one parent who migrated to Germany or was born in Germany as a foreign national. The figures presented here are based on this definition only.
In 2010, 2.3 million families with children under 18 years were living in Germany, in which at least one parent had foreign roots. They represented 29% of the total of 8.1 million families with minor children. Compared with 2005 – the year when the microcensus started to collect detailed information on the population with a migrant background – the proportion of migrant families has risen by 2 percentage points. In 2019, 40% children under 5 years old had migrant background.
Most of the families with a migrant background live in the western part of Germany. In 2010, the proportion of migrant families in all families was 32% in the former territory of the Federal Republic. This figure was more than double that in the new Länder (incl. Berlin) where it stood at 15%.Eastern Germany has a much lower proportion of immigrants than the West, as the GDR did not let in that many guest workers and Eastern Germany's is not doing as good as West Germany's and had a higher percentage of jobless persons until recently. However in recent years the number of people with an immigrant background in East Germany has been growing as refugees (as well as German Repatriates) are distributed with the Königssteiner Schlüssel, so every German state has to take the same number of them compared to its population and economy. In 2019 19.036 million people or 89,6% of people with an immigrant background live in Western Germany (excluding Berlin), being 28,7% of its population, while 1.016 million people with immigrant background 4,8% live in Eastern States, being 8,2% of population, and 1.194 million people with an immigrant background 5,6% live in Berlin, being 33,1% of its population.
In 2019, 26% of Germans of any age group (up from 18,4% in 2008) and 39% of German children (up from 30% in 2008) had at least one parent born abroad. Average age for Germans with at least one parent born abroad was 35.6 years (up from 33.8 years in 2008), while that for Germans, who had two parents born in Germany was 47.3 years (up from 44.6 in 2008).
The largest groups of people with an immigrant background in Germany are people from Turkey, Poland and Russia.
, the population by background was as follows:
Four other sizable groups of people are referred to as "national minorities" ("nationale Minderheiten") because they have lived in their respective regions for centuries: Danes, Frisians, Roma and Sinti, and Sorbs. There is a Danish minority (about 50,000, according to government sources) in the northernmost state of Schleswig-Holstein. Eastern and Northern Frisians live at Schleswig-Holstein's western coast, and in the north-western part of Lower Saxony. They are part of a wider community (Frisia) stretching from Germany to the northern Netherlands. The Sorbs, a Slavic people with about 60,000 members (according to government sources), are in the Lusatia region of Saxony and Brandenburg. They are the last remnants of the Slavs that lived in central and eastern Germany since the 7th century to have kept their traditions and not been completely integrated into the wider German nation.
Until World War II the Poles were recognized as one of the national minorities. In 1924 the Union of Poles in Germany had initiated cooperation between all national minorities in Germany under the umbrella organization Association of National Minorities in Germany. Some of the union members wanted the Polish communities in easternmost Germany (now Poland) to join the newly established Polish nation after World War I. Even before the German invasion of Poland, leading anti-Nazi members of the Polish minority were deported to concentration camps; some were executed at the Piaśnica murder site. Minority rights for Poles in Germany were revoked by Hermann Göring's World War II decree of 27 February 1940, and their property was confiscated.
After the war ended, the German government did not re-implement national minority rights for ethnic Poles. The reason for this is that the areas of Germany which formerly had a native Polish minority were annexed to Poland and the Soviet Union, while almost all of the native German populations (formerly the ethnic majority) in these areas subsequently fled or were expelled by force. With the mixed German-Polish territories now lost, the German government subsequently regarded ethnic Poles residing in what remained of Germany as immigrants, just like any other ethnic population with a recent history of arrival. In contrast, Germans living in Poland are recognized as national minority and have granted seats in Polish Parliament. It must be said, however, that an overwhelming number of Germans in Poland have centuries-old historical ties to the lands they now inhabit, whether from living in territory that once belonged to the German state, or from centuries-old communities. In contrast, most Poles in present-day Germany are recent immigrants, though there are some communities which have been present since the 19th and perhaps even the 18th centuries. Despite protests by some in the older Polish-German communities, and despite Germany being now a signatory to the Framework Convention for the Protection of National Minorities, Germany has so far refused to re-implement minority rights for ethnic Poles, based on the fact that almost all areas of historically mixed German-Polish heritage (where the minority rights formerly existed) are no longer part of Germany and because the vast majority of ethnic Poles now residing in Germany are recent immigrants.
Roma people have been in Germany since the Middle Ages. They were persecuted by the Nazis, and thousands of Roma living in Germany were killed by the Nazi regime. Nowadays, they are spread all over Germany, mostly living in major cities. It is difficult to estimate their exact number, as the German government counts them as "persons without migrant background" in their statistics. There are also many assimilated Sinti and Roma. A vague figure given by the German Department of the Interior is about 70,000. In contrast to the old-established Roma population, the majority of them do not have German citizenship, they are classified as immigrants or refugees.
After World War II, 14 million ethnic Germans were expelled from the eastern territories of Germany and homelands outside the former German Empire. The accommodation and integration of these "Heimatvertriebene" in the remaining part of Germany, in which many cities and millions of apartments had been destroyed, was a major effort in the post-war occupation zones and later states of Germany.
Since the 1960s, ethnic Germans from the People's Republic of Poland and Soviet Union (especially from Kazakhstan, Russia, and Ukraine), have come to Germany. During the time of Perestroika, and after the dissolution of the Soviet Union, the number of immigrants increased heavily. Some of these immigrants are of mixed ancestry. During the 10-year period between 1987 and 2001, a total of 1,981,732 ethnic Germans from the FSU immigrated to Germany, along with more than a million of their non-German relatives. After 1997, however ethnic Slavs or those belonging to Slavic-Germanic mixed origins outnumbered these with only Germanic descent amongst the immigrants. The total number of people currently living in Germany having FSU connection is around 4 to 4.5 million (Including Germans, Slavs, Jews and those of mixed origins), out of that more than 50% is of German descent.
Germany now has Europe's third-largest Jewish population. In 2004, twice as many Jews from former Soviet republics settled in Germany as in Israel, bringing the total inflow to more than 100,000 since 1991. Jews have a voice in German public life through the Central Council of Jews in Germany (Zentralrat der Juden in Deutschland). Some Jews from the former Soviet Union are of mixed heritage.
In 2019 there were also a growing number of at least 529,000 black Afro-Germans defined as people with an African migrant background. Out of them more than 400 thousand have a citizenship of a Subsahara-African country, with others being German citizens. Most of them live in Berlin and Hamburg. Numerous persons from northern African Tunisia and Morocco live in Germany. While they are considered members of a minority group, for the most part, they do not considers themselves "Afro-Germans," nor are most of them perceived as such by the German people. However, Germany does not keep any statistics regarding ethnicity or race. Hence, the exact number of Germans of African descent is unknown.
Germany's biggest East Asian minorities are the Chinese people in Germany, numbering 189,000
and Vietnamese people in Germany, numbering 188,000,many of whom living in Berlin and eastern Germany.
Also there are about 35,000 Japanese citizens residing in Germany. There are also groups of South Asian and Southeast Asian immigrants. Around 163,000 Indians and 124,000 Pakistanis live in Germany. Additionally some 30,000 Filipino citizens and more than 20,000 Indonesian citizens reside in Germany.
Numerous descendants of the so-called "Gastarbeiter" live in Germany. The "Gastarbeiter" mostly came from Turkey, Italy, Greece, Spain, Morocco, Portugal, the forme Yugoslavia, Tunisia and Chile.
Also included were Vietnam, Mongolia, North Korea, Angola, Mozambique and Cuba when the former East Germany existed until reunification in 1990. The (socialist) German Democratic Republic (East Germany) however had their guest-workers stay in single-sex dormitories. Female guest workers had to sign contracts saying that they were not allowed to fall pregnant during their stay. If they fell pregnant nevertheless they faced forced abortion or deportation. This is one of the reasons why the vast majority of ethnic minorities today lives in western Germany and also one of the reasons why minorities such as the Vietnamese have the most unusual population pyramid, with nearly all second-generation Vietnamese Germans born after 1989.
There is strong discrimination against Asian Germans in Germany. In a survey conducted by the Free University of Berlin between October and November 2020, 49% of Asian Germans said they had been discriminated against. In terms of discrimination, 62% were subjected to verbal insults, 11% were subjected to physical attacks such as being pushed, spit on, or sprayed with disinfectant. And 27% were rejected from medical clinics. The biggest problem is that Germans are insensitive to their own sense of discrimination, and most Germans are not aware that discrimination against Asians is taking place in Germany.
## Foreign nationals in Germany.
, the most common groups of resident foreign nationals in Germany were as follows:
This list does not include non-ethnic Germans with German nationality and foreign nationals without resident status.
## Genetics of the German native people.
The most common Y chromosome haplogroups among German males are Haplogroup R1b, followed by Haplogroup I1, and Haplogroup R1a.
## Geography.
With an estimated 83.2 million inhabitants in December 2020,Germany is the second-most populous country in Europe after Russia, and ranks as the 19th largest country in the world in terms of population. Its population density stands at 233 inhabitants per square kilometer.
### States.
Germany comprises sixteen states that are collectively referred to as "Länder". Due to differences in size and population the subdivision of these states varies, especially between city-states ("Stadtstaaten") and states with larger territories ("Flächenländer"). For regional administrative purposes four states, namely Baden-Württemberg, Bavaria, Hesse and North Rhine-Westphalia, consist of a total of 19 Government Districts ("Regierungsbezirke"). As of 2019 Germany is divided into 400 districts ("Kreise") on municipal level, these consist of 294 rural districts and 106 urban districts.
### Metropolitan regions.
Germany officially has eleven metropolitan regions. In 2005, Germany had 82 cities with more than 100,000 inhabitants.
## Immigration.
The United Nations Population Fund lists Germany as host to the third-highest number of international migrants worldwide, behind the United States and Saudi Arabia. The largest ethnic group of non-German origin are the Turkish. Since the 1960s, West and later reunified Germany has attracted immigrants primarily from Southern and Eastern Europe as well as Turkey, many of whom (or their children) have acquired German citizenship over time. While most of these immigrants initially arrived as guest workers, changes to guest worker legislation allowed many to stay and to build lives in Germany.
Germany had signed special visa agreements with several countries in times of severe labour shortages or when particular skills were deficient within the country. During the 1960s and 1970s, agreements were signed with the governments of Turkey, Yugoslavia, Italy and Spain to help Germany overcome its severe labour shortage.
As of 2012, after Germany fully legalized visa-free immigrants from the eastern states of the EU, the largest sources of net immigration to Germany were other European countries, most importantly Poland, Romania, Bulgaria, Hungary, Italy, Spain, and Greece; notably, in the case of Turkey, German Turks moving to Turkey slightly outnumbered new immigrants in 2012, however, in recent years there are more Turkish immigrants in Germany than emigrants again, including illegal Turkish migrants.
In 2015, there was a large increase in asylum applications, mainly due to the violent conflicts in Syria, Iraq and Afghanistan: 476,649 asylum applications were counted that year..This number went up to even 745,545 in 2016 and began to decline after it.
## Education.
Responsibility for educational oversight in Germany lies primarily with the individual federated states. Since the 1960s, a reform movement has attempted to unify secondary education into a "Gesamtschule" (comprehensive school); several West German states later simplified their school systems to two or three tiers. A system of apprenticeship called "Duale Ausbildung" ("dual education") allows pupils in vocational training to learn in a company as well as in a state-run vocational school.
Optional kindergarten education is provided for all children between three and six years old, after which school attendance is compulsory for at least nine years, depending on the state. Primary education usually lasts for four years and public schools are not stratified at this stage. In contrast, secondary education includes three traditional types of schools focused on different levels of academic ability: the "Gymnasium" enrols the most academically promising children and prepares students for university studies; the "Realschule" for intermediate students lasts six years; the "Hauptschule" prepares pupils for vocational education.
In addition Germany has a comprehensive school known as the "Gesamtschule". While some German schools such as the Gymnasium and the Realschule have rather strict entrance requirements, the Gesamtschule does not have such requirements. They offer college preparatory classes for the students who are doing well, general education classes for average students, and remedial courses for those who aren't doing that well. In most cases students attending a Gesamtschule may graduate with the Hauptschulabschluss, the Realschulabschluss or the Abitur depending on how well they did in school.
The percentage of students attending a Gesamtschule varies by Bundesland. In 2007 the State of Brandenburg more than 50% of all students attended a Gesamtschule, while in the State of Bavaria less than 1% did.
The general entrance requirement for university is Abitur, a qualification normally based on continuous assessment during the last few years at school and final examinations; however there are a number of exceptions, and precise requirements vary, depending on the state, the university and the subject. Germany's universities are recognised internationally; in the Academic Ranking of World Universities (ARWU) for 2008, six of the top 100 universities in the world are in Germany, and 18 of the top 200. Nearly all German universities are public institutions, tuition fees in the range of €500 were introduced in some states after 2006, but quickly abolished again until 2014.
"Percentage of jobholders holding Hauptschulabschluss, Realschulabschluss or Abitur in Germany"
### Literacy.
Over 99% of those of age 15 and above are estimated to be able to read and write. However, a growing number of inhabitants are functionally illiterate. The young are much more likely to be functionally illiterate than the old. According to a study done by the University of Bremen in cooperation with the "Bundesverband Alphabetisierung e.V.", 10% of youngsters living in Germany are functionally illiterate and one quarter are able to understand only basic level texts. Illiteracy rates of youngsters vary by ethnic group and parents' socioeconomic class.
## Health.
The life expectancy in Germany is 81.1 years (78.7 years males, 83.6 years females, 2020 est.). 
, the principal cause of death was cardiovascular disease, at 42%, followed by malignant tumours, at 25%.
, about 82,000 Germans had been infected with HIV/AIDS and 26,000 had died from the disease (cumulatively, since 1982).
According to a 2005 survey, 27% of German adults are smokers.
A 2009 study shows Germany is near the median in terms of overweight and obese people in Europe.
## Religion.
The national constitutions of 1919 and 1949 guarantee freedom of faith and religion; earlier, these freedoms were mentioned only in state constitutions. The modern constitution of 1949 also states that no one may be discriminated against due to their faith or religious opinions. A state church does not exist in Germany (see Freedom of religion in Germany).
According to a 1990s poll by "Der Spiegel", 45% of Germans believe in God, and a quarter in Jesus Christ. According to the Eurobarometer Poll 2010, 44% of German citizens responded that "they believe there is a God", 25% responded that "they believe there is some sort of spirit or life force" and 27% responded that "they don't believe there is any sort of spirit, God or life force". 4% gave no response.
Christianity is the largest religion in Germany, comprising an estimated 55.1% of the country's population.
Smaller religious groups (less than 1%) include Judaism, Buddhism and Hinduism.
The two largest churches, the Roman Catholic Church and the Protestant Evangelical Church in Germany (EKD), have lost significant number of adherents. In 2019 the Catholic Church accounted for 27.2% and the Evangelical Church for 24.9% of the population. Orthodox Church has 1.9% and other Christian churches and groups summed up to 1.1% of the population. Since the reunification of Germany, the number of non-religious people has grown and an estimated 38.8% of the country's population are not affiliated with any church or religion.
The other religions make up to less than 1% of the population. Buddhism has around 200,000 adherents (0.2%), Judaism has around 200,000 adherents (0.2%), Hinduism 90,000 (0.1%), Sikhism 75,000 (0.1%) and Yazidis religion (45,000-60,000). All other religious communities in Germany have fewer than 50,000 (&lt;0.1%) adherents.
Protestantism is concentrated in the north and east and Roman Catholicism is concentrated in the south and west. According to the last nationwide census, Protestantism is more widespread among the population with German citizenship; there are slightly more Catholics total because of the Catholic immigrant population (including such groups as Poles and Italians). The former Pope, Benedict XVI, was born in Bavaria. Non-religious people, including atheists and agnostics, might make up as many as 55% of the total population, and are especially numerous in the former East Germany and major metropolitan areas.
Of the roughly 4 million Muslims, most are Sunnis and Alevites from Turkey, but there are a small number of Shi'ites and other denominations. 1.9% of the country's overall population declare themselves Orthodox Christians, with Serbs, Greeks, Romanians, Ukrainians and Russians being the most numerous. Germany has Europe's third-largest Jewish population (after France and the United Kingdom). In 2004, twice as many Jews from former Soviet republics settled in Germany as in Israel, bringing the total Jewish population to more than 200,000, compared to 30,000 prior to German reunification. Large cities with significant Jewish populations include Berlin, Frankfurt and Munich. Around 250,000 active Buddhists live in Germany; 50% of them are Asian immigrants.
### 2011 Census.
Census results were as follows:
## Languages.
German is the only official and most widely spoken language. Standard German is understood throughout the country.
### Minority languages.
Danish, Low German, Low Rhenish, the Sorbian languages (Lower Sorbian and Upper Sorbian), and the two Frisian languages, Saterfrisian and North Frisian, are officially recognized and protected as minority languages by the European Charter for Regional or Minority Languages in their respective regions. With speakers of Romany living in all parts of Germany, the federal government has promised to take action to protect the language. Until now, only Hesse has followed Berlin's announcement, and agreed on implementing concrete measures to support Romany speakers.
Implementation of the Charter is poor. The monitoring reports on charter implementation in Germany show many provisions unfulfilled. 
### High German dialects.
German dialects – some quite distinct from the standard language – are used in everyday speech, especially in rural regions. Many dialects, for example the Upper German varieties, are to some degree cultivated as symbols of regional identity and have their own literature, theaters and some TV programming. While speaking a dialect outside its native region might be frowned upon, in their native regions some dialects can be spoken by all social classes. . Nevertheless, partly due to the prevalence of Standard German in media, the use of dialects has declined over the past century, especially in the younger population.
The social status of different German dialects can vary greatly. The Alemannic and Bavarian dialects of the south are positively valued by their speakers and can be used in almost all social circumstances. The Saxonian and Thuringian dialects have less prestige and are subject to derision. While Bavarian and Alemannic have kept much of their distinctiveness, the Middle German dialects, which are closer to Standard German, have lost some of their distinctive lexical and grammatical features and tend to be only pronunciation variants of Standard German.
### Low Saxon dialects.
Low Saxon is officially recognized as a language on its own, but despite this fact, there's little official action taken on fostering the language. Historically one third of Germany's territory and population was Low Saxon speaking. No data was ever collected on the actual number of speakers, but today the number of speakers ranges around 5 million persons. Despite this relatively high number of speakers there is very little coverage in the media (mostly on NDR TV, no regular programming) and very little education in or on the language. The language is not fixed as part of the school curriculum and Low Saxon is used as a medium of instruction in one school only in the whole Germany (as a "model project" in primary school sided by education in Standard German). As a consequence the younger generation refused to adopt the native language of their parents. Language prevalence dropped from more than 90% (depending on the exact region) in the 1930s to less than 5% today. This accounts for a massive intergenerational gap in language use. Older people regularly use the language and take private initiative to maintain the language, but the lack of innovative potential of the younger generation hinders language maintenance. The language too has an own literature (around 150 published books every year) and there are many theatres (mostly lay stages, but some professional ones, like for example Ohnsorg-Theater).
Use of Low Saxon is mainly restricted to use among acquaintances, like family members, neighbours and friends. A meeting of a village council can be held almost completely in Low Saxon if all participants know each other (as long as written protocols are written in Standard German), but a single foreigner can make the whole switching to Standard German.
The Low Saxon dialects are different in their status too. There's a north–south gradient in language maintenance. The Southern dialects of Westfalian, Eastfalian and Brandenburgish have had much stronger speaker losses, than the northern coastal dialects of Northern Low Saxon. While Eastfalian has lost speakers to Standard German, Westfalian has lost speakers to Standard German and Standard German based regiolect of the Rhine-Ruhr area. Brandenburgish speakers mostly switched to the Standard German-based regiolect of Berlin. Brandenburgish is almost completely replaced by the Berlin regiolect. Northern Low Saxon speakers switched mostly to pure Standard German.
### Foreign languages.
English is the most common foreign language and almost universally taught by the secondary level; it is also taught at elementary level in some states. Other commonly-taught languages are French, Italian, Spanish, Portuguese, and Russian. Dutch is taught in states bordering the Netherlands, and Polish in the eastern states bordering Poland. Latin and Ancient Greek are part of the classical education syllabus offered in many secondary schools.
According to a 2004 survey, two-thirds of Germany's citizens have at least basic knowledge of English. About 20% consider themselves to be competent speakers of French, followed by speakers of Russian (7%), Italian (6.1%), and Spanish (5.6%). The relatively high number of Russian speakers is a result of immigration from the former Soviet Union to Germany for almost 10 consecutive years, plus its having been learned in school by many older former East Germans as compulsory first foreign language.

</doc>
<doc id="11930" url="https://en.wikipedia.org/wiki?curid=11930" title="Economy of Germany">
Economy of Germany

The economy of Germany is a highly developed social market economy. It has the largest national economy in Europe, the fourth-largest by nominal GDP in the world, and fifth by GDP (PPP). In 2017, the country accounted for 28% of the euro area economy according to the International Monetary Fund (IMF). Germany is a founding member of the European Union and the Eurozone. 
In 2016, Germany recorded the highest trade surplus in the world, worth $310 billion. This economic result made it the biggest capital exporter globally. Germany is one of the largest exporters globally with $1810.93 billion worth of goods and services exported in 2019. The service sector contributes around 70% of the total GDP, industry 29.1%, and agriculture 0.9%. Exports accounted for 41% of national output. The top 10 exports of Germany are vehicles, machinery, chemical goods, electronic products, electrical equipment, pharmaceuticals, transport equipment, basic metals, food products, and rubber and plastics. The economy of Germany is the largest manufacturing economy in Europe, and it is less likely to be affected by a financial downturn. Germany conducts applied research with practical industrial value and sees itself as a bridge between the latest university insights and industry-specific product and process improvements. It generates a great deal of knowledge in its own laboratories.
Germany is rich in timber, lignite, potash and salt. Some minor sources of natural gas are being exploited in the state of Lower Saxony. Until the German reunification, the German Democratic Republic mined for uranium in the Ore Mountains (see also: SAG/SDAG Wismut). Energy in Germany is sourced predominantly by fossil fuels (30%), with wind power in second place, then nuclear power, gas, solar, biomass (wood and biofuels) and hydro. Germany is the first major industrialized nation to commit to the renewable energy transition called Energiewende. Germany is the leading producer of wind turbines in the world. Renewables produced 46% of electricity consumed in Germany (as of 2019).
99 percent of all German companies belong to the German "Mittelstand," small and medium-sized enterprises, which are mostly family-owned. Of the world's 2000 largest publicly listed companies measured by revenue, the Fortune Global 2000, 53 are headquartered in Germany, with the Top 10 being Allianz, Daimler, Volkswagen, Siemens, BMW, Deutsche Telekom, Bayer, BASF, Munich Re and SAP.
Germany is the world's top location for trade fairs. Around two thirds of the world's leading trade fairs take place in Germany. The largest annual international trade fairs and congresses are held in several German cities such as Hanover, Frankfurt, Cologne, Leipzig and Düsseldorf.
## History.
### Age of Industrialization.
The Industrial Revolution in Germany got underway approximately a century later than in the United Kingdom, France, and Belgium, partly because Germany only became a unified country in 1871.The establishment of the Deutscher Zollverein (German Customs Union) in 1834 and the expansion of railway systems were the main drivers of Germany's industrial development and political union. From 1834, tariff barriers between increasing numbers of the Kleindeutschland German states were eliminated. In 1835 the first German railway linked the Franconian cities of Nuremberg and Fürth – it proved so successful that the decade of the 1840s saw "railway mania" in all the German states. Between 1845 and 1870, of rail had been built and in 1850 Germany was building its own locomotives. Over time, other German states joined the customs union and started linking their railroads, which began to connect the corners of Germany. The growth of free trade and a rail system across Germany intensified economic development which opened up new markets for local products, created a pool of middle managers, increased the demand for engineers, architects, and skilled machinists, and stimulated investments in coal and iron.
Another factor that propelled German industry forward was the unification of the monetary system, made possible in part by political unification. The Deutsche Mark, a new monetary coinage system backed by gold, was introduced in 1871. However, this system did not fully come into use as silver coins retained their value until 1907.
The victory of Prussia and her allies over Napoleon III of France in the Franco-Prussian War of 1870-1871 marked the end of French hegemony in Europe and resulted in the proclamation of the German Empire in 1871. The establishment of the empire inherently presented Europe with the reality of a new populous and industrializing polity possessing a considerable, and undeniably increasing, economic and diplomatic presence. The influence of French economic principles produced important institutional reforms in Germany, including the abolition of feudal restrictions on the sale of large landed estates, the reduction of the power of the guilds in the cities, and the introduction of a new, more efficient commercial law. Nonetheless, political decisions about the economy of the empire were still largely controlled by a coalition of "rye and iron", that is the Prussian Junker landowners of the east and the Ruhr heavy industry of the west.
Regarding politics and society, between 1881 and 1889 Chancellor Otto von Bismarck promoted laws that provided social insurance and improved working conditions. He instituted the world's first welfare state. Germany was the first to introduce social insurance programs including universal healthcare, compulsory education, sickness insurance, accident insurance, disability insurance, and a retirement pension. Moreover, the government's universal education policy bore fruit with Germany achieving the highest literacy rate in the world – 99% – education levels that provided the nation with more people good at handling numbers, more engineers, chemists, opticians, skilled workers for its factories, skilled managers, knowledgeable farmers, and skilled military personnel.
By 1900 Germany surpassed Britain and the United States in steel production. The German economic miracle was also intensified by unprecedented population growth from 35 million in 1850 to 67 million in 1913. From 1895 to 1907, the number of workers engaged in machine building doubled from half a million to well over a million. Only 40 percent of Germans lived in rural areas by 1910, a drop from 67% at the birth of the Empire. Industry accounted for 60 percent of the gross national product in 1913. The German chemical industry became the most advanced in the world, and by 1914 the country was producing half the world's electrical equipment.
The rapid advance to industrial maturity led to a drastic shift in Germany's economic situation – from a rural economy into a major exporter of finished goods. The ratio of the finished product to total exports jumped from 38% in 1872 to 63% in 1912. By 1913 Germany had come to dominate all the European markets. By 1914 Germany had become one of the biggest exporters in the world.
### Weimar Republic and Third Reich.
The Nazis rose to power while unemployment was very high, but achieved full employment later thanks to massive public works programs such as the Reichsbahn, Reichspost and the Reichsautobahn projects. In 1935 rearmament in contravention of the Treaty of Versailles added to the economy.
Weimar and Nazi Germany By Stephen J. Lee
The post-1931 financial crisis economic policies of expansionary fiscal policies (as Germany was off the gold standard) was advised by their non-Nazi Minister of Economics, Hjalmar Schacht, who in 1933 became the president of the central bank. Hjalmar Schacht later abdicated from the post in 1938 and was replaced by Hermann Göring.
The trading policies of the Third Reich aimed at self-sufficiency but with a lack of raw materials Germany would have to maintain trade links but on bilateral preferences, foreign exchange controls, import quotas, and export subsidies under what was called the "New Plan"(Neuer Plan) of 19 September 1934. The "New Plan" was based on trade with less developed countries who would trade raw materials for German industrial goods saving currency. Southern Europe was preferable to Western Europe and North America as there could be no trade blockades. This policy became known as the Grosswirtschaftsraum ("greater economic area") policy.
Eventually, the Nazi party developed strong relationships with big business and abolished trade unions in 1933 in order to form the National Labor Service (RAD), German Labor Front (DAF) to set working hours, Beauty of Labour (SDA) which set working conditions and Strength through Joy (KDF) to ensure sports clubs for workers.
### West Germany.
Beginning with the replacement of the Reichsmark with the Deutsche Mark as legal tender, a lasting period of low inflation and rapid industrial growth was overseen by the government led by German Chancellor Konrad Adenauer and his minister of economics, Ludwig Erhard, raising West Germany from total wartime devastation to one of the most developed nations in modern Europe.
In 1953 it was decided that Germany was to repay $1.1 billion of the aid it had received. The last repayment was made in June 1971.
Apart from these factors, hard work and long hours at full capacity among the population in the 1950s, 1960s, and early 1970s and extra labor supplied by thousands of Gastarbeiter ("guest workers") provided a vital base for the economic upturn.
### East Germany.
By the early 1950s, the Soviet Union had seized reparations in the form of agricultural and industrial products and demanded further heavy reparation payments. Silesia with the Upper Silesian Coal Basin, and Stettin, a prominent natural port, were lost to Poland.
Exports from West Germany exceeded $323 billion in 1988. In the same year, East Germany exported $30.7 billion worth of goods; 65% to other communist states. East Germany had zero unemployment.
In 1976 the average annual GDP growth was roughly 5.9%.
### Federal Republic.
The German economy practically stagnated in the beginning of the 2000s. The worst growth figures were achieved in 2002 (+1.4%), in 2003 (+1.0%) and in 2005 (+1.4%). Unemployment was also chronically high. Due to these problems, together with Germany's aging population, the welfare system came under considerable strain. This led the government to push through a wide-ranging program of belt-tightening reforms, Agenda 2010, including the labor market reforms known as Hartz I - IV.
In the later part of the first decade of 2000, the world economy experienced high growth, from which Germany as a leading exporter also profited. Some credit the Hartz reforms with achieving high growth and declining unemployment but others contend that they resulted in a massive decrease in standards of living and that its effects are limited and temporary.
The nominal GDP of Germany contracted in the second and third quarters of 2008, putting the country in a technical recession following a global and European recession cycle. German industrial output dropped to 3.6% in September vis-à-vis August. In January 2009 the German government under Angela Merkel approved a €50 billion ($70 billion) economic stimulus plan to protect several sectors from a downturn and a subsequent rise in unemployment rates. Germany exited the recession in the second and third quarters of 2009, mostly due to rebounding manufacturing orders and exports - primarily from outside the Euro Zone - and relatively steady consumer demand.
Germany is a founding member of the EU, the G8 and the G20, and was the world's largest exporter from 2003 to 2008. In 2011 it remained the third largest exporter and third largest importer. Most of the country's exports are in engineering, especially machinery, automobiles, chemical goods and metals. Germany is a leading producer of wind turbines and solar-power technology. Annual trade fairs and congresses are held in cities throughout Germany.
2011 was a record-breaking year for the German economy. German companies exported goods worth over €1 trillion ($1.3 trillion), the highest figure in history. The number of people in work has risen to 41.6 million, the highest recorded figure.
Through 2012, Germany's economy continued to be stronger relative to local neighboring nations.
## Data.
As of December 2017, the unemployment rate was at 5.5 percent.
, the unemployment rate was 4.8 percent.
, the CPI rate was 0.6 percent.
The following table shows the main economic indicators in 1980–2020. Inflation below 2% is in green.
1980 to 1995
1996 to 2010
2011 to 2020
### Companies.
Of the world's 500 largest stock-market-listed companies measured by revenue in 2010, the Fortune Global 500, 37 are headquartered in Germany. 30 Germany-based companies are included in the DAX, the German stock market index. Well-known global brands are Mercedes-Benz, BMW, SAP, Siemens, Volkswagen, Adidas, Audi, Allianz, Porsche, Bayer, BASF, Bosch, and Nivea.
Germany is recognised for its specialised small and medium enterprises, known as the Mittelstand model. SMEs account for more than 99 per cent of German companies. Around 1,000 of these companies are global market leaders in their segment and are labelled hidden champions.
From 1991 to 2010, 40,301 mergers and acquisitions with an involvement of German firms with a total known value of 2,422 bil. EUR have been announced. The largest transactions since 1991 are: the acquisition of Mannesmann by Vodafone for 204.8 bil. EUR in 1999, the merger of Daimler-Benz with Chrysler to form DaimlerChrysler in 1998 valued at 36.3 bil. EUR.
Berlin (Economy of Berlin) developed an international Startup ecosystem and became a leading location for venture capital funded firms in the European Union.
The list includes the largest German companies by revenue in 2011:
### Mergers and acquisitions.
Since the German reunification, there have been 52,258 mergers or acquisitions deals inbound or outbound in Germany. The most active year in terms of value was 1999 with a cumulated value of 48. bil. EUR, twice as much as the runner up which was 2006 with 24. bil. EUR (see graphic "M&amp;A in Germany").
Here is a list of the top 10 deals (ranked by value) that include a German company. The Vodafone - Mannesmann deal is still the biggest deal in global history.
## Economic region.
Germany as a federation is a polycentric country and does not have a single economic center. The stock exchange is located in Frankfurt am Main, the largest Media company (Bertelsmann SE &amp; Co. KGaA) is headquartered in Gütersloh; the largest car manufacturers are in Wolfsburg (Volkswagen), Stuttgart (Mercedes-Benz and Porsche), and Munich (Audi and BMW).
Germany is an advocate of closer European economic and political integration. Its commercial policies are increasingly determined by agreements among European Union (EU) members and EU single market legislation. Germany introduced the common European currency, the euro on 1 January 1999. Its monetary policy is set by the European Central Bank in Frankfurt.
The southern states ("Bundesländer"), especially Bayern, Baden-Württemberg, and Hessen, are economically stronger than the northern states. One of Germany's traditionally strongest (and at the same time oldest) economic regions is the Ruhr area in the west, between Duisburg and Dortmund. 27 of the country's 100 largest companies are located there. In recent years, however, the area, whose economy is based on natural resources and heavy industry, has seen a substantial rise in unemployment (2010: 8.7%).
The economy of Bayern and Baden-Württemberg, the states with the lowest number of unemployed people (2018: 2.7%, 3.1%), on the other hand, is based on high-value products. Important sectors are automobiles, electronics, aerospace, and biomedicine, among others. Baden-Württemberg is an industrial center especially for the automobile and machine-building industry and the home of brands like Mercedes-Benz (Daimler), Porsche and Bosch.
With the reunification on 3 October 1990, Germany began the major task of reconciling the economic systems of the two former republics. Interventionist economic planning ensured gradual development in eastern Germany up to the level of former West Germany, but the standard of living and annual income remains significantly higher in western German states. The modernization and integration of the eastern German economy continues to be a long-term process scheduled to last until the year 2019, with annual transfers from west to east amounting to roughly $80 billion. The overall unemployment rate has consistently fallen since 2005 and reached a 20-year low in 2012. The country in July 2014 began legislating to introduce a federally mandated minimum wage which would come into effect on 1 January 2015.
### Wealth.
The following top 10 list of German billionaires is based on an annual assessment of wealth and assets compiled and published by "Forbes" magazine on 1 March 2016.
Wolfsburg is the city in Germany with the country's highest per capita GDP, at $128,000. The following top 10 list of German cities with the highest per capita GDP is based on a study by the Cologne Institute for Economic Research on 31 July 2013.
## Sectors.
Germany has a social market economy characterised by a highly qualified labor force, a developed infrastructure, a large capital stock, a low level of corruption, and a high level of innovation. It has the largest national economy in Europe, the fourth largest by nominal GDP in the world, and ranked fifth by GDP (PPP) in 2015.
The service sector contributes around 70% of the total GDP, industry 29.1%, and agriculture 0.9%.
### Primary.
In 2010 agriculture, forestry, and mining accounted for only 0.9% of Germany's gross domestic product (GDP) and employed only 2.4% of the population, down from 4% in 1991. Agriculture is extremely productive, and Germany can cover 90% of its nutritional needs with domestic production. Germany is the third-largest agricultural producer in the European Union after France and Italy. Germany's principal agricultural products are potatoes, wheat, barley, sugar beets, fruit, and cabbages. 
Despite the country's high level of industrialization, almost one-third of its territory is covered by forest. The forestry industry provides for about two-thirds of domestic consumption of wood and wood products, so Germany is a net importer of these items.
The German soil is relatively poor in raw materials. Only lignite (brown coal) and potash salt (Kalisalz) are available in significant quantities. However, the former GDR's Wismut mining company produced a total of 230,400 tonnes of uranium between 1947 and 1990 and made East Germany the fourth-largest producer of uranium ore worldwide (largest in USSR's sphere of control) at the time. Oil, natural gas, and other resources are, for the most part, imported from other countries.
Potash salt is mined in the center of the country (Niedersachsen, Sachsen-Anhalt and Thüringen). The most important producer is K+S (formerly Kali und Salz AG).
Germany's bituminous coal deposits were created more than 300 million years ago from swamps which extended from the present-day South England, over the Ruhr area to Poland. Lignite deposits developed similarly, but during a later period, about 66 million years ago. Because the wood is not yet completely transformed into coal, brown coal contains less energy than bituminous coal.
Lignite is extracted in the extreme western and eastern parts of the country, mainly in Nordrhein-Westfalen, Sachsen and Brandenburg. Considerable amounts are burned in coal plants near the mining areas, to produce electricity. Transporting lignite over far distances is not economically feasible, therefore the plants are located practically next to the extraction sites. Bituminous coal is mined in Nordrhein-Westfalen and Saarland. Most power plants burning bituminous coal operate on imported material, therefore the plants are located not only near to the mining sites, but throughout the country.
In 2019, the country was the world's 3rd largest producer of selenium, the world's 5th largest producer of potash, the world's 5th largest producer of boron, the world's 7th largest producer of lime, the world's 13th largest producer of fluorspar, the world's 14th largest producer of feldspar, the world's 17th largest producer of graphite, the world's 18th largest producer of sulfur, in addition to being the 4th largest world producer of salt.
### Industry.
Industry and construction accounted for 30.7% of the gross domestic product in 2017 and employed 24.2% of the workforce. Germany excels in the production of automobiles, machinery, electrical equipment and chemicals. With the manufacture of 5.2 million vehicles in 2009, Germany was the world's fourth-largest producer and largest exporter of automobiles. German automotive companies enjoy an extremely strong position in the so-called premium segment, with a combined world market share of about 90%.
Small- to medium-sized manufacturing firms (Mittelstand companies) which specialize in technologically advanced niche products and are often family-owned form a major part of the German economy. It is estimated that about 1500 German companies occupy a top three position in their respective market segment worldwide. In about two thirds of all industry sectors German companies belong to the top three competitors.
Germany is the only country among the top five arms exporters that is not a permanent member of the United Nations Security Council.
### Services.
In 2017 services constituted 68.6% of gross domestic product (GDP), and the sector employed 74.3% of the workforce. The subcomponents of services are financial, renting, and business activities (30.5%); trade, hotels and restaurants, and transport (18%); and other service activities (21.7%).
Germany is the seventh most visited country in the world, with a total of 407 million overnights during 2012. This number includes 68.83 million nights by foreign visitors. In 2012, over 30.4 million international tourists arrived in Germany. Berlin has become the third most visited city destination in Europe. Additionally, more than 30% of Germans spend their holiday in their own country, with the biggest share going to Mecklenburg-Vorpommern. Domestic and international travel and tourism combined directly contribute over EUR43.2 billion to German GDP. Including indirect and induced impacts, the industry contributes 4.5% of German GDP and supports 2 million jobs (4.8% of total employment). The largest annual international trade fairs and congresses are held in several German cities such as Hannover, Frankfurt, and Berlin.
## Government finances.
The debt-to-GDP ratio of Germany had its peak in 2010 when it stood at 80.3% and decreased since then. According to Eurostat, the government gross debt of Germany amounts to €2,152.0 billion or 71.9% of its GDP in 2015. The federal government achieved a budget surplus of €12.1 billion ($13.1 billion) in 2015. Germany's credit rating by credit rating agencies Standard &amp; Poor's, Moody's and Fitch Ratings stands at the highest possible rating "AAA" with a stable outlook in 2016.
Germany's "debt clock" ("Schuldenuhr") reversed for the first time in 20 years in January 2018. It is now currently increasing at 10,424.00 per second (Oct2020)..
Economists generally see Germany's current account surplus as undesirable.
## Infrastructure.
### Energy.
Germany is the world's fifth-largest consumer of energy, and two-thirds of its primary energy was imported in 2002. In the same year, Germany was Europe's largest consumer of electricity, totaling 512.9 terawatt-hours. Government policy promotes energy conservation and the development of renewable energy sources, such as solar, wind, biomass, hydroelectric, and geothermal energy. As a result of energy-saving measures, energy efficiency has been improving since the beginning of the 1970s. The government has set the goal of meeting half the country's energy demands from renewable sources by 2050. Renewable energy also plays an increasing role in the labor market: Almost 700,000 people are employed in the energy sector. About 50 percent of them work with renewable energies.
In 2000, the red-green coalition under Chancellor Schröder and the German nuclear power industry agreed to phase out all nuclear power plants by 2021. The conservative coalition under Chancellor Merkel reversed this decision in January 2010, electing to keep plants open. The nuclear disaster of the Japanese nuclear plant Fukushima in March 2011 however, changed the political climate fundamentally: Older nuclear plants have been shut down. Germany is seeking to have wind, solar, biogas, and other renewable energy sources play a bigger role, as the country looks to completely phase out nuclear power by 2022 and coal-fired power plants by 2038. Renewable energy yet still plays a more modest role in energy consumption, though German solar and wind power industries play a leading role worldwide.
In 2009, Germany's total energy consumption (not just electricity) came from the following sources:
oil 34.6%, natural gas 21.7%, lignite 11.4%, bituminous coal 11.1%, nuclear power 11.0%, hydro and wind power 1.5%, others 9.0%.
In the first half of 2021, coal, natural gas and nuclear energy comprised 56% of the total electricity fed into Germany's grid in the first half of 2021. Coal was the leader out of the conventional energy sources, comprising over 27% of Germany's electricity. Wind power's contribution to the electric grid was 22%.
There are 3 major entry points for oil pipelines: in the northeast (the Druzhba pipeline, coming from Gdańsk), west (coming from Rotterdam) and southeast (coming from Nelahozeves). The oil pipelines of Germany do not constitute a proper network, and sometimes only connect two different locations. Major oil refineries are located in or near the following cities: Schwedt, Spergau, Vohburg, Burghausen, Karlsruhe, Cologne, Gelsenkirchen, Lingen, Wilhelmshaven, Hamburg and Heide.
Germany's network of natural gas pipelines, on the other hand, is dense and well-connected. Imported pipeline gas comes mostly from Russia, the Netherlands and the United Kingdom. Although gas imports from Russia have been historically reliable, even during the cold war, recent price disputes between Gazprom and the former Soviet states, such as Ukraine, have also affected Germany. As a result, high political importance is placed on the construction of the Nord Stream pipeline, running from Vyborg in Russia along the Baltic sea to Greifswald in Germany. This direct connection avoids third-party transit countries. Germany imports 50% to 75% of its natural gas from Russia.
### Transport.
With its central position in Europe, Germany is an important transportation hub. This is reflected in its dense and modern transportation networks. The extensive motorway (Autobahn) network ranks worldwide third largest in its total length and features a lack of blanket speed limits on the majority of routes.
Germany has established a polycentric network of high-speed trains. The InterCityExpress or "ICE" is the most advanced service category of the Deutsche Bahn and serves major German cities as well as destinations in neighbouring countries. The train maximum speed varies between 200 km/h and 320 km/h (125-200 mph). Connections are offered at either 30-minute, hourly, or two-hourly intervals. German railways are heavily subsidised, receiving €17.0 billion in 2014.
The largest German airports are Frankfurt Airport and Munich Airport, both are global hubs of Lufthansa. Other major airports are Berlin Brandenburg Airport, Düsseldorf, Hamburg, Hanover, Cologne/Bonn, and Stuttgart.
## Technology.
Germany's achievements in sciences have been significant, and research and development efforts form an integral part of the economy.
Germany is also one of the leading countries in developing and using green technologies. Companies specializing in green technology have an estimated turnover of €200 billion. German expertise in engineering, science, and research is eminently respectable.
The lead markets of Germany's green technology industry are power generation, sustainable mobility, material efficiency, energy efficiency, waste management and recycling, sustainable water management.
Regarding triadic patents, Germany is in third place after the US and Japan. With more than 26,500 registrations for patents submitted to the European Patent Office, Germany is the leading European nation. Siemens, Bosch and BASF, with almost 5,000 registrations for patents between them in 2008, are among the Top 5 of more than 35,000 companies registering patents. Together with the US and Japan, about patents for nano, bio, and new technologies Germany is one of the world's most active nations. With around one-third of triadic patents Germany leads the way worldwide in the field of vehicle emission reduction.
According to Winfried Kretschmann, who is premier of the region where Daimler is based, "China dominates the production of solar cells? Tesla is ahead in electric cars and Germany has lost the first round of digitalization to Google, Apple, and the like. Whether Germany has a future as an industrial economy will depend on whether we can manage the ecological and digital transformation of our economy".
## Challenges.
Despite economic prosperity, Germany's biggest threat to future economic development is the nation's declining birthrate which is among the lowest in the world. This is particularly prevalent in parts of society with higher education. As a result, the numbers of workers are expected to decrease and the government spending needed to support pensioners and healthcare will increase if the trend is not reversed.
Less than a quarter of German people expect living conditions to improve in the coming decades.
On August 25, 2020, Federal Statistical Office of Germany revealed that the German economy plunged by 9.7% in the second quarter which is the worst on record. The latest figures show how hard the German economy was hit by the coronavirus pandemic.

</doc>
<doc id="11932" url="https://en.wikipedia.org/wiki?curid=11932" title="Transport in Germany">
Transport in Germany

As a densely populated country in a central location in Europe and with a developed economy, Germany has a dense and modern transport infrastructure.
The first highway system to have been built, the extensive German Autobahn network famously has no general speed limit for light vehicles (although there are speed limits in many sections today, and there is a blanket 80 km/h limit for trucks). The country's most important waterway is the river Rhine. The largest port is that of Hamburg. Frankfurt Airport is a major international airport and European transport hub. Air travel is used for greater distances within Germany but faces competition from the state-owned Deutsche Bahn's rail network. High-speed trains called ICE connect cities for passenger travel with speeds up to 300 km/h. Many German cities have rapid transit systems and public transport is available in most areas. Buses have historically only played a marginal role in long-distance passenger service, as all routes directly competing with rail services were technically outlawed by a law dating to 1935 (during the Nazi era). Only in 2012 was this law officially amended and thus a long-distance bus market has also emerged in Germany since then.
Since German reunification substantial effort has been made to improve and expand transport infrastructure in what was formerly East Germany.
Verkehrsmittel and Verkehrszeichen - Transportation signs in Germany are available here in German and English.
## Road and automotive transport.
### Overview.
The volume of traffic in Germany, especially goods transportation, is at a very high level due to its central location in Europe.
In the past few decades, much of the freight traffic shifted from rail to road, which led the Federal Government to introduce a motor toll for trucks in 2005. Individual road usage increased resulting in a relatively high traffic density to other nations. A further increase of traffic is expected in the future.
High-speed vehicular traffic has a long tradition in Germany given that the first freeway (Autobahn) in the world, the AVUS, and the world's first automobile were developed and built in Germany. Germany possesses one of the most dense road systems of the world. German motorways have no blanket speed limit for light vehicles. However, posted limits are in place on many dangerous or congested stretches as well as where traffic noise or pollution poses a problem (20.8% under static or temporary limits and an average 2.6% under variable traffic control limit applications as of 2015).
The German government has had issues with upkeep of the country's autobahn network, having had to revamp the Eastern portion's transport system since the unification of Germany between the German Democratic Republic (East Germany) and the Federal Republic of Germany (West Germany). With that, numerous construction projects have been put on hold in the west, and a vigorous reconstruction has been going on for almost 20 years. However, ever since the European Union formed, an overall streamlining and change of route plans have occurred as faster and more direct links to former Soviet bloc countries now exist and are in the works, with intense co-operation among European countries.
Intercity bus service within Germany fell out of favour as post-war prosperity increased, and became almost extinct when legislation was introduced in the 1980s to protect the national railway. After that market was deregulated in 2012, some 150 new intercity bus lines have been established, leading to a significant shift from rail to bus for long journeys. The market has since consolidated with Flixbus controlling over 90% of it and also expanding into neighboring countries.
### Roads.
Germany has approximately 650,000 km of roads, of which 231,000 km are non-local roads. The road network is extensively used with nearly 2 trillion km travelled by car in 2005, in comparison to just 70 billion km travelled by rail and 35 billion km travelled by plane.
The Autobahn is the German federal highway system. The official German term is (plural "", abbreviated 'BAB'), which translates as 'federal motorway'. Where no local speed limit is posted, the advisory limit "(Richtgeschwindigkeit)" is 130 km/h. The "Autobahn" network had a total length of about in 2016, which ranks it among the most dense and longest systems in the world. Only federally built controlled-access highways meeting certain construction standards including at least two lanes per direction are called "Bundesautobahn". They have their own, blue-coloured signs and their own numbering system. All "Autobahnen" are named by using the capital letter A, followed by a blank and a number (for example A 8).
The main "Autobahnen" going all across Germany have single digit numbers. Shorter highways of regional importance have double digit numbers (like A 24, connecting Berlin and Hamburg). Very short stretches built for heavy local traffic (for example ring roads or the A 555 from Cologne to Bonn) usually have three digits, where the first digit depends on the region.
East–west routes are usually even-numbered, north–south routes are usually odd-numbered. The numbers of the north–south "Autobahnen" increase from west to east; that is to say, the more easterly roads are given higher numbers. Similarly, the east–west routes use increasing numbers from north to south.
The autobahns are considered the safest category of German roads: for example, in 2012, while carrying 31% of all motorized road traffic, they only accounted for 11% of Germany's traffic fatalities.&lt;ref name="http://www.bast.de 2012"&gt;&lt;/ref&gt;
German autobahns are still toll-free for light vehicles, but on 1 January 2005, a blanket mandatory toll on heavy trucks was introduced.
The national roads in Germany are called "Bundesstraßen" (federal roads). Their numbers are usually well known to local road users, as they appear (written in black digits on a yellow rectangle with black border) on direction traffic signs and on street maps. A Bundesstraße is often referred to as "B" followed by its number, for example "B1", one of the main east–west routes. More important routes have lower numbers. Odd numbers are usually applied to north–south oriented roads, and even numbers for east–west routes. Bypass routes are referred to with an appended "a" (alternative) or "n" (new alignment), as in "B 56n".
Other main public roads are maintained by the "Bundesländer" (states), called "Landesstraße" (country road) or "Staatsstraße" (state road). The numbers of these roads are prefixed with "L", "S" or "St", but are usually not seen on direction signs or written on maps. They appear on the kilometre posts on the roadside. Numbers are unique only within one state.
The "Landkreise" (districts) and municipalities are in charge of the minor roads and streets within villages, towns and cities. These roads have the number prefix "K" indicating a "Kreisstraße".
## Rail transport.
### Overview.
Germany features a total of 43,468 km railways, of which at least 19,973 km are electrified (2014).
Deutsche Bahn (German Rail) is the major German railway infrastructure and service operator. Though Deutsche Bahn is a private company, the government still holds all shares and therefore Deutsche Bahn can still be called a state-owned company. Since its reformation under private law in 1994, Deutsche Bahn AG (DB AG) no longer publishes details of the tracks it owns; in addition to the DBAG system there are about 280 privately or locally owned railway companies which own an approximate 3,000 km to 4,000 km of the total tracks and use DB tracks in "open access".
Railway subsidies amounted to €17.0 billion in 2014 and there are significant differences between the financing of long-distance and short-distance (or local) trains in Germany. While long-distance trains can be run by any railway company, the companies also receive no subsidies from the government. Local trains however are subsidised by the German states, which pay the operating companies to run these trains and indeed in 2013, 59% of the cost of short-distance passenger rail transport was covered by subsidies. This resulted in many private companies offering to run local train services as they can provide cheaper service than the state-owned Deutsche Bahn. Track construction is entirely and track maintenance partly government financed both for long and short range trains. On the other hand, all rail vehicles are charged track access charges by DB Netz which in turn delivers (part of) its profits to the federal budget.
High speed rail started in the early 1990s with the introduction of the Inter City Express (ICE) into revenue service after first plans to modernize the rail system had been drawn up under the government of Willy Brandt. While the high speed network is not as dense as those of France or Spain, ICE or slightly slower (max. speed 200 km/h) Intercity (IC) serve most major cities. Several extensions or upgrades to high speed lines are under construction or planned for the near future, some of them after decades of planning.
The fastest high-speed train operated by Deutsche Bahn, the InterCityExpress or ICE connects major German and neighbouring international centres such as Zurich, Vienna, Copenhagen, Paris, Amsterdam and Brussels. The rail network throughout Germany is extensive and provides excellent service in most areas. On regular lines, at least one train every two hours will call even in the smallest of villages during the day. Nearly all larger metropolitan areas are served by S-Bahn, U-Bahn, Straßenbahn and/or bus networks.
The German government on 13 February 2018 announced plans to make public transportation free as a means to reduce road traffic and decrease air pollution to EU-mandated levels. The new policy will be put to the test by the end of the year in the cities of Bonn, Essen, Herrenberg, Reutlingen and Mannheim. Issues remain concerning the costs of such a move as ticket sales for public transportation constitute a major source of income for cities.
### International freight trains.
While Germany and most of contiguous Europe use , differences in signalling, rules and regulations, electrification voltages, etc. create obstacles for freight operations across borders. These obstacles are slowly being overcome, with international (in- and outgoing) and transit (through) traffic being responsible for a large part of the recent uptake in rail freight volume. EU regulations have done much to harmonize standards, making cross border operations easier. Maschen Marshalling Yard near Hamburg is the second biggest in the world and the biggest in Europe. It serves as a freight hub distributing goods from Scandinavia to southern Europe and from Central Europe to the port of Hamburg and overseas. Being a densely populated prosperous country in the center of Europe, there are many important transit routes through Germany. The Mannheim–Karlsruhe–Basel railway has undergone upgrades and refurbishments since the 1980s and will likely undergo further upgrades for decades to come as it is the main route from the North Sea Ports to northern Italy via the Gotthard Base Tunnel.
### S-Bahn.
Almost all major metro areas of Germany have suburban rail systems called S-Bahnen ("Schnellbahnen"). These usually connect larger agglomerations to their suburbs and often other regional towns, although the Rhein-Ruhr S-Bahn connects several large cities. A S-Bahn doesn't skip stations and runs more frequently than other trains. In Berlin and Hamburg the S-Bahn has a U-Bahn-like service and uses a third rail whereas all other S-Bahn services rely on regular catenary power supply.
### Rapid transit (U-Bahn).
Relatively few cities have a full-fledged underground U-Bahn system; S-Bahn (suburban commuter railway) systems are far more common. In some cities the distinction between U-Bahn and S-Bahn systems is blurred, for instance some S-Bahn systems run underground, have frequencies similar to U-Bahn, and form part of the same integrated transport network. A larger number of cities has upgraded their tramways to light rail standards. These systems are called Stadtbahn (not to be confused with S-Bahn), on main line rails.
Cities with U-Bahn systems are:
With the exception of Hamburg, all of those aforementioned cities also have a tram system, often with new lines built to light rail standards.
Cities with "Stadtbahn" systems can be found in the article Trams in Germany.
### Trams (Straßenbahn).
Germany was among the first countries to have electric street - running railways and Berlin has one of the longest tram networks in the world. Many West German cities abandoned their previous tram systems in the 1960s and 1970s while others upgraded them to "Stadtbahn" (~light rail) standard, often including underground sections. In the East, most cities retained or even expanded their tram systems and since reunification a trend towards new tram construction can be observed in most of the country. Today the only major German city without a tram or light rail system is Hamburg. Tram-train systems like the Karlsruhe model first came to prominence in Germany in the early 1990s and are implemented or discussed in several cities, providing coverage far into the rural areas surrounding cities.
## Air transport.
Short distances and the extensive network of motorways and railways make airplanes uncompetitive for travel within Germany. Only about 1% of all distance travelled was by plane in 2002. But due to a decline in prices with the introduction of low-fares airlines, domestic air travel is becoming more attractive. In 2013 Germany had the fifth largest passenger air market in the world with 105,016,346 passengers. However, the advent of new faster rail lines often leads to cuts in service by the airlines or even total abandonment of routes like Frankfurt-Cologne, Berlin-Hannover or Berlin-Hamburg.
### Airlines.
Germany's largest airline is Lufthansa, which was privatised in the 1990s. Lufthansa also operates two regional subsidiaries under the Lufthansa Regional brand and a low-cost subsidiary, Eurowings, which operates independently. Lufthansa flies a dense network of domestic, European and intercontinental routes. Germany's second-largest airline was Air Berlin, which also operated a network of domestic and European destinations with a focus on leisure routes as well as some long-haul services. Air Berlin declared bankruptcy in 2017 with the last flight under its own name in October of that year.
Charter and leisure carriers include Condor, TUIfly, MHS Aviation and Sundair. Major German cargo operators are Lufthansa Cargo, European Air Transport Leipzig (which is a subsidiary of DHL) and AeroLogic (which is jointly owned by DHL and Lufthansa Cargo).
### Airports.
Frankfurt Airport is Germany's largest airport, a major transportation hub in Europe and the world's twelfth busiest airport. It is one of the airports with the largest number of international destinations served worldwide. Depending on whether total passengers, flights or cargo traffic are used as a measure, it ranks first, second or third in Europe alongside London Heathrow Airport and Paris-Charles de Gaulle Airport. Germany's second biggest international airport is Munich Airport followed by Düsseldorf Airport.
There are several more scheduled passenger airports throughout Germany, mainly serving European metropolitan and leisure destinations. Intercontinental long-haul routes are operated to and from the airports in Frankfurt, Munich, Düsseldorf, Berlin-Tegel, Cologne/Bonn, Hamburg and Stuttgart.
Berlin Brandenburg Airport is expected to become the third largest German airport by annual passengers once it opens, serving as single airport for Berlin. Originally planned to be completed in 2011, the new airport has been delayed several times due to poor construction management and technical difficulties. As of September 2014, it is not yet known when the new airport will become operational. In 2017 it was announced that the airport wouldn't open before 2019. In the same year a non-binding referendum to keep Tegel Airport open even after the new airport opens was passed by Berlin voters. BER has opened on October 31, 2020
Airports — with paved runways:
Airports — with unpaved runways:
Heliports: 23 (2013 est.)
## Water transport.
Waterways: 7,467 km (2013); major rivers include the Rhine and Elbe; Kiel Canal is an important connection between the Baltic Sea and North Sea and one of the busiest waterways in the world, the Rhine-Main-Danube Canal links Rotterdam on the North Sea with the Black Sea. It passes through the highest point reachable by ocean-going vessels from the sea. The Canal has gained importance for leisure cruises in addition to cargo traffic.
Pipelines: oil 2,400 km (2013)
Ports and harbours: Berlin, Bonn, Brake, Bremen, Bremerhaven, Cologne, Dortmund, Dresden, Duisburg, Emden, Fürth, Hamburg, Karlsruhe, Kiel, Lübeck, Magdeburg, Mannheim, Nuremberg, Oldenburg, Rostock, Stuttgart, Wilhelmshaven
The port of Hamburg is the largest sea-harbour in Germany and ranks #3 in Europe (after Rotterdam and Antwerpen), #17 worldwide (2016), in total container traffic.
Merchant marine:
&lt;br&gt;total: 427 ships 
&lt;br&gt;Ships by type: barge carrier 2, bulk carrier 6, cargo ship 51, chemical tanker 15, container ship 298, Liquified Gas Carrier 6, passenger ship 4, petroleum tanker 10, refrigerated cargo 3, roll-on/roll-off ship 6 (2010 est.)
Ferries operate mostly between mainland Germany and its islands, serving both tourism and freight transport. Car ferries also operate across the Baltic Sea to the Nordic countries, Russia and the Baltic countries. Rail ferries operate across the Fehmahrnbelt, from Rostock to Sweden (both carrying passenger trains) and from the Mukran port in Sassnitz on the island of Rügen to numerous Baltic Sea destinations (freight only).
## See also.
&lt;br&gt;

</doc>
<doc id="11933" url="https://en.wikipedia.org/wiki?curid=11933" title="Military of Germany (disambiguation)">
Military of Germany (disambiguation)

Military of Germany may refer to:

</doc>
<doc id="11934" url="https://en.wikipedia.org/wiki?curid=11934" title="Foreign relations of Germany">
Foreign relations of Germany

The Federal Republic of Germany (FRG) is a Central European country and member of the European Union, G4, G7, the G20, the Organisation for Economic Co-operation and Development and the North Atlantic Treaty Organization (NATO). It maintains a network of 229 diplomatic missions abroad and holds relations with more than 190 countries. As one of the world's leading industrialized countries it is recognized as a major power in European and global affairs.
## Primary institutions and actors.
### Federal Cabinet.
The three cabinet-level ministries responsible for guiding Germany's foreign policy are the Ministry of Defense, the Ministry of Economic Cooperation and Development and the Federal Foreign Office. In practice, most German federal departments play some role in shaping foreign policy in the sense that there are few policy areas left that remain outside of international jurisdiction. The bylaws of the Federal Cabinet (as delineated in Germany's Basic Law), however, assign the Federal Foreign Office a coordinating function. Accordingly, other ministries may only invite foreign guests or participate in treaty negotiations with the approval of the Federal Foreign Office.
### Bundestag.
With respect to foreign policy, the Bundestag acts in a supervisory capacity. Each of its committees – most notably the foreign relations committee – oversees the country's foreign policy. The consent of the Bundestag (and insofar as Länder are impacted, the Bundesrat) is required to ratify foreign treaties. If a treaty legislation passes first reading, it is referred to the Committee on Foreign Affairs, which is capable of delaying ratification and prejudice decision through its report to the Bundestag.
In 1994, a full EU Committee was also created for the purpose of addressing the large flow of EU-related topics and legislation. Also, the committee has the mandate to speak on behalf of the Bundestag and represent it when deciding an EU policy position. A case in point was the committee's involvement regarding the European Union's eastern enlargement wherein the Committee on Foreign Affairs is responsible for relations with ECE states while the EU Committee is tasked with the negotiations.
### NGOs.
There is a raft of NGOs in Germany that engage foreign policy issues. These NGOs include think-tanks (German Council on Foreign Relations), single-issue lobbying organizations (Amnesty International), as well as other organizations that promote stronger bilateral ties between Germany and other countries (Atlantic Bridge). While the budgets and methods of NGOs are distinct, the overarching goal to persuade decision-makers to the wisdom of their own views is a shared one. In 2004, a new German governance framework, particularly on foreign and security policy areas, emerged where NGOs are integrated into actual policymaking. The idea is that the cooperation between state and civil society groups increases the quality of conflict resolution, development cooperation and humanitarian aid for fragile states. The framework seeks to benefit from the expertise of the NGOs in exchange for these groups to have a chance for influencing foreign policy.
## Disputes.
In 2001, the discovery that the terrorist cell which carried out the attacks against the United States on 11 September 2001, was based in Hamburg, sent shock waves through the country.
The government of Chancellor Gerhard Schröder backed the following U.S. military actions, sending Bundeswehr troops to Afghanistan to lead a joint NATO program to provide security in the country after the ousting of the Taliban.
Nearly all of the public was strongly against America's 2003 invasion of Iraq, and any deployment of troops. This position was shared by the SPD/Green government, which led to some friction with the United States.
In August 2006, the German government disclosed a botched plot to bomb two German trains. The attack was to occur in July 2006 and involved a 21-year-old Lebanese man, identified only as Youssef Mohammed E. H. Prosecutors said Youssef and another man left suitcases stuffed with crude propane-gas bombs on the trains.
As of February 2007, Germany had about 3,000 NATO-led International Security Assistance Force force in Afghanistan as part of the War on Terrorism, the third largest contingent after the United States (14,000) and the United Kingdom (5,200). German forces are mostly in the more secure north of the country.
However, Germany, along with some other larger European countries (with the exception of the UK and the Netherlands), have been criticised by the UK and Canada for not sharing the burden of the more intensive combat operations in southern Afghanistan.
## Global initiatives.
### Humanitarian aid.
Germany is the largest net contributor to the United Nations and has several development agencies working in Africa and the Middle East. The development policy of the Federal Republic of Germany is an independent area of German foreign policy. It is formulated by the Federal Ministry for Economic Cooperation and Development (BMZ) and carried out by the implementing organisations. The German government sees development policy as a joint responsibility of the international community. It is the world's third biggest aid donor after the United States and France. Germany spent 0.37 per cent of its gross domestic product (GDP) on development, which is below the government's target of increasing aid to 0.51 per cent of GDP by 2010. The international target of 0.7% of GNP would have not been reached either.
## International organizations.
Germany is a member of the Council of Europe, European Union, European Space Agency, G4, G8, International Monetary Fund, NATO, OECD, Organization for Security and Co-operation in Europe, UN, World Bank Group and the World Trade Organization.
### European Union.
European integration has gone a long way since the European Coal and Steel Community (ECSC) and the Elysée Treaty. Peaceful collaborations with its neighbors remain one of Germany's biggest political objectives, and Germany has been on the forefront of most achievements made in European integration:
Most of the social issues facing European countries in general: immigration, aging populations, straining social-welfare and pension systems – are all important in Germany.
Germany seeks to maintain peace through the "deepening" of integration among current members of the European Union member states
Germany has been the largest net contributor to EU budgets for decades (in absolute terms – given Germany's comparatively large population – not per capita) and seeks to limit the growth of these net payments in the enlarged union.
### NATO.
Under the doctrine introduced by the 2003 Defense Policy Guidelines, Germany continues to give priority to the transatlantic partnership with the United States through the North Atlantic Treaty Organization. However, Germany is giving increasing attention to coordinating its policies with the European Union through the Common Foreign and Security Policy.
### UN.
The German Federal Government began an initiative to obtain a permanent seat in the United Nations Security Council, as part of the Reform of the United Nations. This would require approval of a two-thirds majority of the member states and approval of all five Security Council veto powers.
This aspiration could be successful due to Germany's good relations with the People's Republic of China and the Russian Federation. Germany is a stable and democratic republic and a G7 country which are also favourable attributes. The United Kingdom and France support German ascension to the supreme body. The U.S. is sending mixed signals.
NATO member states, including Germany, decided not to sign the UN treaty on the Prohibition of Nuclear Weapons, a binding agreement for negotiations for the total elimination of nuclear weapons, supported by more than 120 nations.
## Europe.
### Balkan states.
The German government was a strong supporter of the enlargement of NATO.
Germany was one of the first nations to recognize Croatia and Slovenia as independent nations, rejecting the concept of Yugoslavia as the only legitimate political order in the Balkans (unlike other European powers, who first proposed a pro-Belgrade policy). This is why Serb authorities sometimes referred to "new German imperialism" as one of the main reasons for Yugoslavia's collapse. German troops participate in the multinational efforts to bring "peace and stability" to the Balkans.
### Central Europe.
Weimar triangle (France, Germany and Poland); Germany continues to be active economically in the states of Central Europe, and to actively support the development of democratic institutions. In the 2000s, Germany has been arguably the centerpiece of the European Union (though the importance of France cannot be overlooked in this connection).

</doc>
<doc id="11935" url="https://en.wikipedia.org/wiki?curid=11935" title="Politics of Germany">
Politics of Germany

Germany is a democratic, federal parliamentary republic, where federal legislative power is vested in the Bundestag (the parliament of Germany) and the Bundesrat (the representative body of the Länder, Germany's regional states).
The federal system has, since 1949, been dominated by the Christian Democratic Union (CDU) and the Social Democratic Party of Germany (SPD). The judiciary of Germany is independent of the executive and the legislature, while it is common for leading members of the executive to be members of the legislature as well. The political system is laid out in the 1949 constitution, the "Grundgesetz" (Basic Law), which remained in effect with minor amendments after German reunification in 1990.
The constitution emphasizes the protection of individual liberty in an extensive catalogue of human and civil rights and divides powers both between the federal and state levels and between the legislative, executive and judicial branches.
West Germany was a founding member of the European Community in 1958, which became the EU in 1993. Germany is part of the Schengen Area, and has been a member of the eurozone since 1999. It is a member of the United Nations, NATO, the G7, the G20 and the OECD.
## History.
### Prior to 1998.
Beginning with the election of Konrad Adenauer in 1949, the Federal Republic of Germany had Christian Democratic chancellors for 20 years until a coalition between the Social Democrats and the Liberals took over. From 1982, Christian Democratic leader Helmut Kohl was chancellor in a coalition with the Liberals for 16 years. In this period fell the reunification of Germany, in 1990: the German Democratic Republic joined the Federal Republic. In the former GDR's territory, five "Länder" (states) were established or reestablished. The two parts of Berlin united as one "Land" (state).
The political system of the Federal Republic remained more or less unchanged. Specific provisions for the former GDR territory were enabled via the "unification treaty" between the Federal Republic and the GDR prior to the unification day of 3 October 1990. However, Germany saw in the following two distinct party systems: the Green party and the Liberals remained mostly West German parties, while in the East the former socialist state party, now called PDS, flourished along with the Christian Democrats and Social Democrats.
### 1998–2005.
After 16 years of the Christian–Liberal coalition, led by Helmut Kohl, the Social Democratic Party of Germany (SPD) together with the Greens won the Bundestag elections of 1998. SPD vice chairman Gerhard Schröder positioned himself as a centrist candidate, in contradiction to the leftist SPD chairman Oskar Lafontaine. The Kohl government was hurt at the polls by slower economic growth in the East in the previous two years, and constantly high unemployment. The final margin of victory was sufficiently high to permit a "red-green" coalition of the SPD with Alliance 90/The Greens ("Bündnis '90/Die Grünen"), bringing the Greens into a national government for the first time.
Initial problems of the new government, marked by policy disputes between the moderate and traditional left wings of the SPD, resulted in some voter disaffection. Lafontaine left the government (and later his party) in early 1999. The CDU won in some important state elections but was hit in 2000 by a party donation scandal from the Kohl years. As a result of this Christian Democratic Union (CDU) crisis, Angela Merkel became chair.
The next election for the "Bundestag" was on 22 September 2002. Gerhard Schröder led the coalition of SPD and Greens to an eleven-seat victory over the Christian Democrat challengers headed by Edmund Stoiber (CSU). Three factors are generally cited that enabled Schröder to win the elections despite poor approval ratings a few months before and a weaker economy: good handling of the 100-year flood, firm opposition to the US 2003 invasion of Iraq, and Stoiber's unpopularity in the east, which cost the CDU crucial seats there.
In its second term, the red–green coalition lost several very important state elections, for example in Lower Saxony where Schröder was the prime minister from 1990 to 1998. On 20 April 2003, chancellor Schröder announced massive labor market reforms, called Agenda 2010, that cut unemployment benefits. Although these reforms sparked massive protests, they are now credited with being in part responsible for the relatively strong economic performance of Germany during the euro-crisis and the decrease in unemployment in Germany in the years 2006–2007.
### 2005–2009.
On 22 May 2005 the SPD received a devastating defeat in its former heartland, North Rhine-Westphalia. Half an hour after the election results, the SPD chairman Franz Müntefering announced that the chancellor would clear the way for new federal elections.
This took the republic by surprise, especially because the SPD was below 20% in polls at the time. The CDU quickly announced Angela Merkel as Christian Democrat candidate for chancellor, aspiring to be the first female chancellor in German history.
New for the 2005 election was the alliance between the newly formed Electoral Alternative for Labor and Social Justice (WASG) and the PDS, planning to fuse into a common party (see Left Party.PDS). With the former SPD chairman, Oskar Lafontaine for the WASG and Gregor Gysi for the PDS as prominent figures, this alliance soon found interest in the media and in the population. Polls in July saw them as high as 12%.
Whereas in May and June 2005 victory of the Christian Democrats seemed highly likely, with some polls giving them an absolute majority, this picture changed shortly before the election on 18 September 2005.
The election results of 18 September were surprising because they differed widely from the polls of the previous weeks. The Christian Democrats even lost votes compared to 2002, narrowly reaching the first place with only 35.2%, and failed to get a majority for a "black–yellow" government of CDU/CSU and liberal FDP. But the red–green coalition also failed to get a majority, with the SPD losing votes, but polling 34.2% and the greens staying at 8.1%. The Left reached 8.7% and entered the "Bundestag", whereas the far-right NPD only got 1.6%.
The most likely outcome of coalition talks was a so-called grand coalition between the Christian Democrats (CDU/CSU) and the Social Democrats (SPD). Three party coalitions and coalitions involving The Left had been ruled out by all interested parties (including The Left itself). On 22 November 2005, Angela Merkel was sworn in by president Horst Köhler for the office of Bundeskanzlerin.
The existence of the grand coalition on federal level helped smaller parties' electoral prospects in state elections. Since in 2008, the CSU lost its absolute majority in Bavaria and formed a coalition with the FDP, the grand coalition had no majority in the "Bundesrat" and depended on FDP votes on important issues. In November 2008, the SPD re-elected its already retired chair Franz Müntefering and made Frank-Walter Steinmeier its leading candidate for the federal election in September 2009.
As a result of that federal election, the grand coalition brought losses for both parties and came to an end. The SPD suffered the heaviest losses in its history and was unable to form a coalition government. The CDU/CSU had only little losses but also reached a new historic low with its worst result since 1949. The three smaller parties thus had more seats in the German "Bundestag" than ever before, with the liberal party FDP winning 14.6% of votes.
### 2009–2013.
The CDU/CSU and FDP together held 332 seats (of 622 total seats) and had been in coalition since 27 October 2009. Angela Merkel was re-elected as chancellor, and Guido Westerwelle served as the foreign minister and vice chancellor of Germany. After being elected into the federal government, the FDP suffered heavy losses in the following state elections. The FDP had promised to lower taxes in the electoral campaign, but after being part of the coalition they had to concede that this was not possible due to the economic crisis of 2008. Because of the losses, Guido Westerwelle had to resign as chair of the FDP in favor of Philipp Rösler, Federal minister of health, who was consequently appointed as vice chancellor. Shortly after, Philipp Rösler changed office and became federal minister of economics and technology.
After their electoral fall, the Social Democrats were led by Sigmar Gabriel, a former federal minister and prime minister of Lower Saxony, and by Frank-Walter Steinmeier as the head of the parliamentary group. He resigned on 16 January 2017 and proposed his longtime friend and president of European Parliament Martin Schulz as his successor and chancellor candidate.
Germany has seen increased political activity by citizens outside the established political parties with respect to local and environmental issues such as the location of Stuttgart 21, a railway hub, and construction of Berlin Brandenburg Airport.
### 2013–2017.
The 18th federal elections in Germany resulted in the re-election of Angela Merkel and her Christian democratic parliamentary group of the parties CDU and CSU, receiving 41.5% of all votes. Following Merkel's first two historically low results, her third campaign marked the CDU/CSU's best result since 1994 and only for the second time in German history the possibility of gaining an absolute majority. Their former coalition partner, the FDP, narrowly failed to reach the 5% threshold and did not gain seats in the Bundestag.
Not having reached an absolute majority, the CDU/CSU formed a grand coalition with the social-democratic SPD after the longest coalition talks in history, making the head of the party Sigmar Gabriel vice-chancellor and federal Minister for Economic Affairs and Energy. Together they held 504 of a total 631 seats (CDU/CSU 311 and SPD 193). The only two opposition parties were The Left (64 seats) and Alliance '90/The Greens (63 seats), which was acknowledged as creating a critical situation in which the opposition parties did not even have enough seats to use the special controlling powers of the opposition.
### 2017–2021.
The 19th federal elections in Germany took place on 24 September 2017. The two big parties, the conservative parliamentary group CDU/CSU and the social democrat SPD were in a similar situation as in 2009, after the last grand coalition had ended, and both had suffered severe losses; reaching their second worst and worst result respectively in 2017.
Many votes in the 2017 elections went to smaller parties, leading the right-wing populist party AfD (Alternative for Germany) into the Bundestag which marked a big shift in German politics since it was the first far-right party to win seats in parliament since the 1950s.
With Merkel's candidacy for a fourth term, the CDU/CSU only reached 33.0% of the votes, but won the highest number of seats, leaving no realistic coalition option without the CDU/CSU. As all parties in the Bundestag strictly ruled out a coalition with the AfD, the only options for a majority coalition were a so-called "Jamaican" coalition (CDU/CSU, FDP, Greens; named after the party colors resembling those of the Jamaican flag) and a grand coalition with the SPD, which was at first opposed by the Social Democrats and their leader Martin Schulz.
Coalition talks between the three parties of the "Jamaican" coalition were held but the final proposal was rejected by the liberals of the FDP, leaving the government in limbo. Following the unprecedented situation, for the first time in German history different minority coalitions or even direct snap coalitions were also heavily discussed. At this point, Federal President Steinmeier invited leaders of all parties for talks about a government, being the first President in the history of the Federal Republic to do so.
Official coalition talks between CDU/CSU and SPD started in January 2018 and led to a renewal of the grand coalition on 12 March 2018 as well as the subsequent re-election of Angela Merkel as chancellor.
Scheduled elections for the new Bundestag were held on 26 September 2021 during the COVID-19 pandemic. Angela Merkel did not candidate for a fifth term but left the field to her CDU party colleague Armin Laschet. In the elections the Social Democrats won the majority of votes ahead of the government-leading Union parties, however, coalition talks are still ongoing and no new government has been formed yet.
## Constitution.
The "Basic Law for the Federal Republic of Germany" (Grundgesetz der Bundesrepublik Deutschland) is the Constitution of Germany. It was formally approved on 8 May 1949, and, with the signature of the Allies of World War II on 12 May, came into effect on 23 May, as the constitution of those states of West Germany that were initially included within the Federal Republic. The 1949 Basic Law is a response to the perceived flaws of the 1919 Weimar Constitution, which failed to prevent the rise of the Nazi party in 1933. Since 1990, in the course of the reunification process after the fall of the Berlin Wall, the Basic Law also applies to the eastern states of the former German Democratic Republic.
## Executive.
### Head of state.
The German head of state is the Federal President. As in Germany's parliamentary system of government, the Federal Chancellor runs the government and day-to-day politics, while the role of the Federal President is mostly ceremonial. The Federal President, by their actions and public appearances, represents the state itself, its existence, its legitimacy, and unity. Their office involves an integrative role. Nearly all actions of the Federal President become valid only after a countersignature of a government member.
The President is not obliged by Constitution to refrain from political views. He or she is expected to give direction to general political and societal debates, but not in a way that links him to party politics. Most German Presidents were active politicians and party members prior to the office, which means that they have to change their political style when becoming president. The function comprises the official residence of Bellevue Palace.
Under Article 59 (1) of the Basic Law, the Federal President represents the Federal Republic of Germany in matters of international law, concludes treaties with foreign states on its behalf and accredits diplomats.
All federal laws must be signed by the President before they can come into effect; he or she does not have a veto, but the conditions for refusing to sign a law on the basis of unconstitutionality are the subject of debate. The office is currently held by Frank-Walter Steinmeier (since 2017). 
The Federal President does have a role in the political system, especially at the establishment of a new government and the dissolution of the Bundestag (parliament). This role is usually nominal but can become significant in case of political instability. Additionally, a Federal President together with the Federal Council can support the government in a "legislatory emergency state" to enable laws against the will of the Bundestag (Article 81 of the Basic Law). However, so far the Federal President has never had to use these "reserve powers".
### Head of government.
The "Bundeskanzler" (federal chancellor) heads the "Bundesregierung" (federal government) and thus the executive branch of the federal government. They are elected by and responsible to the "Bundestag", Germany's parliament. The other members of the government are the Federal Ministers; they are chosen by the Chancellor. Germany, like the United Kingdom, can thus be classified as a parliamentary system. The office is currently held by Olaf Scholz (since 2021). 
The Chancellor cannot be removed from office during a four-year term unless the "Bundestag" has agreed on a successor. This constructive vote of no confidence is intended to avoid a similar situation to that of the Weimar Republic in which the executive did not have enough support in the legislature to govern effectively, but the legislature was too divided to name a successor. The current system also prevents the Chancellor from calling a snap election.
Except in the periods 1969–1972 and 1976–1982, when the Social Democratic party of Chancellor Brandt and Schmidt came in second in the elections, the chancellor has always been the candidate of the largest party, usually supported by a coalition of two parties with a majority in the parliament. The chancellor appoints one of the federal ministers as their deputy, who has the unofficial title Vice Chancellor (). The office is currently held by Robert Habeck (since 2021). 
### Cabinet.
The German Cabinet (Bundeskabinett or Bundesregierung) is the chief executive body of the Federal Republic of Germany. It consists of the chancellor and the cabinet ministers. The fundamentals of the cabinet's organization are set down in articles 62–69 of the Basic Law. The current cabinet is Scholz (since 2021). 
### Agencies.
Agencies of the German government include:
## Legislature.
Federal legislative power is divided between the "Bundestag" and the "Bundesrat". The "Bundestag" is directly elected by the German people, while the "Bundesrat" represents the governments of the regional states ("Länder"). The federal legislature has powers of exclusive jurisdiction and concurrent jurisdiction with the states in areas specified in the constitution.
The "Bundestag" is more powerful than the "Bundesrat" and only needs the latter's consent for proposed legislation related to revenue shared by the federal and state governments, and the imposition of responsibilities on the states. In practice, however, the agreement of the "Bundesrat" in the legislative process is often required, since federal legislation frequently has to be executed by state or local agencies. In the event of disagreement between the "Bundestag" and the "Bundesrat", either side can appeal to the (Mediation Committee), a conference committee-like body of 16 "Bundesrat" and 16 "Bundestag" members, to find a compromise.
### Bundestag.
The "Bundestag" (Federal Diet) is elected for a four-year term and consists of 598 or more members elected by a means of mixed-member proportional representation, which Germans call "personalised proportional representation". 299 members represent single-seat constituencies and are elected by a first past the post electoral system. Parties that obtain fewer constituency seats than their national share of the vote are allotted seats from party lists to make up the difference. In contrast, parties that obtain more constituency seats than their national share of the vote are allowed to keep these so-called overhang seats. In the parliament that was elected in 2009, there were 24 overhang seats, giving the "Bundestag" a total of 622 members. After Bundestag elections since 2013, other parties obtain extra seats ("balance seats") that offset advantages from their rival's overhang seats. The current "Bundestag" is the largest in German history with 709 members.
A party must receive either five percent of the national vote or win at least three directly elected seats to be eligible for non-constituency seats in the "Bundestag". This rule, often called the "five percent hurdle", was incorporated into Germany's election law to prevent political fragmentation and disproportionately influential minority parties.
The first "Bundestag" elections were held in the Federal Republic of Germany ("West Germany") on 14 August 1949. Following reunification, elections for the first all-German "Bundestag" were held on 2 December 1990. The last federal election was held on 26 September 2021.
## Judiciary.
Germany follows the civil law tradition. The judicial system comprises three types of courts.
The main difference between the Federal Constitutional Court and the Federal Court of Justice is that the Federal Constitutional Court may only be called if a constitutional matter within a case is in question (e.g. a possible violation of human rights in a criminal trial), while the Federal Court of Justice may be called in any case.
## Foreign relations.
Germany maintains a network of 229 diplomatic missions abroad and holds relations with more than 190 countries. It is the largest contributor to the budget of the European Union (providing 27%) and third largest contributor to the United Nations (providing 8%). Germany is a member of the NATO defence alliance, the Organisation of Economic Co-operation and Development (OECD), the G8, the G20, the World Bank and the International Monetary Fund (IMF).
Germany has played a leading role in the European Union since its inception and has maintained a strong alliance with France since the end of World War II. The alliance was especially close in the late 1980s and early 1990s under the leadership of Christian Democrat Helmut Kohl and Socialist François Mitterrand. Germany is at the forefront of European states seeking to advance the creation of a more unified European political, defence, and security apparatus. For a number of decades after WWII, the Federal Republic of Germany kept a notably low profile in international relations, because of both its recent history and its occupation by foreign powers.
During the Cold War, Germany's partition by the Iron Curtain made it a symbol of East–West tensions and a political battleground in Europe. However, Willy Brandt's "Ostpolitik" was a key factor in the "détente" of the 1970s. In 1999, Chancellor Gerhard Schröder's government defined a new basis for German foreign policy by taking a full part in the decisions surrounding the NATO war against Yugoslavia and by sending German troops into combat for the first time since World War II.
The governments of Germany and the United States are close political allies. The 1948 Marshall Plan and strong cultural ties have crafted a strong bond between the two countries, although Schröder's very vocal opposition to the Iraq War had suggested the end of Atlanticism and a relative cooling of German–American relations. The two countries are also economically interdependent: 5.0% of German exports in goods are US-bound and 3.5% of German imported goods originate from the US with a trade deficit of -63,678.5 million dollars for the United States (2017). Other signs of the close ties include the continuing position of German–Americans as the largest reported ethnic group in the US, and the status of Ramstein Air Base (near Kaiserslautern) as the largest US military community outside the US.
The policy on foreign aid is an important area of German foreign policy. It is formulated by the Federal Ministry for Economic Cooperation and Development (BMZ) and carried out by the implementing organisations. The German government sees development policy as a joint responsibility of the international community. It is the world's fourth biggest aid donor after the United States, the United Kingdom and France. Germany spent 0.37 per cent of its gross domestic product (GDP) on development, which is below the government's target of increasing aid to 0.51 per cent of GDP by 2010.
## Administrative divisions.
Germany comprises sixteen states that are collectively referred to as "Länder". Due to differences in size and population, the subdivision of these states varies especially between city-states ("Stadtstaaten") and states with larger territories ("Flächenländer"). For regional administrative purposes five states, namely Baden-Württemberg, Bavaria, Hesse, North Rhine-Westphalia and Saxony, consist of a total of 22 Government Districts ("Regierungsbezirke"). As of 2009 Germany is divided into 403 districts ("Kreise") on municipal level, these consist of 301 rural districts and 102 urban districts.

</doc>
<doc id="11936" url="https://en.wikipedia.org/wiki?curid=11936" title="Germany/History">
Germany/History



</doc>
<doc id="11947" url="https://en.wikipedia.org/wiki?curid=11947" title="Good argument">
Good argument



</doc>
<doc id="11952" url="https://en.wikipedia.org/wiki?curid=11952" title="Gnu/Linux">
Gnu/Linux



</doc>
<doc id="11953" url="https://en.wikipedia.org/wiki?curid=11953" title="History of geometry">
History of geometry

Geometry (from the ; "geo-" "earth", "-metron" "measurement") arose as the field of knowledge dealing with spatial relationships. Geometry was one of the two fields of pre-modern mathematics, the other being the study of numbers (arithmetic).
Classic geometry was focused in compass and straightedge constructions. Geometry was revolutionized by Euclid, who introduced mathematical rigor and the axiomatic method still in use today. His book, "The Elements" is widely considered the most influential textbook of all time, and was known to all educated people in the West until the middle of the 20th century.
In modern times, geometric concepts have been generalized to a high level of abstraction and complexity, and have been subjected to the methods of calculus and abstract algebra, so that many modern branches of the field are barely recognizable as the descendants of early geometry. (See Areas of mathematics and Algebraic geometry.)
## Early geometry.
The earliest recorded beginnings of geometry can be traced to early peoples, who discovered obtuse triangles in the ancient Indus Valley (see Harappan mathematics), and ancient Babylonia (see Babylonian mathematics) from around 3000 BC. Early geometry was a collection of empirically discovered principles concerning lengths, angles, areas, and volumes, which were developed to meet some practical need in surveying, construction, astronomy, and various crafts. Among these were some surprisingly sophisticated principles, and a modern mathematician might be hard put to derive some of them without the use of calculus and algebra . For example, both the Egyptians and the Babylonians were aware of versions of the Pythagorean theorem about 1500 years before Pythagoras and the Indian Sulba Sutras around 800 BC contained the first statements of the theorem; the Egyptians had a correct formula for the volume of a frustum of a square pyramid.
### Egyptian geometry.
The ancient Egyptians knew that they could approximate the area of a circle as follows:
Problem 50 of the Ahmes papyrus uses these methods to calculate the area of a circle, according to a rule that the area is equal to the square of 8/9 of the circle's diameter. This assumes that is 4×(8/9)2 (or 3.160493...), with an error of slightly over 0.63 percent. This value was slightly less accurate than the calculations of the Babylonians (25/8 = 3.125, within 0.53 percent), but was not otherwise surpassed until Archimedes' approximation of 211875/67441 = 3.14163, which had an error of just over 1 in 10,000.
Ahmes knew of the modern 22/7 as an approximation for , and used it to split a hekat, hekat x 22/x x 7/22 = hekat; however, Ahmes continued to use the traditional 256/81 value for for computing his hekat volume found in a cylinder.
Problem 48 involved using a square with side 9 units. This square was cut into a 3x3 grid. The diagonal of the corner squares were used to make an irregular octagon with an area of 63 units. This gave a second value for of 3.111...
The two problems together indicate a range of values for between 3.11 and 3.16.
Problem 14 in the Moscow Mathematical Papyrus gives the only ancient example finding the volume of a frustum of a pyramid, describing the correct formula:
where "a" and "b" are the base and top side lengths of the truncated pyramid and "h" is the height.
### Babylonian geometry.
The Babylonians may have known the general rules for measuring areas and volumes. They measured the circumference of a circle as three times the diameter and the area as one-twelfth the square of the circumference, which would be correct if "π" is estimated as 3. The volume of a cylinder was taken as the product of the base and the height, however, the volume of the frustum of a cone or a square pyramid was incorrectly taken as the product of the height and half the sum of the bases. The Pythagorean theorem was also known to the Babylonians. Also, there was a recent discovery in which a tablet used "π" as 3 and 1/8. The Babylonians are also known for the Babylonian mile, which was a measure of distance equal to about seven miles today. This measurement for distances eventually was converted to a time-mile used for measuring the travel of the Sun, therefore, representing time. There have been recent discoveries showing that ancient Babylonians may have discovered astronomical geometry nearly 1400 years before Europeans did.
### Vedic India geometry.
The Indian Vedic period had a tradition of geometry, mostly expressed in the construction of elaborate altars.
Early Indian texts (1st millennium BC) on this topic include the "Satapatha Brahmana" and the "Śulba Sūtras".
According to , the "Śulba Sūtras" contain "the earliest extant verbal expression of the Pythagorean Theorem in the world, although it had already been known to the Old Babylonians." The diagonal rope (') of an oblong (rectangle) produces both which the flank ("pārśvamāni") and the horizontal (') &lt;ropes&gt; produce separately." 
They contain lists of Pythagorean triples, which are particular cases of Diophantine equations.
They also contain statements (that with hindsight we know to be approximate) about squaring the circle and "circling the square."
The "Baudhayana Sulba Sutra", the best-known and oldest of the "Sulba Sutras" (dated to the 8th or 7th century BC) contains examples of simple Pythagorean triples, such as: formula_2, formula_3, formula_4, formula_5, and formula_6 as well as a statement of the Pythagorean theorem for the sides of a square: "The rope which is stretched across the diagonal of a square produces an area double the size of the original square." It also contains the general statement of the Pythagorean theorem (for the sides of a rectangle): "The rope stretched along the length of the diagonal of a rectangle makes an area which the vertical and horizontal sides make together."
According to mathematician S. G. Dani, the Babylonian cuneiform tablet Plimpton 322 written c. 1850 BC "contains fifteen Pythagorean triples with quite large entries, including (13500, 12709, 18541) which is a primitive triple, indicating, in particular, that there was sophisticated understanding on the topic" in Mesopotamia in 1850 BC. "Since these tablets predate the Sulbasutras period by several centuries, taking into account the contextual appearance of some of the triples, it is reasonable to expect that similar understanding would have been there in India." Dani goes on to say:
 "As the main objective of the "Sulvasutras" was to describe the constructions of altars and the geometric principles involved in them, the subject of Pythagorean triples, even if it had been well understood may still not have featured in the "Sulvasutras". The occurrence of the triples in the "Sulvasutras" is comparable to mathematics that one may encounter in an introductory book on architecture or another similar applied area, and
would not correspond directly to the overall knowledge on the topic at that time. Since, unfortunately, no other contemporaneous sources have been found it may never be possible to settle this issue satisfactorily."
In all, three "Sulba Sutras" were composed. The remaining two, the "Manava Sulba Sutra" composed by Manava (fl. 750-650 BC) and the "Apastamba Sulba Sutra", composed by Apastamba (c. 600 BC), contained results similar to the "Baudhayana Sulba Sutra".
## Greek geometry.
### Classical Greek geometry.
For the ancient Greek mathematicians, geometry was the crown jewel of their sciences, reaching a completeness and perfection of methodology that no other branch of their knowledge had attained. They expanded the range of geometry to many new kinds of figures, curves, surfaces, and solids; they changed its methodology from trial-and-error to logical deduction; they recognized that geometry studies "eternal forms", or abstractions, of which physical objects are only approximations; and they developed the idea of the "axiomatic method", still in use today.
#### Thales and Pythagoras.
Thales (635-543 BC) of Miletus (now in southwestern Turkey), was the first to whom deduction in mathematics is attributed. There are five geometric propositions for which he wrote deductive proofs, though his proofs have not survived. Pythagoras (582-496 BC) of Ionia, and later, Italy, then colonized by Greeks, may have been a student of Thales, and traveled to Babylon and Egypt. The theorem that bears his name may not have been his discovery, but he was probably one of the first to give a deductive proof of it. He gathered a group of students around him to study mathematics, music, and philosophy, and together they discovered most of what high school students learn today in their geometry courses. In addition, they made the profound discovery of incommensurable lengths and irrational numbers.
#### Plato.
Plato (427-347 BC) was a philosopher, highly esteemed by the Greeks. There is a story that he had inscribed above the entrance to his famous school, "Let none ignorant of geometry enter here." However, the story is considered to be untrue. Though he was not a mathematician himself, his views on mathematics had great influence. Mathematicians thus accepted his belief that geometry should use no tools but compass and straightedge – never measuring instruments such as a marked ruler or a protractor, because these were a workman's tools, not worthy of a scholar. This dictum led to a deep study of possible compass and straightedge constructions, and three classic construction problems: how to use these tools to trisect an angle, to construct a cube twice the volume of a given cube, and to construct a square equal in area to a given circle. The proofs of the impossibility of these constructions, finally achieved in the 19th century, led to important principles regarding the deep structure of the real number system. Aristotle (384-322 BC), Plato's greatest pupil, wrote a treatise on methods of reasoning used in deductive proofs (see Logic) which was not substantially improved upon until the 19th century.
### Hellenistic geometry.
#### Euclid.
Euclid (c. 325-265 BC), of Alexandria, probably a student at the Academy founded by Plato, wrote a treatise in 13 books (chapters), titled "The Elements of Geometry", in which he presented geometry in an ideal axiomatic form, which came to be known as Euclidean geometry. The treatise is not a compendium of all that the Hellenistic mathematicians knew at the time about geometry; Euclid himself wrote eight more advanced books on geometry. We know from other references that Euclid's was not the first elementary geometry textbook, but it was so much superior that the others fell into disuse and were lost. He was brought to the university at Alexandria by Ptolemy I, King of Egypt.
"The Elements" began with definitions of terms, fundamental geometric principles (called "axioms" or "postulates"), and general quantitative principles (called "common notions") from which all the rest of geometry could be logically deduced. Following are his five axioms, somewhat paraphrased to make the English easier to read.
Concepts, that are now understood as algebra, were expressed geometrically by Euclid, a method referred to as Greek geometric algebra.
#### Archimedes.
Archimedes (287-212 BC), of Syracuse, Sicily, when it was a Greek city-state, is often considered to be the greatest of the Greek mathematicians, and occasionally even named as one of the three greatest of all time (along with Isaac Newton and Carl Friedrich Gauss). Had he not been a mathematician, he would still be remembered as a great physicist, engineer, and inventor. In his mathematics, he developed methods very similar to the coordinate systems of analytic geometry, and the limiting process of integral calculus. The only element lacking for the creation of these fields was an efficient algebraic notation in which to express his concepts.
#### After Archimedes.
After Archimedes, Hellenistic mathematics began to decline. There were a few minor stars yet to come, but the golden age of geometry was over. Proclus (410-485), author of "Commentary on the First Book of Euclid", was one of the last important players in Hellenistic geometry. He was a competent geometer, but more importantly, he was a superb commentator on the works that preceded him. Much of that work did not survive to modern times, and is known to us only through his commentary. The Roman Republic and Empire that succeeded and absorbed the Greek city-states produced excellent engineers, but no mathematicians of note.
The great Library of Alexandria was later burned. There is a growing consensus among historians that the Library of Alexandria likely suffered from several destructive events, but that the destruction of Alexandria's pagan temples in the late 4th century was probably the most severe and final one. The evidence for that destruction is the most definitive and secure. Caesar's invasion may well have led to the loss of some 40,000-70,000 scrolls in a warehouse adjacent to the port (as Luciano Canfora argues, they were likely copies produced by the Library intended for export), but it is unlikely to have affected the Library or Museum, given that there is ample evidence that both existed later.
Civil wars, decreasing investments in maintenance and acquisition of new scrolls and generally declining interest in non-religious pursuits likely contributed to a reduction in the body of material available in the Library, especially in the 4th century. The Serapeum was certainly destroyed by Theophilus in 391, and the Museum and Library may have fallen victim to the same campaign.
## Classical Indian geometry.
In the Bakhshali manuscript, there is a handful of geometric problems (including problems about volumes of irregular solids). The Bakhshali manuscript also "employs a decimal place value system with a dot for zero." Aryabhata's "Aryabhatiya" (499) includes the computation of areas and volumes.
Brahmagupta wrote his astronomical work "" in 628. Chapter 12, containing 66 Sanskrit verses, was divided into two sections: "basic operations" (including cube roots, fractions, ratio and proportion, and barter) and "practical mathematics" (including mixture, mathematical series, plane figures, stacking bricks, sawing of timber, and piling of grain). In the latter section, he stated his famous theorem on the diagonals of a cyclic quadrilateral:
Brahmagupta's theorem: If a cyclic quadrilateral has diagonals that are perpendicular to each other, then the perpendicular line drawn from the point of intersection of the diagonals to any side of the quadrilateral always bisects the opposite side.
Chapter 12 also included a formula for the area of a cyclic quadrilateral (a generalization of Heron's formula), as well as a complete description of rational triangles ("i.e." triangles with rational sides and rational areas).
Brahmagupta's formula: The area, "A", of a cyclic quadrilateral with sides of lengths "a", "b", "c", "d", respectively, is given by
where "s", the semiperimeter, given by: formula_8
Brahmagupta's Theorem on rational triangles: A triangle with rational sides formula_9 and rational area is of the form:
for some rational numbers formula_11 and formula_12.
## Chinese geometry.
The first definitive work (or at least oldest existent) on geometry in China was the "Mo Jing", the Mohist canon of the early philosopher Mozi (470-390 BC). It was compiled years after his death by his followers around the year 330 BC. Although the "Mo Jing" is the oldest existent book on geometry in China, there is the possibility that even older written material existed. However, due to the infamous Burning of the Books in a political maneuver by the Qin Dynasty ruler Qin Shihuang (r. 221-210 BC), multitudes of written literature created before his time were purged. In addition, the "Mo Jing" presents geometrical concepts in mathematics that are perhaps too advanced not to have had a previous geometrical base or mathematic background to work upon.
The "Mo Jing" described various aspects of many fields associated with physical science, and provided a small wealth of information on mathematics as well. It provided an 'atomic' definition of the geometric point, stating that a line is separated into parts, and the part which has no remaining parts (i.e. cannot be divided into smaller parts) and thus forms the extreme end of a line is a point. Much like Euclid's first and third definitions and Plato's 'beginning of a line', the "Mo Jing" stated that "a point may stand at the end (of a line) or at its beginning like a head-presentation in childbirth. (As to its invisibility) there is nothing similar to it." Similar to the atomists of Democritus, the "Mo Jing" stated that a point is the smallest unit, and cannot be cut in half, since 'nothing' cannot be halved. It stated that two lines of equal length will always finish at the same place, while providing definitions for the "comparison of lengths" and for "parallels", along with principles of space and bounded space. It also described the fact that planes without the quality of thickness cannot be piled up since they cannot mutually touch. The book provided definitions for circumference, diameter, and radius, along with the definition of volume.
The Han Dynasty (202 BC-220 AD) period of China witnessed a new flourishing of mathematics. One of the oldest Chinese mathematical texts to present geometric progressions was the "Suàn shù shū" of 186 BC, during the Western Han era. The mathematician, inventor, and astronomer Zhang Heng (78-139 AD) used geometrical formulas to solve mathematical problems. Although rough estimates for pi (π) were given in the "Zhou Li" (compiled in the 2nd century BC), it was Zhang Heng who was the first to make a concerted effort at creating a more accurate formula for pi. Zhang Heng approximated pi as 730/232 (or approx 3.1466), although he used another formula of pi in finding a spherical volume, using the square root of 10 (or approx 3.162) instead. Zu Chongzhi (429-500 AD) improved the accuracy of the approximation of pi to between 3.1415926 and 3.1415927, with 355⁄113 (密率, Milü, detailed approximation) and 22⁄7 (约率, Yuelü, rough approximation) being the other notable approximation. In comparison to later works, the formula for pi given by the French mathematician Franciscus Vieta (1540-1603) fell halfway between Zu's approximations.
### "The Nine Chapters on the Mathematical Art".
"The Nine Chapters on the Mathematical Art", the title of which first appeared by 179 AD on a bronze inscription, was edited and commented on by the 3rd century mathematician Liu Hui from the Kingdom of Cao Wei. This book included many problems where geometry was applied, such as finding surface areas for squares and circles, the volumes of solids in various three-dimensional shapes, and included the use of the Pythagorean theorem. The book provided illustrated proof for the Pythagorean theorem, contained a written dialogue between of the earlier Duke of Zhou and Shang Gao on the properties of the right angle triangle and the Pythagorean theorem, while also referring to the astronomical gnomon, the circle and square, as well as measurements of heights and distances. The editor Liu Hui listed pi as 3.141014 by using a 192 sided polygon, and then calculated pi as 3.14159 using a 3072 sided polygon. This was more accurate than Liu Hui's contemporary Wang Fan, a mathematician and astronomer from Eastern Wu, would render pi as 3.1555 by using 142⁄45. Liu Hui also wrote of mathematical surveying to calculate distance measurements of depth, height, width, and surface area. In terms of solid geometry, he figured out that a wedge with rectangular base and both sides sloping could be broken down into a pyramid and a tetrahedral wedge. He also figured out that a wedge with trapezoid base and both sides sloping could be made to give two tetrahedral wedges separated by a pyramid. Furthermore, Liu Hui described Cavalieri's principle on volume, as well as Gaussian elimination. From the "Nine Chapters", it listed the following geometrical formulas that were known by the time of the Former Han Dynasty (202 BCE–9 CE).
Areas for the
Volumes for the
Continuing the geometrical legacy of ancient China, there were many later figures to come, including the famed astronomer and mathematician Shen Kuo (1031-1095 CE), Yang Hui (1238-1298) who discovered Pascal's Triangle, Xu Guangqi (1562-1633), and many others.
## Islamic Golden Age.
By the beginning of the 9th century, the "Islamic Golden Age" flourished, the establishment of the House of Wisdom in Baghdad marking a separate tradition of science in the medieval Islamic world, building not only Hellenistic but also on Indian sources.
Although the Islamic mathematicians are most famed for their work on algebra, number theory and number systems, they also made considerable contributions to geometry, trigonometry and mathematical astronomy, and were responsible for the development of algebraic geometry.
Al-Mahani (born 820) conceived the idea of reducing geometrical problems such as duplicating the cube to problems in algebra. Al-Karaji (born 953) completely freed algebra from geometrical operations and replaced them with the arithmetical type of operations which are at the core of algebra today.
Thābit ibn Qurra (known as Thebit in Latin) (born 836) contributed to a number of areas in mathematics, where he played an important role in preparing the way for such important mathematical discoveries as the extension of the concept of number to (positive) real numbers, integral calculus, theorems in spherical trigonometry, analytic geometry, and non-Euclidean geometry. In astronomy Thabit was one of the first reformers of the Ptolemaic system, and in mechanics he was a founder of statics. An important geometrical aspect of Thabit's work was his book on the composition of ratios. In this book, Thabit deals with arithmetical operations applied to ratios of geometrical quantities. The Greeks had dealt with geometric quantities but had not thought of them in the same way as numbers to which the usual rules of arithmetic could be applied. By introducing arithmetical operations on quantities previously regarded as geometric and non-numerical, Thabit started a trend which led eventually to the generalisation of the number concept.
In some respects, Thabit is critical of the ideas of Plato and Aristotle, particularly regarding motion. It would seem that here his ideas are based on an acceptance of using arguments concerning motion in his geometrical arguments. Another important contribution Thabit made to geometry was his generalization of the Pythagorean theorem, which he extended from special right triangles to all triangles in general, along with a general proof.
Ibrahim ibn Sinan ibn Thabit (born 908), who introduced a method of integration more general than that of Archimedes, and al-Quhi (born 940) were leading figures in a revival and continuation of Greek higher geometry in the Islamic world. These mathematicians, and in particular Ibn al-Haytham, studied optics and investigated the optical properties of mirrors made from conic sections.
Astronomy, time-keeping and geography provided other motivations for geometrical and trigonometrical research. For example, Ibrahim ibn Sinan and his grandfather Thabit ibn Qurra both studied curves required in the construction of sundials. Abu'l-Wafa and Abu Nasr Mansur both applied spherical geometry to astronomy.
A 2007 paper in the journal "Science" suggested that girih tiles possessed properties consistent with self-similar fractal quasicrystalline tilings such as the Penrose tilings.
## Renaissance.
The transmission of the Greek Classics to medieval Europe via the Arabic literature of the 9th to 10th century "Islamic Golden Age" began in the 10th century and culminated in the Latin translations of the 12th century.
A copy of Ptolemy's "Almagest" was brought back to Sicily by Henry Aristippus (d. 1162), as a gift from the Emperor to King William I (r. 1154–1166). An anonymous student at Salerno travelled to Sicily and translated the "Almagest" as well as several works by Euclid from Greek to Latin. Although the Sicilians generally translated directly from the Greek, when Greek texts were not available, they would translate from Arabic. Eugenius of Palermo (d. 1202) translated Ptolemy's "Optics" into Latin, drawing on his knowledge of all three languages in the task.
The rigorous deductive methods of geometry found in Euclid's "Elements of Geometry" were relearned, and further development of geometry in the styles of both Euclid (Euclidean geometry) and Khayyam (algebraic geometry) continued, resulting in an abundance of new theorems and concepts, many of them very profound and elegant.
Advances in the treatment of perspective were made in Renaissance art of the 14th to 15th century which went beyond what had been achieved in antiquity. 
In Renaissance architecture of the "Quattrocento", concepts of architectural order were explored and rules were formulated. A prime example of is the Basilica di San Lorenzo in Florence by Filippo Brunelleschi (1377–1446).
In c. 1413 Filippo Brunelleschi demonstrated the geometrical method of perspective, used today by artists, by painting the outlines of various Florentine buildings onto a mirror. 
Soon after, nearly every artist in Florence and in Italy used geometrical perspective in their paintings, notably Masolino da Panicale and Donatello. Melozzo da Forlì first used the technique of upward foreshortening (in Rome, Loreto, Forlì and others), and was celebrated for that. Not only was perspective a way of showing depth, it was also a new method of composing a painting. Paintings began to show a single, unified scene, rather than a combination of several.
As shown by the quick proliferation of accurate perspective paintings in Florence, Brunelleschi likely understood (with help from his friend the mathematician Toscanelli), but did not publish, the mathematics behind perspective. Decades later, his friend Leon Battista Alberti wrote "De pictura" (1435/1436), a treatise on proper methods of showing distance in painting based on Euclidean geometry. Alberti was also trained in the science of optics through the school of Padua and under the influence of Biagio Pelacani da Parma who studied Alhazen's "Optics'.
Piero della Francesca elaborated on Della Pittura in his "De Prospectiva Pingendi" in the 1470s. Alberti had limited himself to figures on the ground plane and giving an overall basis for perspective. Della Francesca fleshed it out, explicitly covering solids in any area of the picture plane. Della Francesca also started the now common practice of using illustrated figures to explain the mathematical concepts, making his treatise easier to understand than Alberti's. Della Francesca was also the first to accurately draw the Platonic solids as they would appear in perspective.
Perspective remained, for a while, the domain of Florence. Jan van Eyck, among others, was unable to create a consistent structure for the converging lines in paintings, as in London's The Arnolfini Portrait, because he was unaware of the theoretical breakthrough just then occurring in Italy. However he achieved very subtle effects by manipulations of scale in his interiors. Gradually, and partly through the movement of academies of the arts, the Italian techniques became part of the training of artists across Europe, and later other parts of the world.
The culmination of these Renaissance traditions finds its ultimate synthesis in the research of the architect, geometer, and optician Girard Desargues on perspective, optics and projective geometry.
The "Vitruvian Man" by Leonardo da Vinci(c. 1490) depicts a man in two superimposed positions with his arms and legs apart and inscribed in a circle and square. The drawing is based on the correlations of ideal human proportions with geometry described by the ancient Roman architect Vitruvius in Book III of his treatise "De Architectura".
## Modern geometry.
### The 17th century.
In the early 17th century, there were two important developments in geometry. The first and most important was the creation of analytic geometry, or geometry with coordinates and equations, by René Descartes (1596–1650) and Pierre de Fermat (1601–1665). This was a necessary precursor to the development of calculus and a precise quantitative science of physics. The second geometric development of this period was the systematic study of projective geometry by Girard Desargues (1591–1661). Projective geometry is the study of geometry without measurement, just the study of how points align with each other. There had been some early work in this area by Hellenistic geometers, notably Pappus (c. 340). The greatest flowering of the field occurred with Jean-Victor Poncelet (1788–1867).
In the late 17th century, calculus was developed independently and almost simultaneously by Isaac Newton (1642–1727) and Gottfried Wilhelm Leibniz (1646–1716). This was the beginning of a new field of mathematics now called analysis. Though not itself a branch of geometry, it is applicable to geometry, and it solved two families of problems that had long been almost intractable: finding tangent lines to odd curves, and finding areas enclosed by those curves. The methods of calculus reduced these problems mostly to straightforward matters of computation.
### The 18th and 19th centuries.
#### Non-Euclidean geometry.
The very old problem of proving Euclid's Fifth Postulate, the "Parallel Postulate", from his first four postulates had never been forgotten. Beginning not long after Euclid, many attempted demonstrations were given, but all were later found to be faulty, through allowing into the reasoning some principle which itself had not been proved from the first four postulates. Though Omar Khayyám was also unsuccessful in proving the parallel postulate, his criticisms of Euclid's theories of parallels and his proof of properties of figures in non-Euclidean geometries contributed to the eventual development of non-Euclidean geometry. By 1700 a great deal had been discovered about what can be proved from the first four, and what the pitfalls were in attempting to prove the fifth. Saccheri, Lambert, and Legendre each did excellent work on the problem in the 18th century, but still fell short of success. In the early 19th century, Gauss, Johann Bolyai, and Lobatchewsky, each independently, took a different approach. Beginning to suspect that it was impossible to prove the Parallel Postulate, they set out to develop a self-consistent geometry in which that postulate was false. In this they were successful, thus creating the first non-Euclidean geometry. By 1854, Bernhard Riemann, a student of Gauss, had applied methods of calculus in a ground-breaking study of the intrinsic (self-contained) geometry of all smooth surfaces, and thereby found a different non-Euclidean geometry. This work of Riemann later became fundamental for Einstein's theory of relativity.
It remained to be proved mathematically that the non-Euclidean geometry was just as self-consistent as Euclidean geometry, and this was first accomplished by Beltrami in 1868. With this, non-Euclidean geometry was established on an equal mathematical footing with Euclidean geometry.
While it was now known that different geometric theories were mathematically possible, the question remained, "Which one of these theories is correct for our physical space?" The mathematical work revealed that this question must be answered by physical experimentation, not mathematical reasoning, and uncovered the reason why the experimentation must involve immense (interstellar, not earth-bound) distances. With the development of relativity theory in physics, this question became vastly more complicated.
#### Introduction of mathematical rigor.
All the work related to the Parallel Postulate revealed that it was quite difficult for a geometer to separate his logical reasoning from his intuitive understanding of physical space, and, moreover, revealed the critical importance of doing so. Careful examination had uncovered some logical inadequacies in Euclid's reasoning, and some unstated geometric principles to which Euclid sometimes appealed. This critique paralleled the crisis occurring in calculus and analysis regarding the meaning of infinite processes such as convergence and continuity. In geometry, there was a clear need for a new set of axioms, which would be complete, and which in no way relied on pictures we draw or on our intuition of space. Such axioms, now known as Hilbert's axioms, were given by David Hilbert in 1894 in his dissertation "Grundlagen der Geometrie" ("Foundations of Geometry"). Some other complete sets of axioms had been given a few years earlier, but did not match Hilbert's in economy, elegance, and similarity to Euclid's axioms.
#### Analysis situs, or topology.
In the mid-18th century, it became apparent that certain progressions of mathematical reasoning recurred when similar ideas were studied on the number line, in two dimensions, and in three dimensions. Thus the general concept of a metric space was created so that the reasoning could be done in more generality, and then applied to special cases. This method of studying calculus- and analysis-related concepts came to be known as analysis situs, and later as topology. The important topics in this field were properties of more general figures, such as connectedness and boundaries, rather than properties like straightness, and precise equality of length and angle measurements, which had been the focus of Euclidean and non-Euclidean geometry. Topology soon became a separate field of major importance, rather than a sub-field of geometry or analysis.
### The 20th century.
Developments in algebraic geometry included the study of curves and surfaces over finite fields as demonstrated by the works of among others André Weil, Alexander Grothendieck, and Jean-Pierre Serre as well as over the real or complex numbers. Finite geometry itself, the study of spaces with only finitely many points, found applications in coding theory and cryptography. With the advent of the computer, new disciplines such as computational geometry or digital geometry deal with geometric algorithms, discrete representations of geometric data, and so forth.

</doc>
<doc id="11955" url="https://en.wikipedia.org/wiki?curid=11955" title="George H. W. Bush">
George H. W. Bush

George Herbert Walker Bush (June 12, 1924November 30, 2018) was an American politician, diplomat, and businessman who served as the 41st president of the United States from 1989 to 1993. A member of the Republican Party, Bush also served as the 43rd vice president from 1981 to 1989 under Ronald Reagan, in the U.S. House of Representatives, as U.S. Ambassador to the United Nations, and as Director of Central Intelligence.
Bush was raised in Greenwich, Connecticut, and attended Phillips Academy before serving in the United States Navy Reserve during World War II. After the war, he graduated from Yale and moved to West Texas, where he established a successful oil company. After an unsuccessful run for the United States Senate, he won the election to the 7th congressional district of Texas in 1966. President Richard Nixon appointed Bush to the position of Ambassador to the United Nations in 1971 and to the position of chairman of the Republican National Committee in 1973. In 1974, President Gerald Ford appointed him as the Chief of the Liaison Office to the People's Republic of China, and in 1976 Bush became the Director of Central Intelligence. Bush ran for president in 1980, but was defeated in the Republican presidential primaries by Ronald Reagan, who then selected Bush as his vice presidential running mate.
In the 1988 presidential election, Bush defeated Democrat Michael Dukakis, becoming the first incumbent vice president to be elected president since Martin Van Buren in 1836. Foreign policy drove the Bush presidency, as he navigated the final years of the Cold War and played a key role in the reunification of Germany. Bush presided over the invasion of Panama and the Gulf War, ending the Iraqi occupation of Kuwait in the latter conflict. Though the agreement was not ratified until after he left office, Bush negotiated and signed the North American Free Trade Agreement (NAFTA), which created a trade bloc consisting of the United States, Canada, and Mexico. Domestically, Bush reneged on by enacting legislation to raise taxes with the justification of reducing the budget deficit. He also championed and signed three pieces of Bipartisan legislation, the Americans with Disabilities Act of 1990, Immigration Act of 1990 and the Clean Air Act Amendments of 1990. He also successfully appointed David Souter and Clarence Thomas to the Supreme Court. Bush lost the 1992 presidential election to Democrat Bill Clinton following an economic recession, his turnaround on his tax promise, and the decreased emphasis of foreign policy in a post–Cold War political climate.
After leaving office in 1993, Bush was active in humanitarian activities, often working alongside Bill Clinton, his former opponent. With the victory of his son, George W. Bush, in the 2000 presidential election, the two became the second father–son pair to serve as the nation's president, following John Adams and John Quincy Adams. Another son, Jeb Bush, unsuccessfully sought the Republican presidential nomination in the 2016 Republican primaries. Historians generally rank Bush as an above-average president.
## Early life and education (1924–1948).
George Herbert Walker Bush was born in Milton, Massachusetts on June 12, 1924. He was the second son of Prescott Bush and Dorothy (Walker) Bush. His paternal grandfather, Samuel P. Bush, worked as an executive for a railroad parts company in Columbus, Ohio, while his maternal grandfather and namesake, George Herbert Walker, led Wall Street investment bank W. A. Harriman &amp; Co. Walker was known as "Pop", and young Bush was called "Poppy" as a tribute to him. The Bush family moved to Greenwich, Connecticut in 1925, and Prescott took a position with W. A. Harriman &amp; Co. (which later merged into Brown Brothers Harriman &amp; Co.) the following year.
Bush spent most of his childhood in Greenwich, at the family vacation home in Kennebunkport, Maine, or at his maternal grandparents' plantation in South Carolina. Because of the family's wealth, Bush was largely unaffected by the Great Depression. He attended Greenwich Country Day School from 1929 to 1937 and Phillips Academy, an elite private academy in Massachusetts, from 1937 to 1942. While at Phillips Academy, he served as president of the senior class, secretary of the student council, president of the community fund-raising group, a member of the editorial board of the school newspaper, and captain of the varsity baseball and soccer teams.
### World War II.
On his 18th birthday, immediately after graduating from Phillips Academy, he enlisted in the United States Navy as a naval aviator. After a period of training, he was commissioned as an ensign in the Naval Reserve at Naval Air Station Corpus Christi on June 9, 1943, becoming one of the youngest aviators in the Navy. Beginning in 1944, Bush served in the Pacific theater, where he flew a Grumman TBF Avenger, a torpedo bomber capable of taking off from aircraft carriers. His squadron was assigned to the as a member of Air Group 51, where his lanky physique earned him the nickname "Skin".
Bush flew his first combat mission in May 1944, bombing Japanese-held Wake Island, and was promoted to lieutenant (junior grade) on August 1, 1944. During an attack on a Japanese installation in Chichijima, Bush's aircraft successfully attacked several targets, but was downed by enemy fire. Though both of Bush's fellow crew members died, Bush successfully bailed out from the aircraft and was rescued by the . Several of the aviators shot down during the attack were captured and executed, and their livers were eaten by their captors. Bush's survival after such a close brush with death shaped him profoundly, leading him to ask, "Why had I been spared and what did God have for me?" He was later awarded the Distinguished Flying Cross for his role in the mission.
Bush returned to "San Jacinto" in November 1944, participating in operations in the Philippines. In early 1945, he was assigned to a new combat squadron, VT-153, where he trained to take part in an invasion of mainland Japan. On September 2, 1945, before any invasion took place, Japan formally surrendered following the atomic bombings of Hiroshima and Nagasaki. Bush was released from active duty that same month, but was not formally discharged from the Navy until October 1955, at which point he had reached the rank of lieutenant. By the end of his period of active service, Bush had flown 58 missions, completed 128 carrier landings, and recorded 1228 hours of flight time.
### Marriage.
Bush met Barbara Pierce at a Christmas dance in Greenwich in December 1941, and, after a period of courtship, they became engaged in December 1943. While Bush was on leave from the Navy, they married in Rye, New York, on January 6, 1945. The Bushes enjoyed a strong marriage, and Barbara would later be a popular First Lady, seen by many as "a kind of national grandmother". They have six children: George W. (b. 1946), Robin (1949–1953), Jeb (b. 1953), Neil (b. 1955), Marvin (b. 1956), and Doro (b. 1959). Their oldest daughter, Robin, died of leukemia in 1953.
### College years.
Bush enrolled at Yale College, where he took part in an accelerated program that enabled him to graduate in two and a half years rather than the usual four. He was a member of the Delta Kappa Epsilon fraternity and was elected its president. He also captained the Yale baseball team and played in the first two College World Series as a left-handed first baseman. Like his father, he was a member of the Yale cheerleading squad and was initiated into the Skull and Bones secret society. He graduated Phi Beta Kappa in 1948 with a Bachelor of Arts degree, majoring in economics and minoring in sociology.
## Business career (1948–1963).
After graduating from Yale, Bush moved his young family to West Texas. Biographer Jon Meacham writes that Bush's relocation to Texas allowed him to move out of the "daily shadow of his Wall Street father and Grandfather Walker, two dominant figures in the financial world", but would still allow Bush to "call on their connections if he needed to raise capital." His first position in Texas was an oil field equipment salesman for Dresser Industries, which was led by family friend Neil Mallon. While working for Dresser, Bush lived in various places with his family: Odessa, Texas; Ventura, Bakersfield and Compton, California; and Midland, Texas. In 1952, he volunteered for the successful presidential campaign of Republican candidate Dwight D. Eisenhower. That same year, his father won election to represent Connecticut in the United States Senate as a member of the Republican Party.
With support from Mallon and Bush's uncle, George Herbert Walker Jr., Bush and John Overbey launched the Bush-Overbey Oil Development Company in 1951. In 1953 he co-founded the Zapata Petroleum Corporation, an oil company that drilled in the Permian Basin in Texas. In 1954, he was named president of the Zapata Offshore Company, a subsidiary which specialized in offshore drilling. Shortly after the subsidiary became independent in 1959, Bush moved the company and his family from Midland to Houston. There, he befriended James Baker, a prominent attorney who later became an important political ally. Bush remained involved with Zapata until the mid-1960s, when he sold his stock in the company for approximately $1 million.
In 1988, "The Nation" published an article alleging that Bush worked as an operative of the Central Intelligence Agency (CIA) during the 1960s; Bush denied this claim.
## Early political career (1963–1971).
### Entry into politics.
By the early 1960s, Bush was widely regarded as an appealing political candidate, and some leading Democrats attempted to convince Bush to become a Democrat. He declined to leave the Republican Party, later citing his belief that the national Democratic Party favored "big, centralized government". The Democratic Party had historically dominated Texas, but Republicans scored their first major victory in the state with John G. Tower's victory in a 1961 special election to the United States Senate. Motivated by Tower's victory, and hoping to prevent the far-right John Birch Society from coming to power, Bush ran for the chairmanship of the Harris County Republican Party, winning election in February 1963. Like most other Texas Republicans, Bush supported conservative Senator Barry Goldwater over the more centrist Nelson Rockefeller in the 1964 Republican Party presidential primaries.
In 1964, Bush sought to unseat liberal Democrat Ralph W. Yarborough in Texas's U.S. Senate election. Bolstered by superior fundraising, Bush won the Republican primary by defeating former gubernatorial nominee Jack Cox in a run-off election. In the general election, Bush attacked Yarborough's vote for the Civil Rights Act of 1964, which banned racial and gender discrimination in public institutions and in many privately owned businesses. Bush argued that the act unconstitutionally expanded the powers of the federal government, but he was privately uncomfortable with the racial politics of opposing the act. He lost the election 56 percent to 44 percent, though he did run well ahead of Barry Goldwater, the Republican presidential nominee. Despite the loss, the "New York Times" reported that Bush was "rated by political friend and foe alike as the Republicans' best prospect in Texas because of his attractive personal qualities and the strong campaign he put up for the Senate".
### U.S. House of Representatives.
In 1966, Bush ran for the United States House of Representatives in Texas's 7th congressional district, a newly redistricted seat in the Greater Houston area. Initial polling showed him trailing his Democratic opponent, Harris County District Attorney Frank Briscoe, but he ultimately won the race with 57 percent of the vote. In an effort to woo potential candidates in the South and Southwest, House Republicans secured Bush an appointment to the powerful United States House Committee on Ways and Means, making Bush the first freshman to serve on the committee since 1904. His voting record in the House was generally conservative. He supported the Nixon administration's Vietnam policies, but broke with Republicans on the issue of birth control, which he supported. He also voted for the Civil Rights Act of 1968, although it was generally unpopular in his district. In 1968, Bush joined several other Republicans in issuing the party's Response to the State of the Union address; Bush's part of the address focused on a call for fiscal responsibility.
Though most other Texas Republicans supported Ronald Reagan in the 1968 Republican Party presidential primaries, Bush endorsed Richard Nixon, who went on to win the party's nomination. Nixon considered selecting Bush as his running mate in the 1968 presidential election, but he ultimately chose Spiro Agnew instead. Bush won re-election to the House unopposed, while Nixon defeated Hubert Humphrey in the presidential election. In 1970, with President Nixon's support, Bush gave up his seat in the House to run for the Senate against Yarborough. Bush easily won the Republican primary, but Yarborough was defeated by the more conservative Lloyd Bentsen in the Democratic primary. Ultimately, Bentsen defeated Bush, taking 53.5 percent of the vote.
## Nixon and Ford administrations (1971–1977).
### Ambassador to the United Nations.
After the 1970 Senate election, Bush accepted a position as a senior adviser to the president, but he convinced Nixon to instead appoint him as the U.S. Ambassador to the United Nations. The position represented Bush's first foray into foreign policy, as well as his first major experiences with the Soviet Union and China, the two major U.S. rivals in the Cold War. During Bush's tenure, the Nixon administration pursued a policy of détente, seeking to ease tensions with both the Soviet Union and China. Bush's ambassadorship was marked by a defeat on the China question, as the United Nations General Assembly voted to expel the Republic of China and replace it with the People's Republic of China in October 1971. In the 1971 crisis in Pakistan, Bush supported an Indian motion at the UN General Assembly to condemn the Pakistani government of Yahya Khan for waging genocide in East Pakistan (modern Bangladesh), referring to the "tradition which we have supported that the human rights question transcended domestic jurisdiction and should be freely debated". Bush's support for India at the UN put him into conflict with Nixon who was supporting Pakistan, partly because Yahya Khan was a useful intermediary in his attempts to reach out to China and partly because the president was fond of Yahya Khan.
### Chairman of the Republican National Committee.
After Nixon won a landslide victory in the 1972 presidential election, he appointed Bush as chair of the Republican National Committee (RNC). In that position, he was charged with fundraising, candidate recruitment, and making appearances on behalf of the party in the media.
When Agnew was being investigated for corruption, Bush assisted, at the request of Nixon and Agnew, in pressuring John Glenn Beall Jr., the U.S. Senator from Maryland, to force his brother, George Beall the U.S. Attorney in Maryland, who was supervising the investigation into Agnew. Attorney Beall ignored the pressure.
During Bush's tenure at the RNC, the Watergate scandal emerged into public view; the scandal originated from the June 1972 break-in of the Democratic National Committee, but also involved later efforts to cover up the break-in by Nixon and other members of the White House. Bush initially defended Nixon steadfastly, but as Nixon's complicity became clear he focused more on defending the Republican Party.
Following the resignation of Vice President Agnew in 1973 for a scandal unrelated to Watergate, Bush was considered for the position of vice president, but the appointment instead went to Gerald Ford. After the public release of an audio recording that confirmed that Nixon had plotted to use the CIA to cover up the Watergate break-in, Bush joined other party leaders in urging Nixon to resign. When Nixon resigned on August 9, 1974, Bush noted in his diary that "There was an aura of sadness, like somebody died... The [resignation] speech was vintage Nixon—a kick or two at the press—enormous strains. One couldn't help but look at the family and the whole thing and think of his accomplishments and then think of the shame... [President Gerald Ford's swearing-in offered] indeed a new spirit, a new lift."
### Head of U.S. Liaison Office in China.
Upon his ascension to the presidency, Ford strongly considered Bush, Donald Rumsfeld, and Nelson Rockefeller for the vacant position of vice president. Ford ultimately chose Nelson Rockefeller, partly because of the publication of a news report claiming that Bush's 1970 campaign had benefited from a secret fund set up by Nixon; Bush was later cleared of any suspicion by a special prosecutor. Bush accepted appointment as Chief of the U.S. Liaison Office in the People's Republic of China, making him the de facto ambassador to China. According to biographer Jon Meacham, Bush's time in China convinced him that American engagement abroad was needed to ensure global stability, and that the United States "needed to be visible but not pushy, muscular but not domineering."
### Director of Central Intelligence.
In January 1976, Ford brought Bush back to Washington to become the Director of Central Intelligence (DCI), placing him in charge of the CIA. In the aftermath of the Watergate scandal and the Vietnam War, the CIA's reputation had been damaged for its role in various covert operations, and Bush was tasked with restoring the agency's morale and public reputation. During Bush's year in charge of the CIA, the U.S. national security apparatus actively supported Operation Condor operations and right-wing military dictatorships in Latin America. Meanwhile, Ford decided to drop Rockefeller from the ticket for the 1976 presidential election; he considered Bush as his running mate, but ultimately chose Bob Dole. In his capacity as DCI, Bush gave national security briefings to Jimmy Carter both as a presidential candidate and as president-elect.
## 1980 presidential election.
Bush's tenure at the CIA ended after Carter narrowly defeated Ford in the 1976 presidential election. Out of public office for the first time since the 1960s, Bush became chairman on the Executive Committee of the First International Bank in Houston. He also spent a year as a part-time professor of Administrative Science at Rice University's Jones School of Business, continued his membership in the Council on Foreign Relations, and joined the Trilateral Commission. Meanwhile, he began to lay the groundwork for his candidacy in the 1980 Republican Party presidential primaries. In the 1980 Republican primary campaign, Bush faced Ronald Reagan, who was widely regarded as the front-runner, as well as other contenders like Senator Bob Dole, Senator Howard Baker, Texas Governor John Connally, Congressman Phil Crane, and Congressman John B. Anderson.
Bush's campaign cast him as a youthful, "thinking man's candidate" who would emulate the pragmatic conservatism of President Eisenhower. In the midst of the Soviet–Afghan War, which brought an end to a period of détente, and the Iran hostage crisis, in which 52 Americans were taken hostage, the campaign highlighted Bush's foreign policy experience. At the outset of the race, Bush focused heavily on winning the January 21 Iowa caucuses, making 31 visits to the state. He won a close victory in Iowa with 31.5% to Reagan's 29.4%. After the win, Bush stated that his campaign was full of momentum, or "the Big Mo", and Reagan reorganized his campaign. Partly in response to the Bush campaign's frequent questioning of Reagan's age (Reagan turned 69 in 1980), the Reagan campaign stepped up attacks on Bush, painting him as an elitist who was not truly committed to conservatism. Prior to the New Hampshire primary, Bush and Reagan agreed to a two-person debate, organized by "The Nashua Telegraph" but paid for by the Reagan campaign.
Days before the debate, Reagan announced that he would invite four other candidates to the debate; Bush, who had hoped that the one-on-one debate would allow him to emerge as the main alternative to Reagan in the primaries, refused to debate the other candidates. All six candidates took the stage, but Bush refused to speak in the presence of the other candidates. Ultimately, the other four candidates left the stage and the debate continued, but Bush's refusal to debate anyone other than Reagan badly damaged his campaign in New Hampshire. He ended up decisively losing New Hampshire's primary to Reagan, winning just 23 percent of the vote. Bush revitalized his campaign with a victory in Massachusetts, but lost the next several primaries. As Reagan built up a commanding delegate lead, Bush refused to end his campaign, but the other candidates dropped out of the race. Criticizing his more conservative rival's policy proposals, Bush famously labeled Reagan's supply side-influenced plans for massive tax cuts as "voodoo economics". Though he favored lower taxes, Bush feared that dramatic reductions in taxation would lead to deficits and, in turn, cause inflation.
After Reagan clinched a majority of delegates in late May, Bush reluctantly dropped out of the race. At the 1980 Republican National Convention, Reagan made the last-minute decision to select Bush as his vice presidential nominee after negotiations with Ford regarding a Reagan–Ford ticket collapsed. Though Reagan had resented many of the Bush campaign's attacks during the primary campaign, and several conservative leaders had actively opposed Bush's nomination, Reagan ultimately decided that Bush's popularity with moderate Republicans made him the best and safest pick. Bush, who had believed his political career might be over following the primaries, eagerly accepted the position and threw himself into campaigning for the Reagan–Bush ticket. The 1980 general election campaign between Reagan and Carter was conducted amid a multitude of domestic concerns and the ongoing Iran hostage crisis, and Reagan sought to focus the race on Carter's handling of the economy. Though the race was widely regarded as a close contest for most of the campaign, Reagan ultimately won over the large majority of undecided voters. Reagan took 50.7 percent of the popular vote and 489 of the 538 electoral votes, while Carter won 41% of the popular vote and John Anderson, running as an independent candidate, won 6.6% of the popular vote.
## Vice Presidency (1981–1989).
As vice president, Bush generally maintained a low profile, recognizing the constitutional limits of the office; he avoided decision-making or criticizing Reagan in any way. This approach helped him earn Reagan's trust, easing tensions left over from their earlier rivalry. Bush also generally enjoyed a good relationship with Reagan staffers, including his close friend Jim Baker, who served as Reagan's initial chief of staff. His understanding of the vice presidency was heavily influenced by Vice President Walter Mondale, who enjoyed a strong relationship with President Carter in part because of his ability to avoid confrontations with senior staff and Cabinet members, and by Vice President Nelson Rockefeller's difficult relationship with some members of the White House staff during the Ford administration. The Bushes attended a large number of public and ceremonial events in their positions, including many state funerals, which became a common joke for comedians. As the President of the Senate, Bush also stayed in contact with members of Congress and kept the president informed on occurrences on Capitol Hill.
### First term.
On March 30, 1981, while Bush was in Texas, Reagan was shot and seriously wounded by John Hinckley Jr. Bush immediately flew back to Washington D.C.; when his plane landed, his aides advised him to proceed directly to the White House by helicopter in order to show that the government was still functioning. Bush rejected the idea, as he feared that such a dramatic scene risked giving the impression that he sought to usurp Reagan's powers and prerogatives. During Reagan's short period of incapacity, Bush presided over Cabinet meetings, met with congressional leaders and foreign leaders, and briefed reporters, but he consistently rejected the possibility of invoking the Twenty-fifth Amendment. Bush's handling of the attempted assassination and its aftermath made a positive impression on Reagan, who recovered and returned to work within two weeks of the shooting. From then on, the two men would have regular Thursday lunches in the Oval Office.
Bush was assigned by Reagan to chair two special task forces, one on deregulation and one on international drug smuggling. Both were popular issues with conservatives, and Bush, largely a moderate, began courting them through his work. The deregulation task force reviewed hundreds of rules, making specific recommendations on which ones to amend or revise, in order to curb the size of the federal government. The Reagan administration's deregulation push had a strong impact on broadcasting, finance, resource extraction, and other economic activities, and the administration eliminated numerous government positions. Bush also oversaw the administration's national security crisis management organization, which had traditionally been the responsibility of the National Security Advisor. In 1983, Bush toured Western Europe as part of the Reagan administration's ultimately successful efforts to convince skeptical NATO allies to support the deployment of Pershing II missiles.
Reagan's approval ratings fell after his first year in office, but they bounced back when the United States began to emerge from recession in 1983. Former Vice President Walter Mondale was nominated by the Democratic Party in the 1984 presidential election. Down in the polls, Mondale selected Congresswoman Geraldine Ferraro as his running mate in hopes of galvanizing support for his campaign, thus making Ferraro the first female major party vice presidential nominee in U.S. history. She and Bush squared off in a single televised vice presidential debate. Public opinion polling consistently showed a Reagan lead in the 1984 campaign, and Mondale was unable to shake up the race. In the end, Reagan won re-election, winning 49 of 50 states and receiving 59% of the popular vote to Mondale's 41%.
### Second term.
Mikhail Gorbachev came to power in the Soviet Union in 1985. Rejecting the ideologically rigidity of his three elderly sick predecessors, Gorbachev insisted on urgently needed economic and political reforms called "glasnost" (openness) and "perestroika" (restructuring). At the 1987 Washington Summit, Gorbachev and Reagan signed the Intermediate-Range Nuclear Forces Treaty, which committed both signatories to the total abolition of their respective short-range and medium-range missile stockpiles. The treaty marked the beginning of a new era of trade, openness, and cooperation between the two powers. President Reagan and Secretary of State George Shultz took the lead in these negotiations, but Bush sat in on many meetings. Bush did not agree with many of the Reagan policies, but he did tell Gorbachev that he would seek to continue improving relations if he succeeded Reagan. On July 13, 1985, Bush became the first vice president to serve as acting president when Reagan underwent surgery to remove polyps from his colon; Bush served as the acting president for approximately eight hours.
In 1986, the Reagan administration was shaken by a scandal when it was revealed that administration officials had secretly arranged weapon sales to Iran during the Iran–Iraq War. The officials had used the proceeds to fund the Contra rebels in their fight against the leftist Sandinista government in Nicaragua. Democrats had passed a law that appropriated funds could not be used to help the Contras. Instead the administration used non-appropriated funds from the sales. When news of affair broke to the media, Bush stated that he had been "out of the loop" and unaware of the diversion of funds. Biographer Jon Meacham writes that "no evidence was ever produced proving Bush was aware of the diversion to the contras," but he criticizes Bush's "out of the loop" characterization, writing that the "record is clear that Bush was aware that the United States, in contravention of its own stated policy, was trading arms for hostages". The Iran–Contra scandal, as it became known, did serious damage to the Reagan presidency, raising questions about Reagan's competency. Congress established the Tower Commission to investigate the scandal, and, at Reagan's request, a panel of federal judges appointed Lawrence Walsh as a special prosecutor charged with investigating the Iran–Contra scandal. The investigations continued after Reagan left office and, though Bush was never charged with a crime, the Iran–Contra scandal would remain a political liability for him.
On July 3, 1988, the guided missile cruiser accidentally shot down Iran Air Flight 655, killing 290 passengers. Bush, then-vice president, defended his country at the UN by arguing that the U.S. attack had been a wartime incident and the crew of "Vincennes" had acted appropriately to the situation.
### 1988 presidential election.
Bush began planning for a presidential run after the 1984 election, and he officially entered the 1988 Republican Party presidential primaries in October 1987. He put together a campaign led by Reagan staffer Lee Atwater, and which also included his son, George W. Bush, and media consultant Roger Ailes. Though he had moved to the right during his time as vice president, endorsing a Human Life Amendment and repudiating his earlier comments on "voodoo economics," Bush still faced opposition from many conservatives in the Republican Party. His major rivals for the Republican nomination were Senate Minority Leader Bob Dole of Kansas, Congressman Jack Kemp of New York, and Christian televangelist Pat Robertson. Reagan did not publicly endorse any candidate, but he privately expressed support for Bush.
Though considered the early front-runner for the nomination, Bush came in third in the Iowa caucus, behind Dole and Robertson. Much as Reagan had done in 1980, Bush reorganized his staff and concentrated on the New Hampshire primary. With help from Governor John H. Sununu and an effective campaign attacking Dole for raising taxes, Bush overcame an initial polling deficit and won New Hampshire with 39 percent of the vote. After Bush won South Carolina and 16 of the 17 states holding a primary on Super Tuesday, his competitors dropped out of the race.
Bush, occasionally criticized for his lack of eloquence when compared to Reagan, delivered a well-received speech at the Republican convention. Known as the "thousand points of light" speech, it described Bush's vision of America: he endorsed the Pledge of Allegiance, prayer in schools, capital punishment, and gun rights. Bush also , stating: "Congress will push me to raise taxes, and I'll say no, and they'll push, and I'll say no, and they'll push again. And all I can say to them is: read my lips. No new taxes." Bush selected little-known Senator Dan Quayle of Indiana as his running mate. Though Quayle had compiled an unremarkable record in Congress, he was popular among many conservatives, and the campaign hoped that Quayle's youth would appeal to younger voters.
Meanwhile, the Democratic Party nominated Governor Michael Dukakis, who was known for presiding over an economic turnaround in Massachusetts. Leading in the general election polls against Bush, Dukakis ran an ineffective, low-risk campaign. The Bush campaign attacked Dukakis as an unpatriotic liberal extremist and seized on the Willie Horton case, in which a convicted felon from Massachusetts raped a woman while on a prison furlough, a program Dukakis supported as governor. The Bush campaign charged that Dukakis presided over a "revolving door" that allowed dangerous convicted felons to leave prison. Dukakis damaged his own campaign with a widely mocked ride in an M1 Abrams tank and a poor performance at the second presidential debate. Bush also attacked Dukakis for opposing a law that would require all students to recite the Pledge of Allegiance. The election is widely considered to have had a high level of negative campaigning, though political scientist John Geer has argued that the share of negative ads was in line with previous presidential elections.
Bush defeated Dukakis by a margin of 426 to 111 in the Electoral College, and he took 53.4 percent of the national popular vote. Bush ran well in all the major regions of the country, but especially in the South. He became the fourth sitting vice president to be elected president and the first to do so since Martin Van Buren in 1836 and the first person to succeed a president from his own party via election since Herbert Hoover in 1929. In the concurrent congressional elections, Democrats retained control of both houses of Congress.
## Presidency (1989–1993).
Bush was inaugurated on January 20, 1989, succeeding Ronald Reagan. In his inaugural address, Bush said:
Bush's first major appointment was that of James Baker as Secretary of State. Leadership of the Department of Defense went to Dick Cheney, who had previously served as Gerald Ford's chief of staff and would later serve as vice president under his son George W. Bush. Jack Kemp joined the administration as Secretary of Housing and Urban Development, while Elizabeth Dole, the wife of Bob Dole and a former Secretary of Transportation, became the Secretary of Labor under Bush. Bush retained several Reagan officials, including Secretary of the Treasury Nicholas F. Brady, Attorney General Dick Thornburgh, and Secretary of Education Lauro Cavazos. New Hampshire Governor John Sununu, a strong supporter of Bush during the 1988 campaign, became chief of staff. Brent Scowcroft was appointed as the National Security Advisor, a role he had also held under Ford.
### Foreign affairs.
#### End of the Cold War.
During the first year of his tenure, Bush put a pause on Reagan's détente policy toward the USSR. Bush and his advisers were initially divided on Gorbachev; some administration officials saw him as a democratic reformer, but others suspected him of trying to make the minimum changes necessary to restore the Soviet Union to a competitive position with the United States. In 1989, all the Communist governments collapsed in Eastern Europe. Gorbachev declined to send in the Soviet military, effectively abandoning the Brezhnev Doctrine. The U.S. was not directly involved in these upheavals, but the Bush administration avoided gloating over the demise of the Eastern Bloc to avoid undermining further democratic reforms.
Bush and Gorbachev met at the Malta Summit in December 1989. Though many on the right remained wary of Gorbachev, Bush came away with the belief that Gorbachev would negotiate in good faith. For the remainder of his term, Bush sought cooperative relations with Gorbachev, believing that he was the key to peace. The primary issue at the Malta Summit was the potential reunification of Germany. While Britain and France were wary of a re-unified Germany, Bush joined West German Chancellor Helmut Kohl in pushing for German reunification. Bush believed that a reunified Germany would serve American interests. After extensive negotiations, Gorbachev agreed to allow a reunified Germany to be a part of NATO, and Germany officially reunified in October 1990 after paying billions of marks to Moscow.
Gorbachev used force to suppress nationalist movements within the Soviet Union itself. A crisis in Lithuania left Bush in a difficult position, as he needed Gorbachev's cooperation in the reunification of Germany and feared that the collapse of the Soviet Union could leave nuclear arms in dangerous hands. The Bush administration mildly protested Gorbachev's suppression of Lithuania's independence movement, but took no action to directly intervene. Bush warned independence movements of the disorder that could come with secession from the Soviet Union; in a 1991 address that critics labeled the "Chicken Kiev speech", he cautioned against "suicidal nationalism". In July 1991, Bush and Gorbachev signed the Strategic Arms Reduction Treaty (START I) treaty, in which both countries agreed to cut their strategic nuclear weapons by 30 percent.
In August 1991, hard-line Communists launched a coup against Gorbachev; while the coup quickly fell apart, it broke the remaining power of Gorbachev and the central Soviet government. Later that month, Gorbachev resigned as general secretary of the Communist party, and Russian president Boris Yeltsin ordered the seizure of Soviet property. Gorbachev clung to power as the President of the Soviet Union until December 1991, when the Soviet Union dissolved. Fifteen states emerged from the Soviet Union, and of those states, Russia was the largest and most populous. Bush and Yeltsin met in February 1992, declaring a new era of "friendship and partnership". In January 1993, Bush and Yeltsin agreed to START II, which provided for further nuclear arms reductions on top of the original START treaty. The collapse of the Soviet Union prompted reflections on the future of the world following the end of the Cold War; one political scientist, Francis Fukuyama, speculated that humanity had reached the "end of history" in that liberal, capitalist democracy had permanently triumphed over Communism and fascism. Meanwhile, the collapse of the Soviet Union and other Communist governments led to post-Soviet conflicts in Central Europe, Eastern Europe, Central Asia, and Africa that would continue long after Bush left office.
#### Invasion of Panama.
During the 1980s, the U.S. had provided aid to Panamanian leader Manuel Noriega, an anti-Communist dictator who engaged in drug trafficking. In May 1989, Noriega annulled the results of a democratic presidential election in which Guillermo Endara had been elected. Bush objected to the annulment of the election and worried about the status of the Panama Canal with Noriega still in office. Bush dispatched 2,000 soldiers to the country, where they began conducting regular military exercises in violation of prior treaties. After a U.S. serviceman was shot by Panamanian forces in December 1989, Bush ordered the United States invasion of Panama, known as "Operation Just Cause". The invasion was the first large-scale American military operation in more than 40 years that was not related to the Cold War. American forces quickly took control of the Panama Canal Zone and Panama City. Noriega surrendered on January 3, 1990, and was quickly transported to a prison in the United States. Twenty-three Americans died in the operation, while another 394 were wounded. Noriega was convicted and imprisoned on racketeering and drug trafficking charges in April 1992. Historian Stewart Brewer argues that the invasion "represented a new era in American foreign policy" because Bush did not justify the invasion under the Monroe Doctrine or the threat of Communism, but rather on the grounds that it was in the best interests of the United States.
#### Gulf War.
Faced with massive debts and low oil prices in the aftermath of the Iran–Iraq War, Iraqi leader Saddam Hussein decided to conquer the country of Kuwait, a small, oil-rich country situated on Iraq's southern border. After Iraq invaded Kuwait in August 1990, Bush imposed economic sanctions on Iraq and assembled a multi-national coalition opposed to the invasion. The administration feared that a failure to respond to the invasion would embolden Hussein to attack Saudi Arabia or Israel, and wanted to discourage other countries from similar aggression. Bush also wanted to ensure continued access to oil, as Iraq and Kuwait collectively accounted for 20 percent of the world's oil production, and Saudi Arabia produced another 26 percent of the world's oil supply.
At Bush's insistence, in November 1990, the United Nations Security Council approved a resolution authorizing the use of force if Iraq did not withdraw from Kuwait by January 15, 1991. Gorbachev's support, as well as China's abstention, helped ensure passage of the UN resolution. Bush convinced Britain, France, and other nations to commit soldiers to an operation against Iraq, and he won important financial backing from Germany, Japan, South Korea, Saudi Arabia, and the United Arab Emirates. In January 1991, Bush asked Congress to approve a joint resolution authorizing a war against Iraq. Bush believed that the UN resolution had already provided him with the necessary authorization to launch a military operation against Iraq, but he wanted to show that the nation was united behind a military action. Despite the opposition of a majority of Democrats in both the House and the Senate, Congress approved the Authorization for Use of Military Force Against Iraq Resolution of 1991.
After the January 15 deadline passed without an Iraqi withdrawal from Kuwait, U.S. and coalition forces conducted a bombing campaign that devastated Iraq's power grid and communications network, and resulted in the desertion of about 100,000 Iraqi soldiers. In retaliation, Iraq launched Scud missiles at Israel and Saudi Arabia, but most of the missiles did little damage. On February 23, coalition forces began a ground invasion into Kuwait, evicting Iraqi forces by the end of February 27. About 300 Americans, as well as approximately 65 soldiers from other coalition nations, died during the military action. A cease fire was arranged on March 3, and the UN passed a resolution establishing a peacekeeping force in a demilitarized zone between Kuwait and Iraq. A March 1991 Gallup poll showed that Bush had an approval rating of 89 percent, the highest presidential approval rating in the history of Gallup polling. After 1991, the UN maintained economic sanctions against Iraq, and the United Nations Special Commission was assigned to ensure that Iraq did not revive its weapons of mass destruction program.
#### NAFTA.
In 1987, the U.S. and Canada had reached a free trade agreement that eliminated many tariffs between the two countries. President Reagan had intended it as the first step towards a larger trade agreement to eliminate most tariffs among the United States, Canada, and Mexico. The Bush administration, along with the Progressive Conservative Canadian Prime Minister Brian Mulroney, spearheaded the negotiations of the North American Free Trade Agreement (NAFTA) with Mexico. In addition to lowering tariffs, the proposed treaty would affect patents, copyrights, and trademarks. In 1991, Bush sought fast track authority, which grants the president the power to submit an international trade agreement to Congress without the possibility of amendment. Despite congressional opposition led by House Majority Leader Dick Gephardt, both houses of Congress voted to grant Bush fast track authority. NAFTA was signed in December 1992, after Bush lost re-election, but President Clinton won ratification of NAFTA in 1993. NAFTA remains controversial for its impact on wages, jobs, and overall economic growth.
### Domestic affairs.
#### Economy and fiscal issues.
The U.S. economy had generally performed well since emerging from recession in late 1982, but it slipped into a mild recession in 1990. The unemployment rate rose from 5.9 percent in 1989 to a high of 7.8 percent in mid-1991. Large federal deficits, spawned during the Reagan years, rose from $152.1 billion in 1989 to $220 billion for 1990; the $220 billion deficit represented a threefold increase since 1980. As the public became increasingly concerned about the economy and other domestic affairs, Bush's well-received handling of foreign affairs became less of an issue for most voters. Bush's top domestic priority was to bring an end to federal budget deficits, which he saw as a liability for the country's long-term economic health and standing in the world. As he was opposed to major defense spending cuts and had pledged to not raise taxes, the president had major difficulties in balancing the budget.
Bush and congressional leaders agreed to avoid major changes to the budget for fiscal year 1990, which began in October 1989. However, both sides knew that spending cuts or new taxes would be necessary in the following year's budget in order to avoid the draconian automatic domestic spending cuts required by the Gramm–Rudman–Hollings Balanced Budget Act of 1987. Bush and other leaders also wanted to cut deficits because Federal Reserve Chair Alan Greenspan refused to lower interest rates, and thus stimulate economic growth, unless the federal budget deficit was reduced. In a statement released in late June 1990, Bush said that he would be open to a deficit reduction program which included spending cuts, incentives for economic growth, budget process reform, as well as tax increases. To fiscal conservatives in the Republican Party, Bush's statement represented a betrayal, and they heavily criticized him for compromising so early in the negotiations.
In September 1990, Bush and Congressional Democrats announced a compromise to cut funding for mandatory and discretionary programs while also raising revenue, partly through a higher gas tax. The compromise additionally included a "pay as you go" provision that required that new programs be paid for at the time of implementation. House Minority Whip Newt Gingrich led the conservative opposition to the bill, strongly opposing any form of tax increase. Some liberals also criticized the budget cuts in the compromise, and in October, the House rejected the deal, resulting in a brief government shutdown. Without the strong backing of the Republican Party, Bush agreed to another compromise bill, this one more favorable to Democrats. The Omnibus Budget Reconciliation Act of 1990 (OBRA-90), enacted on October 27, 1990, dropped much of the gasoline tax increase in favor of higher income taxes on top earners. It included cuts to domestic spending, but the cuts were not as deep as those that had been proposed in the original compromise. Bush's decision to sign the bill damaged his standing with conservatives and the general public, but it also laid the groundwork for the budget surpluses of the late 1990s.
#### Discrimination.
The disabled had not received legal protections under the landmark Civil Rights Act of 1964, and many faced discrimination and segregation by the time Bush took office. In 1988, Lowell P. Weicker Jr. and Tony Coelho had introduced the Americans with Disabilities Act, which barred employment discrimination against qualified individuals with disabilities. The bill had passed the Senate but not the House, and it was reintroduced in 1989. Though some conservatives opposed the bill due to its costs and potential burdens on businesses, Bush strongly supported it, partly because his son, Neil, had struggled with dyslexia. After the bill passed both houses of Congress, Bush signed the Americans with Disabilities Act of 1990 into law in July 1990. The act required employers and public accommodations to make "reasonable accommodations" for the disabled, while providing an exception when such accommodations imposed an "undue hardship".
Senator Ted Kennedy later led the congressional passage of a separate civil rights bill designed to facilitate launching employment discrimination lawsuits. In vetoing the bill, Bush argued that it would lead to racial quotas in hiring. In November 1991, Bush signed the Civil Rights Act of 1991, which was largely similar to the bill he had vetoed in the previous year.
In August 1990, Bush signed the Ryan White CARE Act, the largest federally funded program dedicated to assisting persons living with HIV/AIDS. Throughout his presidency, the AIDS epidemic grew dramatically in the U.S. and around the world, and Bush often found himself at odds with AIDS activist groups who criticized him for not placing a high priority on HIV/AIDS research and funding. Frustrated by the administration's lack of urgency on the issue, ACT UP, dumped the ashes of HIV/AIDS victims on the White House lawn during a viewing of the AIDS Quilt in 1992. By that time, HIV had become the leading cause of death in the U.S. for men aged 25–44.
#### Environment.
In June 1989, the Bush administration proposed a bill to amend the Clean Air Act. Working with Senate Majority Leader George J. Mitchell, the administration won passage of the amendments over the opposition of business-aligned members of Congress who feared the impact of tougher regulations. The legislation sought to curb acid rain and smog by requiring decreased emissions of chemicals such as sulfur dioxide, and was the first major update to the Clean Air Act since 1977. Bush also signed the Oil Pollution Act of 1990 in response to the Exxon Valdez oil spill. However, the League of Conservation Voters criticized some of Bush's other environmental actions, including his opposition to stricter auto-mileage standards.
#### Points of Light.
President Bush devoted attention to voluntary service as a means of solving some of America's most serious social problems. He often used the "thousand points of light" theme to describe the power of citizens to solve community problems. In his 1989 inaugural address, President Bush said, "I have spoken of a thousand points of light, of all the community organizations that are spread like stars throughout the Nation, doing good." During his presidency, Bush honored numerous volunteers with the Daily Point of Light Award, a tradition that was continued by his presidential successors. In 1990, the Points of Light Foundation was created as a nonprofit organization in Washington to promote this spirit of volunteerism. In 2007, the Points of Light Foundation merged with the Hands On Network to create a new organization, Points of Light.
#### Judicial appointments.
Bush appointed two justices to the Supreme Court of the United States. In 1990, Bush appointed a largely unknown state appellate judge, David Souter, to replace liberal icon William Brennan. Souter was easily confirmed and served until 2009, but joined the liberal bloc of the court, disappointing Bush. In 1991, Bush nominated conservative federal judge Clarence Thomas to succeed Thurgood Marshall, a long-time liberal stalwart. Thomas, the former head of the Equal Employment Opportunity Commission (EEOC), faced heavy opposition in the Senate, as well as from pro-choice groups and the NAACP. His nomination faced another difficulty when Anita Hill accused Thomas of having sexually harassed her during his time as the chair of EEOC. Thomas won confirmation in a narrow 52–48 vote; 43 Republicans and 9 Democrats voted to confirm Thomas's nomination, while 46 Democrats and 2 Republicans voted against confirmation. Thomas became one of the most conservative justices of his era.
#### Other issues.
Bush's education platform consisted mainly of offering federal support for a variety of innovations, such as open enrollment, incentive pay for outstanding teachers, and rewards for schools that improve performance with underprivileged children. Though Bush did not pass a major educational reform package during his presidency, his ideas influenced later reform efforts, including Goals 2000 and the No Child Left Behind Act. Bush signed the Immigration Act of 1990, which led to a 40 percent increase in legal immigration to the United States. The act more than doubled the number of visas given to immigrants on the basis of job skills. In the wake of the savings and loan crisis, Bush proposed a $50 billion package to rescue the savings and loans industry, and also proposed the creation of the Office of Thrift Supervision to regulate the industry. Congress passed the Financial Institutions Reform, Recovery, and Enforcement Act of 1989, which incorporated most of Bush's proposals.
### Public image.
Bush was widely seen as a "pragmatic caretaker" president who lacked a unified and compelling long-term theme in his efforts. Indeed, Bush's sound bite where he refers to the issue of overarching purpose as "the vision thing" has become a metonym applied to other political figures accused of similar difficulties. His ability to gain broad international support for the Gulf War and the war's result were seen as both a diplomatic and military triumph, rousing bipartisan approval, though his decision to withdraw without removing Saddam Hussein left mixed feelings, and attention returned to the domestic front and a souring economy. A "New York Times" article mistakenly depicted Bush as being surprised to see a supermarket barcode reader; the report of his reaction exacerbated the notion that he was "out of touch". Amid the early 1990s recession, his image shifted from "conquering hero" to "politician befuddled by economic matters".
At the elite level, a number of commentators and political experts deplored the state of American politics in 1991–1992, and reported the voters were angry. Many analysts blamed the poor quality of national election campaigns.
### 1992 presidential campaign.
Bush announced his reelection bid in early 1992; with a coalition victory in the Persian Gulf War and high approval ratings, Bush's reelection initially looked likely. As a result, many leading Democrats, including Mario Cuomo, Dick Gephardt, and Al Gore, declined to seek their party's presidential nomination. However, Bush's tax increase had angered many conservatives, who believed that Bush had strayed from the conservative principles of Ronald Reagan. He faced a challenge from conservative political columnist Pat Buchanan in the 1992 Republican primaries. Bush fended off Buchanan's challenge and won his party's nomination at the 1992 Republican National Convention, but the convention adopted a socially conservative platform strongly influenced by the Christian right.
Meanwhile, the Democrats nominated Governor Bill Clinton of Arkansas. A moderate who was affiliated with the Democratic Leadership Council (DLC), Clinton favored welfare reform, deficit reduction, and a tax cut for the middle class. In early 1992, the race took an unexpected twist when Texas billionaire H. Ross Perot launched a third party bid, claiming that neither Republicans nor Democrats could eliminate the deficit and make government more efficient. His message appealed to voters across the political spectrum disappointed with both parties' perceived fiscal irresponsibility. Perot also attacked NAFTA, which he claimed would lead to major job losses. National polling taken in mid-1992 showed Perot in the lead, but Clinton experienced a surge through effective campaigning and the selection of Senator Al Gore, a popular and relatively young Southerner, as his running mate.
Clinton won the election, taking 43 percent of the popular vote and 370 electoral votes, while Bush won 37.5 percent of the popular vote and 168 electoral votes. Perot won 19% of the popular vote, one of the highest totals for a third-party candidate in U.S. history, drawing equally from both major candidates, according to exit polls. Clinton performed well in the Northeast, the Midwest, and the West Coast, while also waging the strongest Democratic campaign in the South since the 1976 election. Several factors were important in Bush's defeat. The ailing economy which arose from recession may have been the main factor in Bush's loss, as 7 in 10 voters said on election day that the economy was either "not so good" or "poor". On the eve of the 1992 election, the unemployment rate stood at 7.8%, which was the highest it had been since 1984. The president was also damaged by his alienation of many conservatives in his party. Bush blamed Perot in part for his defeat, though exit polls showed that Perot drew his voters about equally from Clinton and Bush.
Despite his defeat, Bush left office with a 56 percent job approval rating in January 1993. Like many of his predecessors, Bush issued a series of pardons during his last days in office. In December 1992, he granted executive clemency to six former senior government officials implicated in the Iran-Contra scandal, most prominently former Secretary of Defense Caspar Weinberger. The charges against the six were that they lied to or withheld information from Congress. The pardons effectively brought an end to the Iran-Contra scandal.
According to Seymour Martin Lipset, the 1992 election had several unique characteristics. Voters felt that economic conditions were worse than they actually were, which harmed Bush. A rare event was the presence of a strong third-party candidate. Liberals launched a backlash against 12 years of a conservative White House. The chief factor was Clinton uniting his party, and winning over a number of heterogeneous groups.
## Post-presidency (1993–2018).
### Appearances.
After leaving office, Bush and his wife built a retirement house in the community of West Oaks, Houston. He established a presidential office within the Park Laureate Building on Memorial Drive in Houston. He also frequently spent time at his vacation home in Kennebunkport, took annual cruises in Greece, went on fishing trips in Florida, and visited the Bohemian Club in Northern California. He declined to serve on corporate boards, but delivered numerous paid speeches and served as an adviser to The Carlyle Group, a private equity firm. He never published his memoirs, but he and Brent Scowcroft co-wrote "A World Transformed", a 1999 work on foreign policy. Portions of his letters and his diary were later published as "The China Diary of George H. W. Bush" and "All The Best, George Bush".
During a 1993 visit to Kuwait, Bush was targeted in an assassination plot directed by the Iraqi Intelligence Service. President Clinton retaliated when he ordered the firing of 23 cruise missiles at Iraqi Intelligence Service headquarters in Baghdad. Bush did not publicly comment on the assassination attempt or the missile strike, but privately spoke with Clinton shortly before the strike took place. In the 1994 gubernatorial elections, his sons George W. and Jeb concurrently ran for Governor of Texas and Governor of Florida. Concerning their political careers, he advised them both that "[a]t some point both of you may want to say 'Well, I don't agree with my Dad on that point' or 'Frankly I think Dad was wrong on that.' Do it. Chart your own course, not just on the issues but on defining yourselves". George W. won his race against Ann Richards while Jeb lost to Lawton Chiles. After the results came in, the elder Bush told ABC, "I have very mixed emotions. Proud father, is the way I would sum it all up." Jeb would again run for governor of Florida in 1998 and win at the same time that his brother George W. won re-election in Texas. It marked the second time in United States history that a pair of brothers served simultaneously as governors.
Bush supported his son's candidacy in the 2000 presidential election, but did not actively campaign in the election and did not deliver a speech at the 2000 Republican National Convention. George W. Bush defeated Al Gore in the 2000 election and was re-elected in 2004. Bush and his son thus became the second father–son pair to each serve as President of the United States, following John Adams and John Quincy Adams. Through previous administrations, the elder Bush had ubiquitously been known as "George Bush" or "President Bush", but following his son's election the need to distinguish between them has made retronymic forms such as "George H. W. Bush" and "George Bush Sr." and colloquialisms such as "Bush 41" and "Bush the Elder" more common. Bush advised his son on some personnel choices, approving of the selection of Dick Cheney as running mate and the retention of George Tenet as CIA Director. However, he was not consulted on all appointments, including that of his old rival, Donald Rumsfeld, as Secretary of Defense. Though he avoided giving unsolicited advice to his son, Bush and his son also discussed some matters of policy, especially regarding national security issues.
In his retirement, Bush used the public spotlight to support various charities. Despite earlier political differences with Bill Clinton, the two former presidents eventually became friends. They appeared together in television ads, encouraging aid for victims of Hurricane Katrina and the 2004 Indian Ocean earthquake and tsunami. However, when interviewed by Jon Meacham, Bush criticized Donald Rumsfeld, Dick Cheney, and even his own son George W. Bush for their handling of foreign policy after the September 11 attacks.
### Final years.
Bush supported Republican John McCain in the 2008 presidential election, and Republican Mitt Romney in the 2012 presidential election, but both were defeated by Democrat Barack Obama. In 2011, Obama awarded Bush with the Presidential Medal of Freedom, the highest civilian honor in the United States.
Bush supported his son Jeb's bid in the 2016 Republican primaries. Jeb Bush's campaign struggled however, and he withdrew from the race during the primaries. Neither George H.W. nor George W. Bush endorsed the eventual Republican nominee, Donald Trump; all three Bushes emerged as frequent critics of Trump's policies and speaking style, while Trump frequently criticized George W. Bush's presidency. George H. W. Bush later said that he voted for the Democratic nominee, Hillary Clinton, in the general election. After the election, Bush wrote a letter to president-elect Donald Trump in January 2017 to inform him that because of his poor health, he would not be able to attend Trump's inauguration on January 20; he gave him his best wishes.
In August 2017, after the violence at Unite the Right rally in Charlottesville, both Presidents Bush released a joint statement saying, "America must always reject racial bigotry, anti-Semitism, and hatred in all forms[. ...] As we pray for Charlottesville, we are all reminded of the fundamental truths recorded by that city's most prominent citizen in the Declaration of Independence: we are all created equal and endowed by our Creator with unalienable rights."
On April 17, 2018, Barbara Bush, died at the age of 92 at her home in Houston, Texas. Her funeral was held at St. Martin's Episcopal Church in Houston four days later. Bush, along with former Presidents Barack Obama, George W. Bush (son), Bill Clinton and First Ladies Melania Trump, Michelle Obama, Laura Bush (daughter-in-law) and Hillary Clinton attended the funeral and posed together for a photo as a sign of unity.
On November 1, 2018, Bush went to the polls to vote early in the midterm elections. This would be his final public appearance.
### Death and funeral.
After a long battle with vascular Parkinson's disease, Bush died at his home in Houston on November 30, 2018, at the age of 94. At the time of his death he was the longest-lived U.S. president, a distinction now held by Jimmy Carter. He was also the third-oldest vice president. Bush lay in state in the Rotunda of the U.S. Capitol from December 3 through December 5; he was the 12th U.S. president to be accorded this honor. Then, on December 5, Bush's casket was transferred from the Capitol rotunda to Washington National Cathedral where a state funeral was held. After the funeral, Bush's body was transported to George H.W. Bush Presidential Library in College Station, Texas, where he was buried next to his wife Barbara and daughter Robin. At the funeral, former president George W. Bush eulogized his father saying,
## Personal life.
In 1991, "The New York Times" revealed that Bush was suffering from Graves' disease, a non-contagious thyroid condition that his wife Barbara also suffered from. Bush had two separate hip replacement surgeries in 2000 and 2007. Thereafter, Bush started to experience weakness in his legs, which was attributed vascular parkinsonism, a form of Parkinson's disease. He progressively developed problems walking, initially needing a walking stick for mobility aid before he eventually came to rely on a wheelchair from 2011 onwards.
Bush was a lifelong Episcopalian and a member of St. Martin's Episcopal Church in Houston. As President, Bush regularly attended services at St. John's Episcopal Church in Washington D.C. He cited various moments in his life on the deepening of his faith, including his escape from Japanese forces in 1944, and the death of his three-year-old daughter Robin in 1953. His faith was reflected in his Thousand Points of Light speech, his support for prayer in schools, and his support for the pro-life movement (following his election as vice president).
## Legacy.
### Historical reputation.
Polls of historians and political scientists have ranked Bush in the top half of presidents. A 2018 poll of the American Political Science Association's Presidents and Executive Politics section ranked Bush as the 17th best president out of 44. A 2017 C-Span poll of historians also ranked Bush as the 20th best president out of 43. Richard Rose described Bush as a "guardian" president, and many other historians and political scientists have similarly described Bush as a passive, hands-off president who was "largely content with things as they were". Professor Steven Knott writes that "[g]enerally the Bush presidency is viewed as successful in foreign affairs but a disappointment in domestic affairs."
Biographer Jon Meacham writes that, after he left office, many Americans viewed Bush as "a gracious and underappreciated man who had many virtues but who had failed to project enough of a distinctive identity and vision to overcome the economic challenges of 1991–92 and to win a second term." Bush himself noted that his legacy was "lost between the glory of Reagan ... and the trials and tribulations of my sons." In the 2010s, Bush was fondly remembered for his willingness to compromise, which contrasted with the intensely partisan era that followed his presidency.
In 2018, "Vox" highlighted Bush for his "pragmatism" as a moderate Republican president by working across the aisle. They specifically noted Bush's accomplishments within the domestic policy by making bipartisan deals, including raising the tax budget among the wealthy with the Omnibus Budget Reconciliation Act of 1990. Bush also helped pass the Americans with Disabilities Act of 1990 which "The New York Times" described as "the most sweeping anti-discrimination law since the Civil Rights Act of 1964. In response to the Exxon Valdez oil spill, Bush built another bipartisan coalition to strengthen the Clean Air Act Amendments of 1990. Bush also championed and signed into a law the Immigration Act of 1990, a sweeping bipartisan immigration reform act that made it easier for immigrants to legally enter the county, while also granting immigrants fleeing violence the temporary protected status visa, as well as lifted the pre-naturalization English testing process, and finally "eliminated the exclusion of homosexuals under what Congress now deemed the medically unsound classification of “sexual deviant” that was included in the 1965 act." Bush stated, "Immigration is not just a link to our past but its also a bridge to America's future".
According to "USA Today", the legacy of Bush's presidency was defined by his victory over Iraq after the invasion of Kuwait, and by his presiding over the dissolution of the Soviet Union and German reunification. Michael Beschloss and Strobe Talbott praise Bush's handling of the USSR, especially how he prodded Gorbachev in terms of releasing control over the satellite states and permitting German unification—and especially a united Germany in NATO. Andrew Bacevich judges the Bush administration as “morally obtuse” in the light of its “business-as-usual” attitude towards China after the massacre in Tiananmen Square and its uncritical support of Gorbachev as the Soviet Union disintegrated. David Rothkopf argues:
### Memorials, awards, and honors.
In 1990, "Time" magazine named him the Man of the Year. In 1997, the Houston Intercontinental Airport was renamed as the George Bush Intercontinental Airport. In 1999, the CIA headquarters in Langley, Virginia, was named the "George Bush Center for Intelligence" in his honor. In 2011, Bush, an avid golfer, was inducted in the World Golf Hall of Fame. The (CVN-77), the tenth and last supercarrier of the United States Navy, was named for Bush. Bush is commemorated on a postage stamp that was issued by the United States Postal Service in 2019.
The George H.W. Bush Presidential Library and Museum, the tenth U.S. presidential library, was completed in 1997. It contains the presidential and vice presidential papers of Bush and the vice presidential papers of Dan Quayle. The library is located on a site on the west campus of Texas A&amp;M University in College Station, Texas. Texas A&amp;M University also hosts the Bush School of Government and Public Service, a graduate public policy school.

</doc>
<doc id="11956" url="https://en.wikipedia.org/wiki?curid=11956" title="GPS (disambiguation)">
GPS (disambiguation)

GPS is the Global Positioning System, a satellite-based navigation system.
GPS may also refer to:

</doc>
<doc id="11958" url="https://en.wikipedia.org/wiki?curid=11958" title="George Berkeley">
George Berkeley

George Berkeley (; 12 March 168514 January 1753) – known as Bishop Berkeley (Bishop of Cloyne of the Anglican Church of Ireland) – was an Anglo-Irish philosopher whose primary achievement was the advancement of a theory he called "immaterialism" (later referred to as "subjective idealism" by others). This theory denies the existence of material substance and instead contends that familiar objects like tables and chairs are ideas perceived by the minds and, as a result, cannot exist without being perceived. Berkeley is also known for his critique of abstraction, an important premise in his argument for immaterialism.
In 1709, Berkeley published his first major work, "", in which he discussed the limitations of human vision and advanced the theory that the proper objects of sight are not material objects, but light and colour. This foreshadowed his chief philosophical work, "A Treatise Concerning the Principles of Human Knowledge", in 1710, which, after its poor reception, he rewrote in dialogue form and published under the title "Three Dialogues between Hylas and Philonous" in 1713. In this book, Berkeley's views were represented by Philonous (Greek: "lover of mind"), while Hylas ("hyle", Greek: "matter") embodies the Irish thinker's opponents, in particular John Locke.
Berkeley argued against Isaac Newton's doctrine of absolute space, time and motion in "De Motu" ("On Motion"), published 1721. His arguments were a precursor to the views of Mach and Einstein. In 1732, he published "Alciphron", a Christian apologetic against the free-thinkers, and in 1734, he published "The Analyst", a critique of the foundations of calculus, which was influential in the development of mathematics.
Interest in Berkeley's work increased after World War II because he tackled many of the issues of paramount interest to philosophy in the 20th century, such as the problems of perception, the difference between primary and secondary qualities, and the importance of language.
## Biography.
### Ireland.
Berkeley was born at his family home, Dysart Castle, near Thomastown, County Kilkenny, Ireland, the eldest son of William Berkeley, a cadet of the noble family of Berkeley whose ancestry can be trace back to the Anglo-Saxon period and who had served as feudal lords and landowners in Gloucester, England. Little is known of his mother. He was educated at Kilkenny College and attended Trinity College Dublin, where he was elected a Scholar in 1702, being awarded BA in 1704 and MA and a Fellowship in 1707. He remained at Trinity College after completion of his degree as a tutor and Greek lecturer.
His earliest publication was on mathematics, but the first that brought him notice was his "", first published in 1709. In the essay, Berkeley examines visual distance, magnitude, position and problems of sight and touch. While this work raised much controversy at the time, its conclusions are now accepted as an established part of the theory of optics.
The next publication to appear was the "Treatise Concerning the Principles of Human Knowledge" in 1710, which had great success and gave him a lasting reputation, though few accepted his theory that nothing exists outside the mind. This was followed in 1713 by "Three Dialogues between Hylas and Philonous", in which he propounded his system of philosophy, the leading principle of which is that the world, as represented by our senses, depends for its existence on being perceived.
For this theory, the "Principles" gives the exposition and the "Dialogues" the defence. One of his main objectives was to combat the prevailing materialism of his time. The theory was largely received with ridicule, while even those such as Samuel Clarke and William Whiston, who did acknowledge his "extraordinary genius," were nevertheless convinced that his first principles were false.
### England and Europe.
Shortly afterwards, Berkeley visited England and was received into the circle of Addison, Pope and Steele. In the period between 1714 and 1720, he interspersed his academic endeavours with periods of extensive travel in Europe, including one of the most extensive Grand Tours of the length and breadth of Italy ever undertaken. In 1721, he took Holy Orders in the Church of Ireland, earning his doctorate in divinity, and once again chose to remain at Trinity College Dublin, lecturing this time in Divinity and in Hebrew. In 1721/2 he was made Dean of Dromore and, in 1724, Dean of Derry.
In 1723, following her violent quarrel with Jonathan Swift, who had been her intimate friend for many years, Esther Vanhomrigh (for whom Swift had created the nickname "Vanessa") named Berkeley her co-heir along with the barrister Robert Marshall; her choice of legatees caused a good deal of surprise since she did not know either of them well, although Berkeley as a very young man had known her father. Swift said generously that he did not grudge Berkeley his inheritance, much of which vanished in a lawsuit in any event. A story that Berkeley and Marshall disregarded a condition of the inheritance that they must publish the correspondence between Swift and Vanessa is probably untrue.
In 1725, he began the project of founding a college in Bermuda for training ministers and missionaries in the colony, in pursuit of which he gave up his deanery with its income of £1100.
### Marriage and America.
In 1728, he married Anne Forster, daughter of John Forster, Chief Justice of the Irish Common Pleas, and his first wife Rebecca Monck. He then went to America on a salary of £100 per annum. He landed near Newport, Rhode Island, where he bought a plantation at Middletownthe famous "Whitehall". Berkeley purchased several enslaved Africans to work on the plantation. It has been claimed that "he introduced Palladianism into America by borrowing a design from [William] Kent's "Designs of Inigo Jones" for the door-case of his house in Rhode Island, Whitehall." He also brought to New England John Smibert, the Scottish artist he "discovered" in Italy, who is generally regarded as the founding father of American portrait painting. Meanwhile, he drew up plans for the ideal city he planned to build on Bermuda. He lived at the plantation while he waited for funds for his college to arrive. The funds, however, were not forthcoming. "With the withdrawal from London of his own persuasive energies, opposition gathered force; and the Prime Minister, Walpole grew steadily more sceptical and lukewarm. At last it became clear that the essential Parliamentary grant would be not forthcoming" and in 1732 he left America and returned to London. He and Anne had four children who survived infancy: Henry, George, William and Julia, and at least two other children who died in infancy. William's death in 1751 was a great cause of grief to his father.
### Episcopate in Ireland.
Berkeley was nominated to be the Bishop of Cloyne in the Church of Ireland on 18 January 1734. He was consecrated as such on 19 May 1734. He was the Bishop of Cloyne until his death on 14 January 1753, although he died at Oxford (see below).
### Humanitarian work.
While living in London's Saville Street, he took part in efforts to create a home for the city's abandoned children. The Foundling Hospital was founded by Royal Charter in 1739, and Berkeley is listed as one of its original governors.
### Last works.
His last two publications were "Siris: A Chain of Philosophical Reflexions and Inquiries Concerning the Virtues of Tarwater, And divers other Subjects connected together and arising one from another" (1744) and "Further Thoughts on Tar-water" (1752). Pine tar is an effective antiseptic and disinfectant when applied to cuts on the skin, but Berkeley argued for the use of pine tar as a broad panacea for diseases. His 1744 work on tar-water sold more copies than any of his other books during Berkeley's lifetime.
He remained at Cloyne until 1752, when he retired. With his wife and daughter Julia he went to Oxford to live with his son George and supervise his education. He died soon afterward and was buried in Christ Church Cathedral, Oxford. His affectionate disposition and genial manners made him much loved and held in warm regard by many of his contemporaries. Anne outlived her husband by many years, and died in 1786.
## Contributions to philosophy.
The use of the concepts of "spirit" and "idea" is central in Berkeley's philosophy. As used by him, these concepts are difficult to translate into modern terminology. His concept of "spirit" is close to the concept of "conscious subject" or of "mind", and the concept of "idea" is close to the concept of "sensation" or "state of mind" or "conscious experience".
Thus Berkeley denied the existence of matter as a metaphysical substance, but did not deny the existence of physical objects such as apples or mountains ("I do not argue against the existence of any one thing that we can apprehend, either by sense or reflection. That the things I see with mine eyes and touch with my hands do exist, really exist, I make not the least question. The only thing whose existence we deny, is that which philosophers call matter or corporeal substance. And in doing of this, there is no damage done to the rest of mankind, who, I dare say, will never miss it.", "Principles" #35). This basic claim of Berkeley's thought, his "idealism", is sometimes and somewhat derisively called "immaterialism" or, occasionally, subjective idealism. In "Principles" #3, he wrote, using a combination of Latin and English, "esse is percipi" (to be is to be perceived), most often if slightly inaccurately attributed to Berkeley as the pure Latin phrase esse est percipi. The phrase appears associated with him in authoritative philosophical sources, e.g., "Berkeley holds that there are no such mind-independent things, that, in the famous phrase, "esse est percipi (aut percipere)"—to be is to be perceived (or to perceive)."
Hence, human knowledge is reduced to two elements: that of spirits and of ideas ("Principles" #86). In contrast to ideas, a spirit cannot be perceived. A person's spirit, which perceives ideas, is to be comprehended intuitively by inward feeling or reflection ("Principles" #89). For Berkeley, we have no direct 'idea' of spirits, albeit we have good reason to believe in the existence of other spirits, for their existence explains the purposeful regularities we find in experience ("It is plain that we cannot know the existence of other spirits otherwise than by their operations, or the ideas by them excited in us", "Dialogues" #145). This is the solution that Berkeley offers to the problem of other minds. Finally, the order and purposefulness of the whole of our experience of the world and especially of nature overwhelms us into believing in the existence of an extremely powerful and intelligent spirit that causes that order. According to Berkeley, reflection on the attributes of that external spirit leads us to identify it with God. Thus a material thing such as an apple consists of a collection of ideas (shape, color, taste, physical properties, etc.) which are caused in the spirits of humans by the spirit of God.
### Theology.
A convinced adherent of Christianity, Berkeley believed God to be present as an immediate cause of all our experiences.
Here is Berkeley's proof of the existence of God:
As T. I. Oizerman explained:
Berkeley believed that God is not the distant engineer of Newtonian machinery that in the fullness of time led to the growth of a tree in the university quadrangle. Rather, the perception of the tree is an idea that God's mind has produced in the mind, and the tree continues to exist in the quadrangle when "nobody" is there, simply because God is an infinite mind that perceives all.
The philosophy of David Hume concerning causality and objectivity is an elaboration of another aspect of Berkeley's philosophy. A.A. Luce, the most eminent Berkeley scholar of the 20th century, constantly stressed the continuity of Berkeley's philosophy. The fact that Berkeley returned to his major works throughout his life, issuing revised editions with only minor changes, also counts against any theory that attributes to him a significant volte-face.
### Relativity arguments.
John Locke (Berkeley's intellectual predecessor) states that we define an object by its primary and secondary qualities. He takes heat as an example of a secondary quality. If you put one hand in a bucket of cold water, and the other hand in a bucket of warm water, then put both hands in a bucket of lukewarm water, one of your hands is going to tell you that the water is cold and the other that the water is hot. Locke says that since two different objects (both your hands) perceive the water to be hot "and" cold, then the heat is not a quality of the water.
While Locke used this argument to distinguish primary from secondary qualities, Berkeley extends it to cover primary qualities in the same way. For example, he says that size is not a quality of an object because the size of the object depends on the distance between the observer and the object, or the size of the observer. Since an object is a different size to different observers, then size is not a quality of the object. Berkeley rejects shape with a similar argument and then asks: if neither primary qualities nor secondary qualities are of the object, then how can we say that there is anything more than the qualities we observe?
Relativity is the idea that there is no objective, universal truth; it is a state of dependence in which the existence of one independent object is solely dependent on that of another. According to Locke, characteristics of primary qualities are mind-independent, such as shape, size, etc., whereas secondary qualities are mind-dependent, for example, taste and color. George Berkeley refuted John Locke's belief on primary and secondary qualities because Berkeley believed that "we cannot abstract the primary qualities (e.g shape) from secondary ones (e.g color)". Berkeley argued that perception is dependent on the distance between the observer and the object, and "thus, we cannot conceive of mechanist material bodies which are extended but not (in themselves) colored". What perceived can be the same type of quality, but completely opposite form each other because of different positions and perceptions, what we perceive can be different even when the same types of things consist of contrary qualities. Secondary qualities aid in people's conception of primary qualities in an object, like how the color of an object leads people to recognize the object itself. More specifically, the color red can be perceived in apples, strawberries, and tomatoes, yet we would not know what these might look like without its color. We would also be unaware of what the color red looked like if red paint, or any object that has a perceived red color, failed to exist. From this, we can see that colors cannot exist on their own and can solely represent a group of perceived objects. Therefore, both primary and secondary qualities are mind-dependent: they cannot exist without our minds.
George Berkeley was a philosopher who was against rationalism and "classical" empiricism. He was a "subjective idealist" or "empirical idealist", who believed that reality is constructed entirely of immaterial, conscious minds and their ideas; everything that exists is somehow dependent on the subject perceiving it, except the subject themselves. He refuted the existence of abstract objects that many other philosophers believed to exist, notably Plato. According to Berkeley, "an abstract object does not exist in space or time and which is therefore entirely non-physical and non-mental"; however, this argument contradicts with his relativity argument. If "esse est percipi", (Latin meaning that to exist is to be perceived) is true, then the objects in the relativity argument made by Berkeley can either exist or not. Berkeley believed that only the minds' perceptions and the Spirit that perceives are what exists in reality; what people perceive every day is only the idea of an object's existence, but the objects themselves are not perceived. Berkeley also discussed how, at times, materials cannot be perceived by oneself, and the mind of oneself cannot understand the objects. However, there also exists an "omnipresent, eternal mind" that Berkeley believed to consist of God and the Spirit, both omniscient and all-perceiving. According to Berkeley, God is the entity who controls everything, yet Berkeley also argued that "abstract object[s] do not exist in space or time". In other words, as Warnock argues, Berkeley "had recognized that he could not square with his own talk of "spirits", of our minds and of God; for these are perceivers and not among objects of perception. Thus he says, rather weakly and without elucidation, that in addition to our ideas we also have "notions"—we know what it means to speak of "spirits" and their operations."
However, the relativity argument violates the idea of immaterialism. Berkeley's immaterialism argues that "esse est percipi (aut percipere)", which in English is to be is to be perceived (or to perceive). That is saying only what perceived or perceives is real, and without our perception or God's nothing can be real. Yet, if the relativity argument, also by Berkeley, argues that the perception of an object depends on the different positions, then this means that what perceived can either be real or not because the perception does not show that whole picture and the whole picture cannot be perceived. Berkeley also believes that "when one perceives mediately, one perceives one idea by means of perceiving another". By this, it can be elaborated that if the standards of what perceived at first are different, what perceived after that can be different, as well. In the heat perception described above, one hand perceived the water to be hot and the other hand perceived the water to be cold due to relativity. If applying the idea "to be is to be perceived", the water should be both cold and hot because both perceptions are perceived by different hands. However, the water cannot be cold and hot at the same time for it self-contradicts, so this shows that what perceived is not always true because it sometimes can break the law of noncontradiction. In this case, "it would be arbitrary anthropocentrism to claim that humans have special access to the true qualities of objects". The truth for different people can be different, and humans are limited to accessing the absolute truth due to relativity. Summing up, nothing can be absolutely true due to relativity or the two arguments, to be is to be perceived and the relativity argument, do not always work together.
### New theory of vision.
In his "Essay Towards a New Theory of Vision", Berkeley frequently criticised the views of the Optic Writers, a title that seems to include Molyneux, Wallis, Malebranche and Descartes. In sections 1–51, Berkeley argued against the classical scholars of optics by holding that: "spatial depth, as the distance that separates the perceiver from the perceived object is itself invisible". That is, we do not see space directly or deduce its form logically using the laws of optics. Space for Berkeley is no more than a contingent expectation that visual and tactile sensations will follow one another in regular sequences that we come to expect through habit.
Berkeley goes on to argue that visual cues, such as the perceived extension or 'confusion' of an object, can only be used to indirectly judge distance, because the viewer learns to associate visual cues with tactile sensations. Berkeley gives the following analogy regarding indirect distance perception: one perceives distance indirectly just as one perceives a person's embarrassment indirectly. When looking at an embarrassed person, we infer indirectly that the person is embarrassed by observing the red color on the person's face. We know through experience that a red face tends to signal embarrassment, as we've learned to associate the two.
The question concerning the visibility of space was central to the Renaissance perspective tradition and its reliance on classical optics in the development of pictorial representations of spatial depth. This matter was debated by scholars since the 11th-century Arab polymath and mathematician Alhazen (al-Hasan Ibn al-Haytham) affirmed in experimental contexts the visibility of space. This issue, which was raised in Berkeley's theory of vision, was treated at length in the "Phenomenology of Perception" of Maurice Merleau-Ponty, in the context of confirming the visual perception of spatial depth ("la profondeur"), and by way of refuting Berkeley's thesis.
Berkeley wrote about the perception of size in addition to that of distance. He is frequently misquoted as believing in size–distance invariance—a view held by the Optic Writers. This idea is that we scale the image size according to distance in a geometrical manner. The error may have become commonplace because the eminent historian and psychologist E. G. Boring perpetuated it. In fact, Berkeley argued that the same cues that evoke distance also evoke size, and that we do not first see size and then calculate distance. It is worth quoting Berkeley's words on this issue (Section 53):
What inclines men to this mistake (beside the humour of making one see by geometry) is, that the same perceptions or ideas which suggest distance, do also suggest magnitude ... I say they do not first suggest distance, and then leave it to the judgement to use that as a medium, whereby to collect the magnitude; but they have as close and immediate a connexion with the magnitude as with the distance; and suggest magnitude as independently of distance, as they do distance independently of magnitude.
Berkeley claimed that his visual theories were “vindicated” by a 1728 report regarding the recovery of vision in a 13-year-old boy operated for congenital cataracts by surgeon William Cheselden. In 2021, the name of Cheselden's patient was published for the first time: Daniel Dolins. Berkeley knew the Dolins family, had numerous social links to Cheselden, including the poet Alexander Pope, and Princess Caroline, to whom Cheselden's patient was presented. The report misspelled Cheselden's name, used language typical of Berkeley, and may even have been ghost-written by Berkeley. Unfortunately, Dolins was never able to see well enough to read, and there is no evidence that the surgery improved Dolins' vision at any point prior to his death at age 30.
### Philosophy of physics.
"Berkeley's works display his keen interest in natural philosophy [...] from his earliest writings ("Arithmetica", 1707) to his latest ("Siris", 1744). Moreover, much of his philosophy is shaped fundamentally by his engagement with the science of his time." The profundity of this interest can be judged from numerous entries in Berkeley's "Philosophical Commentaries" (1707–1708), e.g. "Mem. to Examine &amp; accurately discuss the scholium of the 8th Definition of Mr Newton's Principia." (#316)
Berkeley argued that forces and gravity, as defined by Newton, constituted "occult qualities" that "expressed nothing distinctly". He held that those who posited "something unknown in a body of which they have no idea and which they call the principle of motion, are in fact simply stating that the principle of motion is unknown." Therefore, those who "affirm that active force, action, and the principle of motion are really in bodies are adopting an opinion not based on experience." Forces and gravity existed nowhere in the phenomenal world. On the other hand, if they resided in the category of "soul" or "incorporeal thing", they "do not properly belong to physics" as a matter. Berkeley thus concluded that forces lay beyond any kind of empirical observation and could not be a part of proper science. He proposed his theory of signs as a means to explain motion and matter without reference to the "occult qualities" of force and gravity.
### Berkeley's razor.
Berkeley's razor is a rule of reasoning proposed by the philosopher Karl Popper in his study of Berkeley's key scientific work "De Motu". Berkeley's razor is considered by Popper to be similar to Ockham's razor but "more powerful". It represents an extreme, empiricist view of scientific observation that states that the scientific method provides us with no true insight into the nature of the world. Rather, the scientific method gives us a variety of partial explanations about regularities that hold in the world and that are gained through experiment. The nature of the world, according to Berkeley, is only approached through proper metaphysical speculation and reasoning. Popper summarises Berkeley's razor as such:
A general practical result—which I propose to call "Berkeley's razor"—of [Berkeley's] analysis of physics allows us "a priori" to eliminate from physical science all essentialist explanations. If they have a mathematical and predictive content they may be admitted "qua" mathematical hypotheses (while their essentialist interpretation is eliminated). If not they may be ruled out altogether. This razor is sharper than Ockham's: "all" entities are ruled out except those which are perceived.
In another essay of the same book titled "Three Views Concerning Human Knowledge", Popper argues that Berkeley is to be considered as an instrumentalist philosopher, along with Robert Bellarmine, Pierre Duhem and Ernst Mach. According to this approach, scientific theories have the status of serviceable fictions, useful inventions aimed at explaining facts, and without any pretension to be true. Popper contrasts instrumentalism with the above-mentioned essentialism and his own "critical rationalism".
### Philosophy of mathematics.
In addition to his contributions to philosophy, Berkeley was also very influential in the development of mathematics, although in a rather indirect sense. "Berkeley was concerned with mathematics and its philosophical interpretation from the earliest stages of his intellectual life."
Berkeley's "Philosophical Commentaries" (1707–1708) witness to his interest in mathematics:
Axiom. No reasoning about things whereof we have no idea. Therefore no reasoning about Infinitesimals. (#354)
Take away the signs from Arithmetic &amp; Algebra, &amp; pray what remains? (#767)
These are sciences purely Verbal, &amp; entirely useless but for Practise in Societys of Men. No speculative knowledge, no comparison of Ideas in them. (#768)
In 1707, Berkeley published two treatises on mathematics. In 1734, he published "The Analyst", subtitled "A DISCOURSE Addressed to an Infidel Mathematician", a critique of calculus. Florian Cajori called this treatise "the most spectacular event of the century in the history of British mathematics." However, a recent study suggests that Berkeley misunderstood Leibnizian calculus. The mathematician in question is believed to have been either Edmond Halley, or Isaac Newton himself—though if to the latter, then the discourse was posthumously addressed, as Newton died in 1727. "The Analyst" represented a direct attack on the foundations and principles of calculus and, in particular, the notion of fluxion or infinitesimal change, which Newton and Leibniz used to develop the calculus. In his critique, Berkeley coined the phrase "ghosts of departed quantities", familiar to students of calculus. Ian Stewart's book "From Here to Infinity" captures the gist of his criticism.
Berkeley regarded his criticism of calculus as part of his broader campaign against the religious implications of Newtonian mechanicsas a defence of traditional Christianity against deism, which tends to distance God from His worshipers. Specifically, he observed that both Newtonian and Leibnizian calculus employed infinitesimals sometimes as positive, nonzero quantities and other times as a number explicitly equal to zero. Berkeley's key point in "The Analyst" was that Newton's calculus (and the laws of motion based in calculus) lacked rigorous theoretical foundations. He claimed that
In every other Science Men prove their Conclusions by their Principles, and not their Principles by the Conclusions. But if in yours you should allow your selves this unnatural way of proceeding, the Consequence would be that you must take up with Induction, and bid adieu to Demonstration. And if you submit to this, your Authority will no longer lead the way in Points of Reason and Science.
Berkeley did not doubt that calculus produced real world truth; simple physics experiments could verify that Newton's method did what it claimed to do. "The cause of Fluxions cannot be defended by reason", but the results could be defended by empirical observation, Berkeley's preferred method of acquiring knowledge at any rate. Berkeley, however, found it paradoxical that "Mathematicians should deduce true Propositions from false Principles, be right in Conclusion, and yet err in the Premises." In "The Analyst" he endeavoured to show "how Error may bring forth Truth, though it cannot bring forth Science". Newton's science, therefore, could not on purely scientific grounds justify its conclusions, and the mechanical, deistic model of the universe could not be rationally justified.
The difficulties raised by Berkeley were still present in the work of Cauchy whose approach to calculus was a combination of infinitesimals and a notion of limit, and were eventually sidestepped by Weierstrass by means of his (ε, δ) approach, which eliminated infinitesimals altogether. More recently, Abraham Robinson restored infinitesimal methods in his 1966 book "Non-standard analysis" by showing that they can be used rigorously.
### Moral philosophy.
The tract "A Discourse on Passive Obedience" (1712) is considered Berkeley's major contribution to moral and political philosophy.
In "A Discourse on Passive Obedience", Berkeley defends the thesis that people have "a moral duty to observe the negative precepts (prohibitions) of the law, including the duty not to resist the execution of punishment." However, Berkeley does make exceptions to this sweeping moral statement, stating that we need not observe precepts of "usurpers or even madmen" and that people can obey different supreme authorities if there are more than one claims to the highest authority.
Berkeley defends this thesis with a deductive proof stemming from the laws of nature. First, he establishes that because God is perfectly good, the end to which he commands humans must also be good, and that end must not benefit just one person, but the entire human race. Because these commands—or laws—if practiced, would lead to the general fitness of humankind, it follows that they can be discovered by the right reason—for example, the law to never resist supreme power can be derived from reason because this law is "the only thing that stands between us and total disorder". Thus, these laws can be called the laws of nature, because they are derived from God—the creator of nature himself. "These laws of nature include duties never to resist the supreme power, lie under oath ... or do evil so that good may come of it."
One may view Berkeley's doctrine on Passive Obedience as a kind of 'Theological Utilitarianism', insofar as it states that we have a duty to uphold a moral code which presumably is working towards the ends of promoting the good of humankind. However, the concept of 'ordinary' Utilitarianism is fundamentally different in that it "makes utility the one and only "ground" of obligation"—that is, Utilitarianism is concerned with whether particular actions are morally permissible in specific situations, while Berkeley's doctrine is concerned with whether or not we should follow moral rules in any and all circumstances. Whereas Act Utilitarianism might, for example, justify a morally impermissible act in light of the specific situation, Berkeley's doctrine of Passive Obedience holds that it is never morally permissible to not follow a moral rule, even when it seems like breaking that moral rule might achieve the happiest ends. Berkeley holds that even though sometimes, the consequences of an action in a specific situation might be bad, the general tendencies of that action benefits humanity.
Other important sources for Berkeley's views on morality are "Alciphron" (1732), especially dialogues I–III, and the "Discourse to Magistrates" (1738)." "Passive Obedience" is notable partly for containing one of the earliest statements of rule utilitarianism.
### Immaterialism.
George Berkeley’s theory that matter does not exist comes from the belief that "sensible things are those only which are immediately perceived by sense." Berkeley says in his book called "The Principles of Human Knowledge" that "the ideas of sense are stronger, livelier, and clearer than those of the imagination; and they are also steady, orderly and coherent." From this we can tell that the things that we are perceiving are truly real rather than it just being a dream.
All knowledge comes from perception; what we perceive are ideas, not things in themselves; a thing in itself must be outside experience; so the world only consists of ideas and minds that perceive those ideas; a thing only exists so far as it perceives or is perceived. Through this we can see that consciousness is considered something that exists to Berkeley due to its ability to perceive. "'To be,' said of the object, means to be perceived, 'esse est percipi'; 'to be', said of the subject, means to perceive or 'percipere'." Having established this, Berkeley then attacks the "opinion strangely prevailing amongst men, that houses, mountains, rivers, and in a word all sensible objects have an existence natural or real, distinct from being perceived". He believes this idea to be inconsistent because such an object with an existence independent of perception must have both sensible qualities, and thus be known (making it an idea), and also an insensible reality, which Berkeley believes is inconsistent. Berkeley believes that the error arises because people think that perceptions can imply or infer something about the material object. Berkeley calls this concept "abstract ideas". He rebuts this concept by arguing that people cannot conceive of an object without also imagining the sensual input of the object. He argues in "Principles of Human Knowledge" that, similar to how people can only sense matter with their senses through the actual sensation, they can only conceive of matter (or, rather, ideas of matter) through the idea of sensation of matter. This implies that everything that people can conceive in regards to matter is only ideas about matter. Thus, matter, should it exist, must exist as collections of ideas, which can be perceived by the senses and interpreted by the mind. But if matter is just a collection of ideas, then Berkeley concludes that matter, in the sense of a material substance, does not exist as most philosophers of Berkeley's time believed. Indeed, if a person visualizes something, then it must have some color, however dark or light; it cannot just be a shape of no color at all if a person is to visualize it.
Berkeley's ideas raised controversy because his argument refuted Descartes' worldview, which was expanded upon by Locke, and resulted in the rejection of Berkeley's form of empiricism by several philosophers of the seventeenth and eighteenth centuries. In Locke's worldview, "the world causes the perceptual ideas we have of it by the way it interacts with our senses." This contradicts with Berkeley's worldview because not only does it suggest the existence of physical causes in the world, but in fact there is no physical world beyond our ideas. The only causes that exist in Berkeley's worldview are those that are a result of the use of the will.
Berkeley's theory relies heavily on his form of empiricism, which in turn relies heavily on the senses. His empiricism can be defined by five propositions: all significant words stand for ideas; all knowledge of things is about ideas; all ideas come from without or from within; if from without it must be by the senses, and they are called sensations (the real things), if from within they are the operations of the mind, and are called thoughts. Berkeley clarifies his distinction between ideas by saying they "are imprinted on the senses," "perceived by attending to the passions and operations of the mind," or "are formed by help of memory and imagination." One refutation of his idea was: if someone leaves a room and stops perceiving that room does that room no longer exist? Berkeley answers this by claiming that it is still being perceived and the consciousness that is doing the perceiving is God. (This makes Berkeley's argument hinge upon an omniscient, omnipresent deity.) This claim is the only thing holding up his argument which is "depending for our knowledge of the world, and of the existence of other minds, upon a God that would never deceive us." Berkeley anticipates a second objection, which he refutes in "Principles of Human Knowledge". He anticipates that the materialist may take a representational materialist standpoint: although the senses can only perceive ideas, these ideas resemble (and thus can be compared to) the actual, existing object. Thus, through the sensing of these ideas, the mind can make inferences as to matter itself, even though pure matter is non-perceivable. Berkeley's objection to that notion is that "an idea can be like nothing but an idea; a color or figure can be like nothing but another color or figure". Berkeley distinguishes between an idea, which is mind-dependent, and a material substance, which is not an idea and is mind-independent. As they are not alike, they cannot be compared, just as one cannot compare the color red to something that is invisible, or the sound of music to silence, other than that one exists and the other does not. This is called the likeness principle: the notion that an idea can only be like (and thus compared to) another idea.
Berkeley attempted to show how ideas manifest themselves into different objects of knowledge:
Berkeley also attempted to prove the existence of God throughout his beliefs in immaterialism.
## Influence.
Berkeley's "Treatise Concerning the Principles of Human Knowledge" was published three years before the publication of Arthur Collier's "Clavis Universalis", which made assertions similar to those of Berkeley's. However, there seemed to have been no influence or communication between the two writers.
German philosopher Arthur Schopenhauer once wrote of him: "Berkeley was, therefore, the first to treat the subjective starting-point really seriously and to demonstrate irrefutably its absolute necessity. He is the father of idealism ...".
Berkeley is considered one of the originators of British empiricism. A linear development is often traced from three great "British Empiricists", leading from Locke through Berkeley to Hume.
Berkeley influenced many modern philosophers, especially David Hume. Thomas Reid admitted that he put forward a drastic criticism of Berkeleianism after he had been an admirer of Berkeley's philosophical system for a long time. Berkeley's "thought made possible the work of Hume and thus Kant, notes Alfred North Whitehead." Some authors draw a parallel between Berkeley and Edmund Husserl.
When Berkeley visited America, the American educator Samuel Johnson visited him, and the two later corresponded. Johnson convinced Berkeley to establish a scholarship program at Yale, and to donate a large number of books as well as his plantation to the college when the philosopher returned to England. It was one of Yale's largest and most important donations; it doubled its library holdings, improved the college's financial position and brought Anglican religious ideas and English culture into New England. Johnson also took Berkeley's philosophy and used parts of it as a framework for his own American Practical Idealism school of philosophy. As Johnson's philosophy was taught to about half the graduates of American colleges between 1743 and 1776, and over half of the contributors to the "Declaration of Independence "were connected to it, Berkeley's ideas were indirectly a foundation of the American Mind.
Outside of America, during Berkeley's lifetime his philosophical ideas were comparatively uninfluential. But interest in his doctrine grew from the 1870s when Alexander Campbell Fraser, "the leading Berkeley scholar of the nineteenth century", published "The Works of George Berkeley". A powerful impulse to serious studies in Berkeley's philosophy was given by A. A. Luce and Thomas Edmund Jessop, "two of the twentieth century's foremost Berkeley scholars", thanks to whom Berkeley scholarship was raised to the rank of a special area of historico-philosophical science. In addition, the philosopher Colin Murray Turbayne wrote extensively on Berkeley's use of language as model for visual, physiological, natural and metaphysical relationships.
The proportion of Berkeley scholarship, in literature on the history of philosophy, is increasing. This can be judged from the most comprehensive bibliographies on George Berkeley. During the period of 1709–1932, about 300 writings on Berkeley were published. That amounted to 1.5 publication per annum. During the course of 1932–79, over one thousand works were brought out, i.e., 20 works per annum. Since then, the number of publications has reached 30 per annum. In 1977 publication began in Ireland of a special journal on Berkeley's life and thought ("Berkeley Studies"). In 1988, the Australian philosopher Colin Murray Turbayne established the International Berkeley Essay Prize Competition at the University of Rochester in an effort to advance scholarship and research on the works of Berkeley.
Other than philosophy, Berkeley also influenced modern psychology with his work on John Locke's theory of association and how it could be used to explain how humans gain knowledge in the physical world. He also used the theory to explain perception, stating that all qualities were, as Locke would call them, "secondary qualities", therefore perception laid entirely in the perceiver and not in the object. These are both topics today studied in modern psychology.
## Appearances in literature.
Lord Byron's "Don Juan" references immaterialism in the Eleventh Canto:
 When Bishop Berkeley said 'there was no matter,'&lt;br&gt;
 And proved it—'t was no matter what he said:&lt;br&gt;
 They say his system 't is in vain to batter,&lt;br&gt;
 Too subtle for the airiest human head;&lt;br&gt;
 And yet who can believe it? I would shatter&lt;br&gt;
 Gladly all matters down to stone or lead,&lt;br&gt;
 Or adamant, to find the world a spirit,&lt;br&gt;
 And wear my head, denying that I wear it.
Herman Melville humorously references Berkeley in Chapter 20 of Mardi (1849), when outlining a character's belief of being on board a ghostship:
And here be it said, that for all his superstitious misgivings about the brigantine; his imputing to her something equivalent to a purely phantom-like nature, honest Jarl was nevertheless exceedingly downright and practical in all hints and proceedings concerning her. Wherein, he resembled my Right Reverend friend, Bishop Berkeley–truly, one of your lords spiritual—who, metaphysically speaking, holding all objects to be mere optical delusions, was, notwithstanding, extremely matter-of-fact in all matters touching matter itself. Besides being pervious to the points of pins, and possessing a palate capable of appreciating plum-puddings:—which sentence reads off like a pattering of hailstones.
James Joyce references Berkeley's philosophy in the third episode of "Ulysses" (1922):
Who watches me here? Who ever anywhere will read these written words? Signs on a white field. Somewhere to someone in your flutiest voice. The good bishop of Cloyne took the veil of the temple out of his shovel hat: veil of space with coloured emblems hatched on its field. Hold hard. Coloured on a flat: yes, that's right. Flat I see, then think distance, near, far, flat I see, east, back. Ah, see now!
In commenting on a review of "", author Vladimir Nabokov alludes to Berkeley's philosophy as informing his novel:
And finally I owe no debt whatsoever (as Mr. Leonard seems to think) to the famous Argentine essayist and his rather confused compilation "A New Refutation of Time." Mr. Leonard would have lost less of it had he gone straight to Berkeley and Bergson. ("Strong Opinions", pp. 2892–90)
James Boswell, in the part of his "Life of Samuel Johnson" covering the year 1763, recorded Johnson's opinion of one aspect of Berkeley's philosophy:
After we came out of the church, we stood talking for some time together of Bishop Berkeley's ingenious sophistry to prove the non-existence of matter, and that every thing in the universe is merely ideal. I observed, that though we are satisfied his doctrine is untrue, it is impossible to refute it. I shall never forget the alacrity with which Johnson answered, striking his foot with mighty force against a large stone, till he rebounded from it,– "I refute it "thus"."
## Commemoration.
Both the University of California, Berkeley, and the city of Berkeley, California, were named after him, although the pronunciation has evolved to suit American English: ( ). The naming was suggested in 1866 by Frederick H. Billings, a trustee of the then College of California. Billings was inspired by Berkeley's "Verses on the Prospect of Planting Arts and Learning in America", particularly the final stanza: "Westward the course of empire takes its way; The first four Acts already past, A fifth shall close the Drama with the day; Time's noblest offspring is the last."
The Town of Berkley, currently the least populated town in Bristol County, Massachusetts, was founded on 18 April 1735 and named after the renowned philosopher. It is located 40 miles south of Boston and 25 miles north of Middletown, Rhode Island.
A residential college and an Episcopal seminary at Yale University also bear Berkeley's name, as does the Berkeley Library at Trinity College, Dublin.
Berkeley Preparatory School in Tampa, Florida, a private school affiliated with the Episcopal Church, is also named for him.
"Bishop Berkeley's Gold Medals" are two awards given annually at Trinity College Dublin, "provided outstanding merit is shown", to candidates answering a special examination in Greek. The awards were founded in 1752 by Berkeley.
An Ulster History Circle blue plaque commemorating him is located in Bishop Street Within, city of Derry.
Berkeley's farmhouse in Middletown, Rhode Island, is preserved as Whitehall Museum House, also known as Berkeley House, and was listed on the National Register of Historic Places in 1970. St. Columba's Chapel, located in the same town, was formerly named "The Berkeley Memorial Chapel," and the appellation still survives at the end of the formal name of the parish, "St. Columba's, the Berkeley Memorial Chapel".
### Veneration.
Berkeley is honoured together with Joseph Butler with a feast day on the liturgical calendar of the Episcopal Church (USA) on 16 June.

</doc>
<doc id="11959" url="https://en.wikipedia.org/wiki?curid=11959" title="G. E. Moore">
G. E. Moore

George Edward Moore (4 November 1873 – 24 October 1958) was an English philosopher who, along with Bertrand Russell, Ludwig Wittgenstein and earlier Gottlob Frege, was among the founders of analytic philosophy. He and Russell led the turn from idealism in British philosophy, and became known for advocating common-sense concepts and contributing to ethics, epistemology and metaphysics. He was said to have an "exceptional personality and moral character". Ray Monk later dubbed him "the most revered philosopher of his era". As Professor of Philosophy at the University of Cambridge, he influenced but abstained from the Bloomsbury Group. He edited an influential journal, "Mind". A fellow of the British Academy from 1918, he was among the intellectually secret Cambridge Apostles in 1894–1901 and chaired the Cambridge University Moral Sciences Club in 1912–1944. As a humanist, he served as President of the British Ethical Union (now Humanists UK) in 1935–1936.
## Life.
Moore was born in Upper Norwood, in south-east London, on 4 November 1873, the middle child of seven of Dr Daniel Moore and Henrietta Sturge. His grandfather was the author Dr George Moore. His eldest brother was Thomas Sturge Moore, a poet, writer and engraver.
He was educated at Dulwich College and in 1892 went up to Trinity College, Cambridge, to read classics and moral sciences. He became a Fellow of Trinity in 1898 and went on to hold the University of Cambridge chair of Mental Philosophy and Logic from 1925 to 1939.
Moore is best known today for defending ethical non-naturalism, his emphasis on common sense in philosophical method, and the paradox that bears his name. He was admired by and influenced among other philosophers, and by the Bloomsbury Group, but unlike his colleague and admirer Russell, who for some years thought he fulfilled his "ideal of genius", mostly unknown today outside of academic philosophy. Moore's essays are known for their clarity and circumspection of writing style and methodical and patient approach to philosophical problems. He was critical of modern philosophy for lack of progress, which he saw as a stark contrast to the dramatic advances in the natural sciences since the Renaissance. Among Moore's most famous works are his "Principia Ethica", and his essays, "The Refutation of Idealism", "A Defence of Common Sense", and "A Proof of the External World".
Moore was an important and admired member of the secretive Cambridge Apostles, a discussion group drawn from the British intellectual elite. At the time another member, a 22-year-old Bertrand Russell, wrote, "I almost worship him as if he were a god. I have never felt such an extravagant admiration for anybody," and would later write that "for some years he fulfilled my ideal of genius. He was in those days beautiful and slim, with a look almost of inspiration as deeply passionate as Spinoza's".
From 1918 to 1919 Moore chaired the Aristotelian Society, a group committed to systematic study of philosophy, its historical development and its methods and problems.
G. E. Moore died at the Evelyn Nursing Home on 24 October 1958. He was cremated at Cambridge Crematorium on 28 October 1958 and his ashes interred at the Parish of the Ascension Burial Ground in the city. His wife Dorothy Ely (18921977) was buried there. Together they had two sons, the poet Nicholas Moore and the composer Timothy Moore.
## Philosophy.
### Ethics.
His influential work "Principia Ethica" is one of the main inspirations of the movement against ethical naturalism (see ethical non-naturalism) and is partly responsible for the twentieth-century concern with meta-ethics.
#### The naturalistic fallacy.
Moore asserted that philosophical arguments can suffer from a confusion between the use of a term in a particular argument and the definition of that term (in all arguments). He named this confusion the naturalistic fallacy. For example, an ethical argument may claim that if a thing has certain properties, then that thing is 'good.' A hedonist may argue that 'pleasant' things are 'good' things. Other theorists may argue that 'complex' things are 'good' things. Moore contends that, even if such arguments are correct, they do not provide definitions for the term 'good'. The property of 'goodness' cannot be defined. It can only be shown and grasped. Any attempt to define it (X is good if it has property Y) will simply shift the problem (Why is Y-ness good in the first place?).
#### Open-question argument.
Moore's argument for the indefinability of 'good' (and thus for the fallaciousness in the "naturalistic fallacy") is often called the open-question argument; it is presented in §13 of "Principia Ethica". The argument hinges on the nature of statements such as "Anything that is pleasant is also good" and the possibility of asking questions such as "Is it "good" that x is pleasant?". According to Moore, these questions are "open" and these statements are "significant"; and they will remain so no matter what is substituted for "pleasure". Moore concludes from this that any analysis of value is bound to fail. In other words, if value could be analysed, then such questions and statements would be trivial and obvious. Since they are anything but trivial and obvious, value must be indefinable.
Critics of Moore's arguments sometimes claim that he is appealing to general puzzles concerning analysis (cf. the paradox of analysis), rather than revealing anything special about value. The argument clearly depends on the assumption that if 'good' were definable, it would be an analytic truth about 'good', an assumption that many contemporary moral realists like Richard Boyd and Peter Railton reject. Other responses appeal to the Fregean distinction between sense and reference, allowing that value concepts are special and "sui generis", but insisting that value properties are nothing but natural properties (this strategy is similar to that taken by non-reductive materialists in philosophy of mind).
#### Good as indefinable.
Moore contended that goodness cannot be analysed in terms of any other property. In "Principia Ethica", he writes:
Therefore, we cannot define 'good' by explaining it in other words. We can only point to a "thing" or an "action" and say "That is good." Similarly, we cannot describe to a person born totally blind exactly what yellow is. We can only show a sighted person a piece of yellow paper or a yellow scrap of cloth and say "That is yellow."
#### Good as a non-natural property.
In addition to categorising 'good' as indefinable, Moore also emphasized that it is a non-natural property. This means that it cannot be empirically or scientifically tested or verifiedit is not within the bounds of "natural science".
#### Moral knowledge.
Moore argued that, once arguments based on the naturalistic fallacy had been discarded, questions of intrinsic goodness could be settled only by appeal to what he (following Sidgwick) called "moral intuitions": self-evident propositions which recommend themselves to moral reflection, but which are not susceptible to either direct proof or disproof ("Principia", § 45). As a result of his view, he has often been described by later writers as an advocate of ethical intuitionism. Moore, however, wished to distinguish his view from the views usually described as "Intuitionist" when "Principia Ethica" was written:
Moore distinguished his view from the view of deontological intuitionists, who held that "intuitions" could determine questions about what "actions" are right or required by duty. Moore, as a consequentialist, argued that "duties" and moral rules could be determined by investigating the "effects" of particular actions or kinds of actions ("Principia", § 89), and so were matters for empirical investigation rather than direct objects of intuition (Prncipia, § 90). On Moore's view, "intuitions" revealed not the rightness or wrongness of specific actions, but only what things were good in themselves, as "ends to be pursued".
#### Right action, duty and virtue.
Moore holds that are those producing the most good. The difficulty with this is that the consequences of most actions are too vast for us to properly take into account, especially the long-term consequences. Because of this, Moore suggests that the definition of duty is limited to what generally produces better results than probable alternatives in a comparatively near future. Whether a given rule of action turns out to be a "duty" depends to some extent on the conditions of the corresponding society but "duties" agree mostly with what common-sense recommends. Virtues, like honesty, can in turn be defined as "permanent dispositions" to perform duties.
### Proof of an external world.
One of the most important parts of Moore's philosophical development was his break from the idealism that dominated British philosophy (as represented in the works of his former teachers F. H. Bradley and John McTaggart), and his defence of what he regarded as a "common sense" form of realism. In his 1925 essay "A Defence of Common Sense", he argued against idealism and scepticism toward the external world, on the grounds that they could not give reasons to accept that their metaphysical premises were more plausible than the reasons we have for accepting the common sense claims about our knowledge of the world, which sceptics and idealists must deny. He famously put the point into dramatic relief with his 1939 essay "Proof of an External World", in which he gave a common sense argument against scepticism by raising his right hand and saying "Here is one hand" and then raising his left and saying "And here is another", then concluding that there are at least two external objects in the world, and therefore that he knows (by this argument) that an external world exists. Not surprisingly, not everyone inclined to sceptical doubts found Moore's method of argument entirely convincing; Moore, however, defends his argument on the grounds that sceptical arguments seem invariably to require an appeal to "philosophical intuitions" that we have considerably less reason to accept than we have for the common sense claims that they supposedly refute. (In addition to fueling Moore's own work, the "Here is one hand" argument also deeply influenced Wittgenstein, who spent his last years working out a new approach to Moore's argument in the remarks that were published posthumously as "On Certainty".)
### Moore's paradox.
Moore is also remembered for drawing attention to the peculiar inconsistency involved in uttering a sentence such as "It is raining, but I do not believe it is raining", a puzzle now commonly called "Moore's paradox". The puzzle arises because it seems impossible for anyone to consistently "assert" such a sentence; but there doesn't seem to be any "logical contradiction" between "It is raining" and "I don't believe that it is raining", because the former is a statement about the weather and the latter a statement about a person's belief about the weather, and it is perfectly logically possible that it may rain whilst a person does not believe that it is raining.
In addition to Moore's own work on the paradox, the puzzle also inspired a great deal of work by Ludwig Wittgenstein, who described the paradox as the most impressive philosophical insight that Moore had ever introduced. It is said that when Wittgenstein first heard this paradox one evening (which Moore had earlier stated in a lecture), he rushed round to Moore's lodgings, got him out of bed and insisted that Moore repeat the entire lecture to him.
### Organic wholes.
Moore's description of the principle of organic unity is extremely straightforward, nonetheless, and a variant on a pattern that began with Aristotle:
According to Moore, a moral actor cannot survey the 'goodness' inherent in the various parts of a situation, assign a value to each of them, and then generate a sum in order to get an idea of its total value. A moral scenario is a complex assembly of parts, and its total value is often created by the relations between those parts, and not by their individual value. The organic metaphor is thus very appropriate: biological organisms seem to have emergent properties which cannot be found anywhere in their individual parts. For example, a human brain seems to exhibit a capacity for thought when none of its neurons exhibit any such capacity. In the same way, a moral scenario can have a value far greater than the sum of its component parts.
To understand the application of the organic principle to questions of value, it is perhaps best to consider Moore's primary example, that of a consciousness experiencing a beautiful object. To see how the principle works, a thinker engages in "reflective isolation", the act of isolating a given concept in a kind of null-context and determining its intrinsic value. In our example, we can easily see that, of themselves, beautiful objects and consciousnesses are not particularly valuable things. They might have some value, but when we consider the total value of a consciousness experiencing a beautiful object, it seems to exceed the simple sum of these values. Hence the value of a whole must not be assumed to be the same as the sum of the values of its parts.

</doc>
<doc id="11963" url="https://en.wikipedia.org/wiki?curid=11963" title="Gottleib Fichte">
Gottleib Fichte



</doc>
<doc id="11964" url="https://en.wikipedia.org/wiki?curid=11964" title="Genus–differentia definition">
Genus–differentia definition

A genus–differentia definition is a type of intensional definition, and it is composed of two parts:
For example, consider these two definitions:
Those definitions can be expressed as one genus and two "differentiae":
The use of genus and differentia in constructing definitions goes back at least as far as Aristotle (384–322 BCE).
## Differentiation and Abstraction.
The process of producing new definitions by "extending" existing definitions is commonly known as differentiation (and also as derivation). The reverse process, by which just part of an existing definition is used itself as a new definition, is called abstraction; the new definition is called "an abstraction" and it is said to have been "abstracted away from" the existing definition.
For instance, consider the following:
A part of that definition may be singled out (using parentheses here):
and with that part, an abstraction may be formed:
Then, the definition of "a square" may be recast with that abstraction as its genus:
Similarly, the definition of "a square" may be rearranged and another portion singled out:
leading to the following abstraction:
Then, the definition of "a square" may be recast with that abstraction as its genus:
In fact, the definition of "a square" may be recast in terms of both of the abstractions, where one acts as the genus and the other acts as the differentia:
Hence, abstraction is crucial in simplifying definitions.
## Multiplicity.
When multiple definitions could serve equally well, then all such definitions apply simultaneously. Thus, "a square" is a member of both the genus "[a] rectangle" and the genus "[a] rhombus". In such a case, it is notationally convenient to consolidate the definitions into one definition that is expressed with multiple genera (and possibly no differentia, as in the following):
or completely equivalently:
More generally, a collection of formula_1 equivalent definitions (each of which is expressed with one unique genus) can be recast as one definition that is expressed with formula_2 genera. Thus, the following:
could be recast as:
## Structure.
A genus of a definition provides a means by which to specify an "is-a relationship":
The non-genus portion of the differentia of a definition provides a means by which to specify a "has-a relationship":
When a system of definitions is constructed with genera and differentiae, the definitions can be thought of as nodes forming a hierarchy or—more generally—a directed acyclic graph; a node that has no predecessor is "a most general definition"; each node along a directed path is "more differentiated (or "more derived) than any one of its predecessors, and a node with no successor is "a most differentiated" (or "a most derived") definition.
When a definition, "S", is the tail of each of its successors (that is, "S" has at least one successor and each direct successor of "S" is a most differentiated definition), then "S" is often called "the species of each of its successors, and each direct successor of "S" is often called "an individual (or "an entity") of the species "S"; that is, the genus of an individual is synonymously called "the species" of that individual. Furthermore, the differentia of an individual is synonymously called "the identity" of that individual. For instance, consider the following definition:
In this case:
As in that example, the identity itself (or some part of it) is often used to refer to the entire individual, a phenomenon that is known in linguistics as a "pars pro toto synecdoche".

</doc>
<doc id="11966" url="https://en.wikipedia.org/wiki?curid=11966" title="Firearm">
Firearm

A firearm is any type of gun designed to be readily carried and used by an individual. The term is legally defined further in different countries (see Legal definitions).
The first firearms originated in 10th-century China, when bamboo tubes containing gunpowder and pellet projectiles were mounted on spears to make the portable fire lance, operable by a single person, which was later used to good effect in the Siege of De'an in 1132. In the 13th century, fire lance barrels were replaced with metal tubes and transformed into the metal-barreled hand cannon. The technology gradually spread throughout Eurasia during the 14th century. Older firearms typically used black powder as a propellant, but modern firearms use smokeless powder or other propellants. Most modern firearms (with the notable exception of smoothbore shotguns) have rifled barrels to impart spin to the projectile for improved flight stability.
Modern firearms can be described by their caliber (i.e. bore diameter). For pistols and rifles this is given in millimeters or inches (e.g. 7.62mm or .308 in.), or in the case of shotguns by their gauge (e.g. 12 ga. and 20 ga.). They are also described by the type of action employed (e.g. muzzleloader, breechloader, lever, bolt, pump, revolver, semi-automatic, fully automatic, etc.), together with the usual means of deportment (i.e. hand-held or mechanical mounting). Further classification may make reference to the type of barrel used (i.e. rifled) and to the barrel length (e.g. 24 inches), to the firing mechanism (e.g. matchlock, wheellock, flintlock, or percussion lock), to the design's primary intended use (e.g. hunting rifle), or to the commonly accepted name for a particular variation (e.g. Gatling gun).
Shooters aim firearms at their targets with hand-eye coordination, using either iron sights or optical sights. The accurate range of pistols generally does not exceed , while most rifles are accurate to using iron sights, or to longer ranges whilst using optical sights. (Firearm rounds may be dangerous or lethal well beyond their accurate range; the minimum distance for safety is much greater than the specified range for accuracy). Purpose-built sniper rifles and anti-materiel rifles are accurate to ranges of more than .
## Types.
A firearm is a barreled ranged weapon that inflicts damage on targets by launching one or more projectiles driven by rapidly expanding high-pressure gas produced by exothermic combustion (deflagration) of a chemical propellant, historically black powder, now smokeless powder.
In the military, firearms are categorized into "heavy" and "light" weapons regarding their portability by foot soldiers. Light firearms are those that can be readily carried by individual infantry, though they might still require more than one individual (crew-served) to achieve optimal operational capacity. Heavy firearms are those that are too large and heavy to be transported on foot, or too unstable against recoil and thus require the support of a weapons platform (e.g. a fixed mount, wheeled carriage, vehicle, aircraft or water vessel) to be tactically mobile or useful.
The subset of light firearms that only use kinetic projectiles and are compact enough to be operated to full capacity by a single infantryman (individual-served) are also referred to as "small arms". Such firearms include handguns such as revolvers, pistols and derringers, and long guns such as rifles (including many subtypes such as anti-material rifles, sniper rifles/designated marksman rifles, battle rifles, assault rifles and carbines), shotguns, submachine guns/personal defense weapons and squad automatic weapons/light machine guns.
Among the world's arms manufacturers, the top firearms manufacturers are Browning, Remington, Colt, Ruger, Smith &amp; Wesson, Savage, Mossberg (USA), Heckler &amp; Koch, SIG Sauer, Walther (Germany), ČZUB (Czech Republic), Glock, Steyr-Mannlicher (Austria), FN Herstal (Belgium), Beretta (Italy), Norinco (China), Tula Arms and Kalashnikov (Russia), while former top producers included Mauser, Springfield Armory, and Rock Island Armory under Armscor (Philippines).
 the Small Arms Survey reported that there were over one billion firearms distributed globally, of which 857 million (about 85 percent) were in civilian hands. U.S. civilians alone account for 393 million (about 46 percent) of the worldwide total of civilian-held firearms. This amounts to "120.5 firearms for every 100 residents." The world's armed forces control about 133 million (about 13 percent) of the global total of small arms, of which over 43 percent belong to two countries: the Russian Federation (30.3 million) and China (27.5 million). Law enforcement agencies control about 23 million (about 2 percent) of the global total of small arms.
### Configuration.
#### Handguns.
Handguns are guns that can be used with a single hand, and are the smallest of all firearms. However, the legal definition of a "handgun" varies between countries and regions. For example, in South African law, a "handgun" means a pistol or revolver which can be held in and discharged with one hand. In Australia, the gun law considers a handgun as a firearm carry-able or concealable about the person; or capable of being raised and fired by one hand; or not exceeding . In the United States, Title 18 and the ATF considers a handgun as a firearm which has a short stock and is designed to be held and fired by the use of a single hand.
There are two common types of handguns: revolvers and semi-automatic pistols. Revolvers have a number of firing chambers or "charge holes" in a revolving cylinder; each chamber in the cylinder is loaded with a single cartridge or charge. Semi-automatic pistols have a single fixed firing-chamber machined into the rear of the barrel, and a magazine so they can be used to fire more than one round. Each press of the trigger fires a cartridge, using the energy of the cartridge to activate a mechanism so that the next cartridge may be fired immediately. This is opposed to "double-action" revolvers, which accomplish the same end using a mechanical action linked to the trigger pull.
With the invention of the revolver in 1818, handguns capable of holding multiple rounds became popular. Certain designs of auto-loading pistol appeared beginning in the 1870s and had largely supplanted revolvers in military applications by the end of World War I. By the end of the 20th century, most handguns carried regularly by military, police and civilians were semi-automatic, although revolvers were still widely used. Generally speaking, military and police forces use semi-automatic pistols due to their high magazine capacities and ability to rapidly reload by simply removing the empty magazine and inserting a loaded one. Revolvers are very common among handgun hunters because revolver cartridges are usually more powerful than similar caliber semi-automatic pistol cartridges (which are designed for self-defense) and the strength, simplicity and durability of the revolver design is well-suited to outdoor use. Revolvers, especially in .22 LR and 38 Special/357 Magnum, are also common concealed weapons in jurisdictions allowing this practice because their simple mechanics make them smaller than many autoloaders while remaining reliable. Both designs are common among civilian gun owners, depending on the owner's intention (self-defense, hunting, target shooting, competitions, collecting, etc.).
#### Long guns.
A long gun is any firearm with a notably long barrel, typically a length of (there are restrictions on minimum barrel length in many jurisdictions; maximum barrel length is usually a matter of practicality). Unlike a handgun, long guns are designed to be held and fired with both hands, while braced against either the hip or the shoulder for better stability. The receiver and trigger group is mounted into a stock made of wood, plastic, metal, or composite material, which has sections that form a foregrip, rear grip, and optionally (but typically) a shoulder mount called the "butt". Early long arms, from the Renaissance up to the mid-19th century, were generally smoothbore firearms that fired one or more ball shot, called muskets or arquebus depending on caliber and firing mechanism.
##### Rifles and shotguns.
Most modern long guns are either rifles or shotguns. Both are the successors of the musket, diverging from their parent weapon in distinct ways. A rifle is so named for the spiral grooves (riflings) machined into the inner (bore) surface of its barrel, which imparts a gyroscopically-stabilizing spin to the bullets that it fires. Shotguns are predominantly smoothbore firearms designed to fire a number of "shot" in each discharge; pellet sizes commonly ranging between 2 mm #9 birdshot and 8.4 mm #00 (double-aught) buckshot. Shotguns are also capable of firing single solid projectiles called slugs, or specialty (often "less lethal") rounds such as bean bags, tear gas or breaching rounds. Rifles produce a single point of impact with each firing but a long range and high accuracy; while shotguns produce a cluster of impact points with considerably less range and accuracy. However, the larger impact area of shotguns can compensate for reduced accuracy, since shot spreads during flight; consequently, in hunting, shotguns are generally used for fast-flying game birds.
Rifles and shotguns are commonly used for hunting and often also for home defense, security guard and law enforcement. Usually, large game are hunted with rifles (although shotguns can be used, particularly with slugs), while birds are hunted with shotguns. Shotguns are sometimes preferred for defending a home or business due to their wide impact area, multiple wound tracks (when using buckshot), shorter range, and reduced penetration of walls (when using lighter shot), which significantly reduces the likelihood of unintended harm, although the handgun is also common.
There are a variety of types of rifles and shotguns based on the method they are reloaded. Bolt-action and lever-action rifles are manually operated. Manipulation of the bolt or the lever causes the spent cartridge to be removed, the firing mechanism recocked, and a fresh cartridge inserted. These two types of action are almost exclusively used by rifles. Slide-action (commonly called 'pump-action') rifles and shotguns are manually cycled by shuttling the foregrip of the firearm back and forth. This type of action is typically used by shotguns, but several major manufacturers make rifles that use this action.
Both rifles and shotguns also come in break-action varieties that do not have any kind of reloading mechanism at all but must be hand-loaded after each shot. Both rifles and shotguns come in single- and double-barreled varieties; however, due to the expense and difficulty of manufacturing, double-barreled rifles are rare. Double-barreled rifles are typically intended for African big-game hunts where the animals are dangerous, ranges are short, and speed is of the essence. Very large and powerful calibers are normal for these firearms.
Rifles have been in nationally featured marksmanship events in Europe and the United States since at least the 18th century, when rifles were first becoming widely available. One of the earliest purely "American" rifle-shooting competitions took place in 1775, when Daniel Morgan was recruiting sharpshooters in Virginia for the impending American Revolutionary War. In some countries, rifle marksmanship is still a matter of national pride. Some specialized rifles in the larger calibers are claimed to have an accurate range of up to about , although most have considerably less. In the second half of the 20th century, competitive shotgun sports became perhaps even more popular than riflery, largely due to the motion and immediate feedback in activities such as skeet, trap and sporting clays.
In military use, bolt-action rifles with high-power scopes are common as sniper rifles, however by the Korean War the traditional bolt-action and semi-automatic rifles used by infantrymen had been supplemented by select-fire designs known as automatic rifles.
##### Carbines.
A carbine is a firearm similar to a rifle in form and intended usage, but generally shorter or smaller than the typical "full-size" hunting or battle rifle of a similar time period, and sometimes using a smaller or less-powerful cartridge. Carbines were and are typically used by members of the military in roles that are expected to engage in combat, but where a full-size rifle would be an impediment to the primary duties of that soldier (vehicle drivers, field commanders and support staff, airborne troops, engineers, etc.). Carbines are also common in law enforcement and among civilian owners where similar size, space and/or power concerns may exist. Carbines, like rifles, can be single-shot, repeating-action, semi-automatic or select-fire/fully automatic, generally depending on the time period and intended market. Common historical examples include the Winchester Model 1892, Lee–Enfield "Jungle Carbine", SKS, M1 carbine (no relation to the larger M1 Garand) and M4 carbine (a more compact variant of the current M16 rifle). Modern U.S. civilian carbines include compact customizations of the AR-15, Ruger Mini-14, Beretta Cx4 Storm, Kel-Tec SUB-2000, bolt-action rifles generally falling under the specifications of a scout rifle, and aftermarket conversion kits for popular pistols including the M1911 and Glock models.
##### Machine guns.
A machine gun is a fully automatic firearm, most often separated from other classes of automatic weapons by the use of belt-fed ammunition (though some designs employ drum, pan or hopper magazines), generally in a rifle-inspired caliber ranging between 5.56×45mm NATO (.223 Remington) for a light machine gun to as large as .50 BMG or even larger for crewed or aircraft weapons. Although not widely fielded until World War I, early machine guns were being used by militaries in the second half of the 19th century. Notables in the U.S. arsenal during the 20th century included the M2 Browning .50 caliber heavy machine gun, M1919 Browning .30 caliber medium machine gun, and the M60 7.62×51mm NATO general-purpose machine gun which came into use around the Vietnam War. Machine guns of this type were originally defensive firearms crewed by at least two men, mainly because of the difficulties involved in moving and placing them, their ammunition, and their tripod. In contrast, modern light machine guns such as the FN Minimi are often wielded by a single infantryman. They provide a large ammunition capacity and a high rate of fire, and are typically used to give suppressing fire during infantry movement. Accuracy on machine guns varies based on a wide number of factors from design to manufacturing tolerances, most of which have been improved over time. Machine guns are often mounted on vehicles or helicopters and have been used since World War I as offensive firearms in fighter aircraft and tanks (e.g. for air combat or suppressing fire for ground troop support).
The definition of a machine gun is different in U.S. law. The National Firearms Act and Firearm Owners Protection Act define a "machine gun" in the United States code "Title 26, Subtitle E, Chapter 53, Subchapter B, Part 1, § 5845" as:
"... any firearm which shoots ... automatically more than one shot, without manual reloading, by a single function of the trigger". "Machine gun" is therefore largely synonymous with "automatic weapon" in the U.S. civilian parlance, covering all automatic firearms.
##### Sniper rifles.
The definition of a sniper rifle is disputed among military, police and civilian observers alike, however most generally define a “sniper rifle” as a high powered, semi-automatic/bolt action, precision rifle with an accurate range further than that of a standard rifle. These are often purpose-built for their applications. For example, a police sniper rifle may differ in specs from a military rifle. Police snipers generally do not engage targets at extreme range, but rather, a target at medium range. They may also have multiple targets within the shorter range, and thus a semi-automatic model is preferred to a bolt action. They also may be more compact than mil-spec rifles as police marksmen may need more portability. On the other hand, a military rifle is more likely to use a higher-powered cartridge to defeat body armor or medium-light cover. They are more commonly (but not a lot more) bolt-action, as they are simpler to build and maintain. Also, due to fewer moving and overall parts, they are much more reliable under adverse conditions. They may also have a more powerful scope to acquire targets further away. Overall, sniper units never became prominent until World War I, when the Germans displayed their usefulness on the battlefield. Since then, they have become irrevocably embedded in warfare. Examples of sniper rifles include the Accuracy International AWM, Sako TRG-42 and the CheyTac M200. Examples of specialized sniper cartridges include the .338 Lapua Magnum, .300 Winchester Magnum, and .408 CheyTac rounds.
##### Submachine guns.
A submachine gun is a magazine-fed firearm, usually smaller than other automatic firearms, that fires pistol-caliber ammunition; for this reason certain submachine guns can also be referred to as "machine pistols", especially when referring to handgun-sized designs such as the Škorpion vz. 61 and Glock 18. Well-known examples are the Israeli Uzi and Heckler &amp; Koch MP5 which use the 9×19mm Parabellum cartridge, and the American Thompson submachine gun which fires .45 ACP. Because of their small size and limited projectile penetration compared to high-power rifle rounds, submachine guns are commonly favored by military, paramilitary and police forces for close-quarters engagements such as inside buildings, in urban areas or in trench complexes.
Submachine guns were originally about the size of carbines. Because they fire pistol ammunition, they have limited long-range use, but in close combat can be used in fully automatic in a controllable manner due to the lighter recoil of the pistol ammunition. They are also extremely inexpensive and simple to build in time of war, enabling a nation to quickly arm its military. In the latter half of the 20th century, submachine guns were being miniaturized to the point of being only slightly larger than some large handguns. The most widely used submachine gun at the end of the 20th century was the Heckler &amp; Koch MP5. The MP5 is actually designated as a "machine pistol" by Heckler &amp; Koch (MP5 stands for "Maschinenpistole 5", or Machine Pistol 5), although some reserve this designation for even smaller submachine guns such as the MAC-10 and Glock 18, which are about the size and shape of pistols.
##### Automatic rifles.
An automatic rifle is a magazine-fed firearm, wielded by a single infantryman, that is chambered for rifle cartridges and capable of automatic fire. The M1918 Browning Automatic Rifle was the first U.S. infantry weapon of this type, and was generally used for suppressive or support fire in the role now usually filled by the light machine gun. Other early automatic rifles include the Fedorov Avtomat and the Huot Automatic Rifle. Later, German forces fielded the Sturmgewehr 44 during World War II, a light automatic rifle firing a reduced power "intermediate cartridge". This design was to become the basis for the "assault rifle" subclass of automatic weapons, as contrasted with "battle rifles", which generally fire a traditional "full-power" rifle cartridge.
##### Assault rifles.
In World War II, Germany introduced the StG 44, and brought to the forefront of firearm technology what eventually became the class of firearm most widely adopted by the military, the assault rifle. An assault rifle is usually slightly smaller than a battle rifle such as the American M14, but the chief differences defining an assault rifle are select-fire capability and the use of a rifle round of lesser power, known as an intermediate cartridge.
Soviet engineer Mikhail Kalashnikov quickly adapted the German concept, using a less-powerful 7.62×39mm cartridge derived from the standard 7.62×54mmR Russian battle rifle round, to produce the AK-47, which has become the world's most widely used assault rifle. Soon after World War II, the Automatic Kalashnikov AK-47 assault rifle began to be fielded by the Soviet Union and its allies in the Eastern Bloc, as well as by nations such as China, North Korea, and North Vietnam.
In the United States, the assault rifle design was later in coming; the replacement for the M1 Garand of WWII was another John Garand design chambered for the new 7.62×51mm NATO cartridge; the select-fire M14, which was used by the U.S. military until the 1960s. The significant recoil of the M14 when fired in full-automatic mode was seen as a problem as it reduced accuracy, and in the 1960s it was replaced by Eugene Stoner's AR-15, which also marked a switch from the powerful .30 caliber cartridges used by the U.S. military up until early in the Vietnam War to the much less powerful but far lighter and light recoiling .223 caliber (5.56mm) intermediate cartridge. The military later designated the AR-15 as the "M16". The civilian version of the M16 continues to be known as the AR-15 and looks exactly like the military version, although to conform to ATF regulations in the U.S., it lacks the mechanism that permits fully automatic fire.
Variants of both of the M16 and AK-47 are still in wide international use today, though other automatic rifle designs have since been introduced. A smaller version of the M16A2, the M4 carbine, is widely used by U.S. and NATO tank and vehicle crews, airbornes, support staff, and in other scenarios where space is limited. The IMI Galil, an Israeli-designed weapon based on the action of the AK-47, is in use by Israel, Italy, Burma, the Philippines, Peru, and Colombia. Swiss Arms of Switzerland produces the SIG SG 550 assault rifle used by France, Chile, and Spain among others, and Steyr Mannlicher produces the AUG, a bullpup rifle in use in Austria, Australia, New Zealand, Ireland, and Saudi Arabia among other nations.
Modern designs call for compact weapons retaining firepower. The bullpup design, by mounting the magazine behind the trigger, unifies the accuracy and firepower of the traditional assault rifle with the compact size of the submachine gun (though submachine guns are still used); examples are the French FAMAS and the British SA80.
##### Personal defense weapons.
A recently developed class of firearm is the personal defense weapon or PDW, which is in simplest terms a submachine gun designed to fire ammunitions with ballistic performance similar to rifle cartridges. While a submachine gun is desirable for its compact size and ammunition capacity, its pistol cartridges lack the penetrating capability of a rifle round. Conversely, rifle bullets can pierce light armor and are easier to shoot accurately, but even a carbine such as the Colt M4 is larger and/or longer than a submachine gun, making it harder to maneuver in close quarters. The solution many firearms manufacturers have presented is a weapon resembling a submachine gun in size and general configuration, but which fires a higher-powered armor-penetrating round (often specially designed for the weapon), thus combining the advantages of a carbine and submachine gun. This also earned the PDWs an infrequently used nickname — the submachine carbines. The FN P90 and Heckler &amp; Koch MP7 are most famous examples of PDWs.
##### Battle rifles.
Battle rifles are another subtype of rifle, usually defined as selective fire rifles that use full power rifle cartridges, examples of which include the 7.62x51mm NATO, 7.92x57mm Mauser, and 7.62x54mmR. These serve similar purposes as assault rifles, as they both are usually employed by ground infantry. However, some prefer battle rifles due to their more powerful cartridge, despite added recoil. Some semi-automatic sniper rifles are configured from battle rifles.
### Function.
Firearms are also categorized by their functioning cycle or "action" which describes its loading, firing, and unloading cycle.
#### Manual.
The earliest evolution of the firearm, there are many types of manual action firearms. These can be divided into two basic categories: single shot and repeating.
A single shot firearm can only be fired once per equipped barrel before it must be reloaded or charged via an external mechanism or series of steps. A repeating firearm can be fired multiple times, but can only be fired once with each subsequent pull of the trigger. Between trigger pulls, the firearm's action must be reloaded or charged via an internal mechanism.
#### Lever action.
A gun which has a lever that is pulled down then back up to expel the old cartridge then load a new round.
#### Pump action.
Pump action weapons are primarily shotguns. A pump action is created when the user slides a lever (usually a grip) and it brings a new round in the chamber while expelling the old one.
#### Semi-automatic.
A semi-automatic, self-loading, or "auto loader" firearm is one that performs all steps necessary to prepare it for firing again after a single discharge, until cartridges are no longer available in the weapon's feed device or magazine. Auto loaders fire one round with each pull of the trigger. Some people confuse the term with "fully automatic" firearms. (See next.) While some semi-automatic rifles may resemble military-style firearms, they are not properly classified "Assault Weapons" which refers to those that continue to fire until the trigger is no longer depressed.
#### Automatic.
An "automatic" firearm, or "fully automatic", "fully auto", or "full auto", is generally defined as one that continues to load and fire cartridges from its magazine as long as the trigger is depressed (and until the magazine is depleted of available ammunition.) The first weapon generally considered in this category is the Gatling gun, originally a carriage-mounted, crank-operated firearm with multiple rotating barrels that was fielded in the American Civil War. The modern trigger-actuated machine gun began with various designs developed in the late 19th century and fielded in World War I, such as the Maxim gun, Lewis Gun, and MG 08 "Spandau". Most automatic weapons are classed as long guns (as the ammunition used is of similar type as for rifles, and the recoil of the weapon's rapid fire is better controlled with two hands), but handgun-sized automatic weapons also exist, generally in the "submachine gun" or "machine pistol" class.
#### Selective fire.
Selective fire, or "select fire", means the capability of a weapon's fire control to be adjusted in either semi-automatic, fully automatic firing modes, or 3 round burst. The modes are chosen by means of a selector, which varies depending on the weapon's design. Some selective-fire weapons have burst fire mechanisms built in to limit the maximum number of shots fired in fully automatic mode, with most common limits being two or three rounds per trigger pull. The presence of selective-fire modes on firearms allows more efficient use of ammunition for specific tactical needs, either precision-aimed or suppressive fire. This capability is most commonly found on military weapons of the 20th and 21st centuries, most notably the assault rifles.
## History.
The first primitive firearms were invented about 1250 AD in China when the man-portable fire lance (a bamboo or metal tube that could shoot ignited gunpowder) was combined with projectiles such as scrap metal, broken porcelain, or darts/arrows.
The earliest depiction of a firearm is a sculpture from a cave in Sichuan, China. The sculpture dates to the 12th century and is of a figure carrying a vase-shaped bombard, with flames and a cannonball coming out of it. The oldest surviving gun, a hand cannon made of bronze, has been dated to 1288 because it was discovered at a site in modern-day Acheng District, Heilongjiang, China, where the "Yuan Shi" records that battles were fought at that time. The firearm had a 6.9 inch barrel of a 1-inch diameter, a 2.6 inch chamber for the gunpowder and a socket for the firearm's handle. It is 13.4 inches long and 7.8 pounds without the handle, which would have been made of wood.
The Arabs and Mamluks had firearms in the late 13th century. In the 14th century, firearms were obtained by the Europeans. The Koreans adopted firearms from the Chinese in the 14th century. The Iranians (first Aq Qoyunlu and Safavids) and Indians (first Mughals) all got them no later than the 15th century, from the Ottoman Turks. The people of Nusantara archipelago of Southeast Asia used long arquebus at least by the last quarter of 15th century.
Even though the knowledge of making gunpowder-based weapon in Nusantara archipelago has been known after the failed Mongol invasion of Java (1293), and the predecessor of firearms, the pole gun (bedil tombak), was recorded as being used by Java in 1413, the knowledge of making "true" firearms came much later, after the middle of 15th century. It was brought by the Islamic nations of West Asia, most probably the Arabs. The precise year of introduction is unknown, but it may be safely concluded to be no earlier than 1460. Before the arrival of the Portuguese in Southeast Asia, the natives already possessed firearms, the Java arquebus.
The technology of firearm in Southeast Asia further improved after the Portuguese capture of Malacca (1511). Starting in the 1513, the tradition of German-Bohemian gun making were merged with Turkish gun making traditions. This resulted in Indo-Portuguese tradition of matchlocks. Indian craftsmen modified the design by introducing a very short, almost pistol-like buttstock held against the cheek, not the shoulder, when aiming. They also reduced the caliber and made the gun lighter and more balanced. This was a hit with the Portuguese who did a lot of fighting aboard ship and on river craft, and valued a more compact gun. The Malaccan gunfounders, compared as being in the same level with those of Germany, quickly adapted these new firearms, and thus a new type of arquebus, the istinggar, appeared. The Japanese did not acquire firearms until the 16th century, and then from the Portuguese rather than the Chinese.
The development behind firearms accelerated during the 19th and 20th centuries. Breech-loading became more or less a universal standard for the reloading of most hand-held firearms and continues to be so with some notable exceptions (such as mortars). Instead of loading individual rounds into weapons, magazines holding multiple munitions were adopted—these aided rapid reloading. Automatic and semi-automatic firing mechanisms meant that a single soldier could fire many more rounds in a minute than a vintage weapon could fire over the course of a battle. Polymers and alloys in firearm construction made weaponry progressively lighter and thus easier to deploy. Ammunition changed over the centuries from simple metallic ball-shaped projectiles that rattled down the barrel to bullets and cartridges manufactured to high precision. Especially in the past century has particular attention been devoted to accuracy and sighting to make firearms altogether far more accurate than ever before. More than any single factor though, firearms have proliferated due to the advent of mass production—enabling arms manufacturers to produce large quantities of weaponry to a consistent standard.
Velocities of bullets increased with the use of a "jacket" of a metal such as copper or copper alloys that covered a lead core and allowed the bullet to glide down the barrel more easily than exposed lead. Such bullets are designated as "full metal jacket" (FMJ). Such FMJ bullets are less likely to fragment on impact and are more likely to traverse through a target while imparting less energy. Hence, FMJ bullets impart less tissue damage than non-jacketed bullets that expand. (Dougherty and Eidt, 2009) This led to their adoption for military use by countries adhering to the Hague Convention in 1899.
That said, the basic principle behind firearm operation remains unchanged to this day. A musket of several centuries ago is still similar in principle to a modern-day assault rifle—using the expansion of gases to propel projectiles over long distances—albeit less accurately and rapidly.
### Evolution.
#### Early models.
##### Fire lances.
The Chinese fire lance from the 10th century was the direct predecessor to the modern concept of the firearm. It was not a gun itself, but an addition to the soldiers' spears. Originally it consisted of paper or bamboo barrels that would have incendiary gunpowder within it, that could be lit one time and would project flames at the enemy. Sometimes the Chinese troops would place small projectiles within the barrel that would also be projected when the gunpowder was lit, but most of the explosive force would create flames. Later, the barrel was changed to be made of metal, so that a more explosive gunpowder could be used and put more force into the propulsion of the projectile.
##### Hand cannons.
The original predecessor of all firearms, the Chinese fire lance and hand cannon were loaded with gunpowder and the shot (initially lead shot, later replaced by cast iron) through the muzzle, while a fuse was placed at the rear. This fuse was lit, causing the gunpowder to ignite and propel the cannonball. In military use, the standard hand cannon was tremendously powerful, while also being somewhat useless due to relative inability of the gunner to aim the weapon, or control the ballistic properties of the projectile. Recoil could be absorbed by bracing the barrel against the ground using a wooden support, the forerunner of the stock. Neither the quality or amount of gunpowder, nor the consistency in projectile dimensions were controlled, with resulting inaccuracy in firing due to windage, variance in gunpowder composition, and the difference in diameter between the bore and the shot. The hand cannons were replaced by lighter carriage-mounted artillery pieces, and ultimately the arquebus.
In the 1420s gunpowder was used to propel missiles from hand-held tubes during the Hussite revolt.
##### Muskets.
Muzzle-loading muskets (smooth-bored long guns) were among the first firearms developed. The firearm was loaded through the muzzle with gunpowder, optionally some wadding and then a bullet (usually a solid lead ball, but musketeers could shoot stones when they ran out of bullets). Greatly improved muzzleloaders (usually rifled instead of smooth-bored) are manufactured today and have many enthusiasts, many of whom hunt large and small game with their guns. Muzzleloaders have to be manually reloaded after each shot; a skilled archer could fire multiple arrows faster than most early muskets could be reloaded and fired, although by the mid-18th century, when muzzleloaders became the standard small armament of the military, a well-drilled soldier could fire six rounds in a minute using prepared cartridges in his musket. Before then, effectiveness of muzzleloaders was hindered by both the low reloading speed and, before the firing mechanism was perfected, the very high risk posed by the firearm to the person attempting to fire it.
One interesting solution to the reloading problem was the "Roman Candle Gun" with superposed loads. This was a muzzleloader in which multiple charges and balls were loaded one on top of the other, with a small hole in each ball to allow the subsequent charge to be ignited after the one ahead of it was ignited. It was neither a very reliable nor popular firearm, but it enabled a form of "automatic" fire long before the advent of the machine gun.
#### Loading techniques.
Most early firearms were muzzle-loading. This form of loading has several disadvantages, such as a slow rate of fire and having to expose oneself to enemy fire to reload as the weapon had to be pointed upright so the powder could be poured through the muzzle into the breech followed by the ramming the projectile into the breech. As effective methods of sealing the breech were developed through the development of sturdy, weatherproof, self-contained metallic cartridges, muzzle-loaders were replaced by single-shot breech loaders. Eventually single-shot weapons were replaced by the following repeater type weapons.
#### Internal magazines.
Many firearms made in the late 19th century through the 1950s used internal magazines to load the cartridge into the chamber of the weapon. The most notable and revolutionary weapons of this period appeared during the U.S. Civil War and they were the Spencer and Henry repeating rifles. Both used fixed tubular magazines, the former having the magazine in the buttstock and the latter under the barrel which allowed a larger capacity. Later weapons used fixed box magazines that could not be removed from the weapon without disassembling the weapon itself. Fixed magazines permitted the use of larger cartridges and eliminated the hazard of having the bullet of one cartridge butting next to the primer or rim of another cartridge. These magazines are loaded while they are in the weapon, often using a stripper clip. A clip is used to transfer cartridges into the magazine. Some notable weapons that use internal magazines include the Mosin–Nagant, the Mauser Kar 98k, the Springfield M1903, the M1 Garand, and the SKS. Firearms that have internal magazines are usually, but not always, rifles. Some exceptions to this include the Mauser C96 pistol, which uses an internal magazine, and the Breda 30, an Italian light machine gun.
#### Detachable magazines.
Many modern firearms use what are called detachable or box magazines as their method of chambering a cartridge. Detachable magazines can be removed from the weapon without disassembling the firearms, usually by pushing the magazine release.
#### Belt-fed weapons.
A belt or ammunition belt is a device used to retain and feed cartridges into a firearm commonly used on machine guns. Belts were originally composed of canvas or cloth with pockets spaced evenly to allow the belt to be mechanically fed into the gun. These designs were prone to malfunctions due to the effects of oil and other contaminants altering the belt. Later belt designs used permanently connected metal links to retain the cartridges during feeding. These belts were more tolerant to exposure to solvents and oil. Some notable weapons that use belts are the M240, the M249, the M134 Minigun, and the PK Machine Gun.
#### Firing mechanisms.
##### Matchlock.
Matchlocks were the first and simplest firearms firing mechanisms developed. Using the matchlock mechanism, the powder in the gun barrel was ignited by a piece of burning cord called a "match". The match was wedged into one end of an S-shaped piece of steel. As the trigger (often actually a lever) was pulled, the match was brought into the open end of a "touch hole" at the base of the gun barrel, which contained a very small quantity of gunpowder, igniting the main charge of gunpowder in the gun barrel. The match usually had to be relit after each firing. The main parts to the matchlock firing mechanism are the pan, match, arm and trigger. A benefit of the pan and arm swivel being moved to the side of the gun was it gave a clear line of fire. An advantage to the matchlock firing mechanism is that it did not misfire. However, it also came with some disadvantages. One disadvantage was if it was raining the match could not be kept lit to fire the weapon. Another issue with the match was it could give away the position of soldiers because of the glow, sound, and smell. While European pistols were equipped with wheellock and flintlock mechanism, Asian pistols were equipped with matchlock mechanism.
##### Wheellock.
The wheellock action, a successor to the matchlock, predated the flintlock. Despite its many faults, the wheellock was a significant improvement over the matchlock in terms of both convenience and safety, since it eliminated the need to keep a smoldering match in proximity to loose gunpowder. It operated using a small wheel much like that on cigarette lighters which was wound up with a key before use and which, when the trigger was pulled, spun against a flint, creating the shower of sparks that ignited the powder in the touch hole. Supposedly invented by Leonardo da Vinci, the Italian Renaissance man, the wheellock action was an innovation that was not widely adopted due to the high cost of the clockwork mechanism.
##### Flintlock.
The flintlock action was a major innovation in firearm design. The spark used to ignite the gunpowder in the touch hole was supplied by a sharpened piece of flint clamped in the jaws of a "cock" which, when released by the trigger, struck a piece of steel called the "frizzen" to create the necessary sparks. (The spring-loaded arm that holds a piece of flint or pyrite is referred to as a cock because of its resemblance to a rooster.) The cock had to be manually reset after each firing, and the flint had to be replaced periodically due to wear from striking the frizzen. (See also flintlock mechanism, snaphance, Miquelet lock) The flintlock was widely used during the 17th, 18th, and 19th centuries in both muskets and rifles.
##### Percussion cap.
Percussion caps (caplock mechanisms), coming into wide service in the early 19th century, were a dramatic improvement over flintlocks. With the percussion cap mechanism, the small primer charge of gunpowder used in all preceding firearms was replaced by a completely self-contained explosive charge contained in a small brass "cap". The cap was fastened to the touch hole of the gun (extended to form a "nipple") and ignited by the impact of the gun's "hammer". (The hammer is roughly the same as the cock found on flintlocks except that it does not clamp onto anything.) In the case of percussion caps the hammer was hollow on the end to fit around the cap in order to keep the cap from fragmenting and injuring the shooter.
Once struck, the flame from the cap in turn ignited the main charge of gunpowder, as with the flintlock, but there was no longer any need to charge the touch hole with gunpowder, and even better, the touch hole was no longer exposed to the elements. As a result, the percussion cap mechanism was considerably safer, far more weatherproof, and vastly more reliable (cloth-bound cartridges containing a premeasured charge of gunpowder and a ball had been in regular military service for many years, but the exposed gunpowder in the entry to the touch hole had long been a source of misfires). All muzzleloaders manufactured since the second half of the 19th century use percussion caps except those built as replicas of the flintlock or earlier firearms.
#### Cartridges.
Frenchman Louis-Nicolas Flobert invented the first rimfire metallic cartridge in 1845. His cartridge consisted of a percussion cap with a bullet attached to the top. Flobert then made what he called "parlor guns" for this cartridge, as these rifles and pistols were designed to be shot in indoor shooting parlors in large homes. These 6mm Flobert cartridges, do not contain any powder, the only propellant substance contained in the cartridge is the percussion cap. In English-speaking countries, the 6mm Flobert cartridge corresponds to .22 BB Cap and .22 CB Cap ammunition. These cartridges have a relatively low muzzle velocity of around 700 ft/s (210 m/s).
This was major innovation in firearms ammunition, previously delivered as separate bullets and powder, was combined in a single metallic (usually brass) cartridge containing a percussion cap, powder, and a bullet in one weatherproof package. The main technical advantage of the brass cartridge case was the effective and reliable sealing of high pressure gasses at the breech, as the gas pressure forces the cartridge case to expand outward, pressing it firmly against the inside of the gun barrel chamber. This prevents the leakage of hot gas which could injure the shooter. The brass cartridge also opened the way for modern repeating arms, by uniting the bullet, gunpowder and primer into one assembly that could be fed reliably into the breech by a mechanical action in the firearm.
Before this, a "cartridge" was simply a premeasured quantity of gunpowder together with a ball in a small cloth bag (or rolled paper cylinder), which also acted as wadding for the charge and ball. This early form of cartridge had to be rammed into the muzzleloader's barrel, and either a small charge of gunpowder in the touch hole or an external percussion cap mounted on the touch hole ignited the gunpowder in the cartridge. Cartridges with built-in percussion caps (called "primers") continue to this day to be the standard in firearms. In cartridge-firing firearms, a hammer (or a firing pin struck by the hammer) strikes the cartridge primer, which then ignites the gunpowder within. The primer charge is at the base of the cartridge, either within the rim (a "rimfire" cartridge) or in a small percussion cap embedded in the center of the base (a "centerfire" cartridge). As a rule, centerfire cartridges are more powerful than rimfire cartridges, operating at considerably higher pressures than rimfire cartridges. Centerfire cartridges are also safer, as a dropped rimfire cartridge has the potential to discharge if its rim strikes the ground with sufficient force to ignite the primer. This is practically impossible with most centerfire cartridges.
Nearly all contemporary firearms load cartridges directly into their breech. Some additionally or exclusively load from a magazine that holds multiple cartridges. A magazine is defined as a part of the firearm which exists to store ammunition and assist in its feeding by the action into the breech (such as through the rotation of a revolver's cylinder or by spring-loaded platforms in most pistol and rifle designs). Some magazines, such as that of most centerfire hunting rifles and all revolvers, are internal to and inseparable from the firearm, and are loaded by using a "clip". A clip, often mistakingly used to refer to a detachable "magazine", is a device that holds the ammunition by the rim of the case and is designed to assist the shooter in reloading the firearm's magazine. Examples include revolver speedloaders, the stripper clip used to aid loading rifles such as the Lee–Enfield or Mauser 98, and the en-bloc clip used in loading the M1 Garand. In this sense, "magazines" and "clips", though often used synonymously, refer to different types of devices.
#### Repeating, semi-automatic, and automatic firearms.
Many firearms are "single shot": i.e., each time a cartridge is fired, the operator must manually re-cock the firearm and load another cartridge. The classic single-barreled shotgun is a good example. A firearm that can load multiple cartridges as the firearm is re-cocked is considered a "repeating firearm" or simply a "repeater". A lever-action rifle, a pump-action shotgun, and most bolt-action rifles are good examples of repeating firearms. A firearm that automatically re-cocks and reloads the next round with each trigger pull is considered a semi-automatic or autoloading firearm.
The first "rapid firing" firearms were usually similar to the 19th century Gatling gun, which would fire cartridges from a magazine as fast as and as long as the operator turned a crank. Eventually, the "rapid" firing mechanism was perfected and miniaturized to the extent that either the recoil of the firearm or the gas pressure from firing could be used to operate it, thus the operator needed only to pull a trigger (which made the firing mechanisms truly "automatic"). An automatic (or "fully automatic") firearm is one that automatically re-cocks, reloads, and fires as long as the trigger is depressed. An automatic firearm is capable of firing multiple rounds with one pull of the trigger. The Gatling gun may have been the first automatic weapon, though the modern trigger-actuated machine gun was not widely introduced until the First World War with the German "Spandau" and British Lewis Gun. Automatic rifles such as the Browning Automatic Rifle were in common use by the military during the early part of the 20th century, and automatic rifles that fired handgun rounds, known as submachine guns, also appeared in this time. Many modern military firearms have a selective fire option, which is a mechanical switch that allows the firearm be fired either in the semi-automatic or fully automatic mode. In the current M16A2 and M16A4 variants of the U.S.-made M16, continuous fully automatic fire is not possible, having been replaced by an automatic burst of three cartridges (this conserves ammunition and increases controllability). Automatic weapons are largely restricted to military and paramilitary organizations, though many automatic designs are infamous for their use by civilians.
## Health hazards.
Firearm hazard is quite notable, with a significant impact on the health system. In 2001, for quantification purpose, it was estimated that the cost of fatalities and injuries was US$4700 million per year in Canada (US$170 per Canadian) and US$100,000 million per year in the USA (US$300 per American).
### Death.
From 1990 to 2015, global deaths from assault by firearm rose from 128,000 to 173,000, however this represents a drop in rate from 2.41/100,000 to 2.35/100,000, as world population has increased by more than two billion. Additionally, there were 32,000 unintentional firearm global deaths in 2015.
In 2017, there were 39,773 gun-related deaths in the United States; over 60% were suicides from firearms. Firearms are the second leading mechanism of injury deaths after motor vehicle accidents.
In the 52 high- and middle-income countries, with a combined population of 1,400 million and not engaged in civil conflict, fatalities due to firearm injuries were estimated at 115,000 people per annum, in the 1990s
In those 52 countries, firearm is the first method used for homicide (two thirds) but only the second method for suicide (20%)
To prevent unintentional injury, gun safety training includes education on proper firearm storage and firearm-handling etiquette.
### Injury.
Based on US data, it is estimated that three people are injured for one killed.
### Noise.
A common hazard of repeated firearm use is noise-induced hearing loss (NIHL). NIHL can result from long-term exposure to noise or from high intensity impact noises such as gunshots. Individuals who shoot guns often have a characteristic pattern of hearing loss referred to as "shooters ear". They often have a high frequency loss with better hearing in the low frequencies and one ear is typically worse than the other. The ear on the side the shooter is holding the gun will receive protection from the sound wave from the shoulder while the other ear remains unprotected and more susceptible to the full impact of the sound wave.
The intensity of a gunshot does vary; lower caliber guns are typically on the softer side while higher caliber guns are often louder. The intensity of a gunshot though typically ranges from 140 dB to 175 dB. Indoor shooting also causes loud reverberations which can also be as damaging as the actual gunshot itself. According to the National Institute on Deafness and Other Communication Disorders, noise above 85 dB can begin to cause hearing loss. While many sounds cause damage over time, at the intensity level of a gunshot (140 dB or louder), damage to the ear can occur instantly.
Shooters use custom hearing protection such as electronic type hearing protection for hunters which can amplify soft sounds like leaves crunching while reducing the intensity of the gunshot and custom hearing protection for skeet shooting. 
Even with hearing protection, due to the high intensity of the noise guns produce shooters still develop hearing loss over time.
## Legal definitions.
Firearms include a variety of ranged weapons and there is no agreed-upon definition.
For instance English language laws of big legal entities such as the United States, India the European Union and Canada use different definitions.
Other English language definitions are provided by international treaties.
### United States.
In the United States, under 26 USCA § 861 (a), the term ‘‘firearm’’ means 
According to the US Bureau of Alcohol, Tobacco, Firearms and Explosives, if gas pressurization is achieved through "mechanical" gas compression rather than through chemical propellant combustion, then the device is technically an air gun, not a firearm.
### India.
In India, the arms act, 1959, provides a definition of firearms where "firearms" means arms of any description designed or adapted to discharge a projectile or projectiles of any kind by the action of any explosive or other forms of energy, and includes:
### European Union.
In the European Union, a European Directive amended by EU directive 2017/853 set minimum standards regarding civilian firearms acquisition and possession that EU Member States must implement into their national legal systems. In this context, since 2017, firearms are considered as "any portable barrelled weapon that expels, is designed to expel or may be converted to expel a shot, bullet or projectile by the action of a combustible propellant".
For legal reasons, objects can be considered as a firearm if they have the appearance of a firearm or are made in a way which makes it possible to convert them to a firearm. Member states may be allowed to exclude from their gun control law items such as antique weapons, or specific purposes items which can only be used for that sole purpose.
### Canada.
In Canada, firearms are defined by the Criminal Code:
### Australia.
Australia has a definition of firearms in its 1996 legal act:
### South Africa.
In South Africa, Firearms Control Act [No. 60 of 2000] defines firearm since June 2001, with a 2006 amendment of the definition: 
### International treaties.
An inter-American convention defines firearms as:
An international UN protocol on firearms considers that 

</doc>
<doc id="11968" url="https://en.wikipedia.org/wiki?curid=11968" title="George Washington">
George Washington

George Washington (February 22, 1732, 1799) was an American soldier, statesman, and Founding Father who served as the first President of the United States from 1789 to 1797. Appointed by the Continental Congress as commander of the Continental Army, Washington led the Patriot forces to victory in the American Revolutionary War, and presided at the Constitutional Convention of 1787, which established the Constitution of the United States and a federal government. Washington has been called the "Father of the Nation" for his manifold leadership in the formative days of the country.
Washington's first public office was serving as official Surveyor of Culpeper County, Virginia from 1749 to 1750. Subsequently, he received his initial military training (as well as a command with the Virginia Regiment) during the French and Indian War. He was later elected to the Virginia House of Burgesses and was named a delegate to the Continental Congress. Here he was appointed Commanding General of the Continental Army. With this title, he commanded American forces (allied with France) in the defeat and surrender of the British at the Siege of Yorktown during the American Revolutionary War. He resigned his commission after the Treaty of Paris was signed in 1783.
Washington played an indispensable role in adopting and ratifying the Constitution of the United States. He was then twice elected president by the Electoral College unanimously. As president, he implemented a strong, well-financed national government while remaining impartial in a fierce rivalry between cabinet members Thomas Jefferson and Alexander Hamilton. During the French Revolution, he proclaimed a policy of neutrality while sanctioning the Jay Treaty. He set enduring precedents for the office of president, including the title "Mr. President", and his Farewell Address is widely regarded as a pre-eminent statement on republicanism.
Washington owned over a hundred slaves, and he signed measures passed by Congress to protect slavery, as well as measures passed by Congress to curtail slavery. He become troubled with the institution of slavery during the 1770s, and in his will he stipulated that one of his slaves, William Lee, should be freed upon his death, along with 33 more slaves that he acquired in a prior debt agreement with his brother-in-law. He also stipulated that the other 123 slaves that he owned should be freed upon the death of his wife, Martha Washington. She decided to respect her husband's wishes and freed these slaves on January 1, 1801, before her death.
He endeavored to assimilate Native Americans into the Anglo-American culture but fought indigenous resistance during instances of violent conflict. He was a member of the Anglican Church and the Freemasons, and he urged broad religious freedom in his roles as general and president. Upon his death, he was eulogized as "first in war, first in peace, and first in the hearts of his countrymen".
Washington has been memorialized by monuments, a federal holiday, various media, geographical locations, including the national capital, the State of Washington, stamps, and currency, and many scholars and polls rank him among the greatest U.S. presidents. In 1976, as part of commemorations for the U.S. Bicentennial, Washington was posthumously promoted to the rank of General of the Armies of the United States.
## Early life (1732–1752).
The Washington family was a wealthy Virginia planter family that had made its fortune through land speculation and the cultivation of tobacco. Washington's great-grandfather John Washington emigrated in 1656 from Sulgrave, Northamptonshire, England, to the English colony of Virginia where he accumulated of land, including Little Hunting Creek on the Potomac River. George Washington was born on February 22, 1732, at Popes Creek in Westmoreland County, Virginia, and was the first of six children of Augustine and Mary Ball Washington. His father was a justice of the peace and a prominent public figure who had four additional children from his first marriage to Jane Butler. The family moved to Little Hunting Creek in 1735. In 1738, they moved to Ferry Farm near Fredericksburg, Virginia on the Rappahannock River. When Augustine died in 1743, Washington inherited Ferry Farm and ten slaves; his older half-brother Lawrence inherited Little Hunting Creek and renamed it Mount Vernon.
Washington did not have the formal education his elder brothers received at Appleby Grammar School in England, but did attend the Lower Church School in Hartfield. He learned mathematics, trigonometry, and land surveying and became a talented draftsman and map-maker. By early adulthood he was writing with "considerable force" and "precision"; however, his writing displayed little wit or humor. In pursuit of admiration, status, and power, he tended to attribute his shortcomings and failures to someone else's ineffectuality.
Washington often visited Mount Vernon and Belvoir, the plantation that belonged to Lawrence's father-in-law William Fairfax. Fairfax became Washington's patron and surrogate father, and Washington spent a month in 1748 with a team surveying Fairfax's Shenandoah Valley property. He received a surveyor's license the following year from the College of William &amp; Mary. Even though Washington had not served the customary apprenticeship, Fairfax appointed him surveyor of Culpeper County, Virginia, and he appeared in Culpeper County to take his oath of office July 20, 1749. He subsequently familiarized himself with the frontier region, and though he resigned from the job in 1750, he continued to do surveys west of the Blue Ridge Mountains. By 1752 he had bought almost in the Valley and owned .
In 1751, Washington made his only trip abroad when he accompanied Lawrence to Barbados, hoping the climate would cure his brother's tuberculosis. Washington contracted smallpox during that trip, which immunized him and left his face slightly scarred. Lawrence died in 1752, and Washington leased Mount Vernon from his widow Anne; he inherited it outright after her death in 1761.
## Colonial military career (1752–1758).
Lawrence Washington's service as adjutant general of the Virginia militia inspired his half-brother George to seek a commission. Virginia's lieutenant governor, Robert Dinwiddie, appointed George Washington as a major and commander of one of the four militia districts. The British and French were competing for control of the Ohio Valley. While the British were constructing forts along the Ohio River, the French were doing the same—constructing forts between the Ohio River and Lake Erie.
In October 1753, Dinwiddie appointed Washington as a special envoy. He had sent George to demand French forces to vacate land that was being claimed by the British. Washington was also appointed to make peace with the Iroquois Confederacy, and to gather further intelligence about the French forces. Washington met with Half-King Tanacharison, and other Iroquois chiefs, at Logstown, and gathered information about the numbers and locations of the French forts, as well as intelligence concerning individuals taken prisoner by the French. Washington was given the nickname Conotocaurius (town destroyer or devourer of villages) by Tanacharison. The nickname had previously been given to his great-grandfather John Washington in the late seventeenth century by the Susquehannock.
Washington's party reached the Ohio River in November 1753, and were intercepted by a French patrol. The party was escorted to Fort Le Boeuf, where Washington was received in a friendly manner. He delivered the British demand to vacate to the French commander Saint-Pierre, but the French refused to leave. Saint-Pierre gave Washington his official answer in a sealed envelope after a few days' delay, as well as food and extra winter clothing for his party's journey back to Virginia. Washington completed the precarious mission in 77 days, in difficult winter conditions, achieving a measure of distinction when his report was published in Virginia and in London.
### French and Indian War.
In February 1754, Dinwiddie promoted Washington to lieutenant colonel and second-in-command of the 300-strong Virginia Regiment, with orders to confront French forces at the Forks of the Ohio. Washington set out for the Forks with half the regiment in April and soon learned a French force of 1,000 had begun construction of Fort Duquesne there. In May, having set up a defensive position at Great Meadows, he learned that the French had made camp seven miles (11 km) away; he decided to take the offensive.
The French detachment proved to be only about fifty men, so Washington advanced on May 28 with a small force of Virginians and Indian allies to ambush them. What took place, known as the Battle of Jumonville Glen or the "Jumonville affair", was disputed, and French forces were killed outright with muskets and hatchets. French commander Joseph Coulon de Jumonville, who carried a diplomatic message for the British to evacuate, was killed. French forces found Jumonville and some of his men dead and scalped and assumed Washington was responsible. Washington blamed his translator for not communicating the French intentions. Dinwiddie congratulated Washington for his victory over the French. This incident ignited the French and Indian War, which later became part of the larger Seven Years' War.
The full Virginia Regiment joined Washington at Fort Necessity the following month with news that he had been promoted to command of the regiment and colonel upon the regimental commander's death. The regiment was reinforced by an independent company of a hundred South Carolinians led by Captain James Mackay, whose royal commission outranked that of Washington, and a conflict of command ensued. On July 3, a French force attacked with 900 men, and the ensuing battle ended in Washington's surrender. In the aftermath, Colonel James Innes took command of intercolonial forces, the Virginia Regiment was divided, and Washington was offered a captaincy which he refused, with the resignation of his commission.
In 1755, Washington served voluntarily as an aide to General Edward Braddock, who led a British expedition to expel the French from Fort Duquesne and the Ohio Country. On Washington's recommendation, Braddock split the army into one main column and a lightly equipped "flying column". Suffering from a severe case of dysentery, Washington was left behind, and when he rejoined Braddock at Monongahela the French and their Indian allies ambushed the divided army. Two-thirds of the British force became casualties, including the mortally wounded Braddock. Under the command of Lieutenant Colonel Thomas Gage, Washington, still very ill, rallied the survivors and formed a rear guard, allowing the remnants of the force to disengage and retreat. During the engagement, he had two horses shot from under him, and his hat and coat were bullet-pierced. His conduct under fire redeemed his reputation among critics of his command in the Battle of Fort Necessity, but he was not included by the succeeding commander (Colonel Thomas Dunbar) in planning subsequent operations.
The Virginia Regiment was reconstituted in August 1755, and Dinwiddie appointed Washington its commander, again with the rank of colonel. Washington clashed over seniority almost immediately, this time with John Dagworthy, another captain of superior royal rank, who commanded a detachment of Marylanders at the regiment's headquarters in Fort Cumberland. Washington, impatient for an offensive against Fort Duquesne, was convinced Braddock would have granted him a royal commission and pressed his case in February 1756 with Braddock's successor, William Shirley, and again in January 1757 with Shirley's successor, Lord Loudoun. Shirley ruled in Washington's favor only in the matter of Dagworthy; Loudoun humiliated Washington, refused him a royal commission and agreed only to relieve him of the responsibility of manning Fort Cumberland.
In 1758, the Virginia Regiment was assigned to the British Forbes Expedition to capture Fort Duquesne. Washington disagreed with General John Forbes' tactics and chosen route. Forbes nevertheless made Washington a brevet brigadier general and gave him command of one of the three brigades that would assault the fort. The French abandoned the fort and the valley before the assault was launched; Washington saw only a friendly fire incident which left 14 dead and 26 injured. The war lasted another four years, and Washington resigned his commission and returned to Mount Vernon.
Under Washington, the Virginia Regiment had defended of frontier against twenty Indian attacks in ten months. He increased the professionalism of the regiment as it increased from 300 to 1,000 men, and Virginia's frontier population suffered less than other colonies. Some historians have said this was Washington's "only unqualified success" during the war. Though he failed to realize a royal commission, he did gain self-confidence, leadership skills, and invaluable knowledge of British military tactics. The destructive competition Washington witnessed among colonial politicians fostered his later support of a strong central government.
## Marriage, civilian, and political life (1755–1775).
On January 6, 1759, Washington, at age 26, married Martha Dandridge Custis, the 27-year-old widow of wealthy plantation owner Daniel Parke Custis. The marriage took place at Martha's estate; she was intelligent, gracious, and experienced in managing a planter's estate, and the couple created a happy marriage. They raised John Parke Custis (Jacky) and Martha "Patsy" Parke Custis, children from her previous marriage, and later Jacky's children Eleanor Parke Custis (Nelly) and George Washington Parke Custis (Washy). Washington's 1751 bout with smallpox is thought to have rendered him sterile, though it is equally likely that "Martha may have sustained injury during the birth of Patsy, her final child, making additional births impossible." The couple lamented not having any children together. They moved to Mount Vernon, near Alexandria, where he took up life as a planter of tobacco and wheat and emerged as a political figure.
The marriage gave Washington control over Martha's one-third dower interest in the Custis estate, and he managed the remaining two-thirds for Martha's children; the estate also included 84 slaves. He became one of Virginia's wealthiest men, which increased his social standing.
At Washington's urging, Governor Lord Botetourt fulfilled Dinwiddie's 1754 promise of land bounties to all-volunteer militia during the French and Indian War. In late 1770, Washington inspected the lands in the Ohio and Great Kanawha regions, and he engaged surveyor William Crawford to subdivide it. Crawford allotted to Washington; Washington told the veterans that their land was hilly and unsuitable for farming, and he agreed to purchase , leaving some feeling they had been duped. He also doubled the size of Mount Vernon to and increased its slave population to more than a hundred by 1775.
Washington's political activities included supporting the candidacy of his friend George William Fairfax in his 1755 bid to represent the region in the Virginia House of Burgesses. This support led to a dispute which resulted in a physical altercation between Washington and another Virginia planter, William Payne. Washington defused the situation, including ordering officers from the Virginia Regiment to stand down. Washington apologized to Payne the following day at a tavern. Payne had been expecting to be challenged to a duel.
As a respected military hero and large landowner, Washington held local offices and was elected to the Virginia provincial legislature, representing Frederick County in the House of Burgesses for seven years beginning in 1758. He plied the voters with beer, brandy, and other beverages, although he was absent while serving on the Forbes Expedition. He won the election with roughly 40 percent of the vote, defeating three other candidates with the help of several local supporters. He rarely spoke in his early legislative career, but he became a prominent critic of Britain's taxation policy and mercantilist policies towards the American colonies starting in the 1760s.
By occupation, Washington was a planter, and he imported luxuries and other goods from England, paying for them by exporting tobacco. His profligate spending combined with low tobacco prices left him £1,800 in debt by 1764, prompting him to diversify his holdings. In 1765, because of erosion and other soil problems, he changed Mount Vernon's primary cash crop from tobacco to wheat and expanded operations to include corn flour milling and fishing. Washington also took time for leisure with fox hunting, fishing, dances, theater, cards, backgammon, and billiards.
Washington soon was counted among the political and social elite in Virginia. From 1768 to 1775, he invited some 2,000 guests to his Mount Vernon estate, mostly those whom he considered "people of rank". He became more politically active in 1769, presenting legislation in the Virginia Assembly to establish an embargo on goods from Great Britain.
Washington's step-daughter Patsy Custis suffered from epileptic attacks from age 12, and she died in his arms in 1773. The following day, he wrote to Burwell Bassett: "It is easier to conceive, than to describe, the distress of this Family". He canceled all business activity and remained with Martha every night for three months.
### Opposition to British Parliament and Crown.
Washington played a central role before and during the American Revolution. His disdain for the British military had begun when he was passed over for promotion into the Regular Army. Opposed to taxes imposed by the British Parliament on the Colonies without proper representation, he and other colonists were also angered by the Royal Proclamation of 1763 which banned American settlement west of the Allegheny Mountains and protected the British fur trade.
Washington believed the Stamp Act of 1765 was an "Act of Oppression", and he celebrated its repeal the following year. In March 1766, Parliament passed the Declaratory Act asserting that Parliamentary law superseded colonial law. In the late 1760s, the interference of the British Crown in American lucrative western land speculation spurred on the American Revolution. Washington himself was a prosperous land speculator, and in 1767, he encouraged "adventures" to acquire backcountry western lands. Washington helped lead widespread protests against the Townshend Acts passed by Parliament in 1767, and he introduced a proposal in May 1769 drafted by George Mason which called Virginians to boycott British goods; the Acts were mostly repealed in 1770.
Parliament sought to punish Massachusetts colonists for their role in the Boston Tea Party in 1774 by passing the Coercive Acts, which Washington referred to as "an invasion of our rights and privileges". He said Americans must not submit to acts of tyranny since "custom and use shall make us as tame and abject slaves, as the blacks we rule over with such arbitrary sway". That July, he and George Mason drafted a list of resolutions for the Fairfax County committee which Washington chaired, and the committee adopted the Fairfax Resolves calling for a Continental Congress, and an end to the slave trade. On August 1, Washington attended the First Virginia Convention, where he was selected as a delegate to the First Continental Congress, September 5 to October 26, 1774, which he also attended. As tensions rose in 1774, he helped train county militias in Virginia and organized enforcement of the Continental Association boycott of British goods instituted by the Congress.
The American Revolutionary War began on April 19, 1775, with the Battles of Lexington and Concord and the Siege of Boston. The colonists were divided over breaking away from British rule and split into two factions: Patriots who rejected British rule, and Loyalists who desired to remain subject to the King. General Thomas Gage was commander of British forces in America at the beginning of the war. Upon hearing the shocking news of the onset of war, Washington was "sobered and dismayed", and he hastily departed Mount Vernon on May 4, 1775, to join the Second Continental Congress in Philadelphia.
## Commander in chief (1775–1783).
Congress created the Continental Army on June 14, 1775, and Samuel and John Adams nominated Washington to become its commander-in-chief. Washington was chosen over John Hancock because of his military experience and the belief that a Virginian would better unite the colonies. He was considered an incisive leader who kept his "ambition in check". He was unanimously elected commander in chief by Congress the next day.
Washington appeared before Congress in uniform and gave an acceptance speech on June 16, declining a salary—though he was later reimbursed expenses. He was commissioned on June 19 and was roundly praised by Congressional delegates, including John Adams, who proclaimed that he was the man best suited to lead and unite the colonies. Congress appointed Washington "General &amp; Commander in chief of the army of the United Colonies and of all the forces raised or to be raised by them", and instructed him to take charge of the siege of Boston on June 22, 1775.
Congress chose his primary staff officers, including Major General Artemas Ward, Adjutant General Horatio Gates, Major General Charles Lee, Major General Philip Schuyler, Major General Nathanael Greene, Colonel Henry Knox, and Colonel Alexander Hamilton. Washington was impressed by Colonel Benedict Arnold and gave him responsibility for launching an invasion of Canada. He also engaged French and Indian War compatriot Brigadier General Daniel Morgan. Henry Knox impressed Adams with ordnance knowledge, and Washington promoted him to colonel and chief of artillery.
At the start of the war, Washington opposed the recruiting of blacks, both free and enslaved, into the Continental Army. After his appointment, Washington banned their enlistment. The British saw an opportunity to divide the colonies, and the colonial governor of Virginia issued a proclamation, which promised freedom to slaves if they joined the British. Desperate for manpower by late 1777, Washington relented and overturned his ban. By the end of the war, around one-tenth of Washington's army were blacks.
After the war Washington became the target of accusations made by General Lee involving his alleged questionable conduct as Commander in Chief during the war that were published by patriot-printer William Goddard. Goddard in a letter of May 30, 1785, had informed Washington of Lee's request to publish his account and assured him that he "...took the liberty to suppress such expressions as appeared to be the ebullitions of a disappointed &amp; irritated mind ...". Washington replied, telling Goddard to print what he saw fit, and to let "... the impartial &amp; dispassionate world," draw their own conclusions.
### Siege of Boston.
Early in 1775, in response to the growing rebellious movement, London sent British troops, commanded by General Thomas Gage, to occupy Boston. They set up fortifications about the city, making it impervious to attack. Various local militias surrounded the city and effectively trapped the British, resulting in a standoff.
As Washington headed for Boston, word of his march preceded him, and he was greeted everywhere; gradually, he became a symbol of the Patriot cause. Upon arrival on July 2, 1775, two weeks after the Patriot defeat at nearby Bunker Hill, he set up his Cambridge, Massachusetts headquarters and inspected the new army there, only to find an undisciplined and badly outfitted militia. After consultation, he initiated Benjamin Franklin's suggested reforms—drilling the soldiers and imposing strict discipline, floggings, and incarceration. Washington ordered his officers to identify the skills of recruits to ensure military effectiveness, while removing incompetent officers. He petitioned Gage, his former superior, to release captured Patriot officers from prison and treat them humanely. In October 1775, King George III declared that the colonies were in open rebellion and relieved General Gage of command for incompetence, replacing him with General William Howe.
In June 1775, Congress ordered an invasion of Canada. It was led by Benedict Arnold, who, despite Washington's strong objection, drew volunteers from the latter's force during the Siege of Boston. The move on Quebec failed, with the American forces being reduced to less than half and forced to retreat.
The Continental Army, further diminished by expiring short-term enlistments, and by January 1776 reduced by half to 9,600 men, had to be supplemented with the militia, and was joined by Knox with heavy artillery captured from Fort Ticonderoga. When the Charles River froze over, Washington was eager to cross and storm Boston, but General Gates and others were opposed to untrained militia striking well-garrisoned fortifications. Washington reluctantly agreed to secure the Dorchester Heights, 100 feet above Boston, in an attempt to force the British out of the city. On March 9, under cover of darkness, Washington's troops brought up Knox's big guns and bombarded British ships in Boston harbor. On March 17, 9,000 British troops and Loyalists began a chaotic ten-day evacuation of Boston aboard 120 ships. Soon after, Washington entered the city with 500 men, with explicit orders not to plunder the city. He ordered vaccinations against smallpox to great effect, as he did later in Morristown, New Jersey. He refrained from exerting military authority in Boston, leaving civilian matters in the hands of local authorities.
### Battle of Long Island.
Washington then proceeded to New York City, arriving on April 13, 1776, and began constructing fortifications to thwart the expected British attack. He ordered his occupying forces to treat civilians and their property with respect, to avoid the abuses which Bostonian citizens suffered at the hands of British troops during their occupation. A plot to assassinate or capture him was discovered and thwarted, resulting in the arrest of 98 people involved or complicit (56 of which were from Long Island (Kings (Brooklyn) and Queens counties), including the Loyalist Mayor of New York David Mathews. Washington's bodyguard, Thomas Hickey, was hanged for mutiny and sedition. General Howe transported his resupplied army, with the British fleet, from Halifax to New York, knowing the city was key to securing the continent. George Germain, who ran the British war effort in England, believed it could be won with one "decisive blow". The British forces, including more than a hundred ships and thousands of troops, began arriving on Staten Island on July2 to lay siege to the city. After the Declaration of Independence was adopted on July 4, Washington informed his troops in his general orders of July9 that Congress had declared the united colonies to be "free and independent states".
Howe's troop strength totaled 32,000 regulars and Hessians auxiliaries, and Washington's consisted of 23,000, mostly raw recruits and militia. In August, Howe landed 20,000 troops at Gravesend, Brooklyn, and approached Washington's fortifications, as George III proclaimed the rebellious American colonists to be traitors. Washington, opposing his generals, chose to fight, based upon inaccurate information that Howe's army had only 8,000-plus troops. In the Battle of Long Island, Howe assaulted Washington's flank and inflicted 1,500 Patriot casualties, the British suffering 400. Washington retreated, instructing General William Heath to acquisition river craft in the area. On August 30, General William Alexander held off the British and gave cover while the army crossed the East River under darkness to Manhattan Island without loss of life or materiel, although Alexander was captured.
Howe, emboldened by his Long Island victory, dispatched Washington as "George Washington, Esq." in futility to negotiate peace. Washington declined, demanding to be addressed with diplomatic protocol, as general and fellow belligerent, not as a "rebel", lest his men are hanged as such if captured. The Royal Navy bombarded the unstable earthworks on lower Manhattan Island. Washington, with misgivings, heeded the advice of Generals Greene and Putnam to defend Fort Washington. They were unable to hold it, and Washington abandoned it despite General Lee's objections, as his army retired north to the White Plains. Howe's pursuit forced Washington to retreat across the Hudson River to Fort Lee to avoid encirclement. Howe landed his troops on Manhattan in November and captured Fort Washington, inflicting high casualties on the Americans. Washington was responsible for delaying the retreat, though he blamed Congress and General Greene. Loyalists in New York considered Howe a liberator and spread a rumor that Washington had set fire to the city. Patriot morale reached its lowest when Lee was captured. Now reduced to 5,400 troops, Washington's army retreated through New Jersey, and Howe broke off pursuit, delaying his advance on Philadelphia, and set up winter quarters in New York.
### Crossing the Delaware, Trenton, and Princeton.
Washington crossed the Delaware River into Pennsylvania, where Lee's replacement John Sullivan joined him with 2,000 more troops. The future of the Continental Army was in doubt for lack of supplies, a harsh winter, expiring enlistments, and desertions. Washington was disappointed that many New Jersey residents were Loyalists or skeptical about the prospect of independence.
Howe split up his British Army and posted a Hessian garrison at Trenton to hold western New Jersey and the east shore of the Delaware, but the army appeared complacent, and Washington and his generals devised a surprise attack on the Hessians at Trenton, which he codenamed "Victory or Death". The army was to cross the Delaware River to Trenton in three divisions: one led by Washington (2,400 troops), another by General James Ewing (700), and the third by Colonel John Cadwalader (1,500). The force was to then split, with Washington taking the Pennington Road and General Sullivan traveling south on the river's edge.
Washington first ordered a 60-mile search for Durham boats to transport his army, and he ordered the destruction of vessels that could be used by the British. Washington crossed the Delaware River on Christmas night, December 25, 1776, while he personally risked capture staking out the Jersey shoreline. His men followed across the ice-obstructed river in sleet and snow from McConkey's Ferry, with 40 men per vessel. The wind churned up the waters, and they were pelted with hail, but by 3:00a.m. on December 26, they made it across with no losses. Henry Knox was delayed, managing frightened horses and about 18 field guns on flat-bottomed ferries. Cadwalader and Ewing failed to cross due to the ice and heavy currents, and awaiting Washington doubted his planned attack on Trenton. Once Knox arrived, Washington proceeded to Trenton to take only his troops against the Hessians, rather than risk being spotted returning his army to Pennsylvania.
The troops spotted Hessian positions a mile from Trenton, so Washington split his force into two columns, rallying his men: "Soldiers keep by your officers. For God's sake, keep by your officers." The two columns were separated at the Birmingham crossroads. General Nathanael Greene's column took the upper Ferry Road, led by Washington, and General John Sullivan's column advanced on River Road. (.) The Americans marched in sleet and snowfall. Many were shoeless with bloodied feet, and two died of exposure. At sunrise, Washington led them in a surprise attack on the Hessians, aided by Major General Knox and artillery. The Hessians had 22 killed (including Colonel Johann Rall), 83 wounded, and 850 captured with supplies.
Washington retreated across Delaware River to Pennsylvania and returned to New Jersey on January 3, 1777, launching an attack on British regulars at Princeton, with 40 Americans killed or wounded and 273 British killed or captured. American Generals Hugh Mercer and John Cadwalader were being driven back by the British when Mercer was mortally wounded, then Washington arrived and led the men in a counterattack which advanced to within of the British line.
Some British troops retreated after a brief stand, while others took refuge in Nassau Hall, which became the target of Colonel Alexander Hamilton's cannons. Washington's troops charged, the British surrendered in less than an hour, and 194 soldiers laid down their arms. Howe retreated to New York City where his army remained inactive until early the next year. Washington's depleted Continental Army took up winter headquarters in Morristown, New Jersey while disrupting British supply lines and expelling them from parts of New Jersey. Washington later said the British could have successfully counterattacked his encampment before his troops were dug in. The victories at Trenton and Princeton by Washington revived Patriot morale and changed the course of the war. 
The British still controlled New York, and many Patriot soldiers did not re-enlist or deserted after the harsh winter campaign. Congress instituted greater rewards for re-enlisting and punishments for desertion to effect greater troop numbers. Strategically, Washington's victories were pivotal for the Revolution and quashed the British strategy of showing overwhelming force followed by offering generous terms. In February 1777, word reached London of the American victories at Trenton and Princeton, and the British realized the Patriots were in a position to demand unconditional independence.
### Brandywine, Germantown, and Saratoga.
In July 1777, British General John Burgoyne led the Saratoga campaign south from Quebec through Lake Champlain and recaptured Fort Ticonderoga intending to divide New England, including control of the Hudson River. However, General Howe in British-occupied New York blundered, taking his army south to Philadelphia rather than up the Hudson River to join Burgoyne near Albany. Meanwhile, Washington and Gilbert du Motier, Marquis de Lafayette rushed to Philadelphia to engage Howe and were shocked to learn of Burgoyne's progress in upstate New York, where the Patriots were led by General Philip Schuyler and successor Horatio Gates. Washington's army of less experienced men were defeated in the pitched battles at Philadelphia.
Howe outmaneuvered Washington at the Battle of Brandywine on September 11, 1777, and marched unopposed into the nation's capital at Philadelphia. A Patriot attack failed against the British at Germantown in October. Major General Thomas Conway prompted some members of Congress (referred to as the Conway Cabal) to consider removing Washington from command because of the losses incurred at Philadelphia. Washington's supporters resisted, and the matter was finally dropped after much deliberation. Once the plot was exposed, Conway wrote an apology to Washington, resigned, and returned to France.
Washington was concerned with Howe's movements during the Saratoga campaign to the north, and he was also aware that Burgoyne was moving south toward Saratoga from Quebec. Washington took some risks to support Gates' army, sending reinforcements north with Generals Benedict Arnold, his most aggressive field commander, and Benjamin Lincoln. On October 7, 1777, Burgoyne tried to take Bemis Heights but was isolated from support by Howe. He was forced to retreat to Saratoga and ultimately surrendered after the Battles of Saratoga. As Washington suspected, Gates' victory emboldened his critics. Biographer John Alden maintains, "It was inevitable that the defeats of Washington's forces and the concurrent victory of the forces in upper New York should be compared." The admiration for Washington was waning, including little credit from John Adams. British commander Howe resigned in May 1778, left America forever, and was replaced by Sir Henry Clinton.
### Valley Forge and Monmouth.
Washington's army of 11,000 went into winter quarters at Valley Forge north of Philadelphia in December 1777. They suffered between 2,000 and 3,000 deaths in the extreme cold over six months, mostly from disease and lack of food, clothing, and shelter. Meanwhile, the British were comfortably quartered in Philadelphia, paying for supplies in pounds sterling, while Washington struggled with a devalued American paper currency. The woodlands were soon exhausted of game, and by February, lowered morale and increased desertions ensued.
Washington made repeated petitions to the Continental Congress for provisions. He received a congressional delegation to check the Army's conditions and expressed the urgency of the situation, proclaiming: "Something must be done. Important alterations must be made." He recommended that Congress expedite supplies, and Congress agreed to strengthen and fund the army's supply lines by reorganizing the commissary department. By late February, supplies began arriving.
Baron Friedrich Wilhelm von Steuben's incessant drilling soon transformed Washington's recruits into a disciplined fighting force, and the revitalized army emerged from Valley Forge early the following year. Washington promoted Von Steuben to Major General and made him chief of staff.
In early 1778, the French responded to Burgoyne's defeat and entered into a Treaty of Alliance with the Americans. The Continental Congress ratified the treaty in May, which amounted to a French declaration of war against Britain.
The British evacuated Philadelphia for New York that June and Washington summoned a war council of American and French Generals. He chose a partial attack on the retreating British at the Battle of Monmouth; the British were commanded by Howe's successor General Henry Clinton. Generals Charles Lee and Lafayette moved with 4,000 men, without Washington's knowledge, and bungled their first attack on June 28. Washington relieved Lee and achieved a draw after an expansive battle. At nightfall, the British continued their retreat to New York, and Washington moved his army outside the city. Monmouth was Washington's last battle in the North; he valued the safety of his army more than towns with little value to the British.
### West Point espionage.
Washington became "America's first spymaster" by designing an espionage system against the British. In 1778, Major Benjamin Tallmadge formed the Culper Ring at Washington's direction to covertly collect information about the British in New York. Washington had disregarded incidents of disloyalty by Benedict Arnold, who had distinguished himself in many battles.
During mid-1780, Arnold began supplying British spymaster John André with sensitive information intended to compromise Washington and capture West Point, a key American defensive position on the Hudson River. Historians have noted as possible reasons for Arnold's treachery his anger at losing promotions to junior officers, or repeated slights from Congress. He was also deeply in debt, profiteering from the war, and disappointed by Washington's lack of support during his eventual court-martial.
Arnold repeatedly asked for command of West Point, and Washington finally agreed in August. Arnold met André on September 21, giving him plans to take over the garrison. Militia forces captured André and discovered the plans, but Arnold escaped to New York. Washington recalled the commanders positioned under Arnold at key points around the fort to prevent any complicity, but he did not suspect Arnold's wife Peggy. Washington assumed personal command at West Point and reorganized its defenses. André's trial for espionage ended in a death sentence, and Washington offered to return him to the British in exchange for Arnold, but Clinton refused. André was hanged on October 2, 1780, despite his last request being to face a firing squad, to deter other spies.
### Southern theater and Yorktown.
In late 1778, General Clinton shipped 3,000 troops from New York to Georgia and launched a Southern invasion against Savannah, reinforced by 2,000 British and Loyalist troops. They repelled an attack by Patriots and French naval forces, which bolstered the British war effort.
In mid-1779, Washington attacked Iroquois warriors of the Six Nations to force Britain's Indian allies out of New York, from which they had assaulted New England towns. In response, Indian warriors joined with Loyalist rangers led by Walter Butler and killed more than 200 frontiersmen in June, laying waste to the Wyoming Valley in Pennsylvania. Washington retaliated by ordering General John Sullivan to lead an expedition to effect "the total destruction and devastation" of Iroquois villages and take their women and children hostage. Those who managed to escape fled to Canada.
Washington's troops went into quarters at Morristown, New Jersey during the winter of 1779–1780 and suffered their worst winter of the war, with temperatures well below freezing. New York Harbor was frozen over, snow and ice covered the ground for weeks, and the troops again lacked provisions.
Clinton assembled 12,500 troops and attacked Charlestown, South Carolina in January 1780, defeating General Benjamin Lincoln who had only 5,100 Continental troops. The British went on to occupy the South Carolina Piedmont in June, with no Patriot resistance. Clinton returned to New York and left 8,000 troops commanded by General Charles Cornwallis. Congress replaced Lincoln with Horatio Gates; he failed in South Carolina and was replaced by Washington's choice of Nathaniel Greene, but the British already had the South in their grasp. Washington was reinvigorated, however, when Lafayette returned from France with more ships, men, and supplies, and 5,000 veteran French troops led by Marshal Rochambeau arrived at Newport, Rhode Island in July 1780. French naval forces then landed, led by Admiral Grasse, and Washington encouraged Rochambeau to move his fleet south to launch a joint land and naval attack on Arnold's troops.
Washington's army went into winter quarters at New Windsor, New York in December 1780, and Washington urged Congress and state officials to expedite provisions in hopes that the army would not "continue to struggle under the same difficulties they have hitherto endured". On March 1, 1781, Congress ratified the Articles of Confederation, but the government that took effect on March2 did not have the power to levy taxes, and it loosely held the states together.
General Clinton sent Benedict Arnold, now a British Brigadier General with 1,700 troops, to Virginia to capture Portsmouth and conduct raids on Patriot forces from there; Washington responded by sending Lafayette south to counter Arnold's efforts. Washington initially hoped to bring the fight to New York, drawing off British forces from Virginia and ending the war there, but Rochambeau advised Grasse that Cornwallis in Virginia was the better target. Grasse's fleet arrived off the Virginia coast, and Washington saw the advantage. He made a feint towards Clinton in New York, then headed south to Virginia.
The Siege of Yorktown was a decisive Allied victory by the combined forces of the Continental Army commanded by General Washington, the French Army commanded by the General Comte de Rochambeau, and the French Navy commanded by Admiral de Grasse, in the defeat of Cornwallis' British forces. On August 19, the march to Yorktown led by Washington and Rochambeau began, which is known now as the "celebrated march". Washington was in command of an army of 7,800 Frenchmen, 3,100 militia, and 8,000 Continentals. Not well experienced in siege warfare, Washington often referred to the judgment of General Rochambeau and used his advice about how to proceed; however, Rochambeau never challenged Washington's authority as the battle's commanding officer.
By late September, Patriot-French forces surrounded Yorktown, trapped the British army, and prevented British reinforcements from Clinton in the North, while the French navy emerged victorious at the Battle of the Chesapeake. The final American offensive was begun with a shot fired by Washington. The siege ended with a British surrender on October 19, 1781; over 7,000 British soldiers were made prisoners of war, in the last major land battle of the American Revolutionary War. Washington negotiated the terms of surrender for two days, and the official signing ceremony took place on October 19; Cornwallis claimed illness and was absent, sending General Charles O'Hara as his proxy. As a gesture of goodwill, Washington held a dinner for the American, French, and British generals, all of whom fraternized on friendly terms and identified with one another as members of the same professional military caste.
After the surrender at Yorktown, a situation developed that threatened relations between the newly independent America and Britain. Following a series of retributive executions between Patriots and Loyalists, Washington, on May 18, 1782, wrote in a letter to General Moses Hazen that a British captain would be executed in retaliation for the execution of Joshua Huddy, a popular Patriot leader, who was hanged at the direction of the Loyalist Richard Lippincott. Washington wanted Lippincott himself to be executed but was rebuffed. Subsequently, Charles Asgill was chosen instead, by a drawing of lots from a hat. This was a violation of the 14th article of the Yorktown Articles of Capitulation, which protected prisoners of war from acts of retaliation. Later, Washington's feelings on matters changed and in a letter of November 13, 1782, to Asgill, he acknowledged Asgill's letter and situation, expressing his desire not to see any harm come to him. After much consideration between the Continental Congress, Alexander Hamilton, Washington, and appeals from the French Crown, Asgill was finally released, where Washington issued Asgill a pass that allowed his passage to New York.
### Demobilization and resignation.
As peace negotiations started, the British gradually evacuated troops from Savannah, Charlestown, and New York by 1783, and the French army and navy likewise departed. The American treasury was empty, unpaid, and mutinous soldiers forced the adjournment of Congress, and Washington dispelled unrest by suppressing the Newburgh Conspiracy in March 1783; Congress promised officers a five-year bonus. Washington submitted an account of $450,000 in expenses which he had advanced to the army. The account was settled, though it was allegedly vague about large sums and included expenses his wife had incurred through visits to his headquarters.
Washington resigned as commander-in-chief once the Treaty of Paris was signed, and he planned to retire to Mount Vernon. The treaty was ratified in April 1783, and Hamilton's Congressional committee adapted the army for peacetime. Washington gave the Army's perspective to the committee in his "Sentiments on a Peace Establishment". The Treaty was signed on September 3, 1783, and Great Britain officially recognized the independence of the United States. Washington then disbanded his army, giving an eloquent farewell address to his soldiers on November 2. On November 25, the British evacuated New York City, and Washington and Governor George Clinton took possession.
Washington advised Congress in August 1783 to keep a standing army, create a "national militia" of separate state units, and establish a navy and a national military academy. He circulated his "Farewell" orders that discharged his troops, whom he called "one patriotic band of brothers". Before his return to Mount Vernon, he oversaw the evacuation of British forces in New York and was greeted by parades and celebrations, where he announced that Colonel Henry Knox had been promoted commander-in-chief.
After leading the Continental Army for 8½ years, Washington bade farewell to his officers at Fraunces Tavern in December 1783 and resigned his commission days later, refuting Loyalist predictions that he would not relinquish his military command. In a final appearance in uniform, he gave a statement to the Congress: "I consider it an indispensable duty to close this last solemn act of my official life, by commending the interests of our dearest country to the protection of Almighty God, and those who have the superintendence of them, to his holy keeping." Washington's resignation was acclaimed at home and abroad and showed a skeptical world that the new republic would not degenerate into chaos.
The same month, Washington was appointed president-general of the Society of the Cincinnati, a hereditary fraternity, and he served for the remainder of his life.
## Early republic (1783–1789).
### Return to Mount Vernon.
Washington was longing to return home after spending just ten days at Mount Vernon out of years of war. He arrived on Christmas Eve, delighted to be "free of the bustle of a camp and the busy scenes of public life". He was a celebrity and was fêted during a visit to his mother at Fredericksburg in February 1784, and he received a constant stream of visitors wishing to pay their respects to him at Mount Vernon.
Washington reactivated his interests in the Great Dismal Swamp and Potomac canal projects begun before the war, though neither paid him any dividends, and he undertook a 34-day, 680-mile (1090 km) trip to check on his land holdings in the Ohio Country. He oversaw the completion of the remodeling work at Mount Vernon, which transformed his residence into the mansion that survives to this day—although his financial situation was not strong. Creditors paid him in depreciated wartime currency, and he owed significant amounts in taxes and wages. Mount Vernon had made no profit during his absence, and he saw persistently poor crop yields due to pestilence and poor weather. His estate recorded its eleventh year running at a deficit in 1787, and there was little prospect of improvement. Washington undertook a new landscaping plan and succeeded in cultivating a range of fast-growing trees and shrubs that were native to North America. He also began breeding mules after having been gifted a Spanish jack by King Charles III of Spain in 1784. There were few mules in the United States at that time, and he believed that properly bred mules would revolutionize agriculture and transportation.
### Constitutional Convention of 1787.
Before returning to private life in June 1783, Washington called for a strong union. Though he was concerned that he might be criticized for meddling in civil matters, he sent a circular letter to all the states, maintaining that the Articles of Confederation was no more than "a rope of sand" linking the states. He believed the nation was on the verge of "anarchy and confusion", was vulnerable to foreign intervention, and that a national constitution would unify the states under a strong central government. When Shays' Rebellion erupted in Massachusetts on August 29, 1786, over taxation, Washington was further convinced that a national constitution was needed. Some nationalists feared that the new republic had descended into lawlessness, and they met together on September 11, 1786, at Annapolis to ask Congress to revise the Articles of Confederation. One of their biggest efforts, however, was getting Washington to attend. Congress agreed to a Constitutional Convention to be held in Philadelphia in Spring 1787, and each state was to send delegates.
On December 4, 1786, Washington was chosen to lead the Virginia delegation, but he declined on December 21. He had concerns about the legality of the convention and consulted James Madison, Henry Knox, and others. They persuaded him to attend it, however, as his presence might induce reluctant states to send delegates and smooth the way for the ratification process. On March 28, Washington told Governor Edmund Randolph that he would attend the convention but made it clear that he was urged to attend.
Washington arrived in Philadelphia on May 9, 1787, though a quorum was not attained until Friday, May 25. Benjamin Franklin nominated Washington to preside over the convention, and he was unanimously elected to serve as president general. The convention's state-mandated purpose was to revise the Articles of Confederation with "all such alterations and further provisions" required to improve them, and the new government would be established when the resulting document was "duly confirmed by the several states". Governor Edmund Randolph of Virginia introduced Madison's Virginia Plan on May 27, the third day of the convention. It called for an entirely new constitution and a sovereign national government, which Washington highly recommended.
Washington wrote Alexander Hamilton on July 10: "I almost despair of seeing a favorable issue to the proceedings of our convention and do therefore repent having had any agency in the business." Nevertheless, he lent his prestige to the goodwill and work of the other delegates. He unsuccessfully lobbied many to support ratification of the Constitution, such as anti-federalist Patrick Henry; Washington told him "the adoption of it under the present circumstances of the Union is in my opinion desirable" and declared the alternative would be anarchy. Washington and Madison then spent four days at Mount Vernon evaluating the new government's transition.
### Chancellor of William &amp; Mary.
In 1788, the Board of Visitors of the College of William &amp; Mary decided to re-establish the position of Chancellor, and elected Washington to the office on January 18. The College Rector Samuel Griffin wrote to Washington inviting him to the post, and in a letter dated April 30, 1788, Washington accepted the position of the 14th Chancellor of the College of William &amp; Mary. He continued to serve in the post through his presidency until his death on December 14, 1799.
### First presidential election.
The delegates to the Convention anticipated a Washington presidency and left it to him to define the office once elected. The state electors under the Constitution voted for the president on February 4, 1789, and Washington suspected that most republicans had not voted for him. The mandated March4 date passed without a Congressional quorum to count the votes, but a quorum was reached on April 5. The votes were tallied the next day, and Congressional Secretary Charles Thomson was sent to Mount Vernon to tell Washington he had been elected president. Washington won the majority of every state's electoral votes; John Adams received the next highest number of votes and therefore became vice president. Washington had "anxious and painful sensations" about leaving the "domestic felicity" of Mount Vernon, but departed for New York City on April 16 to be inaugurated.
## Presidency (1789–1797).
Washington was inaugurated on April 30, 1789, taking the oath of office at Federal Hall in New York City. His coach was led by militia and a marching band and followed by statesmen and foreign dignitaries in an inaugural parade, with a crowd of 10,000. Chancellor Robert R. Livingston administered the oath, using a Bible provided by the Masons, after which the militia fired a 13-gun salute. Washington read a speech in the Senate Chamber, asking "that Almighty Being who rules over the universe, who presides in the councils of nations—and whose providential aids can supply every human defect, consecrate the liberties and happiness of the people of the United States". Though he wished to serve without a salary, Congress insisted adamantly that he accept it, later providing Washington $25,000 per year to defray costs of the presidency.
Washington wrote to James Madison: "As the first of everything in our situation will serve to establish a precedent, it is devoutly wished on my part that these precedents be fixed on true principles." To that end, he preferred the title "Mr. President" over more majestic names proposed by the Senate, including "His Excellency" and "His Highness the President". His executive precedents included the inaugural address, messages to Congress, and the cabinet form of the executive branch.
Washington had planned to resign after his first term, but the political strife in the nation convinced him he should remain in office. He was an able administrator and a judge of talent and character, and he regularly talked with department heads to get their advice. He tolerated opposing views, despite fears that a democratic system would lead to political violence, and he conducted a smooth transition of power to his successor. He remained non-partisan throughout his presidency and opposed the divisiveness of political parties, but he favored a strong central government, was sympathetic to a Federalist form of government, and leery of the Republican opposition.
Washington dealt with major problems. The old Confederation lacked the powers to handle its workload and had weak leadership, no executive, a small bureaucracy of clerks, a large debt, worthless paper money, and no power to establish taxes. He had the task of assembling an executive department and relied on Tobias Lear for advice selecting its officers. Great Britain refused to relinquish its forts in the American West, and Barbary pirates preyed on American merchant ships in the Mediterranean at a time when the United States did not even have a navy.
### Cabinet and executive departments.
Congress created executive departments in 1789, including the State Department in July, the Department of War in August, and the Treasury Department in September. Washington appointed fellow Virginian Edmund Randolph as Attorney General, Samuel Osgood as Postmaster General, Thomas Jefferson as Secretary of State, and Henry Knox as Secretary of War. Finally, he appointed Alexander Hamilton as Secretary of the Treasury. Washington's cabinet became a consulting and advisory body, not mandated by the Constitution.
Washington's cabinet members formed rival parties with sharply opposing views, most fiercely illustrated between Hamilton and Jefferson. Washington restricted cabinet discussions to topics of his choosing, without participating in the debate. He occasionally requested cabinet opinions in writing and expected department heads to agreeably carry out his decisions.
### Domestic issues.
Washington was apolitical and opposed the formation of parties, suspecting that conflict would undermine republicanism. He exercised great restraint in using his veto power, writing that “I give my Signature to many Bills with which my Judgment is at variance….” 
His closest advisors formed two factions, portending the First Party System. Secretary of the Treasury Alexander Hamilton formed the Federalist Party to promote national credit and a financially powerful nation. Secretary of State Thomas Jefferson opposed Hamilton's agenda and founded the Jeffersonian Republicans. Washington favored Hamilton's agenda, however, and it ultimately went into effect—resulting in bitter controversy.
Washington proclaimed November 26 as a day of Thanksgiving to encourage national unity. "It is the duty of all nations to acknowledge the providence of Almighty God, to obey His will, to be grateful for His benefits, and humbly to implore His protection and favor." He spent that day fasting and visiting debtors in prison to provide them with food and beer.
#### African Americans.
In response to two antislavery petitions that were presented to Congress in 1790, slaveholders in Georgia and South Carolina objected and threatened to "blow the trumpet of civil war". Washington and Congress responded with a series of racist measures: naturalized citizenship was denied to black immigrants; blacks were barred from serving in state militias; the Southwest Territory that would soon become the state of Tennessee was permitted to maintain slavery; and two more slave states were admitted (Kentucky in 1792, and Tennessee in 1796). On February 12, 1793, Washington signed into law the Fugitive Slave Act, which overrode state laws and courts, allowing agents to cross state lines to capture and return escaped slaves. Many free blacks in the north decried the law believing it would allow bounty hunting and the kidnappings of blacks. The Fugitive Slave Act gave effect to the Constitution's Fugitive Slave Clause, and the Act was passed overwhelmingly in Congress (e.g. the vote was 48 to 7 in the House).
On the anti-slavery side of the ledger, in 1789 Washington signed a reenactment of the Northwest Ordinance which freed all slaves brought after 1787 into a vast expanse of federal territory north of the Ohio River, except for slaves escaping from slave states. The Slave Trade Act of 1794, which sharply limited American involvement in the Atlantic slave trade, was signed by Washington. And, Congress acted on February 18, 1791 to admit the free state of Vermont into the Union as the 14th state as of March 4, 1791.
#### National Bank.
Washington's first term was largely devoted to economic concerns, in which Hamilton had devised various plans to address matters. The establishment of public credit became a primary challenge for the federal government. Hamilton submitted a report to a deadlocked Congress, and he, Madison, and Jefferson reached the Compromise of 1790 in which Jefferson agreed to Hamilton's debt proposals in exchange for moving the nation's capital temporarily to Philadelphia and then south near Georgetown on the Potomac River. The terms were legislated in the Funding Act of 1790 and the Residence Act, both of which Washington signed into law. Congress authorized the assumption and payment of the nation's debts, with funding provided by customs duties and excise taxes.
Hamilton created controversy among Cabinet members by advocating establishing the First Bank of the United States. Madison and Jefferson objected, but the bank easily passed Congress. Jefferson and Randolph insisted that the new bank was beyond the authority granted by the constitution, as Hamilton believed. Washington sided with Hamilton and signed the legislation on February 25, and the rift became openly hostile between Hamilton and Jefferson.
The nation's first financial crisis occurred in March 1792. Hamilton's Federalists exploited large loans to gain control of U.S. debt securities, causing a run on the national bank; the markets returned to normal by mid-April. Jefferson believed Hamilton was part of the scheme, despite Hamilton's efforts to ameliorate, and Washington again found himself in the middle of a feud.
#### Jefferson–Hamilton feud.
Jefferson and Hamilton adopted diametrically opposed political principles. Hamilton believed in a strong national government requiring a national bank and foreign loans to function, while Jefferson believed the states and the farm element should primarily direct the government; he also resented the idea of banks and foreign loans. To Washington's dismay, the two men persistently entered into disputes and infighting. Hamilton demanded that Jefferson resign if he could not support Washington, and Jefferson told Washington that Hamilton's fiscal system would lead to the overthrow of the Republic. Washington urged them to call a truce for the nation's sake, but they ignored him.
Washington reversed his decision to retire after his first term to minimize party strife, but the feud continued after his re-election. Jefferson's political actions, his support of Freneau's "National Gazette", and his attempt to undermine Hamilton nearly led Washington to dismiss him from the cabinet; Jefferson ultimately resigned his position in December 1793, and Washington forsook him from that time on.
The feud led to the well-defined Federalist and Republican parties, and party affiliation became necessary for election to Congress by 1794. Washington remained aloof from congressional attacks on Hamilton, but he did not publicly protect him, either. The Hamilton–Reynolds sex scandal opened Hamilton to disgrace, but Washington continued to hold him in "very high esteem" as the dominant force in establishing federal law and government.
#### Whiskey Rebellion.
In March 1791, at Hamilton's urging, with support from Madison, Congress imposed an excise tax on distilled spirits to help curtail the national debt, which took effect in July. Grain farmers strongly protested in Pennsylvania's frontier districts; they argued that they were unrepresented and were shouldering too much of the debt, comparing their situation to excessive British taxation before the Revolutionary War. On August 2, Washington assembled his cabinet to discuss how to deal with the situation. Unlike Washington, who had reservations about using force, Hamilton had long waited for such a situation and was eager to suppress the rebellion by using federal authority and force. Not wanting to involve the federal government if possible, Washington called on Pennsylvania state officials to take the initiative, but they declined to take military action. On August 7, Washington issued his first proclamation for calling up state militias. After appealing for peace, he reminded the protestors that, unlike the rule of the British crown, the Federal law was issued by state-elected representatives.
Threats and violence against tax collectors, however, escalated into defiance against federal authority in 1794 and gave rise to the Whiskey Rebellion. Washington issued a final proclamation on September 25, threatening the use of military force to no avail. The federal army was not up to the task, so Washington invoked the Militia Act of 1792 to summon state militias. Governors sent troops, initially commanded by Washington, who gave the command to Light-Horse Harry Lee to lead them into the rebellious districts. They took 150 prisoners, and the remaining rebels dispersed without further fighting. Two of the prisoners were condemned to death, but Washington exercised his Constitutional authority for the first time and pardoned them.
Washington's forceful action demonstrated that the new government could protect itself and its tax collectors. This represented the first use of federal military force against the states and citizens, and remains the only time an incumbent president has commanded troops in the field. Washington justified his action against "certain self-created societies", which he regarded as "subversive organizations" that threatened the national union. He did not dispute their right to protest, but he insisted that their dissent must not violate federal law. Congress agreed and extended their congratulations to him; only Madison and Jefferson expressed indifference.
### Foreign affairs.
In April 1792, the French Revolutionary Wars began between Great Britain and France, and Washington declared America's neutrality. The revolutionary government of France sent diplomat Citizen Genêt to America, and he was welcomed with great enthusiasm. He created a network of new Democratic-Republican Societies promoting France's interests, but Washington denounced them and demanded that the French recall Genêt. The National Assembly of France granted Washington honorary French citizenship on August 26, 1792, during the early stages of the French Revolution. Hamilton formulated the Jay Treaty to normalize trade relations with Great Britain while removing them from western forts, and also to resolve financial debts remaining from the Revolution. Chief Justice John Jay acted as Washington's negotiator and signed the treaty on November 19, 1794; critical Jeffersonians, however, supported France. Washington deliberated, then supported the treaty because it avoided war with Britain, but was disappointed that its provisions favored Britain. He mobilized public opinion and secured ratification in the Senate but faced frequent public criticism.
The British agreed to abandon their forts around the Great Lakes, and the United States modified the boundary with Canada. The government liquidated numerous pre-Revolutionary debts, and the British opened the British West Indies to American trade. The treaty secured peace with Britain and a decade of prosperous trade. Jefferson claimed that it angered France and "invited rather than avoided" war. Relations with France deteriorated afterward, leaving succeeding president John Adams with prospective war. James Monroe was the American Minister to France, but Washington recalled him for his opposition to the Treaty. The French refused to accept his replacement Charles Cotesworth Pinckney, and the French Directory declared the authority to seize American ships two days before Washington's term ended.
### Native American affairs.
Ron Chernow describes Washington as always trying to be even-handed in dealing with the Natives. He states that Washington hoped they would abandon their itinerant hunting life and adapt to fixed agricultural communities in the manner of white settlers. He also maintains that Washington never advocated outright confiscation of tribal land or the forcible removal of tribes and that he berated American settlers who abused natives, admitting that he held out no hope for pacific relations with the natives as long as "frontier settlers entertain the opinion that there is not the same crime (or indeed no crime at all) in killing a native as in killing a white man."
By contrast, Colin G. Calloway writes that "Washington had a lifelong obsession with getting Indian land, either for himself or for his nation, and initiated policies and campaigns that had devastating effects in Indian country." "The growth of the nation," Galloway has stated, "demanded the dispossession of Indian people. Washington hoped the process could be bloodless and that Indian people would give up their lands for a "fair" price and move away. But if Indians refused and resisted, as they often did, he felt he had no choice but to "extirpate" them and that the expeditions he sent to destroy Indian towns were therefore entirely justified."
During the Fall of 1789, Washington had to contend with the British refusing to evacuate their forts in the Northwest frontier and their concerted efforts to incite hostile Indian tribes to attack American settlers. The Northwest tribes under Miami chief Little Turtle allied with the British Army to resist American expansion, and killed 1,500 settlers between 1783 and 1790.
As documented by Harless (2018), Washington declared that "The Government of the United States are determined that their Administration of Indian Affairs shall be directed entirely by the great principles of Justice and humanity", and provided that treaties should negotiate their land interests. The administration regarded powerful tribes as foreign nations, and Washington even smoked a peace pipe and drank wine with them at the Philadelphia presidential house. He made numerous attempts to conciliate them; he equated killing indigenous peoples with killing whites and sought to integrate them into European-American culture. Secretary of War Henry Knox also attempted to encourage agriculture among the tribes.
In the Southwest, negotiations failed between federal commissioners and raiding Indian tribes seeking retribution. Washington invited Creek Chief Alexander McGillivray and 24 leading chiefs to New York to negotiate a treaty and treated them like foreign dignitaries. Knox and McGillivray concluded the Treaty of New York on August 7, 1790, in Federal Hall, which provided the tribes with agricultural supplies and McGillivray with a rank of Brigadier General Army and a salary of $1,500.
In 1790, Washington sent Brigadier General Josiah Harmar to pacify the Northwest tribes, but Little Turtle routed him twice and forced him to withdraw. The Western Confederacy of tribes used guerrilla tactics and were an effective force against the sparsely manned American Army. Washington sent Major General Arthur St. Clair from Fort Washington on an expedition to restore peace in the territory in 1791. On November 4, St. Clair's forces were ambushed and soundly defeated by tribal forces with few survivors, despite Washington's warning of surprise attacks. Washington was outraged over what he viewed to be excessive Native American brutality and execution of captives, including women and children.
St. Clair resigned his commission, and Washington replaced him with the Revolutionary War hero General Anthony Wayne. From 1792 to 1793, Wayne instructed his troops on Native American warfare tactics and instilled discipline which was lacking under St. Clair. In August 1794, Washington sent Wayne into tribal territory with authority to drive them out by burning their villages and crops in the Maumee Valley. On August 24, the American army under Wayne's leadership defeated the western confederacy at the Battle of Fallen Timbers, and the Treaty of Greenville in August 1795 opened up two-thirds of the Ohio Country for American settlement.
### Second term.
Originally, Washington had planned to retire after his first term, while many Americans could not imagine anyone else taking his place. After nearly four years as president, and dealing with the infighting in his own cabinet and with partisan critics, Washington showed little enthusiasm in running for a second term, while Martha also wanted him not to run. James Madison urged him not to retire, that his absence would only allow the dangerous political rift in his cabinet and the House to worsen. Jefferson also pleaded with him not to retire and agreed to drop his attacks on Hamilton, or he would also retire if Washington did. Hamilton maintained that Washington's absence would be "deplored as the greatest evil" to the country at this time. Washington's close nephew George Augustine Washington, his manager at Mount Vernon, was critically ill and had to be replaced, further increasing Washington's desire to retire and return to Mount Vernon.
When the election of 1792 neared, Washington did not publicly announce his presidential candidacy. Still, he silently consented to run to prevent a further political-personal rift in his cabinet. The Electoral College unanimously elected him president on February 13, 1793, and John Adams as vice president by a vote of 77 to 50. Washington, with nominal fanfare, arrived alone at his inauguration in his carriage. Sworn into office by Associate Justice William Cushing on March 4, 1793, in the Senate Chamber of Congress Hall in Philadelphia, Washington gave a brief address and then immediately retired to his Philadelphia presidential house, weary of office and in poor health.
On April 22, 1793, during the French Revolution, Washington issued his famous Neutrality Proclamation and was resolved to pursue "a conduct friendly and impartial toward the belligerent Powers" while he warned Americans not to intervene in the international conflict. Although Washington recognized France's revolutionary government, he would eventually ask French minister to America Citizen Genêt be recalled over the Citizen Genêt Affair. Genêt was a diplomatic troublemaker who was openly hostile toward Washington's neutrality policy. He procured four American ships as privateers to strike at Spanish forces (British allies) in Florida while organizing militias to strike at other British possessions. However, his efforts failed to draw America into the foreign campaigns during Washington's presidency. On July 31, 1793, Jefferson submitted his resignation from Washington's cabinet. Washington signed the Naval Act of 1794 and commissioned the first six federal frigates to combat Barbary pirates.
In January 1795, Hamilton, who desired more income for his family, resigned office and was replaced by Washington appointment Oliver Wolcott, Jr.. Washington and Hamilton remained friends. However, Washington's relationship with his Secretary of War Henry Knox deteriorated. Knox resigned office on the rumor he profited from construction contracts on U.S. Frigates.
In the final months of his presidency, Washington was assailed by his political foes and a partisan press who accused him of being ambitious and greedy, while he argued that he had taken no salary during the war and had risked his life in battle. He regarded the press as a disuniting, "diabolical" force of falsehoods, sentiments that he expressed in his Farewell Address. At the end of his second term, Washington retired for personal and political reasons, dismayed with personal attacks, and to ensure that a truly contested presidential election could be held. He did not feel bound to a two-term limit, but his retirement set a significant precedent. Washington is often credited with setting the principle of a two-term presidency, but it was Thomas Jefferson who first refused to run for a third term on political grounds.
### Farewell Address.
In 1796, Washington declined to run for a third term of office, believing his death in office would create an image of a lifetime appointment. The precedent of a two-term limit was created by his retirement from office. In May 1792, in anticipation of his retirement, Washington instructed James Madison to prepare a "valedictory address", an initial draft of which was entitled the "Farewell Address". In May 1796, Washington sent the manuscript to his Secretary of Treasury Alexander Hamilton who did an extensive rewrite, while Washington provided final edits. On September 19, 1796, David Claypoole's "American Daily Advertiser" published the final version of the address.
Washington stressed that national identity was paramount, while a united America would safeguard freedom and prosperity. He warned the nation of three eminent dangers: regionalism, partisanship, and foreign entanglements, and said the "name of AMERICAN, which belongs to you, in your national capacity, must always exalt the just pride of patriotism, more than any appellation derived from local discriminations." Washington called for men to move beyond partisanship for the common good, stressing that the United States must concentrate on its own interests. He warned against foreign alliances and their influence in domestic affairs, and bitter partisanship and the dangers of political parties. He counseled friendship and commerce with all nations, but advised against involvement in European wars. He stressed the importance of religion, asserting that "religion and morality are indispensable supports" in a republic. Washington's address favored Hamilton's Federalist ideology and economic policies.
Washington closed the address by reflecting on his legacy:
After initial publication, many Republicans, including Madison, criticized the Address and believed it was an anti-French campaign document. Madison believed Washington was strongly pro-British. Madison also was suspicious of who authored the Address.
In 1839, Washington biographer Jared Sparks maintained that Washington's "...Farewell Address was printed and published with the laws, by order of the legislatures, as an evidence of the value they attached to its political precepts, and of their affection for its author." In 1972, Washington scholar James Flexner referred to the Farewell Address as receiving as much acclaim as Thomas Jefferson's Declaration of Independence and Abraham Lincoln's Gettysburg Address. In 2010, historian Ron Chernow reported the "Farewell Address" proved to be one of the most influential statements on Republicanism.
## Retirement (1797–1799).
Washington retired to Mount Vernon in March 1797 and devoted time to his plantations and other business interests, including his . His plantation operations were only minimally profitable, and his lands in the west (Piedmont) were under Indian attacks and yielded little income, with the squatters there refusing to pay rent. He attempted to sell these but without success. He became an even more committed Federalist. He vocally supported the Alien and Sedition Acts and convinced Federalist John Marshall to run for Congress to weaken the Jeffersonian hold on Virginia.
Washington grew restless in retirement, prompted by tensions with France, and he wrote to Secretary of War James McHenry offering to organize President Adams' army. In a continuation of the French Revolutionary Wars, French privateers began seizing American ships in 1798, and relations deteriorated with France and led to the "Quasi-War". Without consulting Washington, Adams nominated him for a lieutenant general commission on July 4, 1798, and the position of commander-in-chief of the armies. Washington chose to accept, replacing James Wilkinson, and he served as the commanding general from July 13, 1798, until his death 17 months later. He participated in planning for a provisional army, but he avoided involvement in details. In advising McHenry of potential officers for the army, he appeared to make a complete break with Jefferson's Democratic-Republicans: "you could as soon scrub the blackamoor white, as to change the principles of a profest Democrat; and that he will leave nothing unattempted to overturn the government of this country." Washington delegated the active leadership of the army to Hamilton, a major general. No army invaded the United States during this period, and Washington did not assume a field command.
Washington was known to be rich because of the well-known "glorified façade of wealth and grandeur" at Mount Vernon, but nearly all his wealth was in the form of land and slaves rather than ready cash. To supplement his income, he erected a for substantial whiskey production. Historians estimate that the estate was worth about $1million in 1799 dollars, . He bought land parcels to spur development around the new Federal City named in his honor, and he sold individual lots to middle-income investors rather than multiple lots to large investors, believing they would more likely commit to making improvements.
### Final days and death.
On December 12, 1799, Washington inspected his farms on horseback. He returned home late and had guests over for dinner. He had a sore throat the next day but was well enough to mark trees for cutting. That evening, he complained of chest congestion but was still cheerful. On Saturday, he awoke to an inflamed throat and difficulty breathing, so he ordered estate overseer George Rawlins to remove nearly a pint of his blood; bloodletting was a common practice of the time. His family summoned Doctors James Craik, Gustavus Richard Brown, and Elisha C. Dick. (Dr. William Thornton arrived some hours after Washington died.)
Dr. Brown thought Washington had quinsy; Dr. Dick thought the condition was a more serious "violent inflammation of the throat". They continued the process of bloodletting to approximately five pints, and Washington's condition deteriorated further. Dr. Dick proposed a tracheotomy, but the others were not familiar with that procedure and therefore disapproved. Washington instructed Brown and Dick to leave the room, while he assured Craik, "Doctor, I die hard, but I am not afraid to go."
Washington's death came more swiftly than expected. On his deathbed, he instructed his private secretary Tobias Lear to wait three days before his burial, out of fear of being entombed alive. According to Lear, he died peacefully between 10 and 11 p.m. on December 14, 1799, with Martha seated at the foot of his bed. His last words were "'Tis well", from his conversation with Lear about his burial. He was 67.
Congress immediately adjourned for the day upon news of Washington's death, and the Speaker's chair was shrouded in black the next morning. The funeral was held four days after his death on December 18, 1799, at Mount Vernon, where his body was interred. Cavalry and foot soldiers led the procession, and six colonels served as the pallbearers. The Mount Vernon funeral service was restricted mostly to family and friends. Reverend Thomas Davis read the funeral service by the vault with a brief address, followed by a ceremony performed by various members of Washington's Masonic lodge in Alexandria, Virginia. Congress chose Light-Horse Harry Lee to deliver the eulogy. Word of his death traveled slowly; church bells rang in the cities, and many places of business closed. People worldwide admired Washington and were saddened by his death, and memorial processions were held in major cities of the United States. Martha wore a black mourning cape for one year, and she burned their correspondence to protect their privacy. Only five letters between the couple are known to have survived: two from Martha to George and three from him to her.
The diagnosis of Washington's illness and the immediate cause of his death have been subjects of debate since the day he died. The published account of Drs. Craik and Brown stated that his symptoms had been consistent with "cynanche trachealis" (tracheal inflammation), a term of that period used to describe severe inflammation of the upper windpipe, including quinsy. Accusations have persisted since Washington's death concerning medical malpractice, with some believing he had been bled to death. Various modern medical authors have speculated that he died from a severe case of epiglottitis complicated by the given treatments, most notably the massive blood loss which almost certainly caused hypovolemic shock.
## Burial, net worth, and aftermath.
Washington was buried in the old Washington family vault at Mount Vernon, situated on a grassy slope overspread with willow, juniper, cypress, and chestnut trees. It contained the remains of his brother Lawrence and other family members, but the decrepit brick vault needed repair, prompting Washington to leave instructions in his will for the construction of a new vault. Washington's estate at the time of his death was worth an estimated $780,000 in 1799, approximately equivalent to $17.82million in 2021. Washington's peak net worth was $587.0 million, including his 300 slaves. Washington held title to more than 65,000 acres of land in 37 different locations.
In 1830, a disgruntled ex-employee of the estate attempted to steal what he thought was Washington's skull, prompting the construction of a more secure vault. The next year, the new vault was constructed at Mount Vernon to receive the remains of George and Martha and other relatives. In 1832, a joint Congressional committee debated moving his body from Mount Vernon to a crypt in the Capitol. The crypt had been built by architect Charles Bulfinch in the 1820s during the reconstruction of the burned-out capital, after the Burning of Washington by the British during the War of 1812. Southern opposition was intense, antagonized by an ever-growing rift between North and South; many were concerned that Washington's remains could end up on "a shore foreign to his native soil" if the country became divided, and Washington's remains stayed in Mount Vernon.
On October 7, 1837, Washington's remains were placed, still in the original lead coffin, within a marble sarcophagus designed by William Strickland and constructed by John Struthers earlier that year. The sarcophagus was sealed and encased with planks, and an outer vault was constructed around it. The outer vault has the sarcophagi of both George and Martha Washington; the inner vault has the remains of other Washington family members and relatives.
## Personal life.
Washington was somewhat reserved in personality, but he generally had a strong presence among others. He made speeches and announcements when required, but he was not a noted orator or debater. He was taller than most of his contemporaries; accounts of his height vary from to tall, he weighed between as an adult, and he was known for his great strength. He had grey-blue eyes and reddish-brown hair which he wore powdered in the fashion of the day. He had a rugged and dominating presence, which garnered respect from his peers.
He bought William Lee on May 27, 1768, and he was Washington's valet for 20 years. He was the only slave freed immediately in Washington's will.
Washington frequently suffered from severe tooth decay and ultimately lost all his teeth but one. He had several sets of false teeth, which he wore during his presidency, made using a variety of materials including both animal and human teeth, but wood was not used despite common lore. These dental problems left him in constant pain, for which he took laudanum. As a public figure, he relied upon the strict confidence of his dentist.
Washington was a talented equestrian early in life. He collected thoroughbreds at Mount Vernon, and his two favorite horses were Blueskin and Nelson. Fellow Virginian Thomas Jefferson said Washington was "the best horseman of his age and the most graceful figure that could be seen on horseback"; he also hunted foxes, deer, ducks, and other game. He was an excellent dancer and attended the theater frequently. He drank in moderation but was morally opposed to excessive drinking, smoking tobacco, gambling, and profanity.
### Religion and Freemasonry.
Washington was descended from Anglican minister Lawrence Washington (his great-great-grandfather), whose troubles with the Church of England may have prompted his heirs to emigrate to America. Washington was baptized as an infant in April 1732 and became a devoted member of the Church of England (the Anglican Church). He served more than 20 years as a vestryman and churchwarden for Fairfax Parish and Truro Parish, Virginia. He privately prayed and read the Bible daily, and he publicly encouraged people and the nation to pray. He may have taken communion on a regular basis prior to the Revolutionary War, but he did not do so following the war, for which he was admonished by Pastor James Abercrombie.
Washington believed in a "wise, inscrutable, and irresistible" Creator God who was active in the Universe, contrary to deistic thought. He referred to God by the Enlightenment terms "Providence", the "Creator", or the "Almighty", and also as the "Divine Author" or the "Supreme Being". He believed in a divine power who watched over battlefields, was involved in the outcome of war, was protecting his life, and was involved in American politics—and specifically in the creation of the United States. Modern historian Ron Chernow has posited that Washington avoided evangelistic Christianity or hellfire-and-brimstone speech along with communion and anything inclined to "flaunt his religiosity". Chernow has also said Washington "never used his religion as a device for partisan purposes or in official undertakings". No mention of Jesus Christ appears in his private correspondence, and such references are rare in his public writings. He frequently quoted from the Bible or paraphrased it, and often referred to the Anglican "Book of Common Prayer". There is debate on whether he is best classed as a Christian or a theistic rationalist—or both.
Washington emphasized religious toleration in a nation with numerous denominations and religions. He publicly attended services of different Christian denominations and prohibited anti-Catholic celebrations in the Army. He engaged workers at Mount Vernon without regard for religious belief or affiliation. While president, he acknowledged major religious sects and gave speeches on religious toleration. He was distinctly rooted in the ideas, values, and modes of thinking of the Enlightenment, but he harbored no contempt of organized Christianity and its clergy, "being no bigot myself to any mode of worship". In 1793, speaking to members of the New Church in Baltimore, Washington proclaimed, "We have abundant reason to rejoice that in this Land the light of truth and reason has triumphed over the power of bigotry and superstition."
Freemasonry was a widely accepted institution in the late 18th century, known for advocating moral teachings. Washington was attracted to the Masons' dedication to the Enlightenment principles of rationality, reason, and brotherhood. The American Masonic lodges did not share the anti-clerical perspective of the controversial European lodges. A Masonic lodge was established in Fredericksburg in September 1752, and Washington was initiated two months later at the age of 20 as one of its first Entered Apprentices. Within a year, he progressed through its ranks to become a Master Mason. Washington had high regard for the Masonic Order, but his personal lodge attendance was sporadic. In 1777, a convention of Virginia lodges asked him to be the Grand Master of the newly established Grand Lodge of Virginia, but he declined due to his commitments leading the Continental Army. After 1782, he frequently corresponded with Masonic lodges and members, and he was listed as Master in the Virginia charter of Alexandria Lodge No. 22 in 1788.
## Slavery.
In Washington's lifetime, slavery was deeply ingrained in the economic and social fabric of Virginia. Slavery was legal in all of the Thirteen Colonies prior to the American Revolution.
Washington owned enslaved African Americans, and during his lifetime over 577 slaves lived and worked at Mount Vernon. He acquired them through inheritance, gaining control of 84 dower slaves upon his marriage to Martha, and purchased at least 71 slaves between 1752 and 1773. His early views on slavery were no different from any Virginia planter of the time. From the 1760s his attitudes underwent a slow evolution. The first doubts were prompted by his transition from tobacco to grain crops, which left him with a costly surplus of slaves, causing him to question the system's economic efficiency. His growing disillusionment with the institution was spurred by the principles of the American Revolution and revolutionary friends such as Lafayette and Hamilton. Most historians agree the Revolution was central to the evolution of Washington's attitudes on slavery; "After 1783", Kenneth Morgan writes, "...[Washington] began to express inner tensions about the problem of slavery more frequently, though always in private..."
The many contemporary reports of slave treatment at Mount Vernon are varied and conflicting. Historian Kenneth Morgan (2000) maintains that Washington was frugal on spending for clothes and bedding for his slaves, and only provided them with just enough food, and that he maintained strict control over his slaves, instructing his overseers to keep them working hard from dawn to dusk year-round. However, historian Dorothy Twohig (2001) said: "Food, clothing, and housing seem to have been at least adequate". Washington faced growing debts involved with the costs of supporting slaves. He held an "engrained sense of racial superiority" towards African Americans but harbored no ill feelings toward them. Some enslaved families worked at different locations on the plantation but were allowed to visit one another on their days off. Washington's slaves received two hours off for meals during the workday and were given time off on Sundays and religious holidays.
Some accounts report that Washington opposed flogging but at times sanctioned its use, generally as a last resort, on both men and women slaves. Washington used both reward and punishment to encourage discipline and productivity in his slaves. He tried appealing to an individual's sense of pride, gave better blankets and clothing to the "most deserving", and motivated his slaves with cash rewards. He believed "watchfulness and admonition" to be often better deterrents against transgressions but would punish those who "will not do their duty by fair means". Punishment ranged in severity from demotion back to fieldwork, through whipping and beatings, to permanent separation from friends and family by sale. Historian Ron Chernow maintains that overseers were required to warn slaves before resorting to the lash and required Washington's written permission before whipping, though his extended absences did not always permit this. Washington remained dependent on slave labor to work his farms and negotiated the purchase of more slaves in 1786 and 1787.
Washington brought several of his slaves with him and his family to the federal capital during his presidency. When the capital moved from New York City to Philadelphia in 1791, the president began rotating his slave household staff periodically between the capital and Mount Vernon. This was done deliberately to circumvent Pennsylvania's Slavery Abolition Act, which, in part, automatically freed any slave who moved to the state and lived there for more than six months. In May 1796, Martha's personal and favorite slave Oney Judge escaped to Portsmouth. At Martha's behest, Washington attempted to capture Ona, using a Treasury agent, but this effort failed. In February 1797, Washington's personal slave Hercules escaped to Philadelphia and was never found.
In February 1786, Washington took a census of Mount Vernon and recorded 224 slaves. By 1799, slaves at Mount Vernon totaled 317, including 143 children. Washington owned 124 slaves, leased 40, and held 153 for his wife's dower interest. Washington supported many slaves who were too young or too old to work, greatly increasing Mount Vernon's slave population and causing the plantation to operate at a loss.
### Abolition and manumission.
Based on his letters, diary, documents, accounts from colleagues, employees, friends, and visitors, Washington slowly developed a cautious sympathy toward abolitionism that eventually ended with the manumission, by his will, of his own slaves after his death. As president, he remained publicly silent on the topic of slavery, believing it was a nationally divisive issue which could destroy the union.
During the American Revolutionary War, Washington began to change his views on slavery. In a 1778 letter to Lund Washington, he made clear his desire "to get quit of Negroes" when discussing the exchange of slaves for the land he wanted to buy. The next year, Washington stated his intention not to separate enslaved families as a result of "a change of masters". During the 1780s, Washington privately expressed his support for the gradual emancipation of slaves. Between 1783 and 1786, he gave moral support to a plan proposed by Lafayette to purchase land and free slaves to work on it, but declined to participate in the experiment. Washington privately expressed support for emancipation to prominent Methodists Thomas Coke and Francis Asbury in 1785 but declined to sign their petition. In personal correspondence the next year, he made clear his desire to see the institution of slavery ended by a gradual legislative process, a view that correlated with the mainstream antislavery literature published in the 1780s that Washington possessed. He significantly reduced his purchases of slaves after the war but continued to acquire them in small numbers.
In 1788, Washington declined a suggestion from a leading French abolitionist, Jacques Brissot, to establish an abolitionist society in Virginia, stating that although he supported the idea, the time was not yet right to confront the issue. The historian Henry Wiencek (2003) believes, based on a remark that appears in the notebook of his biographer David Humphreys, that Washington considered making a public statement by freeing his slaves on the eve of his presidency in 1789. The historian Philip D. Morgan (2005) disagrees, believing the remark was a "private expression of remorse" at his inability to free his slaves. Other historians agree with Morgan that Washington was determined not to risk national unity over an issue as divisive as slavery. Washington never responded to any of the antislavery petitions he received, and the subject was not mentioned in either his last address to Congress or his Farewell Address.
The first clear indication that Washington seriously intended to free his slaves appears in a letter written to his secretary, Tobias Lear, in 1794. Washington instructed Lear to find buyers for his land in western Virginia, explaining in a private coda that he was doing so "to liberate a certain species of property which I possess, very repugnantly to my own feelings". The plan, along with others Washington considered in 1795 and 1796, could not be realized because he failed to find buyers for his land, his reluctance to break up slave families, and the refusal of the Custis heirs to help prevent such separations by freeing their dower slaves at the same time.
On July 9, 1799, Washington finished making his last will; the longest provision concerned slavery. All his slaves were to be freed after the death of his wife, Martha. Washington said he did not free them immediately because his slaves intermarried with his wife's dower slaves. He forbade their sale or transportation out of Virginia. His will provided that old and young freed people be taken care of indefinitely; younger ones were to be taught to read and write and placed in suitable occupations. Washington freed more than 160 slaves, including 25 he had acquired from his wife's brother in payment of a debt freed by graduation. He was among the few large slave-holding Virginians during the Revolutionary Era who emancipated their slaves.
On January 1, 1801, one year after George Washington's death, Martha Washington signed an order to free his slaves. Many of them, having never strayed far from Mount Vernon, were naturally reluctant to try their luck elsewhere; others refused to abandon spouses or children still held as dower slaves (the Custis estate) and also stayed with or near Martha. Following George Washington's instructions in his will, funds were used to feed and clothe the young, aged, and infirm slaves until the early 1830s.
## Historical reputation and legacy.
Washington's legacy endures as one of the most influential in American history since he served as commander-in-chief of the Continental Army, a hero of the Revolution, and the first president of the United States. Various historians maintain that he also was a dominant factor in America's founding, the Revolutionary War, and the Constitutional Convention. Revolutionary War comrade Light-Horse Harry Lee as "First in war—first in peace—and first in the hearts of his countrymen". Lee's words became the hallmark by which Washington's reputation was impressed upon the American memory, with some biographers regarding him as the great exemplar of republicanism. He set many precedents for the national government and the presidency in particular, and he was called the "Father of His Country" as early as 1778.
In 1879, Congress proclaimed Washington's Birthday to be a federal holiday. Twentieth-century biographer Douglas Southall Freeman concluded, "The great big thing stamped across that man is character." Modern historian David Hackett Fischer has expanded upon Freeman's assessment, defining Washington's character as "integrity, self-discipline, courage, absolute honesty, resolve, and decision, but also forbearance, decency, and respect for others".
Washington became an international symbol for liberation and nationalism as the leader of the first successful revolution against a colonial empire. The Federalists made him the symbol of their party, but the Jeffersonians continued to distrust his influence for many years and delayed building the Washington Monument. Washington was elected a member of the American Academy of Arts and Sciences on January 31, 1781, before he had even begun his presidency. He was posthumously appointed to the grade of General of the Armies of the United States during the United States Bicentennial to ensure he would never be outranked; this was accomplished by the congressional joint resolution passed on January 19, 1976, with an effective appointment date of July 4, 1976. On March 13, 1978, Washington was militarily promoted to the rank of General of the Armies.
Parson Weems wrote a hagiographic biography in 1809 to honor Washington. Historian Ron Chernow maintains that Weems attempted to humanize Washington, making him look less stern, and to inspire "patriotism and morality" and to foster "enduring myths", such as Washington's refusal to lie about damaging his father's cherry tree. Weems' accounts have never been proven or disproven. Historian John Ferling, however, maintains that Washington remains the only founder and president ever to be referred to as "godlike", and points out that his character has been the most scrutinized by historians, past and present. Historian Gordon S. Wood concludes that "the greatest act of his life, the one that gave him his greatest fame, was his resignation as commander-in-chief of the American forces." Chernow suggests that Washington was "burdened by public life" and divided by "unacknowledged ambition mingled with self-doubt". A 1993 review of presidential polls and surveys consistently ranked Washington number 4, 3, or2 among presidents. A 2018 Siena College Research Institute survey ranked him number1 among presidents.
In the 21st century, Washington's reputation has been critically scrutinized. Along with various other Founding Fathers, he has been condemned for holding enslaved human beings. Though he expressed the desire to see the abolition of slavery come through legislation, he did not initiate or support any initiatives for bringing about its end. This has led to calls from some activists to remove his name from public buildings and his statue from public spaces. Nonetheless, Washington maintains his place among the highest-ranked U.S. Presidents, listed second (after Lincoln) in a 2021 C-SPAN poll.
### Memorials.
Jared Sparks began collecting and publishing Washington's documentary record in the 1830s in "Life and Writings of George Washington" (12 vols., 1834–1837). "The Writings of George Washington from the Original Manuscript Sources, 1745–1799" (1931–1944) is a 39-volume set edited by John Clement Fitzpatrick, whom the George Washington Bicentennial Commission commissioned. It contains more than 17,000 letters and documents and is available online from the University of Virginia.
#### Educational institutions.
Numerous secondary schools are named in honor of Washington, as are many universities, including George Washington University and Washington University in St. Louis.
#### Places and monuments.
Many places and monuments have been named in honor of Washington, most notably the capital of the United States, Washington, D.C. The state of Washington is the only US state to be named after a president.
#### Currency and postage.
George Washington appears on contemporary U.S. currency, including the one-dollar bill, the Presidential one-dollar coin and the quarter-dollar coin (the Washington quarter). Washington and Benjamin Franklin appeared on the in 1847. Washington has since appeared on many postage issues, more than any other person.

</doc>
<doc id="11969" url="https://en.wikipedia.org/wiki?curid=11969" title="Gulf Coast of the United States">
Gulf Coast of the United States

The Gulf Coast of the United States is the coastline along the Southern United States where they meet the Gulf of Mexico. The coastal states that have a shoreline on the Gulf of Mexico are Texas, Louisiana, Mississippi, Alabama, and Florida, and these are known as the "Gulf States".
The economy of the Gulf Coast area is dominated by industries related to energy, petrochemicals, fishing, aerospace, agriculture, and tourism. The large cities of the region are (from west to east) Brownsville, Corpus Christi, Houston, Galveston, Beaumont, Lake Charles, Lafayette, Baton Rouge, New Orleans, Gulfport, Biloxi, Mobile, Pensacola, Navarre, St. Petersburg, and Tampa. All are the centers or major cities of their respective metropolitan areas and many of which contain large ports.
## Geography.
The Gulf Coast is made of many inlets, bays, and lagoons. The coast is intersected by numerous rivers, the largest of which is the Mississippi River. Much of the land along the Gulf Coast is, or was, marshland. Ringing the Gulf Coast is the Gulf Coastal Plain, which reaches from Southern Texas to the western Florida Panhandle, while the western portions of the Gulf Coast are made up of many barrier islands and peninsulas, including the Padre Island along the Texas coast. These landforms protect numerous bays and inlets providing as a barrier to oncoming waves. The central part of the Gulf Coast, from eastern Texas through Louisiana, consists primarily of marshland. The eastern part of the Gulf Coast, predominantly Florida, is dotted with many bays and inlets.
### Climate.
The Gulf Coast climate is humid subtropical, although the southwestern tip of Florida, such as Everglades City, features a tropical climate. Much of the year is warm to hot along the Gulf Coast, while the three winter months bring periods of cool (or rarely, cold) weather mixed with mild temperatures. The area is highly vulnerable to hurricanes as well as floods and severe thunderstorms. Much of the Gulf Coast has a summer precipitation maximum, with July or August commonly the wettest month due to the combination of frequent summer thunderstorms produced by relentless heat and humidity, and tropical weather systems (tropical depressions, tropical storms and hurricanes), while winter and early spring rainfall also can be heavy. This pattern is evident at Houston, Texas, New Orleans, Louisiana, Mobile, Alabama and Pensacola, Florida. However, the central and southern Florida peninsula and South Texas has a pronounced winter dry season, as at Tampa and Fort Myers, Florida. On the central and southern Texas coast, winter, early spring and mid-summer are markedly drier, and September is the wettest month on average (as at Corpus Christi and Brownsville, Texas). Tornadoes are infrequent at the coast but do occur; however, they occur more frequently in inland portions of Gulf Coast states. Over most of the Gulf Coast from Houston, Texas eastward, extreme rainfall events are a significant threat, commonly from tropical weather systems, which can bring 4 to 10 or more inches of rain in a single day. In August 2017, Hurricane Harvey made landfall along the central Texas coast, then migrated to and stalled over the greater Houston area for several days, producing extreme, unprecedented rainfall totals of over 40 inches (1,000 mm) in many areas, unleashing widespread flooding. Earthquakes are extremely rare to the area, but a surprising 6.0 earthquake in the Gulf of Mexico on September 10, 2006, could be felt from the cities of New Orleans to Tampa.
## Economic activities.
The Gulf Coast is a major center of economic activity. The marshlands along the Louisiana and Texas coasts provide breeding grounds and nurseries for ocean life that drive the fishing and shrimping industries. The Port of South Louisiana (Metropolitan New Orleans in Laplace) and the Port of Houston are two of the ten busiest ports in the world by cargo volume. As of 2004, seven of the top ten busiest ports in the U.S. are on the Gulf Coast.
The discovery of oil and gas deposits along the coast and offshore, combined with easy access to shipping, have made the Gulf Coast the heart of the U.S. petrochemical industry. The coast contains nearly 4,000 oil platforms.
Besides the above, the region features other important industries including aerospace and biomedical research, as well as older industries such as agriculture and — especially since the development of the Gulf Coast beginning in the 1920s and the increase in wealth throughout the United States — tourism.
## History.
Before European settlers arrived in the region, the Gulf Coast was home to several pre-Columbian kingdoms which had extensive trade networks with empires such as the Aztecs and the Mississippi Mound Builders. Shark and alligator teeth and shells from the Gulf have been found as far north as Ohio, in the mounds of the Hopewell culture.
The first Europeans to settle the Gulf Coast were primarily the French and the Spanish. The Louisiana Purchase, Adams–Onís Treaty and the Texas Revolution made the Gulf Coast a part of the United States during the first half of the 19th century. As the U.S. population continued to expand its frontiers westward, the Gulf Coast was a natural magnet in the South providing access to shipping lanes and both national and international commerce. The development of sugar and cotton production (enabled by slavery) allowed the South to prosper. By the mid 19th century the city of New Orleans, being situated as a key to commerce on the Mississippi River and in the Gulf, had become the largest U.S. city not on the Atlantic seaboard and the fourth largest in the U.S. overall.
Two major events were turning points in the earlier history of the Gulf Coast region. The first was the American Civil War, which caused severe damage to some economic sectors in the South, including the Gulf Coast. The second event was the Galveston Hurricane of 1900. At the end of the 19th century Galveston was, with New Orleans, one of the most developed cities in the region. The city had the third busiest port in the U.S. and its financial district was known as the "Wall Street of the South". The storm mostly destroyed the city, which has never regained its former glory, and set back development in the region.
Since then the Gulf Coast has been hit with numerous other hurricanes. On August 29, 2005, Hurricane Katrina struck the Gulf Coast as a Category 4 hurricane. It was the most damaging storm in the history of the United States, causing upwards of $80 billion in damages, and leaving over 1,800 dead. Again in 2008 the Gulf Coast was struck by a catastrophic hurricane. Due to its immense size, Hurricane Ike caused devastation from the Louisiana coastline all the way to the Kenedy County, Texas region near Corpus Christi. In addition, Ike caused flooding and significant damage along the Mississippi coastline and the Florida Panhandle Ike killed 112 people and left upwards of 300 people missing, never to be found. Hurricane Ike was the third most damaging storm in the history of the United States, causing more than $25 billion in damage along the coast, leaving hundreds of thousands of people homeless, and sparking the largest search-and-rescue operation in U.S. history.
Other than the hurricanes, the Gulf Coast has redeveloped dramatically over the course of the 20th century. The gulf coast is highly populated. The petrochemical industry, launched with the major discoveries of oil in Texas and spurred on by further discoveries in the Gulf waters, has been a vehicle for development in the central and western Gulf which has spawned development on a variety of fronts in these regions. Texas in particular has benefited tremendously from this industry over the course of the 20th century and economic diversification has made the state a magnet for population and home to more Fortune 500 companies than any other U.S. state. Florida has grown as well, driven to a great extent by its long established tourism industry but also by its position as a gateway to the Caribbean and Latin America. As of 2006, these two states are the second and fourth most populous states in the nation, respectively (see this article). Other areas of the Gulf Coast have benefited less, though economic development fueled by tourism has greatly increased property values along the coast, and is now a severe danger to the valuable but fragile ecosystems of the Gulf Coast.
## Metropolitan areas.
The following table lists the 10 largest core-based statistical areas along the Gulf Coast.
## Transportation.
### Air.
#### International service.
International Destinations

</doc>
<doc id="11971" url="https://en.wikipedia.org/wiki?curid=11971" title="Galaxy formation and evolution">
Galaxy formation and evolution

The study of galaxy formation and evolution is concerned with the processes that formed a heterogeneous universe from a homogeneous beginning, the formation of the first galaxies, the way galaxies change over time, and the processes that have generated the variety of structures observed in nearby galaxies. Galaxy formation is hypothesized to occur from structure formation theories, as a result of tiny quantum fluctuations in the aftermath of the Big Bang. The simplest model in general agreement with observed phenomena is the Lambda-CDM model—that is, that clustering and merging allows galaxies to accumulate mass, determining both their shape and structure.
## Commonly observed properties of galaxies.
Because of the inability to conduct experiments in outer space, the only way to “test” theories and models of galaxy evolution is to compare them with observations. Explanations for how galaxies formed and evolved must be able to predict the observed properties and types of galaxies.
Edwin Hubble created the first galaxy classification scheme known as the Hubble tuning-fork diagram. It partitioned galaxies into ellipticals, normal spirals, barred spirals (such as the Milky Way), and irregulars. These galaxy types exhibit the following properties which can be explained by current galaxy evolution theories:
There is a common misconception that Hubble believed incorrectly that the tuning fork diagram described an evolutionary sequence for galaxies, from elliptical galaxies through lenticulars to spiral galaxies. This is not the case; instead, the tuning fork diagram shows an evolution from simple to complex with no temporal connotations intended. Astronomers now believe that disk galaxies likely formed first, then evolved into elliptical galaxies through galaxy mergers.
Current models also predict that the majority of mass in galaxies is made up of dark matter, a substance which is not directly observable, and might not interact through any means except gravity. This observation arises because galaxies could not have formed as they have, or rotate as they are seen to, unless they contain far more mass than can be directly observed.
## Formation of disk galaxies.
The earliest stage in the evolution of galaxies is the formation. When a galaxy forms, it has a disk shape and is called a spiral galaxy due to spiral-like "arm" structures located on the disk. There are different theories on how these disk-like distributions of stars develop from a cloud of matter: however, at present, none of them exactly predicts the results of observation.
### Top-down theories.
Olin Eggen, Donald Lynden-Bell, and Allan Sandage in 1962, proposed a theory that disk galaxies form through a monolithic collapse of a large gas cloud. The distribution of matter in the early universe was in clumps that consisted mostly of dark matter. These clumps interacted gravitationally, putting tidal torques on each other that acted to give them some angular momentum. As the baryonic matter cooled, it dissipated some energy and contracted toward the center. With angular momentum conserved, the matter near the center speeds up its rotation. Then, like a spinning ball of pizza dough, the matter forms into a tight disk. Once the disk cools, the gas is not gravitationally stable, so it cannot remain a singular homogeneous cloud. It breaks, and these smaller clouds of gas form stars. Since the dark matter does not dissipate as it only interacts gravitationally, it remains distributed outside the disk in what is known as the dark halo. Observations show that there are stars located outside the disk, which does not quite fit the "pizza dough" model. It was first proposed by Leonard Searle and Robert Zinn that galaxies form by the coalescence of smaller progenitors. Known as a top-down formation scenario, this theory is quite simple yet no longer widely accepted.
### Bottom-up theories.
More recent theories include the clustering of dark matter halos in the bottom-up process. Instead of large gas clouds collapsing to form a galaxy in which the gas breaks up into smaller clouds, it is proposed that matter started out in these “smaller” clumps (mass on the order of globular clusters), and then many of these clumps merged to form galaxies, which then were drawn by gravitation to form galaxy clusters. This still results in disk-like distributions of baryonic matter with dark matter forming the halo for all the same reasons as in the top-down theory. Models using this sort of process predict more small galaxies than large ones, which matches observations.
Astronomers do not currently know what process stops the contraction. In fact, theories of disk galaxy formation are not successful at producing the rotation speed and size of disk galaxies. It has been suggested that the radiation from bright newly formed stars, or from an active galactic nucleus can slow the contraction of a forming disk. It has also been suggested that the dark matter halo can pull the galaxy, thus stopping disk contraction.
The Lambda-CDM model is a cosmological model that explains the formation of the universe after the Big Bang. It is a relatively simple model that predicts many properties observed in the universe, including the relative frequency of different galaxy types; however, it underestimates the number of thin disk galaxies in the universe. The reason is that these galaxy formation models predict a large number of mergers. If disk galaxies merge with another galaxy of comparable mass (at least 15 percent of its mass) the merger will likely destroy, or at a minimum greatly disrupt the disk, and the resulting galaxy is not expected to be a disk galaxy (see next section). While this remains an unsolved problem for astronomers, it does not necessarily mean that the Lambda-CDM model is completely wrong, but rather that it requires further refinement to accurately reproduce the population of galaxies in the universe.
## Galaxy mergers and the formation of elliptical galaxies.
Elliptical galaxies (such as IC 1101) are among some of the largest known thus far. Their stars are on orbits that are randomly oriented within the galaxy (i.e. they are not rotating like disk galaxies). A distinguishing feature of elliptical galaxies is that the velocity of the stars does not necessarily contribute to flattening of the galaxy, such as in spiral galaxies. Elliptical galaxies have central supermassive black holes, and the masses of these black holes correlate with the galaxy's mass.
Elliptical galaxies have two main stages of evolution. The first is due to the supermassive black hole growing by accreting cooling gas. The second stage is marked by the black hole stabilizing by suppressing gas cooling, thus leaving the elliptical galaxy in a stable state. The mass of the black hole is also correlated to a property called sigma which is the dispersion of the velocities of stars in their orbits. This relationship, known as the M-sigma relation, was discovered in 2000. Elliptical galaxies mostly lack disks, although some bulges of disk galaxies resemble elliptical galaxies. Elliptical galaxies are more likely found in crowded regions of the universe (such as galaxy clusters).
Astronomers now see elliptical galaxies as some of the most evolved systems in the universe. It is widely accepted that the main driving force for the evolution of elliptical galaxies is mergers of smaller galaxies. Many galaxies in the universe are gravitationally bound to other galaxies, which means that they will never escape their mutual pull. If the galaxies are of similar size, the resultant galaxy will appear similar to neither of the progenitors, but will instead be elliptical. There are many types of galaxy mergers, which do not necessarily result in elliptical galaxies, but result in a structural change. For example, a minor merger event is thought to be occurring between the Milky Way and the Magellanic Clouds.
Mergers between such large galaxies are regarded as violent, and the frictional interaction of the gas between the two galaxies can cause gravitational shock waves, which are capable of forming new stars in the new elliptical galaxy. By sequencing several images of different galactic collisions, one can observe the timeline of two spiral galaxies merging into a single elliptical galaxy.
In the Local Group, the Milky Way and the Andromeda Galaxy are gravitationally bound, and currently approaching each other at high speed. Simulations show that the Milky Way and Andromeda are on a collision course, and are expected to collide in less than five billion years. During this collision, it is expected that the Sun and the rest of the Solar System will be ejected from its current path around the Milky Way. The remnant could be a giant elliptical galaxy.
## Galaxy quenching.
One observation (see above) that must be explained by a successful theory of galaxy evolution is the existence of two different populations of galaxies on the galaxy color-magnitude diagram. Most galaxies tend to fall into two separate locations on this diagram: a "red sequence" and a "blue cloud". Red sequence galaxies are generally non-star-forming elliptical galaxies with little gas and dust, while blue cloud galaxies tend to be dusty star-forming spiral galaxies.
As described in previous sections, galaxies tend to evolve from spiral to elliptical structure via mergers. However, the current rate of galaxy mergers does not explain how all galaxies move from the "blue cloud" to the "red sequence". It also does not explain how star formation ceases in galaxies. Theories of galaxy evolution must therefore be able to explain how star formation turns off in galaxies. This phenomenon is called galaxy "quenching".
Stars form out of cold gas (see also the Kennicutt–Schmidt law), so a galaxy is quenched when it has no more cold gas. However, it is thought that quenching occurs relatively quickly (within 1 billion years), which is much shorter than the time it would take for a galaxy to simply use up its reservoir of cold gas. Galaxy evolution models explain this by hypothesizing other physical mechanisms that remove or shut off the supply of cold gas in a galaxy. These mechanisms can be broadly classified into two categories: (1) preventive feedback mechanisms that stop cold gas from entering a galaxy or stop it from producing stars, and (2) ejective feedback mechanisms that remove gas so that it cannot form stars.
One theorized preventive mechanism called “strangulation” keeps cold gas from entering the galaxy. Strangulation is likely the main mechanism for quenching star formation in nearby low-mass galaxies. The exact physical explanation for strangulation is still unknown, but it may have to do with a galaxy's interactions with other galaxies. As a galaxy falls into a galaxy cluster, gravitational interactions with other galaxies can strangle it by preventing it from accreting more gas. For galaxies with massive dark matter halos, another preventive mechanism called “virial shock heating” may also prevent gas from becoming cool enough to form stars.
Ejective processes, which expel cold gas from galaxies, may explain how more massive galaxies are quenched. One ejective mechanism is caused by supermassive black holes found in the centers of galaxies. Simulations have shown that gas accreting onto supermassive black holes in galactic centers produces high-energy jets; the released energy can expel enough cold gas to quench star formation.
Our own Milky Way and the nearby Andromeda Galaxy currently appear to be undergoing the quenching transition from star-forming blue galaxies to passive red galaxies.

</doc>
<doc id="11973" url="https://en.wikipedia.org/wiki?curid=11973" title="Generation X">
Generation X

Generation X (or Gen X for short) is the demographic cohort following the baby boomers and preceding the millennials. Researchers and popular media use the mid-to-late 1960s as starting birth years and the late 1970s to early 1980s as ending birth years, with the generation being generally defined as people born from 1965 to 1980. By this definition and U.S. Census data, there are 65.2 million Gen Xers in the United States as of 2019. Most members of Generation X are the children of the Silent Generation and early boomers; Xers are also often the parents of millennials and Generation Z.
As children in the 1970s and 1980s, a time of shifting societal values, Gen Xers were sometimes called the "latchkey generation", an image spawning from children returning to an empty home and needing to use the door key, due to reduced adult supervision compared to previous generations. This was a result of increasing divorce rates and increased maternal participation in the workforce, prior to widespread availability of childcare options outside the home.
As adolescents and young adults in the 1980s and 1990s, Xers were dubbed the "MTV Generation" (a reference to the music video channel), sometimes being characterized as slackers, cynical, and disaffected. Some of the many cultural influences on Gen X youth included a proliferation of musical genres with strong social-tribal identity such as punk, post-punk, and heavy metal, in addition to later forms developed by gen Xer's themselves (e.g. grunge, grindcore and related genres). Film, both the birth of franchise mega-sequels and a proliferation of Independent film enabled in part by video was also a notable cultural influence. Video games both in amusement parlours and in devices in western homes were also a major part of juvenile entertainment for the first time. Politically, in many Eastern Bloc countries generation X experienced the last days of communism and transition to capitalism as part of its youth. Whilst, in much of the western world, a similar time period was defined by a dominance of conservatism and free market economics.
In midlife during the early 21st century, research describes them as active, happy, and achieving a work–life balance. The cohort has also been credited as entrepreneurial and productive in the workplace more broadly.
## Terminology and etymology.
The term "Generation X" has been used at various times to describe alienated youth. In the early 1950s, Hungarian photographer Robert Capa first used "Generation X" as the title for a photo-essay about young men and women growing up immediately following World War II. The term first appeared in print in a December 1952 issue of "Holiday" magazine announcing their upcoming publication of Capa's photo-essay. From 1976 to 1981, English musician Billy Idol used the moniker as the name for his punk rock band. Idol had attributed the name of his band to the book "Generation X", a 1964 book on British popular youth culture written by journalists Jane Deverson and Charles Hamblett — a copy of which had been owned by Idol's mother. These uses of the term appear to have no connection to Robert Capa's photo-essay.
The term acquired its contemporary application after the release of "", a 1991 novel written by Canadian author Douglas Coupland. In 1987, Coupland had written a piece in "Vancouver Magazine" titled "Generation X" which was "the seed of what went on to become the book". Coupland referenced Billy Idol's band Generation X in the 1987 article and again in 1989 in "Vista" magazine. In the book proposal for his novel, Coupland writes that "Generation X" is "taken from the name of Billy Idol’s long-defunct punk band of the late 1970s". However, in 1995 Coupland denied the term's connection to the band, stating that:
"The book's title came not from Billy Idol's band, as many supposed, but from the final chapter of a funny sociological book on American class structure titled "", by Paul Fussell. In his final chapter, Fussell named an 'X' category of people who wanted to hop off the merry-go-round of status, money, and social climbing that so often frames modern existence."
Author William Strauss noted that around the time Coupland's 1991 novel was published the symbol "X" was prominent in popular culture, as the film "Malcolm X" was released in 1992, and that the name "Generation X" ended up sticking. The "X" refers to an unknown variable or to a desire not to be defined. Strauss's coauthor Neil Howe noted the delay in naming this demographic cohort saying, "Over 30 years after their birthday, they didn't have a name. I think that's germane." Previously, the cohort had been referred to as Post-Boomers, Baby Busters (referencing the drop in the birth rates following the baby boom), New Lost Generation, latchkey kids, MTV Generation, and the 13th Generation (the 13th generation since American independence).
## Date and age range definitions.
Generation X is the demographic cohort following the post–World War II baby-boom, representing a generational change from the baby boomers. Many researchers and demographers use dates which correspond to the fertility-patterns in the population. For Generation X, in the U.S. (and broadly, in the Western world), the period begins at a time when fertility rates started to significantly decrease, following the baby boom peak of the late 1950s, until an upswing in the late 1970s and eventual recovery at the start of the 1980s.
In the U.S., the Pew Research Center, a non-partisan think-tank, delineates a Generation X period of 1965–1980 which has, albeit gradually, come to gain acceptance in academic circles. Moreover, although fertility rates are preponderant in the definition of start and end dates, the center remarks: "Generations are analytical constructs, it takes time for popular and expert consensus to develop as to the precise boundaries that demarcate one generation from another." Pew takes into account other factors, notably the labor market as well as attitudinal and behavioral trends of a group. Writing for Pew's "Trend" magazine in 2018, psychologist Jean Twenge observed that the "birth year boundaries of Gen X are debated but settle somewhere around 1965–1980". According to this definition, the oldest Gen Xer is years old and the youngest is, or is turning, years old in .
The Brookings Institution, another U.S. think-tank, sets the Gen X period as between 1965 and 1981. The U.S. Federal Reserve Board uses 1965–1980 to define Gen X. The U.S. Social Security Administration (SSA) defines the years for Gen X as between 1964 and 1979. The US Department of Defense (DoD), conversely, use dates 1965 to 1977. In their 2002 book "When Generations Collide", Lynne Lancaster and David Stillman use 1965 to 1980, while in 2012 authors Jain and Pant also used parameters of 1965 to 1980. U.S. news outlets such as "The New York Times" and "The Washington Post" describe Generation X as people born between 1965 and 1980. Gallup, Bloomberg, "Business Insider", and "Forbes" use 1965–1980. "Time" magazine states that Generation X is "roughly defined as anyone born between 1965 and 1980".
In Australia, the McCrindle Research Center uses 1965–1979. In the UK, the Resolution Foundation think-tank defines Gen X as those born between 1966 and 1980. PricewaterhouseCoopers, a multinational professional services network headquartered in London, describes Generation X employees as those born from 1965 to 1980.
### Other age range markers.
On the basis of the time it takes for a generation to mature, U.S. authors William Strauss and Neil Howe define Generation X as those born between 1961 and 1981 in their 1991 book titled "Generations", and differentiate the cohort into an early and late wave. Jeff Gordinier, in his 2008 book "X Saves the World", also has a wider definition to include those born between 1961 and 1977 but possibly as late as 1980. George Masnick of the Harvard Joint Center for Housing Studies puts this generation in the time-frame of 1965 to 1984, in order to satisfy the premise that boomers, Xers, and millennials "cover equal 20-year age spans". In 2004, journalist J. Markert also acknowledged the 20-year increments but goes one step further and subdivides the generation into two 10-year cohorts with early and later members of the generation. The first begins in 1966 and ends in 1975 and the second begins in 1976 and ends in 1985; this thinking is applied to each generation (Silent, boomers, Gen X, millennials, etc.).
Based on external events of historical importance, Schewe and Noble in 2002 argue that a cohort is formed against significant milestones and can be any length of time. Against this logic, Generation X begins in 1966 and ends in 1976, with those born between 1955 and 1965 being labelled as "trailing-edge boomers".
In Canada, professor David Foot describes Generation X as late boomers and includes those born between 1960 and 1966, whilst the "Bust Generation", those born between 1967 and 1979, is considered altogether a separate generation, in his 1996 book "Boom Bust &amp; Echo: How to Profit from the Coming Demographic Shift".
### Generational cuspers.
Generation Jones is identified as the group of people born in the latter half of the Baby Boomers from the early 1960s to the early years of Generation X. Individuals born in the Generation X and millennial cusp years of the late 1970s and early to mid-1980s have been identified by the media as a "microgeneration" with characteristics of both generations. Names given to these "cuspers" include Xennials, Generation Catalano, and the Oregon Trail Generation.
## Demographics.
### United States.
There are differences in Gen X population numbers depending on the date-range selected. In the U.S., using Census population projections, the Pew Research Center found that the Gen X population born from 1965 to 1980 numbered 65.2 million in 2019. The cohort is likely to overtake boomers in 2028. A 2010 Census report counted approximately 84 million people living in the US who are defined by birth years ranging from the early 1960s to the early 1980s. In a 2012 article for the Joint Center for Housing Studies of Harvard University, George Masnick wrote that the "Census counted 82.1 million" Gen Xers in the U.S. Masnick concluded that immigration filled in any birth year deficits during low fertility years of the late 1960s and early 1970s. Jon Miller at the Longitudinal Study of American Youth at the University of Michigan wrote that "Generation X refers to adults born between 1961 and 1981" and it "includes 84 million people". In their 1991 book "Generations", authors Howe and Strauss indicated that the total number of Gen X individuals in the U.S. was 88.5 million.
#### Impact of family planning programs.
The birth control pill, introduced in 1960, was one contributing factor of declining birth rates. Initially, the pill spread rapidly amongst married women as an approved treatment for menstrual disturbance. However, it was also found to prevent pregnancy and was prescribed as a contraceptive in 1964. The pill, as it became commonly known, reached younger, unmarried college women in the late 1960s when state laws were amended and reduced the age of majority from 21 to ages 18–20. These policies are commonly referred to as the Early Legal Access (ELA) laws.
Another major factor was abortion, only available in a few states until its legalisation in a 1973 US Supreme Court decision in "Roe v. Wade." This was replicated elsewhere, with reproductive rights legislation passed, notably in the UK (1967), France (1975), West Germany (1976), New Zealand (1977), Italy (1978), and the Netherlands (1980). From 1973 to 1980, the abortion rate per 1,000 US women aged 15–44 increased exponentially from 16% to 29% with more than 9.6 million terminations of pregnancy practiced. Between 1970 and 1980, on average, for every 10 American citizens born, 3 were aborted. However, increased immigration during the same period of time helped to partially offset declining birth-rates and contributed to making Generation X an ethnically and culturally diverse demographic cohort.
#### Parental lineage.
Generally, Gen Xers are the children of the Silent Generation and older baby boomers.
## Characteristics.
### In the United States.
#### As children and adolescents.
##### Rising divorce rates and women workforce participation.
Strauss and Howe, who wrote several books on generations, including one specifically on Generation X titled "13th Gen: Abort, Retry, Ignore, Fail?" (1993), reported that Gen Xers were children at a time when society was less focused on children and more focused on adults. Xers were children during a time of increasing divorce rates, with divorce rates doubling in the mid-1960s, before peaking in 1980. Strauss and Howe described a cultural shift where the long-held societal value of staying together for the sake of the children was replaced with a societal value of parental and individual self-actualization. Strauss wrote that society "moved from what Leslie Fiedler called a 1950s-era 'cult of the child' to what Landon Jones called a 1970s-era 'cult of the adult'". "The Generation Map", a report from Australia's McCrindle Research Center writes of Gen X children: "their Boomer parents were the most divorced generation in Australian history". According to Christine Henseler in the 2012 book "Generation X Goes Global: Mapping a Youth Culture in Motion", "We watched the decay and demise (of the family), and grew callous to the loss."
The Gen X childhood coincided with the sexual revolution of the 1960s to 1980s, which Susan Gregory Thomas described in her book "In Spite of Everything" as confusing and frightening for children in cases where a parent would bring new sexual partners into their home. Thomas also discussed how divorce was different during the Gen X childhood, with the child having a limited or severed relationship with one parent following divorce, often the father, due to differing societal and legal expectations. In the 1970s, only nine U.S. states allowed for joint custody of children, which has since been adopted by all 50 states following a push for joint custody during the mid-1980s. "Kramer vs. Kramer", a 1979 American legal drama based on Avery Corman's best-selling novel, came to epitomize the struggle for child custody and the demise of the traditional nuclear family.
The rapid influx of boomer women into the labor force that began in the 1970s was marked by the confidence of many in their ability to successfully pursue a career while meeting the needs of their children. This resulted in an increase in latchkey children, leading to the terminology of the "latchkey generation" for Generation X. These children lacked adult supervision in the hours between the end of the school day and when a parent returned home from work in the evening, and for longer periods of time during the summer. Latchkey children became common among all socioeconomic demographics, but this was particularly so among middle- and upper-class children. The higher the educational attainment of the parents, the higher the odds the children of this time would be latchkey children, due to increased maternal participation in the workforce at a time before childcare options outside the home were widely available. McCrindle Research Centre described the cohort as "the first to grow up without a large adult presence, with both parents working", stating this led to Gen Xers being more peer-oriented than previous generations.
##### Conservative and neoliberal turn.
Some older Gen Xers started high school in the waning years of the Carter presidency, but much of the cohort became socially and politically conscious during the Reagan Era. President Ronald Reagan, voted in office principally by the boomer generation, embraced "laissez-faire" economics with vigor. His policies included cuts in the growth of government spending, reduction in taxes for the higher echelon of society, legalization of stock buybacks, and deregulation of key industries. Measures had drastic consequences on the social fabric of the country even if, gradually, reforms gained acceptability and exported overseas to willing participants. The early 1980s recession saw unemployment rise to 10.8% in 1982; requiring, more often than not, dual parental incomes. One-in-five American children grew up in poverty during this time. The federal debt almost tripled during Reagan's time in office, from $998 billion in 1981 to $2.857 trillion in 1989, placing greater burden on repayment on the incoming generation.
Government expenditure shifted from domestic programs to defense. Remaining funding initiatives, moreover, tended to be diverted away from programs for children and often directed toward the elderly population, with cuts to Medicaid and programs for children and young families, and protection and expansion of Medicare and Social Security for the elderly population. These programs for the elderly were not tied to economic need. Congressman David Durenberger criticized this political situation, stating that while programs for poor children and for young families were cut, the government provided "free health care to elderly millionaires".
##### The crack epidemic and AIDS.
Gen Xers came of age or were children during the 1980s crack epidemic, which disproportionately impacted urban areas as well as the African-American community. The U.S. Drug turf battles increased violent crime. crack addiction impacted communities and families. Between 1984 and 1989, the homicide rate for black males aged 14 to 17 doubled in the U.S., and the homicide rate for black males aged 18 to 24 increased almost as much. The crack epidemic had a destabilizing impact on families, with an increase in the number of children in foster care. In 1986, President Reagan signed the Anti-Drug Abuse Act to enforce strict mandatory minimum sentencing for drug users. He also increased the federal budget for supply-reduction efforts.
Fear of the impending AIDS epidemic of the 1980s and 1990s loomed over the formative years of Generation X. The emergence of AIDS coincided with Gen X's adolescence, with the disease first clinically observed in the U.S. in 1981. By 1985, an estimated one-to-two million Americans were HIV-positive. This particularly hit the LGBT community. As the virus spread, at a time before effective treatments were available, a public panic ensued. Sex education programs in schools were adapted to address the AIDS epidemic, which taught Gen X students that sex could kill you.
##### The rise of home computing.
Gen Xers were the first children to have access to personal computers in their homes and at schools. In the early 1980s, the growth in the use of personal computers exploded. Manufacturers such as Commodore, Atari, and Apple responded to the demand via 8-bit and 16-bit machines. This in turn stimulated the software industries with corresponding developments for backup storage, use of the floppy disk, zip drive, and CD-ROM. 
At school, several computer projects were supported by the Department of Education under United States Secretary of Education Terrel Bell's "Technology Initiative". This was later mirrored in the UK's 1982 Computers for Schools programme and, in France, under the 1985 scheme "Plan Informatique pour Tous (IPT)." 
##### The post-civil rights generation.
In the U.S., Generation X was the first cohort to grow up post-integration after the racist Jim Crow laws. They were described in a marketing report by "Specialty Retail" as the kids who "lived the civil rights movement". They were among the first children to be bused to attain integration in the public school system. In the 1990s, Strauss reported Gen Xers were "by any measure the least racist of today's generations". In the U.S., Title IX, which passed in 1972, provided increased athletic opportunities to Gen X girls in the public school setting. "Roots", based on the novel by Alex Haley and broadcast as a 12-hour series, was viewed as a turning point in the country's ability to relate to the afro-American history.
#### As young adults.
##### Continued growth in college enrollments.
In the U.S., compared to the boomer generation, Generation X was more educated than their parents. The share of young adults enrolling in college steadily increased from 1983, before peaking in 1998. In 1965, as early boomers entered college, total enrollment of new undergraduates was just over 5.7 million individuals across the public and private sectors. By 1983, the first year of Gen X college enrollments (as per Pew Research's definition), this figure had reached 12.2 million. This was an increase of 53%, effectively a doubling in student intake. As the 1990s progressed, Gen X college enrollments continued to climb, with increased loan borrowing as the cost of an education became substantially more expensive compared to their peers in the mid-1980s. By 1998, the generation's last year of college enrollment, those entering the higher education sector totaled 14.3 million. In addition, unlike Boomers and previous generations, women outpaced men in college completion rates.
##### Adjusting to a new societal environment.
For early Gen Xer graduates entering the job market at the end of the 1980s, economic conditions were challenging and did not show signs of major improvements until the mid-1990s. In the U.S., restrictive monetary policy to curb rising inflation and the collapse of a large number of savings and loan associations (private banks that specialized in home mortgages) impacted the welfare of many American households. This precipitated a large government bailout, which placed further strain on the budget. Furthermore, three decades of growth came to an end. The social contract between employers and employees, which had endured during the 1960s and 1970s and was scheduled to last until retirement, was no longer applicable. By the late 1980s, there were large-scale layoffs of boomers, corporate downsizing, and accelerated offshoring of production.
On the political front, in the U.S. the generation became ambivalent if not outright disaffected with politics. They had been reared in the shadow of the Vietnam War and the Watergate scandal. They came to maturity under the Reagan and George H. W. Bush presidencies, with first-hand experience of the impact of neoliberal policies. Few had experienced a Democratic administration and even then, only, at an atmospheric level. For those on the left of the political spectrum, the disappointments with the previous boomer student mobilizations of the 1960s and the collapse of those movements towards a consumerist "greed is good" and "yuppie" culture during the 1980s felt, to a greater extent, hypocrisy if not outright betrayal. Hence, the preoccupation on "authenticity" and not "selling-out". The Revolutions of 1989 and the collapse of the socialist utopia with the fall of the Berlin Wall, moreover, added to the disillusionment that any alternative to the capitalist model was possible.
##### Birth of the slacker.
In 1990, "Time" magazine published an article titled "Living: Proceeding with Caution", which described those then in their 20s as aimless and unfocused. Media pundits and advertisers further struggled to define the cohort, typically portraying them as "unfocused twentysomethings". A MetLife report noted: "media would portray them as the "Friends" generation: rather self-involved and perhaps aimless...but fun". Gen Xers were often portrayed as apathetic or as "slackers", lacking bearings, a stereotype which was initially tied to Richard Linklater's comedic and essentially plotless 1991 film "Slacker". After the film was released, "journalists and critics thought they put a finger on what was different about these young adults in that 'they were reluctant to grow up' and 'disdainful of earnest action'". Ben Stiller's 1994 film "Reality Bites" also sought to capture the zeitgeist of the generation with a portrayal of the attitudes and lifestyle choices of the time.
Negative stereotypes of Gen X young adults continued, including that they were "bleak, cynical, and disaffected". In 1998, such stereotypes prompted sociological research at Stanford University to study the accuracy of the characterization of Gen X young adults as cynical and disaffected. Using the national General Social Survey, the researchers compared answers to identical survey questions asked of 18–29-year-olds in three different time periods. Additionally, they compared how older adults answered the same survey questions over time. The surveys showed 18–29-year-old Gen Xers did exhibit higher levels of cynicism and disaffection than previous cohorts of 18–29-year-olds surveyed. However, they also found that cynicism and disaffection had increased among all age groups surveyed over time, not just young adults, making this a period effect, not a cohort effect. In other words, adults of all ages were more cynical and disaffected in the 1990s, not just Generation X.
##### Rise of the Internet and the dot-com bubble.
By the mid-late 1990s, under Bill Clinton's presidency, economic optimism had returned to the U.S., with unemployment reduced from 7.5% in 1992 to 4% in 2000. Younger members of Gen X, straddling across administrations, politically experienced a "liberal renewal". In 1997, "Time" magazine published an article titled "Generation X Reconsidered", which retracted the previously-reported negative stereotypes and reported positive accomplishments. The article cited Gen Xers' tendency to found technology startup companies and small businesses, as well as their ambition, which research showed was higher among Gen X young adults than older generations. Yet, the slacker moniker stuck. As the decade progressed, Gen X gained a reputation for entrepreneurship. In 1999, "The New York Times" dubbed them "Generation 1099", describing them as the "once pitied but now envied group of self-employed workers whose income is reported to the Internal Revenue Service not on a W-2 form, but on Form 1099".
Consumer access to the Internet and its commercial development throughout the 1990s witnessed a frenzy of IT initiatives. Newly created companies, launched on stock exchanges globally, were formed with dubitable revenue generation or cash flow. When the dot-com bubble eventually burst in 2000, early Gen Xers who had embarked as entrepreneurs in the IT industry while iding the Internet wave, as well as newly qualified programmers at the tail-end of the generation (who had grown up with AOL and the first Web browsers), were both caught in the crash. This had major repercussions, with cross-generational consequences; five years after the bubble burst, new matriculation of IT millennial undergraduates fell by 40% and by as much as 70% in some information systems programs.
However, following the crisis, sociologist Mike Males reported continued confidence and optimism among the cohort. He reported "surveys consistently find 80% to 90% of Gen Xers self-confident and optimistic". Males wrote "these young Americans should finally get the recognition they deserve", praising the cohort and stating that "the permissively raised, universally deplored Generation X is the true 'great generation', for it has braved a hostile social climate to reverse abysmal trends". He described them as the hardest-working group since the World War II generation. He reported Gen Xers' entrepreneurial tendencies helped create the high-tech industry that fueled the 1990s economic recovery. In 2002, "Time" magazine published an article titled "Gen Xers Aren't Slackers After All", reporting that four out of five new businesses were the work of Gen Xers.
##### Response to 9/11.
In the U.S., Gen Xers were described as the major heroes of the September 11 terrorist attacks by author William Strauss. The firefighters and police responding to the attacks were predominantly from Generation X. Additionally, the leaders of the passenger revolt on United Airlines Flight 93 were also, by majority, Gen Xers. Author Neil Howe reported survey data which showed that Gen Xers were cohabiting and getting married in increasing numbers following the terrorist attacks. Gen X survey respondents reported that they no longer wanted to live alone. In October 2001, the "Seattle Post-Intelligencer" wrote of Gen Xers: "Now they could be facing the most formative events of their lives and their generation." The "Greensboro News &amp; Record" reported members of the cohort "felt a surge of patriotism since terrorists struck" by giving blood, working for charities, donating to charities, and by joining the military to fight the War on Terror. "The Jury Expert", a publication of The American Society of Trial Consultants, reported: "Gen X members responded to the terrorist attacks with bursts of patriotism and national fervor that surprised even themselves."
#### In midlife.
##### Achieving a work-life balance.
In 2011, survey analysis from the "Longitudinal Study of American Youth" found Gen Xers (defined as those who were then between the ages of 30 and 50) to be "balanced, active, and happy" in midlife and as achieving a work-life balance. The Longitudinal Study of Youth is an NIH-NIA funded study by the University of Michigan which has been studying Generation X since 1987. The study asked questions such as "Thinking about all aspects of your life, how happy are you? If zero means that you are very unhappy and 10 means that you are very happy, please rate your happiness." LSA reported that "mean level of happiness was 7.5 and the median (middle score) was 8. Only four percent of Generation X adults indicated a great deal of unhappiness (a score of three or lower). Twenty-nine percent of Generation X adults were very happy with a score of 9 or 10 on the scale."
In 2014, Pew Research provided further insight, describing the cohort as "savvy, skeptical and self-reliant; they're not into preening or pampering, and they just might not give much of a hoot what others think of them. Or whether others think of them at all." Furthermore, guides regarding managing multiple generations in the workforce describe Gen Xers as: independent, resilient, resourceful, self-managing, adaptable, cynical, pragmatic, skeptical of authority, and as seeking a work-life balance.
##### Entrepreneurship as an individual trait.
Individualism is one of the defining traits of Generation X, and is reflected in their entrepreneurial spirit. In the 2008 book "X Saves the World: How Generation X Got the Shaft but Can Still Keep Everything from Sucking", author Jeff Gordinier describes Generation X as a "dark horse demographic" which "doesn't seek the limelight". Gordiner cites examples of Gen Xers' contributions to society such as: Google, Wikipedia, Amazon.com, and YouTube, arguing that if boomers had created them, "we'd never hear the end of it". In the book, Gordinier contrasts Gen Xers to baby boomers, saying boomers tend to trumpet their accomplishments more than Gen Xers do, creating what he describes as "elaborate mythologies" around their achievements. Gordiner cites Steve Jobs as an example, while Gen Xers, he argues, are more likely to "just quietly do their thing".
In a 2007 article published in the Harvard Business Review, authors Strauss and Howe wrote of Generation X: "They are already the greatest entrepreneurial generation in U.S. history; their high-tech savvy and marketplace resilience have helped America prosper in the era of globalization." According to authors Michael Hais and Morley Winograd:
Small businesses and the entrepreneurial spirit that Gen Xers embody have become one of the most popular institutions in America. There's been a recent shift in consumer behavior and Gen Xers will join the "idealist generation" in encouraging the celebration of individual effort and business risk-taking. As a result, Xers will spark a renaissance of entrepreneurship in economic life, even as overall confidence in economic institutions declines. Customers, and their needs and wants (including Millennials) will become the North Star for an entire new generation of entrepreneurs.
A 2015 study by Sage Group reports Gen Xers "dominate the playing field" with respect to founding startups in the United States and Canada, with Xers launching the majority (55%) of all new businesses in 2015.
##### Income benefits of a college education.
Unlike millennials, Generation X was the last generation in the U.S. for whom higher education was broadly financially remunerative. In 2019, the Federal Reserve Bank of St. Louis published research (using data from the 2016 "Survey of Consumer Finances") demonstrating that after controlling for race and age, cohort families with heads of household with post-secondary education and born before 1980 have seen wealth and income premiums, while, for those after 1980, the wealth premium has weakened to a point of statistical insignificance (in part because of the rising cost of college). The income premium, while remaining positive, has declined to historic lows, with more pronounced downward trajectories among heads of household with postgraduate degrees.
##### Parenting and volunteering.
In terms of advocating for their children in the educational setting, author Neil Howe describes Gen X parents as distinct from baby boomer parents. Howe argues that Gen Xers are not helicopter parents, which Howe describes as a parenting style of boomer parents of millennials. Howe described Gen Xers instead as "stealth fighter parents", due to the tendency of Gen X parents to let minor issues go and to not hover over their children in the educational setting, but to intervene forcefully and swiftly in the event of more serious issues. In 2012, the Corporation for National and Community Service ranked Gen X volunteer rates in the U.S. at "29.4% per year", the highest compared with other generations. The rankings were based on a three-year moving average between 2009 and 2011.
##### Income differential with previous generations.
A report titled "Economic Mobility: Is the American Dream Alive and Well?" focused on the income of males 30–39 in 2004 (those born April 1964March 1974). The study was released on 25 May 2007 and emphasized that this generation's men made less (by 12%) than their fathers had at the same age in 1974, thus reversing a historical trend. It concluded that, per year increases in household income generated by fathers/sons slowed from an average of 0.9% to 0.3%, barely keeping pace with inflation. "Family incomes have risen though (over the period 1947 to 2005) because more women have gone to work", "supporting the incomes of men, by adding a second earner to the family. And as with male income, the trend is downward."
### Elsewhere.
Although, globally, children and adolescents of Generation X will have been heavily influenced by U.S. cultural industries with shared global currents (e.g. rising divorce rates, the AIDS epidemic, advancements in ICT), there is not one U.S.-born raised concept but multiple perspectives and geographical outgrowths. Even within the period of analysis, inside national communities, commonalities will have differed on the basis of one's birth date. The generation, Christine Henseler also remarks, was shaped as much by real-world events, within national borders, determined by specific political, cultural, and historical incidents. She adds "In other words, it is in between both real, clearly bordered spaces and more fluid global currents that we can spot the spirit of Generation X."
In 2016, a global consumer insights project from Viacom International Media Networks and Viacom, based on over 12,000 respondents across 21 countries, reported on Gen X's unconventional approach to sex, friendship, and family, their desire for flexibility and fulfillment at work and the absence of midlife crisis for Gen Xers. The project also included a 20 min documentary titled "Gen X Today".
#### Russia.
In Russia Generation Xers are referred to as "the last Soviet children", as the last children to come of age prior to the downfall of communism in their nation and prior to the Dissolution of the Soviet Union. Those that reached adulthood in the 1980s and grew up educated in the doctrines of Marxism and Leninism found themselves against a background of economic and social change, with the advent of Mikhail Gorbachev to power and "Perestroika". However, even before the collapse of the Soviet Union and the disbanding of the Communist Party of the Soviet Union, surveys demonstrated that Russian young people repudiated the key features of the Communist worldview that their party leaders, schoolteachers, and even parents had tried to instill in them. This generation, caught in the transition between Marxism–Leninism and an unknown future, and wooed by the new domestic political classes, remained largely apathetic.
#### France.
In France, "Generation X" is not as widely known or used to define its members. Demographically, this denotes those born from the beginning of the 1960s to the early 1980s. There is general agreement that, domestically, the event that is accepted in France as the separating point between the baby boomer generation and Generation X are the French strikes and violent riots of May 1968 with those of the generation too young to participate. Those at the start of the cohort are sometimes referred to as 'Génération Bof' because of their tendency to use the word 'bof', which, translated into English, means "whatever". The generation is closely associated with socialist François Mitterrand who served as President of France during two consecutive terms between 1981 and 1995 as most transitioned into adulthood during that period. Economically, Xers started when the new labour market was emerging and were the first to fully experience the advent of the post-industrial society. For those at the tail-end of the generation, educational and defense reforms, a new style "baccalauréat général" with three distinct streams in 1995 (the preceding programme, introduced in 1968) and the cessation of military conscription in 1997 (for those born after January 1979) are considered as new transition points to the next.
#### Republic of Ireland.
The term "Generation X" is used to describe Irish people born between 1965 and 1985; they grew up during The Troubles and the 1980s economic recession, coming of age during the Celtic Tiger period of prosperity in the 1990s onward. The appropriateness of the term to Ireland has been questioned, with Darach Ó Séaghdha noting that "Generation X is usually contrasted with the one before by growing up in smaller and different family units on account of their parents having greater access to contraception and divorce – again, things that were not widely available in Ireland. ["Contraception was only available under prescription in 1978 and without prescription in 1985; divorce was illegal until 1996."] However, this generation was in prime position to benefit from the Celtic Tiger, the Peace Process and liberalisations introduced on foot of EU membership and was less likely to emigrate than those that came before and after. You could say that in many ways, these are Ireland’s real boomers."
Culturally, Britpop, Celtic rock, the trad revival, "Father Ted", the 1990 FIFA World Cup and rave culture were significant. The Divine Comedy song "Generation Sex" (1998) painted a picture of hedonism in the late 20th century, as well as its effect on the media.
David McWilliams' 2005 book "The Pope's Children: Ireland's New Elite" profiled Irish people born in the 1970s (just prior to the papal visit to Ireland), which was a baby boom that saw Ireland's population increase for the first time since the 1840s Great Famine. The Pope's Children were in position to benefit from the Celtic Tiger and the newly liberal culture, where the Catholic Church had significantly less social power.
#### United Kingdom.
##### As children, adolescents and young adults.
###### Political environment.
The United Kingdom's Economic and Social Research Council described Generation X as "Thatcher's children" because the cohort grew up while Margaret Thatcher was Prime Minister from 1979 to 1990, "a time of social flux and transformation". Those born in the late 1960s and early 1970s grew up in a period of social unrest. While unemployment was low in the early 1970s, industrial and social unrest escalated. Strike action culminated in the "Winter of Discontent" in 1978–79, and the Troubles began to unfold in Northern Ireland. The turn to neoliberal policies introduced and maintained by consecutive conservative governments from 1979 to 1997 marked the end of the post-war consensus.
###### Education.
The almost universal dismantling of the grammar school system in Great Britain during the 1960s and the 1970s meant that the vast majority of the cohort attended secondary modern schools, relabelled comprehensive schools. Compulsory education ended at the age of 16. As older members of the cohort reached the end of their mandatory schooling, levels of educational enrollment among older adolescents remained below much of the Western world. By the early 1980s, some 80% to 90% of school leavers in France and West Germany received vocational training, compared with 40% in the United Kingdom. By the mid-1980s, over 80% of pupils in the United States and West Germany and over 90% in Japan stayed in education until the age of eighteen, compared with 33% of British pupils. There was, however, broadly a rise in education levels among this age range as Generation X passed through it.
In 1990, 25% of young people in England stayed in some kind of full-time education after the age of 18, this was an increase from 15% a decade earlier. Later, the Further and Higher Education Act 1992 and the liberalisation of higher education in the UK saw greater numbers of those born towards the tail-end of the generation gaining university places.
###### Employment.
The 1980s, when much of Generation X reached working age, was an era defined by high unemployment rates. This was particularly true of the youngest members of the working aged population. In 1984, 26% of 16 to 24 year olds were neither in full-time education or participating in the workforce. However, this figure did decrease as the economic situation improved reaching 17% by 1993.
##### In midlife.
Generation X were far more likely to have children out of wedlock than their parents. The number of babies being born to unmarried parents in England and Wales rose from 11% in 1979, a quarter in 1998, 40% by 2002 and almost half in 2012. They were also significantly more likely to have children later in life than their predecessors. The average age of a mother giving birth rose from 27 in 1982 to 30 in 2012. That year saw 29,994 children born to mothers over the age 40, an increase of 360% from 2002.
A 2016 study of over 2,500 British office workers conducted by Workfront found that survey respondents of all ages selected those from Generation X as the hardest-working employees and members of the workforce (chosen by 60%). Gen X was also ranked highest among fellow workers for having the strongest work ethic (chosen by 59.5%), being the most helpful (55.4%), the most skilled (54.5%), and the best troubleshooters/problem-solvers (41.6%).
##### Political evolution.
Ipsos MORI reports that at the 1987 and 1992 general elections, the first United Kingdom general elections where significant numbers of Generation X members could vote, a plurality of 18 to 24 year olds opted for the Labour Party by a small margin. The polling organisation's figures suggest that in 1987 39% of that age group voted Labour, 37% for the Conservatives and 22% for the SDP–Liberal Alliance. Five years later, these numbers were fairly similar at 38% Labour, 35% Conservative and 19% Liberal Democrats, a party by then formed from the previously mentioned alliance. Both these elections saw a fairly significant lead for the conservatives in the popular vote among the general population.
At the 1997 General election where Labour won a large majority of seats and a comfortable lead in the popular vote, research suggests that voters under the age of 35 were more likely to vote labour if they turned out than the wider electorate but significantly less likely to vote than in 1992. Analysts suggested this may have been due to fewer differences in policies between the major parties and young people having less of a sense of affiliation with particular political parties than older generations. A similar trend continued at the 2001 and 2005 general elections as turnout dropped further among both the relatively young and the wider public.
Voter turnout across the electorate began to recover from a 2001 low until the 2017 general election. Generation X also became more likely to vote as they entered the midlife age demographics. Polling suggests a plurality of their age group backed the Conservatives in 2010 and 2015 but less overwhelming than much of the older generation. At the 2016 EU membership referendum and 2017 general election, Generation X was split with younger members appearing to back remain and Labour and older members tending towards Leave and Conservative in a British electorate more polarised by age than ever before. At the 2019 general election, (where Generation X members then fell between the ages of 39 and 55) voting trends continued to be heavily divided by age. The voting intentions within this age group shifted further right, with increasing age, to the point that a majority of older Generation X members, appeared to be voting for the Conservatives and right of centre parties, as opposed to the left and centre-progressive preferences, Labour, the Lib-Dems, and Greens, etc, of the younger elements.
#### Germany.
In Germany, "Generation X" is not widely used or applied. Instead, reference is made to "Generation Golf" in the previous West German republic, based on a novel by Florian Illies. In the east, children of the "Mauerfall" or coming down of the wall. For former East Germans, there was adaptation, but also a sense of loss of accustomed values and structures. These effects turned into romantic narratives of their childhood. For those in the West, there was a period of discovery and exploration of what had been a forbidden land.
#### South Africa.
In South Africa, Gen Xers spent their formative years of the 1980s during the "hyper-politicized environment of the final years of apartheid".
## Arts and culture.
### Music.
Gen Xers were the first cohort to come of age with MTV. They were the first generation to experience the emergence of music videos as teenagers and are sometimes called the MTV Generation. Gen Xers were responsible for the alternative rock movement of the 1990s and 2000s, including the grunge subgenre. Hip hop has also been described as defining music of the generation, particularly artists such as Tupac Shakur, N.W.A., and The Notorious B.I.G..
#### Punk rock.
From 1974 to 1976, a new generation of rock bands arose, such as the Ramones, Johnny Thunders and the Heartbreakers, The Dictators in New York City, the Sex Pistols, the Clash, the Damned, and Buzzcocks in the United Kingdom, and the Saints in Brisbane. By late 1976, these acts were generally recognized as forming the vanguard of "punk rock", and as 1977 approached, punk rock became a major and highly controversial cultural phenomenon in the UK. It spawned a punk subculture which expressed a youthful rebellion, characterized by distinctive styles of clothing and adornment (ranging from deliberately offensive T-shirts, leather jackets, studded or spiked bands and jewelry, as well as bondage and S&amp;M clothes) and a variety of anti-authoritarian ideologies that have since been associated with the form. By 1977 the influence of punk rock music and its subculture became more pervasive, spreading throughout various countries worldwide. It generally took root in local scenes that tended to reject affiliation with the mainstream. In the late 1970s, punk experienced its second wave. Acts that were not active during its formative years adopted the style.
While at first punk musicians were not Gen Xers themselves (many of them were late boomers, or Generation Jones), the fanbase for punk became increasingly Gen X-oriented as the earliest Xers entered their adolescence, and it therefore made a significant imprint on the cohort. By the 1980s, faster and more aggressive subgenres such as hardcore punk (e.g. Minor Threat), street punk (e.g. the Exploited, NOFX) and anarcho-punk (e.g. Subhumans) became the predominant modes of punk rock. Musicians identifying with or inspired by punk often later pursued other musical directions, resulting in a broad range of spinoffs. This development gave rise to genres such as post-punk, new wave and later indie pop, alternative rock, and noise rock. Gen Xers were no longer simply the consumers of punk, they became the creators as well. By the 1990s, punk rock re-emerged into the mainstream. Punk rock and pop punk bands with Gen X members such as Green Day, Rancid, The Offspring, and Blink-182 brought widespread popularity to the genre .
#### Hard rock.
Arguably in a similar way to punk, a sense of disillusionment, angst and anger catalysed hard rock and heavy metal to grow from the earlier influence of rock.
#### Post-punk.
The energy generated by the punk movement launched a subsequent proliferation of weird and eclectic post-punk sub cultures, spanning new wave, goth etc., and influencing the New Romantics,
#### Grunge.
A notable example of alternative rock is grunge music and the associated subculture that developed in the Pacific Northwest of the U.S. Grunge song lyrics have been called the "...product of Generation X malaise". Vulture commented: "the best bands arose from the boredom of latchkey kids". "People made records entirely to please themselves because there was nobody else to please" commented producer Jack Endino. Grunge lyrics are typically dark, nihilistic, angst-filled, anguished, and often addressing themes such as social alienation, despair and apathy. "The Guardian" wrote that grunge "didn't recycle banal cliches but tackled weighty subjects". Topics of grunge lyrics included homelessness, suicide, rape, broken homes, drug addiction, self-loathing, misogyny, domestic abuse and finding "meaning in an indifferent universe". Grunge lyrics tended to be introspective and aimed to enable the listener to see into hidden personal issues and examine depravity in the world. Notable grunge bands include: Nirvana, Pearl Jam, Alice in Chains, Stone Temple Pilots and Soundgarden.
#### Hip hop.
The golden age of hip hop refers to hip hop music made from the mid-1980s to mid-1990s, typically by artists originating from the New York metropolitan area. The music style was characterized by its diversity, quality, innovation and influence after the genre's emergence and establishment in the previous decade. There were various types of subject matter, while the music was experimental and the sampling eclectic. The artists most often associated with the period are LL Cool J, Run–D.M.C., Public Enemy, the Beastie Boys, KRS-One, Eric B. &amp; Rakim, De La Soul, Big Daddy Kane, EPMD, A Tribe Called Quest, Wu-Tang Clan, Slick Rick, Ultramagnetic MC's, and the Jungle Brothers. Releases by these acts co-existed in this period with, and were as commercially viable as, those of early gangsta rap artists such as Ice-T, Geto Boys and N.W.A, the sex raps of 2 Live Crew and Too Short, and party-oriented music by acts such as Kid 'n Play, The Fat Boys, DJ Jazzy Jeff &amp; The Fresh Prince and MC Hammer.
In addition to lyrical self-glorification, hip hop was also used as a form of social protest. Lyrical content from the era often drew attention to a variety of social issues, including afrocentric living, drug use, crime and violence, religion, culture, the state of the American economy, and the modern man's struggle. Conscious and political hip hop tracks of the time were a response to the effects of American capitalism and former President Reagan's conservative political economy. According to Rose Tricia, "In rap, relationships between black cultural practice, social and economic conditions, technology, sexual and racial politics, and the institution policing of the popular terrain are complex and in constant motion". Even though hip hop was used as a mechanism for different social issues, it was still very complex with issues within the movement itself. There was also often an emphasis on black nationalism. Hip hop artists often talked about urban poverty and the problems of alcohol, drugs, and gangs in their communities. Public Enemy's most influential song, "Fight the Power", came out at this time; the song speaks up to the government, proclaiming that people in the ghetto have freedom of speech and rights like every other American.
### Film.
#### Indie films.
Gen Xers were largely responsible for the "indie film" movement of the 1990s, both as young directors and in large part as the film audiences which were fueling demand for such films. In cinema, directors Kevin Smith, Quentin Tarantino, Sofia Coppola, John Singleton, Spike Jonze, David Fincher, Steven Soderbergh, and Richard Linklater have been called Generation X filmmakers. Smith is most known for his View Askewniverse films, the flagship film being "Clerks", which is set in New Jersey circa 1994, and focuses on two convenience-store clerks in their twenties. Linklater's "Slacker" similarly explores young adult characters who were interested in philosophizing. 
While not a member of Gen X himself, director John Hughes has been recognized as having created classic 1980s teen films with early Gen X characters which "an entire generation took ownership of", including "The Breakfast Club", "Sixteen Candles", "Weird Science", and "Ferris Bueller's Day Off". 
In France, a new movement emerged, the "Cinéma du look", spearheaded by filmmakers Luc Besson, Jean-Jacques Beineix and Leos Carax. Although not Gen Xers themselves, "Subway" (1985), "37°2 le matin" (English: "Betty Blue"; 1986), and "Mauvais Sang" (1986) sought to capture on screen the generation's malaise, sense of entrapment, and desire to escape.
#### Franchise mega sequels.
The birth of franchise mega-sequels in the science fiction, fantasy, and horror fiction genres, such as the epic space opera "Star Wars" and the "Halloween" franchise, had a profound and notable cultural influence.
### Literature.
The literature of early Gen Xers is often dark and introspective. In the U.S., authors such as Elizabeth Wurtzel, David Foster Wallace, Bret Easton Ellis, and Douglas Coupland captured the zeitgeist of this generation. In France, Michel Houellebecq and Frédéric Beigbeder rank among major novelists whose work also reflect the dissatisfaction and melancholies of the cohort. In the UK, Alex Garland, author of "The Beach" (1996), further added to the genre.
## Health problems.
While previous research has indicated that the likelihood of heart attacks was declining among Americans aged 35 to 74, a 2018 study published in the American Heart Association's journal "Circulation" revealed that this was not the case among younger people. By analyzing data from 28,000 patients from across the United States who were hospitalized for heart attacks between 1995 and 2014, they found that a growing number of such patients were between the ages of 35 to 54. In particular, the number of heart-attack patients in this age group at the end of the study was 32%, up from 27% at the start of the study. This increase is most pronounced among women, for whom the number jumped from 21% to 31%. A common theme among those who suffered from heart attacks is that they also had high-blood pressure, diabetes, and chronic kidney disease. As before, such trends were found to be more common among women than among men. Experts suggest a number of reasons for this. Conditions such as coronary artery disease are traditionally viewed as a man's problem, and as such female patients are not considered high-risk individuals. Many women are not only the primary caretakers of their families but also full-time employees, meaning they do not take care of themselves as much as they should.
## Offspring.
Generation X are usually the parents of Generation Z, and sometimes millennials. Jason Dorsey, who works for the Center of Generational Kinetics, observed that like their parents from Generation X, members of Generation Z tend to be autonomous and pessimistic. They need validation less than the millennials and typically become financially literate at an earlier age, as many of their parents bore the full brunt of the Great Recession.

</doc>
<doc id="11974" url="https://en.wikipedia.org/wiki?curid=11974" title="Guam">
Guam

Guam (; ) is an organized, unincorporated territory of the United States in the Micronesia subregion of the western Pacific Ocean. It is the westernmost point and territory of the United States (reckoned from the geographic center of the U.S.); in Oceania, it is the largest and southernmost of the Mariana Islands and the largest island in Micronesia. Guam's capital is Hagåtña, and the most populous village is Dededo.
People born in Guam are American citizens but have no vote in the United States presidential elections while residing in Guam and Guam delegates to the United States House of Representatives have no vote on the floor. Indigenous Guamanians are the Chamoru, historically known as the Chamorro, who are related to the Austronesian peoples of Indonesia, the Philippines, Taiwan, Micronesia, and Polynesia. As of 2021, Guam's population is 168,801. Chamorus are the largest ethnic group, but a minority on the multi-ethnic island. The territory spans and has a population density of .
The Chamoru people settled the island approximately 3,500 years ago. Portuguese explorer Ferdinand Magellan, while in the service of Spain, was the first European to visit the island on March 6, 1521. Guam was colonized by Spain in 1668. Between the 16th and 18th centuries, Guam was an important stopover for the Spanish Manila Galleons. During the Spanish–American War, the United States captured Guam on June 21, 1898. Under the Treaty of Paris, signed December 10, 1898, Spain ceded Guam to the U.S. effective April 11, 1899.
Before World War II, Guam was one of five American jurisdictions in the Pacific Ocean, along with Wake Island in Micronesia, American Samoa and Hawaii in Polynesia, and the Philippines. On December 8, 1941, hours after the attack on Pearl Harbor, Guam was captured by the Japanese, who occupied the island for two and a half years. During the occupation, Guamanians were subjected to forced labor, incarceration, torture and execution. American forces recaptured the island on July 21, 1944, which is commemorated as Liberation Day. Since the 1960s, Guam's economy has been supported primarily by tourism and the U.S. military, for which Guam is a major strategic asset.
An unofficial but frequently used territorial motto is "Where America's Day Begins", which refers to the island's proximity to the International Date Line. Guam is among the 17 non-self-governing territories listed by the United Nations, and has been a member of the Pacific Community since 1983.
## Pre-Contact era.
Guam, along with the Mariana Islands, were the first islands settled by humans in Remote Oceania. Incidentally it is also the first and the longest of the ocean-crossing voyages of the Austronesian peoples, and is separate from the later Polynesian settlement of the rest of Remote Oceania. They were first settled around 1500 to 1400 BC by migrants departing from the Philippines. This was followed by a second migration from the Caroline Islands by the first millennium AD, and a third migration from Island Southeast Asia (likely the Philippines or eastern Indonesia) by 900 AD.
These original settlers of Guam and the Northern Mariana Islands evolved into the Chamoru people, historically known as Chamorros after first contact with the Spaniards. The ancient Chamoru society had four classes: (chiefs), (upper class), (middle class), and (lower class). The were located in the coastal villages, which meant they had the best access to fishing grounds, whereas the were located in the island's interior. and rarely communicated with each other, and often used as intermediaries. There were also " or ", shamans with magical powers and "'" or ", healers who used different kinds of plants and natural materials to make medicine. Belief in spirits of ancient Chamorus called " still persists as a remnant of pre-European culture. It is believed that " or " are the only ones who can safely harvest plants and other natural materials from their homes or "" without incurring the wrath of the "." Their society was organized along matrilineal clans.
The Chamoru people raised colonnades of megalithic capped pillars called upon which they built their homes. Latte stones are stone pillars that are found only in the Mariana Islands; they are a recent development in Pre-Contact Chamoru society. The latte-stone was used as a foundation on which thatched huts were built. Latte stones consist of a base shaped from limestone called the and with a capstone, or , made either from a large brain coral or limestone, placed on top. A possible source for these stones, the Rota Latte Stone Quarry, was discovered in 1925 on Rota.
## Spanish era.
The first European to travel to Guam was Portuguese navigator Ferdinand Magellan, sailing for the King of Spain, when he sighted the island on March 6, 1521, during his fleet's circumnavigation of the globe. Despite Magellan's visit, Guam was not officially claimed by Spain until January 26, 1565, by Miguel López de Legazpi. From 1565 to 1815, Guam and the Northern Mariana Islands, the only Spanish outposts in the Pacific Ocean east of the Philippines, were reprovisioning stops for the Manila galleons, a fleet that covered the Pacific trade route between Acapulco and Manila.
Spanish colonization commenced on June 15, 1668, with the arrival of a mission led by Diego Luis de San Vitores, who established the first Catholic church. The islands were part of the Spanish East Indies, and in turn part of the Viceroyalty of New Spain, based in Mexico City. The Spanish-Chamorro Wars on Guam began in 1670 over growing tensions with the Jesuit mission, with the last large-scale uprising in 1683. Intermittent warfare, plus the typhoons of 1671 and 1693, and in particular the smallpox epidemic of 1688, reduced the Chamoru population from 50,000 to 10,000, finally to less than 5,000.
The island became a rest stop for whalers starting in 1823. A devastating typhoon struck the island on August 10, 1848, followed by a severe earthquake on January 25, 1849, which resulted in many refugees from the Caroline Islands, victims of the resultant tsunami. After a smallpox epidemic killed 3,644 Guamanians in 1856, Carolinians and Japanese were permitted to settle in the Marianas.
## American era.
After almost four centuries as part of the Kingdom of Spain, the United States occupied the island following Spain's defeat in 1898 Spanish–American War, as part of the Treaty of Paris of 1898. Guam was transferred to the United States Navy control on December 23, 1898, by from 25th President William McKinley.
Guam was a station for American merchants and warships traveling to and from the Philippines (another American acquisition from Spain) while the Northern Mariana Islands were sold by Spain to Germany for part of its rapidly expanding German Empire. A U.S. Navy yard was established at Piti in 1899, and a United States Marine Corps barracks at Sumay in 1901. A marine seaplane unit was stationed in Sumay from 1921 to 1930, the first in the Pacific. The Commercial Pacific Cable Company built a telegraph/telephone station in 1903 for the first trans-Pacific communications cable, followed by Pan American World Airways established a seaplane base at Sumay for its trans-Pacific "China Clipper" route.
### World War II.
During World War II, Guam was attacked and invaded by Japan on Monday, December 8, 1941, at the same time as the attack on Pearl Harbor, across the International Date Line. The Japanese renamed Guam (Great Shrine Island). The Japanese occupation of Guam lasted for approximately 31 months. During this period, the indigenous people of Guam were subjected to forced labor, family separation, incarceration, execution, concentration camps, and forced prostitution. Approximately 1,000 people died during the occupation, according to later Congressional committee testimony in 2004. Some historians estimate that war violence killed 10% of Guam's then 20,000 population. The United States returned and fought the Battle of Guam from July 21 to August 10, 1944, to recapture the island from Japanese military occupation. July 21 is now celebrated as Liberation Day, a territorial holiday.
### Post-war.
After World War II, the Guam Organic Act of 1950 established Guam as an unincorporated organized territory of the United States, provided for the structure of the island's civilian government, and granted the people U.S. citizenship. The Governor of Guam was federally appointed until 1968 when the Guam Elective Governor Act provided for the office's popular election. Since Guam is not a U.S. state, U.S. citizens residing on Guam are not allowed to vote for president and their congressional representative is a non-voting member. They do, however, get to vote for party delegates in presidential primaries. In 1969, a referendum on unification with the Northern Mariana Islands was held and rejected. During the 1970s, Dr. Maryly Van Leer Peck started an engineering program, expanded University of Guam, and founded Guam Community College.
The removal of Guam's security clearance by President John F. Kennedy in 1963 allowed for the development of a tourism industry. When the United States closed U.S. Naval Base Subic Bay and Clark Air Base bases in the Philippines after the expiration of their leases in the early 1990s, many of the forces stationed there were relocated to Guam. 
The 1997 Asian financial crisis, which hit Japan particularly hard, severely affected Guam's tourism industry. Military cutbacks in the 1990s also disrupted the island's economy. Economic recovery was further hampered by devastation from Supertyphoons Paka in 1997 and Pongsona in 2002, as well as the effects of the September 11 terrorist attacks on tourism.
## Geography and environment.
Guam is long and wide, giving it an area of (three-fourths the size of Singapore) and making it the 32nd largest island of the United States. It is the southernmost and largest island in the Mariana Island archipelago, as well as the largest in Micronesia. Guam's Point Udall is the westernmost point of the U.S., as measured from the geographic center of the United States.
The Mariana chain of which Guam is a part was created by collision of the Pacific and Philippine Sea tectonic plates, with Guam located on the micro Mariana Plate between the two. Guam is the closest land mass to the Mariana Trench, the deep subduction zone that runs east of the Marianas. Volcanic eruptions established the base of the island in the Eocene, roughly 56 to 33.9 million years ago. The north of Guam is a result of this base being covered with layers of coral reef, turning into limestone, and then being thrust upward by tectonic activity to create a plateau. The rugged south of the island is a result of more recent volcanic activity. Cocos Island off the southern tip of Guam is the largest of the many small islets along the coastline. Guam's highest point is Mount Lamlam at above sea level. If its base is considered to be nearby Challenger Deep, the deepest surveyed point in the Oceans, Mount Lamlam is the world's highest mountain at .
Politically, Guam is divided into 19 villages. The majority of the population lives on the coralline limestone plateaus of the north, with political and economic activity centered in the central and northern regions. The rugged geography of the south largely limits settlement to rural coastal areas. The western coast is leeward of the trade winds and is the location of Apra Harbor, the capital Hagåtña, and the tourist center of Tumon. The U.S. Defense Department owns about 29% of the island, under the management of Joint Region Marianas.
### Climate.
Guam has a tropical rainforest climate (Köppen "Af"), though its driest month of March almost averages dry enough to qualify as a tropical monsoon climate (Köppen "Am"). The weather is generally hot and humid throughout the year with little seasonal temperature variation. Hence, Guam is known to have equable temperatures year-round. Trade winds are fairly constant throughout the year, but there is often a weak westerly monsoon influence in summer. Guam has two distinct seasons: Wet and dry season. The dry season runs from January through May and June being the transitional period. The wet season runs from July through November with an average annual rainfall between 1981 and 2010 of around . The wettest month on record at Guam Airport has been August 1997 with and the driest was February 2015 with . The wettest calendar year has been 1976 with and the driest was in 1998 with . The most rainfall in a single day occurred on October 15, 1953, when fell.
The mean high temperature is and mean low is . Temperatures rarely exceed or fall below . The relative humidity commonly exceeds 84 percent at night throughout the year, but the average monthly humidity hovers near 66 percent. The highest temperature ever recorded in Guam was on April 18, 1971, and April 1, 1990. A record low of was set on February 1, 2021, while the lowest recorded temperature was 65 °F (18.3 °C), set on February 8, 1973.
Guam lies in the path of typhoons and it is common for the island to be threatened by tropical storms and possible typhoons during the wet season. The highest risk of typhoons is from August through November, where typhoons and tropical storms are most probable in the western Pacific. They can, however, occur year-round. Typhoons that have caused major damage on Guam in the American period include the Typhoon of 1900, Karen (1962), Pamela (1976), Paka (1997), and Pongsona (2002).
Since Typhoon Pamela in 1976, wooden structures have been largely replaced by concrete structures. During the 1980s, wooden utility poles began to be replaced by typhoon-resistant concrete and steel poles. After the local Government enforced stricter construction codes, many home and business owners built their structures out of reinforced concrete with installed typhoon shutters.
### Ecology.
Guam has experienced severe impacts from invasive species upon the natural biodiversity of the island. These include the local extinction of endemic bird species after the introduction of the brown tree snake, an infestation of the Asiatic rhinoceros beetle destroying coconut palms, and the effect of introduced feral mammals and amphibians.
Wildfires plague the forested areas of Guam every dry season despite the island's humid climate. Most fires are caused by humans with 80% resulting from arson. Poachers often start fires to attract deer to the new growth. Invasive grass species that rely on fire as part of their natural life cycle grow in many regularly burned areas. Grasslands and "barrens" have replaced previously forested areas leading to greater soil erosion. During the rainy season, sediment is carried by the heavy rains into the Fena Lake Reservoir and Ugum River, leading to water quality problems for southern Guam. Eroded silt also destroys the marine life in reefs around the island. Soil stabilization efforts by volunteers and forestry workers (planting trees) have had little success in preserving natural habitats.
Efforts have been made to protect Guam's coral reef habitats from pollution, eroded silt and overfishing, problems that have led to decreased fish populations. This has both ecological and economic value, as Guam is a significant vacation spot for scuba divers, and one study found that Guam's reefs are worth $127 million per year. In recent years, the Department of Agriculture, Division of Aquatic and Wildlife Resources has established several new marine preserves where fish populations are monitored by biologists. These are located at Pati Point, Piti Bomb Holes, Sasa Bay, Achang Reef Flat, and Tumon Bay. Before adopting U.S. Environmental Protection Agency standards, portions of Tumon Bay were dredged by the hotel chains to provide a better experience for hotel guests. Tumon Bay has since been made into a preserve. A federal Guam National Wildlife Refuge in northern Guam protects the decimated sea turtle population in addition to a small colony of Mariana fruit bats.
Harvest of sea turtle eggs was a common occurrence on Guam before World War II. The green sea turtle ("Chelonia mydas") was harvested legally on Guam before August 1978, when it was listed as threatened under the Endangered Species Act. The hawksbill sea turtle ("Eretmochelys imbricata") has been on the endangered list since 1970. In an effort to ensure the protection of sea turtles on Guam, routine sightings are counted during aerial surveys and nest sites are recorded and monitored for hatchlings.
## Demographics.
According to the 2010 United States Census, the largest ethnic group are the native Chamorus, accounting for 37.3% of the total population. Asians (including Filipinos, Koreans, Chinese, and Japanese) account for 33% of the total population. Other ethnic groups of Micronesia (including those of Chuukese, Palauan, and Pohnpeians) accounts for 10% of the total population. 9.4% of the population are multiracial (two or more races). White Americans account for 7.1% of the total population. The estimated interracial marriage rate is over 40%.
The official languages of the island are English and Chamoru. Filipino is also a common language across the island. Other Pacific island languages and many Asian languages are spoken in Guam as well. Spanish, the language of administration for 300 years, is no longer commonly spoken on the island, although vestiges of the language remain in proper names, loanwords, and place names and it is studied at university and high schools.
The most common religion is Catholicism. According to the Pew Research Center, the religious denominations constitute of the following, in 2010:
## Culture.
The culture of Guam is a reflection of traditional Chamoru customs in combination with American, Spanish and Mexican traditions. Post-European-contact Chamoru Guamanian culture is a combination of American, Spanish, Filipino, other Micronesian Islander and Mexican traditions. Few indigenous pre-Hispanic customs remained following Spanish contact. Hispanic influences are manifested in the local language, music, dance, sea navigation, cuisine, fishing, games (such as , , , and ), songs, and fashion. The island's original community is of Chamorro natives who have inhabited Guam for almost 4000 years. They had their own language related to the languages of Indonesia and southeast Asia. The Spanish later called them Chamorros, a derivative of the word Chamorri is "noble race"). They began to grow rice on the island.
Historically, the native people of Guam venerated the bones of their ancestors, keeping the skulls in their houses in small baskets, and practicing incantations before them when it was desired to attain certain objects. During Spanish rule (1668–1898) the majority of the population was converted to Catholicism and religious festivities such as Easter and Christmas became widespread. Many Chamorus have Spanish surnames, although few of the inhabitants are themselves descended from the Spaniards. Instead, Spanish names and surnames became commonplace after their conversion to Catholicism and the imposition of the Catálogo alfabético de apellidos in Guam. Historically, the diet of the native inhabitants of Guam consisted of fish, fowl, rice, breadfruit, taro, yams, bananas, and coconuts used in a variety of dishes. Post-contact CHamoru cuisine is largely based on corn, and includes tortillas, tamales, atole, and chilaquiles, which are a clear influence from Mesoamerica, principally Mexico, from Spanish trade with Asia.
Due to foreign cultural influence from Spain, most aspects of the early indigenous culture have been lost, though there has been a resurgence in preserving any remaining pre-Hispanic culture in the last few decades. Some scholars have traveled throughout the Pacific Islands conducting research to study what the original Chamoru cultural practices such as dance, language, and canoe building may have been like.
### Sports.
Guam's most popular sport is American football, followed by basketball and baseball respectively. Soccer and other sports are also somewhat popular. Guam hosted the Pacific Games in 1975 and 1999. At the 2007 Games, Guam finished 7th of 22 countries in the medal count, and 14th at the 2011 Games.
Guam men's national basketball team and the women's team are traditional powerhouses in the Oceania region, behind the Australia men's national basketball team and the New Zealand national basketball team. , the men's team is the reigning champion of the Pacific Games Basketball Tournament. Guam is home to various basketball organizations, including the Guam Basketball Association.
The Guam national football team was founded in 1975 and joined FIFA in 1996. It was once considered one of FIFA's weakest teams, and experienced their first victory over a FIFA-registered side in 2009. Guam hosted qualifying games on the island for the first time in 2015 and, in 2018, clinched their first FIFA World Cup Qualifying win. The Guam national rugby union team played its first match in 2005 and has never qualified for a Rugby World Cup.
## Economy.
Guam's economy depends primarily on tourism, Department of Defense installations and locally owned businesses. Under the provisions of a special law by Congress, it is Guam's treasury rather than the U.S. treasury that receives the federal income taxes paid by local taxpayers (including military and civilian federal employees assigned to Guam).
### Tourism.
Lying in the western Pacific, Guam is a popular destination for Japanese tourists. Its tourist hub, Tumon, features over 20 large hotels, a Duty Free Shoppers Galleria, Pleasure Island district, indoor aquarium, Sandcastle Las Vegas–styled shows and other shopping and entertainment venues. It is a relatively short flight from Asia or Australia compared to Hawaii, with hotels and seven public golf courses accommodating over a million tourists per year. Although 75% of the tourists are Japanese, Guam also receives a sizable number of tourists from South Korea, the U.S., the Philippines, and Taiwan. Significant sources of revenue include duty-free designer shopping outlets, and the American-style malls: Micronesia Mall, Guam Premier Outlets, the Agana Shopping Center, and the world's largest Kmart.
The economy had been stable since 2000 due to increased tourism. It was expected to stabilize with the transfer of U.S. Marine Corps' 3rd Marine Expeditionary Force, currently in Okinawa, Japan (approximately 8,000 Marines, along with their 10,000 dependents), to Guam between 2010 and 2015. However, the move was delayed until late 2020, the number of marines decreased to 5,000, and expected to be complete in 2025. In 2003, Guam had a 14% unemployment rate, and the government suffered a $314 million shortfall. As of 2019 the unemployment rate had dropped to 6.1%. By September 2020, however, the unemployment rate had risen again to 17.9%.
The Compacts of Free Association between the United States, the Federated States of Micronesia, the Republic of the Marshall Islands, and the Republic of Palau accorded the former entities of the Trust Territory of the Pacific Islands a political status of "free association" with the United States. The Compacts give citizens of these island nations generally no restrictions to reside in the United States (also its territories), and many were attracted to Guam due to its proximity, environmental, and cultural familiarity. Over the years, it was claimed by some in Guam that the territory has had to bear the brunt of this agreement in the form of public assistance programs and public education for those from the regions involved, and the federal government should compensate the states and territories affected by this type of migration. Over the years, Congress had appropriated "Compact Impact" aids to Guam, the Northern Mariana Islands, and Hawaii, and eventually this appropriation was written into each renewed Compact. Some, however, continue to claim the compensation is not enough or that the distribution of actual compensation received is significantly disproportionate. 
 Guam's largest single private sector employer, with about 1,400 jobs, was Continental Micronesia, a subsidiary of Continental Airlines; it is now a part of United Airlines, a subsidiary of Chicago-based United Airlines Holdings, Inc. the Continental Micronesia annual payroll in Guam was $90 million.
### Military bases.
Currently, Joint Region Marianas maintains jurisdiction over installations which cover approximately , or 29% of the island's total land area. These include:
The U.S. military has proposed building a new aircraft carrier berth on Guam and moving 8,600 Marines, and 9,000 of their dependents, to Guam from Okinawa, Japan. Including the required construction workers, this buildup would increase Guam's population by a total of 79,000, a 49% increase over its 2010 population of 160,000. In a February 2010 letter, the United States Environmental Protection Agency sharply criticized these plans because of a water shortfall, sewage problems and the impact on coral reefs. By 2012, these plans had been cut to have only a maximum of 4,800 Marines stationed on the island, two thirds of whom would be there on a rotational basis without their dependents.
## Government and politics.
Guam is governed by a popularly elected governor and a unicameral 15-member legislature, whose members are known as senators. Its judiciary is overseen by the Supreme Court of Guam.
The District Court of Guam is the court of United States federal jurisdiction in the territory. Guam elects one delegate to the United States House of Representatives, currently Democrat Michael San Nicolas. The delegate does not have a vote on the final passage of legislation, but is accorded a vote in committee, and the privilege to speak to the House. U.S. citizens in Guam vote in a presidential straw poll for their choice in the U.S. presidential general election, but since Guam has no votes in the Electoral College, the poll has no real effect. However, in sending delegates to the Republican and Democratic national conventions, Guam does have influence in the national presidential race. These delegates are elected by local party conventions.
### Political status.
In the 1980s and early 1990s, there was a significant movement in favor of this U.S. territory becoming a commonwealth, which would give it a level of self-government similar to Puerto Rico and the Northern Mariana Islands. In a 1982 plebiscite, voters indicated interest in seeking commonwealth status. However, the federal government rejected the version of a commonwealth that the government of Guam proposed, because its clauses were incompatible with the Territorial Clause (Art. IV, Sec. 3, cl. 2) of the U.S. Constitution. Other movements advocate U.S. statehood for Guam, union with the state of Hawaii, or union with the Northern Mariana Islands as a single territory, or independence.
A Commission on Decolonization was established in 1997 to educate the people of Guam about the various political status options in its relationship with the U.S.: statehood, free association and independence. The island has been considering another non-binding plebiscite on decolonization since 1998, however, the group was dormant for some years. In 2013, the commission began seeking funding to start a public education campaign. There were few subsequent developments until late 2016. In early December 2016, the Commission scheduled a series of education sessions in various villages about the current status of Guam's relationship with the U.S. and the self-determination options that might be considered. The commission's current Executive Director is Edward Alvarez and there are ten members. The group is also expected to release position papers on independence and statehood but the contents have not yet been completed.
The United Nations is in favor of greater self-determination for Guam and other such territories. The UN's Special Committee on Decolonization has agreed to endorse the Governor's education plan. The commission's May 2016 report states: "With academics from the University of Guam, [the Commission] was working to create and approve educational materials. The Office of the Governor was collaborating closely with the Commission" in developing educational materials for the public.
The United States Department of the Interior had approved a $300,000 grant for decolonization education, Edward Alvarez told the United Nations Pacific Regional Seminar in May 2016. "We are hopeful that this might indicate a shift in [United States] policy to its Non-Self-Governing Territories such as Guam, where they will be more willing to engage in discussions about our future and offer true support to help push us towards true self-governances and self-determination."
On July 31, 2020, the Government of Guam joined the Unrepresented Nations and Peoples Organization (UNPO).
### Villages.
Guam is divided into 19 municipal villages:
## Transportation and communications.
Most of the island has state-of-the-art mobile phone services and high-speed internet widely available through either cable or DSL. Guam was added to the North American Numbering Plan (NANP) in 1997 (country code 671 became NANP area code 671), removing the barrier of high-cost international long-distance calls to the U.S. mainland.
Guam is also a major hub for submarine cables between the Western U.S., Hawaii, Australia and Asia. Guam currently serves twelve submarine cables, with most continuing to China. In 2012 "Slate" stated that the island has "tremendous bandwidth" and internet prices comparable to those of the U.S. Mainland due to being at the junction of undersea cables.
In 1899, the local postage stamps were overprinted "Guam" as was done for the other former Spanish colonies, but this was discontinued shortly thereafter and regular U.S. postage stamps have been used ever since. Because Guam is also part of the U.S. Postal System (postal abbreviation: GU, ZIP code range: 96910–96932), mail to Guam from the U.S. mainland is considered domestic and no additional charges are required. Private shipping companies, such as FedEx, UPS, and DHL, however, have no obligation to do so, and do not regard Guam as domestic.
The speed of mail traveling between Guam and the states varies depending on size and time of year. Light, first-class items generally take less than a week to or from the mainland, but larger first-class or Priority items can take a week or two. Fourth-class mail, such as magazines, are transported by sea after reaching Hawaii. Most residents use post office boxes or private mail boxes, although residential delivery is becoming increasingly available. Incoming mail not from the Americas should be addressed to "Guam" instead of "USA" to avoid being routed the long way through the U.S. mainland and possibly charged a higher rate (especially from Asia).
The Port of Guam is the island's lifeline because most products must be shipped into Guam for consumers. It receives the weekly calls of the Hawaii-based shipping line Matson, Inc. whose container ships connect Guam with Honolulu, Hawaii, Los Angeles, California, Oakland, California and Seattle, Washington. The port is also the regional transhipment hub for over 500,000 customers throughout the Micronesian region. The port is the shipping and receiving point for containers designated for the island's U.S. Department of Defense installations, Andersen Air Force Base and Commander, Naval Forces Marianas and eventually the Third Marine Expeditionary Force.
Guam is served by the Antonio B. Won Pat International Airport. The island is outside the United States customs zone, so Guam is responsible for establishing and operating its own customs and quarantine agency and jurisdiction. Therefore, the U.S. Customs and Border Protection only carries out immigration (but not customs) functions. Since Guam is under federal immigration jurisdiction, passengers arriving directly from the United States skip immigration and proceed directly to Guam Customs and Quarantine.
However, due to the Guam and CNMI visa waiver program for certain countries, an eligibility pre-clearance check is carried on Guam for flights to the States. For travel from the Northern Mariana Islands to Guam, a pre-flight passport and visa check is performed before boarding the flight to Guam. On flights from Guam to the Northern Mariana Islands, no immigration check is performed. Traveling between Guam and the States through a foreign point, however, does require a passport.
Most residents travel within Guam using personally owned vehicles. The Guam Regional Transit Authority provides fixed route bus and paratransit services, and some commercial companies operate buses between tourist-frequented locations.
## Education.
Guam Public Library System operates the Nieves M. Flores Memorial Library in Hagåtña and five branch libraries.
The Guam Department of Education serves the entire island of Guam. In 2000, 32,000 students attended Guam's public schools, including 26 elementary schools, eight middle schools, and six high schools and alternative schools. Guam Public Schools have struggled with problems such as high dropout rates and poor test scores. Guam's educational system has always faced unique challenges as a small community located from the U.S. mainland with a very diverse student body including many students who come from backgrounds without traditional American education. An economic downturn in Guam since the mid-1990s has compounded the problems in schools.
Before September 1997, the U.S. Department of Defense partnered with Guam Board of Education. In September 1997, the Department of Defense Education Activity (DoDEA) opened its own schools for children of military personnel. DoDEA schools, which also serve children of some federal civilian employees, had an attendance of 2,500 in 2000. DoDEA Guam operates three elementary/middle schools and one high school.
The University of Guam (UOG) and Guam Community College, both fully accredited by the Western Association of Schools and Colleges, offer courses in higher education. UOG is a member of the exclusive group of only 106 land-grant institutions in the entire United States. Pacific Islands University is a small Christian liberal arts institution nationally accredited by the Transnational Association of Christian Colleges and Schools.
## Health care.
The Government of Guam maintains the island's main health care facility, Guam Memorial Hospital, in Tamuning. U.S. board certified doctors and dentists practice in all specialties. In addition, the U.S. Naval Hospital in Agana Heights serves active-duty members and dependents of the military community. There is one subscriber-based air ambulance located on the island, CareJet, which provides emergency patient transportation across Guam and surrounding islands. A private hospital, the Guam Regional Medical City, opened its doors in early 2016.Medicaid is accepted in Guam.

</doc>
<doc id="11976" url="https://en.wikipedia.org/wiki?curid=11976" title="George Washington/First Inaugural Address">
George Washington/First Inaugural Address



</doc>
<doc id="11977" url="https://en.wikipedia.org/wiki?curid=11977" title="George Washington/Second Inaugural Address">
George Washington/Second Inaugural Address



</doc>
<doc id="11978" url="https://en.wikipedia.org/wiki?curid=11978" title="George W">
George W



</doc>
<doc id="11979" url="https://en.wikipedia.org/wiki?curid=11979" title="Game Boy family">
Game Boy family

The Game Boy family is a line of cartridge-based handheld video game consoles developed, manufactured, released and marketed by Nintendo. It comprises three sub families: Classic Game Boy, Game Boy Color and Game Boy Advance.
Excluding Classic Game Boy systems and Game Boy Micro, all devices in the Game Boy family are backwards compatible with every game produced for a previous console in the family with only a few exceptions. Classic Game Boy systems are forwards compatible with all black cartridge Game Boy Color games, but will not display them in color. This was accomplished through use of cartridges with similar hardware on later consoles in the family.
The Game Boy line was succeeded by the Nintendo DS line. A number of Game Boy, Game Boy Color, and Game Boy Advance games have been rereleased digitally through the Virtual Console service for the Nintendo 3DS and Wii U.
The original and Game Boy Color combined sold 118.69 million units worldwide. All versions of the Game Boy Advance family combined have sold 81.51 million units. All Game Boy systems combined have sold 200.20 million units worldwide.
## History.
Nintendo's Game Boy handheld was first released in 1989. The gaming device was the brainchild of long-time Nintendo employee Gunpei Yokoi, who was the person behind the "Ultra Hand", an expanding arm toy created and produced by Nintendo in 1970, long before Nintendo would enter the video game market. Yokoi was also responsible for the Game &amp; Watch series of handhelds when Nintendo made the move from toys to video games.
When Yokoi designed the original Game Boy, he knew that to be successful, the system needed to be small, light, inexpensive, and durable, as well as have a varied, recognizable library of games upon its release. By following this simple mantra, the Game Boy line managed to gain a vast following despite technically superior alternatives which would have color graphics instead. This is also apparent in the name (conceived by Shigesato Itoi), which connotes a smaller "sidekick" companion to Nintendo's consoles.
Game Boy continues its success to this day and many at Nintendo have dedicated the handheld in Yokoi's memory. Game Boy celebrated its 15th anniversary in 2004, which nearly coincided with the 20-year anniversary of the original Nintendo Entertainment System (NES). To celebrate, Nintendo released the Classic NES Series and an NES controller-themed color scheme for the Game Boy Advance SP.
In 2006, Nintendo president Satoru Iwata said on the rumored demise of the Game Boy brand: "No, it's not true after all. What we are repeatedly saying is that for whichever platform, we are always conducting research and development for the new system, be it the Game Boy, or new console or whatever. And what we just told the reporter was that in thinking about the current situation where we are enjoying great sales with the DS and that we are now trying to launch the Wii, it's unthinkable for us to launch any new platform for the handheld system, including the new version of the GBA... Perhaps they misunderstood a part of this story, but as far as the handheld market is concerned [right now] we really want to focus on more sales of the DS; that's all" until Nintendo ceased the production of the Game Boy Advance games and handheld system in North America on May 15, 2010.
## Classic Game Boy family.
### Game Boy.
The original gray Game Boy was first released in Japan on April 21, 1989. Based on a Z80 processor, it has a black and green reflective LCD screen, an eight-way directional pad, two action buttons (A and B), and Start and Select buttons with the controls being identical to the NES controller. It plays games from ROM-based media contained in cartridges (sometimes called carts or Game Paks). Its graphics are 8-bit (similar to the NES).
The game that pushed the Game Boy into the upper reaches of success was "Tetris". Tetris was widely popular, and on the handheld format could be played anywhere. It came packaged with the Game Boy, and broadened its reach; adults and children alike were buying Game Boys in order to play "Tetris". Releasing "Tetris" on the Game Boy was selected as #4 on GameSpy's "25 Smartest Moments in Gaming".
The original Game Boy was one of the first cartridge-based systems that supported networking: two devices with a Game Link Cable, or up to four with the Four Player Adapter.
In 1995, the "Play it Loud" version of the original Game Boy was released in six different colors; black, red, yellow, green, blue, white and clear as well as additional sports-themed editions.
### Game Boy Pocket.
The Game Boy Pocket is a redesigned version of the original Game Boy having the same features. It was released in 1996. Notably, this variation is smaller and lighter. It comes in seven different colors; red, yellow, green, black, clear, silver, blue, and pink.
Another notable improvement over the original Game Boy is a black-and-white display screen, rather than the green-tinted display of the original Game Boy, that also featured improved response time for less blurring during motion. The Game Boy Pocket takes two AAA batteries as opposed to four AA batteries for roughly ten hours of gameplay. The first model of the Game Boy Pocket did not have an LED to show battery levels, but the feature was added due to public demand.
### Game Boy Light.
In April 1998, a variant of the Game Boy Pocket named Game Boy Light was exclusively released in Japan. The differences between the original Game Boy Pocket and the Game Boy Light is that the Game Boy Light takes on two AA batteries for approximately 20 hours of gameplay (when playing without using the light), rather than two AAA batteries, and it has an electroluminescent screen that can be turned on or off. This electroluminescent screen gave games a blue-green tint and allowed the use of the unit in darkened areas. Playing with the light on would allow about 12 hours of play. The Game Boy Light also comes in six different colors; silver, gold, yellow for the "Pokémon" edition, translucent yellow, clear and translucent red for the "Astro Boy" edition. The Game Boy Light was superseded by the Game Boy Color six months later and was the only Game Boy to have a backlit screen until the release of the Game Boy Advance SP AGS-101 model in 2005.
## Game Boy Color family.
### Game Boy Color.
First released in Japan on October 21, 1998, the Game Boy Color (abbreviated as GBC) added a (slightly smaller) color screen to a form factor similar in size to the Game Boy Pocket. It also has double the processor speed, three times as much memory, and an infrared communications port. Technologically, it was likened to the 8-bit NES video game console from the 1980s although the Game Boy Color has a much larger color palette (56 simultaneous colors out of 32,768 possible) which had some classic NES ports and newer titles. It comes in six different colors; Atomic purple, indigo, berry (red), kiwi (green), dandelion (yellow) and teal. The Game Boy Color also has several special edition variants such as the yellow and silver Pokémon special editions or the Tommy Hilfiger yellow special edition. Like the Game Boy Light, the Game Boy Color takes on two AA batteries. It was the final handheld to have 8-bit graphics and to have a vertical shape.
A major component of the Game Boy Color is its near-universal backward compatibility; that is, a Game Boy Color is able to read older Game Boy cartridges and even play them in a selectable color palette (similar to the Super Game Boy). The only black and white Game Boy games known to be incompatible are "Road Rash" and "Joshua &amp; the Battle of Jericho". Backwards compatibility became a major feature of the Game Boy line, since it allowed each new launch to begin with a significantly larger library than any of its competitors. Some games written specifically for the Game Boy Color can be played on older model Game Boys, whereas others cannot (see the Game Paks section for more information).
## Game Boy Advance family.
### Game Boy Advance.
In Japan, on March 21, 2001, Nintendo released a significant upgrade to the Game Boy line. The Game Boy Advance (also referred to as GBA) featured a 32 bit 16.8 MHz ARM. It included a Z80 processor and a switch activated by inserting a Game Boy or Game Boy Color game into the slot for backward compatibility, and had a larger, higher resolution screen. Controls were slightly modified with the addition of "L" and "R" shoulder buttons. Like the Game Boy Light and Game Boy Color, the Game Boy Advance takes on two AA batteries. The system was technically likened to the SNES and showed its power with successful ports of SNES titles such as "Super Mario World", ', ' and "Donkey Kong Country". There were also new titles that could be found only on the GBA, such as ', ', "Wario Land 4", "" and more. A widely criticized drawback of the Game Boy Advance is that the screen is not backlit, making viewing difficult in some conditions. The Game Paks for the GBA are roughly half the length of original Game Boy cartridges and Game Boy Color cartridges, and so older Game Paks would stick out of the top of the unit. When playing older games, the GBA provides the option to play the game at the standard equal square resolution of the original screen or the option to stretch it over the wider GBA screen. The selectable color palettes for the original Game Boy games are identical to what it was on the Game Boy Color. The only Game Boy Color games known to be incompatible are "Pocket Music" and "Chee-Chai Alien". It was the final handheld to require regular batteries and to lack a backlit screen.
### Game Boy Advance SP.
First released in Japan on February 14, 2003, the Game Boy Advance SP—Nintendo model AGS-001—resolved several problems with the original Game Boy Advance model. It featured a new smaller clamshell design with a flip-up screen, a switchable internal frontlight, a rechargeable battery for the first time, and the only notable issue is the omission of the headphone jack, which requires a special adapter, purchased separately. In September 2005, Nintendo released the Game Boy Advance SP model AGS-101, that featured a high quality backlit screen instead of a frontlit, similar to the Game Boy Micro screen but larger. It was the final Game Boy and last handheld to have backwards compatibility with Game Boy and Game Boy Color games.
### Game Boy Micro.
The third form of Game Boy Advance system, the Game Boy Micro is four and a half inches wide (10 cm), two inches tall (5 cm), and weighs 2.8 ounces (80 g). By far the smallest Game Boy created, it has approximately the same dimensions as an original NES controller pad. Its screen is approximately 2/3 the size of the SP and GBA screens while maintaining the same resolution (240×160 pixels) but boasted a higher quality backlit display with adjustable brightness. Included with the system are two additional faceplates which can be swapped to give the system a new look; Nintendo of America sold additional faceplates on its online store. In Europe, the Game Boy Micro comes with a single faceplate. In Japan, a special "Mother 3" limited edition Game Boy Micro was released with the game in the "Mother 3 Deluxe Box". Unlike the Game Boy Advance and Game Boy Advance SP, the Game Boy Micro is unable to play any original Game Boy or Game Boy Color games, only playing Game Boy Advance titles (with the exception of the Nintendo e-Reader, discontinued in America, but still available in Japan).
## Game Paks.
Each video game is stored on a plastic cartridge, officially called a "Game Pak" by Nintendo. All cartridges, excluding those for Game Boy Advance, measure 5.8 by 6.5 cm. The cartridge provides the code and game data to the console's CPU. Some cartridges include a small battery with SRAM, flash memory chip, or EEPROM, which allows game data to be saved when the console is turned off. If the battery runs out in a cartridge, then the save data will be lost, however, it is possible to replace the battery with a new battery. To do this, the cartridge must be unscrewed, opened up, and the old battery would be removed and replaced. This may require desoldering the dead battery and soldering the replacement in place. Before 2003, Nintendo used round, flat watch batteries for saving information on the cartridges. These batteries were replaced in newer cartridges because they could only live for a certain amount of time.
The cartridge is inserted into the console cartridge slot. If the cartridge is removed while the power is on, and the Game Boy does not automatically reset, the game freezes; the Game Boy may exhibit unexpected behavior, such as rows of zeros appearing on the screen, the sound remaining at the same pitch as was emitted the instant the game was pulled out, saved data may be corrupted, and hardware may be damaged. This applies to most video game consoles that use cartridges.
The original Game Boy power switch was designed to prevent the player from being able to remove the cartridge while the power is on. Cartridges intended only for Game Boy Color (and not for the original Game Boy) lack the "notch" for the locking mechanism present in the top of the original cartridges, preventing operation on an original Game Boy (the cartridge can be inserted, but the power switch cannot be moved to the "on" position). Even if this was bypassed by using a Game Boy Pocket, Game Boy Light, or Super Game Boy (and its Japanese-only follow-up), the game would not run, and an image on the screen would inform the user that the game is only compatible with Game Boy Color systems. One exception would be the Kirby Tilt 'n' Tumble game: despite the game cartridge featuring a notch, enabling it to be inserted on the original Game Boy, the game displays an error message indicating that it only plays on Game Boy Color. "Chee Chai Alien" and "Pocket Music" are incompatible with Game Boy Advance models, displaying an error message indicating that they only play on Game Boy Color.
Game Boy Advance cartridges used a similar physical lock-out feature. Notches were located at the base of the cartridge's two back corners. One of these notches was placed as to avoid pressing a switch inside the cartridge slot to help stabilize it. When an older Game Boy or Game Boy Color game was inserted into the cartridge slot, the switch would be pressed down and the Game Boy Advance would start in Game Boy Color mode, while a Game Boy Advance cartridge would not touch the switch and the system would start in Game Boy Advance mode. The Nintendo DS replaced the switch with a solid piece of plastic that would allow Game Boy Advance cartridges to be inserted into Slot 2, but would prevent an older Game Boy or Game Boy Color cartridge from being inserted fully into the slot.
Excluding game-specific variations, there are four types of cartridges compatible with Game Boy systems:
### Grey cartridges.
Grey cartridges (also known as class A) are compatible with all Game Boy systems, excluding Game Boy Micro. All original Game Boy games are of this type. Some of these cartridges are in alternative colors, such as red or blue for "Pokémon Red" and "Blue", and yellow for the "Donkey Kong Land" series. The games on these cartridges are programmed in black and white; the Game Boy Color and later systems provide selectable color palettes for them. Some grey cartridges that were released between 1994 and 1998 have Super Game Boy enhancements. Even fewer grey cartridges were released with built-in features that made them protrude from the slot, but included the notch to be compatible with the original Game Boy (notably the "Game Boy Camera")
### Black cartridges.
Black cartridges (also known as class B or Dual Mode) are compatible with all Game Boy systems, excluding Game Boy Micro. Although the games on these cartridges are programmed in color, they can still be played in monochrome on Game Boy, Game Boy Pocket, Game Boy Light and Super Game Boy (and its Japanese follow-up). Examples of black-cartridge games are ', "Pokémon Gold" and "Silver" (however, the actual colors of these three cartridges are yellow, gold, and silver, respectively). Games such as "Wario Land II" and ' were full-color re-releases of gray-cartridge games but with additional content only available on the Game Boy Color. Some black cartridges have Super Game Boy enhancements. Even some games had built-in features similar to what the later clear cartridges did, like rumble features ("Pokémon Pinball") and infrared receiver ("Robopon Sun, Star, and Moon Versions").
### Clear cartridges.
Clear cartridges (also known as class C) are compatible with Game Boy Color and the Game Boy Advance systems, excluding Game Boy Micro. Some games (such as "Pokémon Crystal") were released in specially colored cartridges, as had been done before, but the new colors remained translucent. Some clear cartridges have built-in features, including rumble features ("Perfect Dark") and tilt sensors ("Kirby Tilt 'n' Tumble"). These cartridges are a slightly different shape from the earlier varieties, and would obstruct the latch if inserted into the original Game Boy. Unlike the Gray cartridges and Black cartridges, the Clear cartridges cannot be played on a Game Boy Pocket, a Game Boy Light or on Super Game Boy (or even its Japanese follow-up). Some class C cartridges (European version of "") used a solid cartridge design, like in Class B.
### Advance cartridges.
Advance cartridges (also known as class D) are half the size of all earlier cartridges and are compatible with Game Boy Advance and later systems including the Nintendo DS. Some cartridges are colored to resemble the game (usually for the "Pokémon" series; "Pokémon Emerald", for example, being a clear emerald green). They are also compatible with Nintendo DS and DS Lite (but see the Reception section for limitations). Some Advance cartridges have built-in features, including rumble features ("Drill Dozer"), tilt sensors ("", "Yoshi's Universal Gravitation") and solar sensors ("Boktai").
## Accessories.
### Stand alone devices.
The Game Boy, as with many other consoles, has had a number of releases from both first-party and unlicensed third-party accessories. The most notable were the Game Boy Camera (left) and the Game Boy Printer (right), both released in 1998.
### Television adapters.
In addition to the Game Boy, special hardware has been released for various handhelds in the Game Boy line so they can be played on a television set.
#### Super Game Boy.
In 1994, a special adapter cartridge for Nintendo's Super Nintendo Entertainment System (SNES) was released called the Super Game Boy. The Super Game Boy allows game cartridges designed for use on the Game Boy to be played on a TV display using the SNES/Super Famicom controllers. When it was released in 1994, the Super Game Boy sold for about $60 in the United States. In the United Kingdom, it retailed for £49.99. The Super Game Boy's technical architecture is similar to that of a regular Game Boy, thus Game Boy games functioned on the native hardware rather than being emulated by the SNES. It was the precursor to the Game Boy Player on the Nintendo GameCube, which functioned in a similar manner.
#### Super Game Boy 2.
A follow-up of the Super Game Boy, the Super Game Boy 2 was released only in Japan in 1998. The border is similar to that of actual Game Boy Pocket hardware, but it includes an actual link cable port, and the clock speed is slowed down to match that of the Game Boy.
#### Game Boy Player.
The Game Boy Player is a device released in 2003 by Nintendo for the GameCube which enables Game Boy (although Super Game Boy enhancements are ignored), Game Boy Color, or Game Boy Advance cartridges to be played on a television. It connects via the high speed parallel port at the bottom of the GameCube and requires use of a boot disc to access the hardware. Unlike devices such as Datel's Advance Game Port, the Game Boy Player does not use software emulation, but instead uses physical hardware nearly identical to that of a Game Boy Advance.
## Reception.
Approximately two thousand games are available for the Game Boy, which can be attributed in part to its sales in the amount of millions, a well-documented design, and a typically short development cycle.
The Nintendo DS and Nintendo DS Lite are able to play the large library of Game Boy Advance games (though the Nintendo DSi, Nintendo DSi XL, Nintendo 3DS, and Nintendo 2DS lack a GBA game cartridge slot). However, the DS consoles do not have a GBA game link connector, and so cannot play multiplayer GBA games (except for the few that are multiplayer on a single GBA) or link to the GameCube. The DS is not backward-compatible with Game Paks for the original Game Boy or the Game Boy Color. With homebrew development on the Nintendo DS, full speed Game Boy and Game Boy Color emulation has been achieved as well as the ability to scale the smaller Game Boy screen image to the full DS screen.
### Legacy.
Numerous musical acts have appropriated the Game Boy as a musical instrument (Game Boy music), using software such as nanoloop or Little Sound DJ.
Certain games released for the Game Boy and Game Boy Color handheld consoles are available via the Virtual Console service on the Nintendo 3DS. Game Boy Advance games were thought to be as well due to the 3DS not being compatible, but it was just a mistranslation. However, ten Game Boy Advance games were released for Nintendo 3DS ambassadors, as in Nintendo 3DS owners who logged into the 3DS eShop before the major August 2011 price drop. The Virtual Console GBA features of releases are limited, and there are no plans to release them to the public. However, starting from April 2014, Nintendo has been releasing Game Boy Advance games as Virtual Console titles via the Nintendo eShop for the Wii U.

</doc>
<doc id="11980" url="https://en.wikipedia.org/wiki?curid=11980" title="Geologic age">
Geologic age



</doc>
<doc id="11981" url="https://en.wikipedia.org/wiki?curid=11981" title="Green alga">
Green alga



</doc>
<doc id="11982" url="https://en.wikipedia.org/wiki?curid=11982" title="Gemini 10">
Gemini 10

Gemini 10 (officially Gemini X) was a 1966 crewed spaceflight in NASA's Gemini program. It was the 8th crewed Gemini flight, the 16th crewed American flight, and the 24th spaceflight of all time (includes X-15 flights over ). During the mission, flown by John Young and future Apollo 11 Command Module Pilot Michael Collins, Collins became the first person to perform two extravehicular activities.
## Crew.
### Support crew.
Jim Lovell and Buzz Aldrin had originally been named the backup crew, but after Charles Bassett and Elliot See died in a T-38 crash, they were moved to the backup crew for Gemini 9 and Alan Bean and Clifton Williams were moved to the Gemini 10 flight.
## Objectives.
Gemini 10 was designed to achieve rendezvous and docking with an Agena Target Vehicle (ATV), and EVA. It was also planned to dock with the ATV from the Gemini 8 mission. This Agena's battery power had failed months earlier, and an approach and docking would demonstrate the ability to rendezvous with a passive object. It would be also the first mission to fire the Agena's own rocket, allowing them to reach higher orbits.
Gemini 10 established that radiation at high altitude was not a problem. After docking with their Agena booster in low orbit, Young and Collins used it to climb temporarily to . After leaving the first Agena, they then rendezvoused with the derelict Agena left over from the aborted Gemini 8 flight—thus executing the program's first double rendezvous. With no electricity on board the second Agena, the rendezvous was accomplished with eyes only—no radar.
After the rendezvous, Collins spacewalked over to the dormant Agena at the end of a tether, making him the first person to meet another spacecraft in orbit. Collins then retrieved a cosmic dust-collecting panel from the side of the Agena. As he was concentrating on keeping his tether clear of the Gemini and Agena, Collins' Hasselblad camera worked itself free and drifted away, so he was unable to take photographs during the spacewalk.
## Flight.
The Agena launched perfectly for the second time, after problems had occurred with the targets for Gemini 6 and 9. Gemini 10 followed 100 minutes later and entered a orbit. They were behind the Agena. Two anomalous events occurred during the launch. At liftoff, a propellant fill umbilical became snared with its release lanyard. It ripped out of the LC-19 service tower and remained attached to the second stage during ascent. Tracking camera footage also showed that the first stage oxidizer tank dome ruptured after staging and released a cloud of nitrogen tetroxide. The telemetry package on the first stage had been disabled at staging, so visual evidence was the only data available. Film review of the Titan II ICBM launches found at least seven other instances of post-staging tank ruptures, most likely caused by flying debris, second stage engine exhaust, or structural bending. NASA finally decided that this phenomenon did not pose any safety risk to the astronauts and took no corrective action.
### First rendezvous.
Collins was unable to use the sextant for navigation as it did not seem to work as expected. At first he mistook airglow as the real horizon when trying to make some fixes on stars. When the image didn't seem right he tried another instrument, but this was not practical to use as it had a very small field of view.
They had a backup in the form of the computers on the ground. They made their first burn to put them into a orbit. However Young didn't realize that during the next burn, he had the spacecraft turned slightly, which meant that they introduced an out-of-plane error. This meant two extra burns were necessary, and by the time they had docked with the Agena, 60% of their fuel had been consumed. It was decided to keep the Gemini docked to the Agena as long as possible, as this would mean that they could use the fuel on board the Agena for attitude control.
The first burn of the Agena engine lasted 80 seconds and put them in a orbit. This was the highest a person had ever been, although the record was soon surpassed by Gemini 11, which went to over . This burn was quite a ride for the crew. Because the Gemini and Agena docked nose-to-nose, the forces experienced were "eyeballs out" as opposed to "eyeballs in" for a launch from Earth. The crew took a couple of pictures when they reached apogee but were more interested in what was going on in the spacecraft — checking the systems and watching the radiation dosage meter.
After this they had their sleep period which lasted for eight hours and then they were ready for another busy day. The crew's first order of business was to make a second burn with the Agena engine to put them into the same orbit as the Gemini 8 Agena. This was at 20:58 UTC on July 19 and lasted 78 seconds and took off their speed, putting them into a orbit. They made one more burn of the Agena to circularize their orbit to .
### EVA 1.
The first of two EVAs on Gemini 10 was a standup EVA, where Collins would stand in the open hatch and take photographs of stars as part of experiment S-13. They used a 70 mm general purpose camera to image the southern Milky Way in ultraviolet. After orbital sunrise Collins photographed a color plate on the side of the spacecraft (MSC-8) to see whether film reproduced colors accurately in space. He reentered the spacecraft six minutes early when both astronauts found that their eyes were irritated, which was caused by a minor leak of lithium hydroxide in the astronauts' oxygen supply. After repressurizing the cabin, they ran the oxygen at high rates and flushed the environment system.
After the exercise of the EVA Young and Collins slept in their second 'night' in space. The next 'morning' they started preparing for the second rendezvous and another EVA.
### Second rendezvous.
After undocking from their Agena, the crew thought they sighted the Gemini 8 Agena. It however turned out to be their own Agena away, while their target was away. It wasn't until just over away that they saw it as a faint star. After a few more correction burns, they were station-keeping away from the Gemini 8 Agena. They found the Agena to be very stable and in good condition.
### EVA 2.
At 48 hours and 41 minutes into the mission, the second EVA began. Collins' first task was to retrieve a Micrometeorite Collector (S-12) from the side of the spacecraft. This he accomplished with some difficulty (similar to that encountered by Eugene Cernan on Gemini 9A). The collector floated out of the cabin at some time during the EVA, and was lost.
Collins next traveled over to the Agena and tried to grab onto the docking cone but found this impossible as it was smooth and had no grip. He used a nitrogen-propelled Hand-Held Maneuvering Unit (HHMU) to move himself towards the Gemini and then back to the Agena. This time he was able to grab hold of some wire bundles and retrieved the Micrometeorite Collector (S-10) from the Agena. He decided against replacing it as a piece of shroud had come loose on the Agena which could have snared the umbilical, and returning to the Gemini was deemed the safest course of action.
The last tasks remaining on this EVA were to test out the HHMU, test orbital mechanics using a tether between the Gemini and Agena, and for Young in the spacecraft to translate over to a passive Collins. However, due to low propellant quantity remaining, combined with intermittent telemetry to monitor it, these fuel costly manoeuvres were abandoned and the EVA was finished after only 39 minutes. During this time, it took the crew eight minutes to close the hatch as they had some difficulty with the umbilical. It was jettisoned along with the chestpack used by Collins an hour later when they opened the hatch for the third and final time.
### Experiments.
There were ten other experiments that the crew performed during the mission. Three were interested in radiation: MSC-3 was the Tri-Axis Magnetometer which measured levels in the South Atlantic Anomaly. There was also MSC-6, a beta spectrometer, which measured potential radiation doses for Apollo missions, and MSC-7, a bremsstrahlung spectrometer which detected radiation flux as a function of energy when the spacecraft passed through the South Atlantic Anomaly.
S-26 investigated the ion and electron wake of the spacecraft. This provided limited results due to the lack of fuel for attitude control, but found that electron and ion temperatures were higher than expected and it registered shock effects during docking and undocking.
The S-5 and S-6 experiments were performed, which were previously carried on Gemini 9A; these were Synoptic Terrain and Synoptic Weather photography respectively. There was also S-1 which was intended to image the Zodiacal light. All of these experiments were of little use as the film used was only half as sensitive as Gemini 9A and the dirty windows lowered the transmission of light by a factor of six.
The crew also tried to perform D-5, a navigation experiment. They were only able to track five stars, with six needed for accurate measurements. The last experiment, D-10, was to investigate an ion-sensing attitude control system. This experiment measured the attitude of the spacecraft from the flow of ions and electrons around the spacecraft in orbit. The results from this experiment showed the system to be accurate and responsive.
### Re-entry.
The last day of the mission was short and retrofire came at 70 hours and 10 minutes into the mission. They landed only away from the intended landing site and were recovered by .
The Gemini 10 mission was supported by the following U.S. Department of Defense resources: 9,067 personnel, 78 aircraft and 13 ships.
## Insignia.
The patch is simple in design but highly symbolic. The main feature is a large X with a Gemini and Agena orbiting around it. The two stars have a variety of meanings: the two rendezvous attempts, Castor and Pollux in Gemini or the two crew members. This is one of the few crew patches without the crew's name. It is able to be displayed "upside down" but is correctly shown with the spacecraft to the right. It was designed by Young's first wife, Barbara.
## Spacecraft location.
For many years the spacecraft was the centerpiece of a space exhibition at Norsk Teknisk Museum, Oslo, Norway. It was returned on request in 2002.
The spacecraft is currently on display at the Cosmosphere in Hutchinson, Kansas.

</doc>
<doc id="11984" url="https://en.wikipedia.org/wiki?curid=11984" title="Gardening">
Gardening

Gardening is the practice of growing and cultivating plants as part of horticulture. In gardens, ornamental plants are often grown for their flowers, foliage, or overall appearance; useful plants, such as root vegetables, leaf vegetables, fruits, and herbs, are grown for consumption, for use as dyes, or for medicinal or cosmetic use.
Gardening ranges in scale from fruit orchards, to long boulevard plantings with one or more different types of shrubs, trees, and herbaceous plants, to residential back gardens including lawns and foundation plantings, and to container gardens grown inside or outside. Gardening may be very specialized, with only one type of plant grown, or involve a variety of plants in mixed plantings. It involves an active participation in the growing of plants, and tends to be labor-intensive, which differentiates it from farming or forestry.
## History.
### Ancient times.
Forest gardening, a forest-based food production system, is the world's oldest form of gardening. Forest gardens originated in prehistoric times along jungle-clad river banks and in the wet foothills of monsoon regions. In the gradual process of families improving their immediate environment, useful tree and vine species were identified, protected and improved while undesirable species were eliminated. Eventually foreign species were also selected and incorporated into the gardens.
After the emergence of the first civilizations, wealthy individuals began to create gardens for aesthetic purposes. Ancient Egyptian tomb paintings from the New Kingdom (around 1500 BC) provide some of the earliest physical evidence of ornamental horticulture and landscape design; they depict lotus ponds surrounded by symmetrical rows of acacias and palms. A notable example of ancient ornamental gardens were the Hanging Gardens of Babylon—one of the Seven Wonders of the Ancient World —while ancient Rome had dozens of gardens.
Wealthy ancient Egyptians used gardens for providing shade. Egyptians associated trees and gardens with gods, believing that their deities were pleased by gardens. Gardens in ancient Egypt were often surrounded by walls with trees planted in rows. Among the most popular species planted were date palms, sycamores, fig trees, nut trees, and willows. These gardens were a sign of higher socioeconomic status. In addition, wealthy ancient Egyptians grew vineyards, as wine was a sign of the higher social classes. Roses, poppies, daisies and irises could all also be found in the gardens of the Egyptians.
Assyria was also renowned for its beautiful gardens. These tended to be wide and large, some of them used for hunting game—rather like a game reserve today—and others as leisure gardens. Cypresses and palms were some of the most frequently planted types of trees.
Gardens were also available in Kush. In Musawwarat es-Sufra, the Great Enclosure dated to the 3rd century BC included splendid gardens.
Ancient Roman gardens were laid out with hedges and vines and contained a wide variety of flowers—acanthus, cornflowers, crocus, cyclamen, hyacinth, iris, ivy, lavender, lilies, myrtle, narcissus, poppy, rosemary and violets—as well as statues and sculptures. Flower beds were popular in the courtyards of rich Romans.
### The Middle Ages.
The Middle Ages represent a period of decline in gardens for aesthetic purposes. After the fall of Rome, gardening was done for the purpose of growing medicinal herbs and/or decorating church altars. Monasteries carried on a tradition of garden design and intense horticultural techniques during the medieval period in Europe. 
Generally, monastic garden types consisted of kitchen gardens, infirmary gardens, cemetery orchards, cloister garths and vineyards. Individual monasteries might also have had a "green court", a plot of grass and trees where horses could graze, as well as a cellarer's garden or private gardens for obedientiaries, monks who held specific posts within the monastery.
Islamic gardens were built after the model of Persian gardens and they were usually enclosed by walls and divided in four by watercourses. Commonly, the centre of the garden would have a reflecting pool or pavilion. Specific to the Islamic gardens are the mosaics and glazed tiles used to decorate the rills and fountains that were built in these gardens.
By the late 13th century, rich Europeans began to grow gardens for leisure and for medicinal herbs and vegetables. They surrounded the gardens by walls to protect them from animals and to provide seclusion. During the next two centuries, Europeans started planting lawns and raising flowerbeds and trellises of roses. Fruit trees were common in these gardens and also in some, there were turf seats. At the same time, the gardens in the monasteries were a place to grow flowers and medicinal herbs but they were also a space where the monks could enjoy nature and relax.
The gardens in the 16th and 17th century were symmetric, proportioned and balanced with a more classical appearance. Most of these gardens were built around a central axis and they were divided into different parts by hedges. Commonly, gardens had flowerbeds laid out in squares and separated by gravel paths.
Gardens in Renaissance were adorned with sculptures, topiary and fountains. In the 17th century, knot gardens became popular along with the hedge mazes. By this time, Europeans started planting new flowers such as tulips, marigolds and sunflowers.
### Cottage gardens.
Cottage gardens, which emerged in Elizabethan times, appear to have originated as a local source for herbs and fruits. One theory is that they arose out of the Black Death of the 1340s, when the death of so many laborers made land available for small cottages with personal gardens. According to the late 19th-century legend of origin, these gardens were originally created by the workers that lived in the cottages of the villages, to provide them with food and herbs, with flowers planted among them for decoration. Farm workers were provided with cottages that had architectural quality set in a small garden—about —where they could grow food and keep pigs and chickens.
Authentic gardens of the yeoman cottager would have included a beehive and livestock, and frequently a pig and sty, along with a well. The peasant cottager of medieval times was more interested in meat than flowers, with herbs grown for medicinal use rather than for their beauty. By Elizabethan times there was more prosperity, and thus more room to grow flowers. Even the early cottage garden flowers typically had their practical use—violets were spread on the floor (for their pleasant scent and keeping out vermin); calendulas and primroses were both attractive and used in cooking. Others, such as sweet William and hollyhocks, were grown entirely for their beauty.
### 18th century.
In the 18th century gardens were laid out more naturally, without any walls. This style of smooth undulating grass, which would run straight to the house, clumps, belts and scattering of trees and his serpentine lakes formed by invisibly damming small rivers, were a new style within the English landscape, a "gardenless" form of landscape gardening, which swept away almost all the remnants of previous formally patterned styles. The English landscape garden usually included a lake, lawns set against groves of trees, and often contained shrubberies, grottoes, pavilions, bridges and follies such as mock temples, Gothic ruins, bridges, and other picturesque architecture, designed to recreate an idyllic pastoral landscape. This new style emerged in England in the early 18th century, and spread across Europe, replacing the more formal, symmetrical garden à la française of the 17th century as the principal gardening style of Europe. The English garden presented an idealized view of nature. They were often inspired by paintings of landscapes by Claude Lorraine and Nicolas Poussin, and some were Influenced by the classic Chinese gardens of the East, which had recently been described by European travelers. The work of Lancelot 'Capability' Brown was particularly influential. Also, in 1804 the Horticultural Society was formed.
Gardens of the 19th century contained plants such as the monkey puzzle or Chile pine. This is also the time when the so-called "gardenesque" style of gardens evolved. These gardens displayed a wide variety of flowers in a rather small space. Rock gardens increased in popularity in the 19th century.
## Types.
Residential gardening takes place near the home, in a space referred to as the garden. Although a garden typically is located on the land near a residence, it may also be located on a roof, in an atrium, on a balcony, in a windowbox, on a patio or vivarium.
Gardening also takes place in non-residential green areas, such as parks, public or semi-public gardens (botanical gardens or zoological gardens), amusement parks, along transportation corridors, and around tourist attractions and garden hotels. In these situations, a staff of gardeners or groundskeepers maintains the gardens.
## Social aspects.
People can express their political or social views in gardens, intentionally or not. The lawn vs. garden issue is played out in urban planning as the debate over the "land ethic" that is to determine urban land use and whether hyper hygienist bylaws (e.g. weed control) should apply, or whether land should generally be allowed to exist in its natural wild state. In a famous Canadian Charter of Rights case, "Sandra Bell vs. City of Toronto", 1997, the right to cultivate all native species, even most varieties deemed noxious or allergenic, was upheld as part of the right of free expression.
Community gardening comprises a wide variety of approaches to sharing land and gardens.
People often surround their house and garden with a hedge. Common hedge plants are privet, hawthorn, beech, yew, leyland cypress, hemlock, arborvitae, barberry, box, holly, oleander, forsythia and lavender. The idea of open gardens without hedges may be distasteful to those who enjoy privacy.
The Slow Food movement has sought in some countries to add an edible school yard and garden classrooms to schools, e.g. in Fergus, Ontario, where these were added to a public school to augment the kitchen classroom. Garden sharing, where urban landowners allow gardeners to grow on their property in exchange for a share of the harvest, is associated with the desire to control the quality of one's food, and reconnect with soil and community.
In US and British usage, the production of ornamental plantings around buildings is called "landscaping", "landscape maintenance" or "grounds keeping", while international usage uses the term "gardening" for these same activities.
Also gaining popularity is the concept of "Green Gardening" which involves growing plants using organic fertilizers and pesticides so that the gardening process – or the flowers and fruits produced thereby – doesn't adversely affect the environment or people's health in any manner.
## Benefits.
Gardening is considered by many people to be a relaxing activity. There are also many studies about the positive effects on mental and physical health in relation to gardening. Specifically, gardening is thought to increase self-esteem and reduce stress. As writer and former teacher Sarah Biddle notes, one's garden may become a "tiny oasis to relax and recharge [one's] batteries."
## Comparison with farming.
Gardening for beauty is likely nearly as old as farming for food, however for most of history for the majority of people there was no real distinction since the need for food and other useful products trumped other concerns. Small-scale, subsistence agriculture (called hoe-farming) is largely indistinguishable from gardening. A patch of potatoes grown by a Peruvian peasant or an Irish smallholder for personal use could be described as either a garden or a farm. Gardening for average people evolved as a separate discipline, more concerned with aesthetics, recreation and leisure,
under the influence of the pleasure gardens of the wealthy. Meanwhile, farming has evolved (in developed countries) in the direction of commercialization, economics of scale, and monocropping.
In respect to its food-producing purpose, gardening is distinguished from farming chiefly by scale and intent. Farming occurs on a larger scale, and with the production of salable goods as a major motivation. Gardening happens on a smaller scale, primarily for pleasure and to produce goods for the gardener's own family or community. There is some overlap between the terms, particularly in that some moderate-sized vegetable growing concerns, often called market gardening, can fit in either category.
The key distinction between gardening and farming is essentially one of scale; gardening can be a hobby or an income supplement, but farming is generally understood as a full-time or commercial activity, usually involving more land and quite different practices. One distinction is that gardening is labor-intensive and employs very little infrastructural capital, sometimes no more than a few tools, e.g. a spade, hoe, basket and watering can. By contrast, larger-scale farming often involves irrigation systems, chemical fertilizers and harvesters or at least ladders, e.g. to reach up into fruit trees. However, this distinction is becoming blurred with the increasing use of power tools in even small gardens.
Monty Don has speculated on an atavistic connection between present-day gardeners and pre-modern peasantry.
The term precision agriculture is sometimes used to describe gardening using intermediate technology (more than tools, less than harvesters), especially of organic varieties. Gardening is effectively scaled up to feed entire villages of over 100 people from specialized plots. A variant is the community garden which offers plots to urban dwellers; see further in allotment (gardening).
## Garden ornaments and accessories.
There is a wide range of garden ornaments and accessories available in the market for both the professional gardener and the amateur to exercise their creativity. These are used to add decoration or functionality, and may be made from a wide range of materials such as copper, stone, wood, bamboo, stainless steel, clay, stained glass, concrete, or iron. Examples include trellis, garden furniture, statues, outdoor fireplaces, fountains, rain chains, urns, bird baths and feeders, wind chimes, and garden lighting such as candle lanterns and oil lamps. The use of these items can be part of the expression of a gardener's gardening personality.
## Gardens as art.
Garden design is considered to be an art in most cultures, distinguished from gardening, which generally means "garden maintenance". Garden design can include different themes such as perennial, butterfly, wildlife, Japanese, water, tropical, or shade gardens.
In Japan, Samurai and Zen monks were often required to build decorative gardens or practice related skills like flower arrangement known as "ikebana". In 18th-century Europe, country estates were refashioned by landscape gardeners into formal gardens or landscaped park lands, such as at Versailles, France, or Stowe, England. Today, landscape architects and garden designers continue to produce artistically creative designs for private garden spaces. In the US, professional landscape designers are certified by the Association of Professional Landscape Designers.
## Garden pests.
Garden pests are generally plants, fungi, or animals (frequently insects) that engage in activity that the gardener considers undesirable. A pest may crowd out desirable plants, disturb soil, stunt the growth of young seedlings, steal or damage fruit, or otherwise kill plants, hamper their growth, damage their appearance, or reduce the quality of the edible or ornamental portions of the plant. Aphids, spider mites, slugs, snails, ants, birds, and even cats are commonly considered to be garden pests.
Because gardeners may have different goals, organisms considered "garden pests" vary from gardener to gardener. "Tropaeolum speciosum", for example, may be considered a desirable and ornamental garden plant, or it may be considered a pest if it seeds and starts to grow where it is not wanted. As another example, in lawns, moss can become dominant and be impossible to eradicate. In some lawns, lichens, especially very damp lawn lichens such as "Peltigera lactucfolia" and "P. membranacea", can become difficult to control and are considered pests.
### Garden pest control.
There are many ways by which unwanted pests are removed from a garden. The techniques vary depending on the pest, the gardener's goals, and the gardener's philosophy. For example, snails may be dealt with through the use of a chemical pesticide, an organic pesticide, hand-picking, barriers, or simply growing snail-resistant plants.
Pest control is often done through the use of pesticides, which may be either organic or artificially synthesized. Pesticides may affect the ecology of a garden due to their effects on the populations of both target and non-target species. For example, unintended exposure to some neonicotinoid pesticides has been proposed as a factor in the recent decline in honey bee populations. A mole vibrator can deter mole activity in a garden.
Other means of control include the removal of infected plants, using fertilizers and biostimulants to improve the health and vigour of plants so they better resist attack, practising crop rotation to prevent pest build-up, using companion planting, and practising good garden hygiene, such as disinfecting tools and clearing debris and weeds which may harbour pests.
### Garden guns.
Garden guns are smooth bore shotguns specifically made to fire .22 caliber snake shot, and are commonly used by gardeners and farmers for pest control. Garden guns are short range weapons that can do little harm past to , and they're relatively quiet when fired with snake shot, compared to a standard ammunition. These guns are especially effective inside of barns and sheds, as the snake shot will not shoot holes in the roof or walls, or more importantly injure livestock with a ricochet. They are also used for pest control at airports, warehouses, stockyards, etc.

</doc>
<doc id="11985" url="https://en.wikipedia.org/wiki?curid=11985" title="Graffiti">
Graffiti

Graffiti (both singular and plural; the singular graffito is rarely used except in archeology) is a type of art genre that means writing or drawings made on a wall or other surface, usually without permission and within public view. Graffiti ranges from simple written words to elaborate wall paintings, and has existed since ancient times, with examples dating back to ancient Egypt, ancient Greece, and the Roman Empire.
Graffiti is a controversial subject. In most countries, marking or painting property without permission is considered by property owners and civic authorities as defacement and vandalism, which is a punishable crime, citing the use of graffiti by street gangs to mark territory or to serve as an indicator of gang-related activities. Graffiti has become visualized as a growing urban "problem" for many cities in industrialized nations, spreading from the New York City subway system in the early 1970s to the rest of the United States and Europe and other world regions.
## Etymology.
"Graffiti" (usually both singular and plural) and the rare singular form "graffito" are from the Italian word "graffiato" ("scratched"). The term "graffiti" is used in art history for works of art produced by scratching a design into a surface. A related term is "sgraffito", which involves scratching through one layer of pigment to reveal another beneath it. This technique was primarily used by potters who would glaze their wares and then scratch a design into it. In ancient times graffiti were carved on walls with a sharp object, although sometimes chalk or coal were used. The word originates from Greek —"graphein"—meaning "to write".
## History.
The term "graffiti" originally referred to the inscriptions, figure drawings, and such, found on the walls of ancient sepulchres or ruins, as in the Catacombs of Rome or at Pompeii. Use of the word has evolved to include any graphics applied to surfaces in a manner that constitutes vandalism.
The only known source of the Safaitic language, an ancient form of Arabic, is from graffiti: inscriptions scratched on to the surface of rocks and boulders in the predominantly basalt desert of southern Syria, eastern Jordan and northern Saudi Arabia. Safaitic dates from the first century BC to the fourth century AD.
### Modern-style graffiti.
The first known example of "modern style" graffiti survives in the ancient Greek city of Ephesus (in modern-day Turkey). Local guides say it is an advertisement for prostitution. Located near a mosaic and stone walkway, the graffiti shows a handprint that vaguely resembles a heart, along with a footprint, a number, and a carved image of a woman's head.
The ancient Romans carved graffiti on walls and monuments, examples of which also survive in Egypt. Graffiti in the classical world had different connotations than they carry in today's society concerning content. Ancient graffiti displayed phrases of love declarations, political rhetoric, and simple words of thought, compared to today's popular messages of social and political ideals.
The eruption of Vesuvius preserved graffiti in Pompeii, which includes Latin curses, magic spells, declarations of love, insults, alphabets, political slogans, and famous literary quotes, providing insight into ancient Roman street life. One inscription gives the address of a woman named Novellia Primigenia of Nuceria, a prostitute, apparently of great beauty, whose services were much in demand. Another shows a phallus accompanied by the text, "mansueta tene" ("handle with care").
Disappointed love also found its way onto walls in antiquity:
Ancient tourists visiting the 5th-century citadel at Sigiriya in Sri Lanka scribbled over 1800 individual graffiti there between the 6th and 18th centuries. Etched on the surface of the Mirror Wall, they contain pieces of prose, poetry, and commentary. The majority of these visitors appear to have been from the elite of society: royalty, officials, professions, and clergy. There were also soldiers, archers, and even some metalworkers. The topics range from love to satire, curses, wit, and lament. Many demonstrate a very high level of literacy and a deep appreciation of art and poetry. Most of the graffiti refer to the frescoes of semi-nude females found there. One reads:
Among the ancient political graffiti examples were Arab satirist poems. Yazid al-Himyari, an Umayyad Arab and Persian poet, was most known for writing his political poetry on the walls between Sajistan and Basra, manifesting a strong hatred towards the Umayyad regime and its "walis", and people used to read and circulate them very widely.
### Level of literacy often evident in graffiti.
Historic forms of graffiti have helped gain understanding into the lifestyles and languages of past cultures. Errors in spelling and grammar in these graffiti offer insight into the degree of literacy in Roman times and provide clues on the pronunciation of spoken Latin. Examples are "CIL" IV, 7838: "Vettium Firmum / aed"[ilem] "quactiliar"[ii] "rog"[ant]. Here, "qu" is pronounced "co". The 83 pieces of graffiti found at "CIL" IV, 4706-85 are evidence of the ability to read and write at levels of society where literacy might not be expected. The graffiti appear on a peristyle which was being remodeled at the time of the eruption of Vesuvius by the architect Crescens. The graffiti were left by both the foreman and his workers. The brothel at "CIL" VII, 12, 18–20 contains more than 120 pieces of graffiti, some of which were the work of the prostitutes and their clients. The gladiatorial academy at "CIL" IV, 4397 was scrawled with graffiti left by the gladiator Celadus Crescens ("Suspirium puellarum Celadus thraex": "Celadus the Thracian makes the girls sigh.")
Another piece from Pompeii, written on a tavern wall about the owner of the establishment and his questionable wine:
It was not only the Greeks and Romans who produced graffiti: the Maya site of Tikal in Guatemala contains examples of ancient Maya graffiti. Viking graffiti survive in Rome and at Newgrange Mound in Ireland, and a Varangian scratched his name (Halvdan) in runes on a banister in the Hagia Sophia at Constantinople. These early forms of graffiti have contributed to the understanding of lifestyles and languages of past cultures.
Graffiti, known as Tacherons, were frequently scratched on Romanesque Scandinavian church walls.
When Renaissance artists such as Pinturicchio, Raphael, Michelangelo, Ghirlandaio, or Filippino Lippi descended into the ruins of Nero's Domus Aurea, they carved or painted their names and returned to initiate the "grottesche" style of decoration.
There are also examples of graffiti occurring in American history, such as Independence Rock, a national landmark along the Oregon Trail.
Later, French soldiers carved their names on monuments during the Napoleonic in the 1790s. Lord Byron's survives on one of the columns of the Temple of Poseidon at Cape Sounion in Attica, Greece.
## Contemporary graffiti.
Contemporary graffiti style has been heavily influenced by hip hop culture and the myriad international styles derived from Philadelphia and New York City Subway graffiti, however, there are many other traditions of notable graffiti in the twentieth century. Graffiti have long appeared on building walls, in latrines, railroad boxcars, subways, and bridges.
The oldest known example of modern graffiti are the "monikers" found on traincars created by hobos and railworkers since the late 1800s. The Bozo Texino monikers were documented by filmmaker Bill Daniel in his 2005 film, "Who is Bozo Texino?".
Some graffiti have their own poignancy. In World War II, an inscription on a wall at the fortress of Verdun was seen as an illustration of the US response twice in a generation to the wrongs of the Old World:
During World War II and for decades after, the phrase "Kilroy was here" with an accompanying illustration was widespread throughout the world, due to its use by American troops and ultimately filtering into American popular culture. Shortly after the death of Charlie Parker (nicknamed "Yardbird" or "Bird"), graffiti began appearing around New York with the words "Bird Lives". The student protests and general strike of May 1968 saw Paris bedecked in revolutionary, anarchistic, and situationist slogans such as "L'ennui est contre-révolutionnaire" ("Boredom is counterrevolutionary") expressed in painted graffiti, poster art, and stencil art. At the time in the US, other political phrases (such as "Free Huey" about Black Panther Huey Newton) became briefly popular as graffiti in limited areas, only to be forgotten. A popular graffito of the early 1970s was "Dick Nixon Before He Dicks You", reflecting the hostility of the youth culture to that US president.
### Advent of aerosol paint.
Rock and roll graffiti is a significant subgenre. A famous graffito of the twentieth century was the inscription in the London tube reading "Clapton is God" in a link to the guitarist Eric Clapton. The phrase was spray-painted by an admirer on a wall in an Islington station on the Underground in the autumn of 1967. The graffito was captured in a photograph, in which a dog is urinating on the wall.
Graffiti also became associated with the anti-establishment punk rock movement beginning in the 1970s. Bands such as Black Flag and Crass (and their followers) widely stenciled their names and logos, while many punk night clubs, squats, and hangouts are famous for their graffiti. In the late 1980s the upside down Martini glass that was the tag for punk band Missing Foundation was the most ubiquitous graffito in lower Manhattan
### Spread of hip hop culture.
"Style Wars" depicted not only famous graffitists such as Skeme, Dondi, MinOne, and ZEPHYR, but also reinforced graffiti's role within New York's emerging hip-hop culture by incorporating famous early break-dancing groups such as Rock Steady Crew into the film and featuring rap in the soundtrack. Although many officers of the New York City Police Department found this film to be controversial, Style Wars is still recognized as the most prolific film representation of what was going on within the young hip hop culture of the early 1980s. Fab5 Freddy and Futura 2000 took hip hop graffiti to Paris and London as part of the New York City Rap Tour in 1983.
### Stencil graffiti emerges.
This period also saw the emergence of the new stencil graffiti genre. Some of the first examples were created in 1981 by graffitists Blek le Rat in Paris, in 1982 by Jef Aerosol in Tours (France); by 1985 stencils had appeared in other cities including New York City, Sydney, and Melbourne, where they were documented by American photographer Charles Gatewood and Australian photographer Rennie Ellis.
### Commercialization and entrance into mainstream pop culture.
With the popularity and legitimization of graffiti has come a level of commercialization. In 2001, computer giant IBM launched an advertising campaign in Chicago and San Francisco which involved people spray painting on sidewalks a peace symbol, a heart, and a penguin (Linux mascot), to represent "Peace, Love, and Linux." IBM paid Chicago and San Francisco collectively US$120,000 for punitive damages and clean-up costs.
In 2005, a similar ad campaign was launched by Sony and executed by its advertising agency in New York, Chicago, Atlanta, Philadelphia, Los Angeles, and Miami, to market its handheld PSP gaming system. In this campaign, taking notice of the legal problems of the IBM campaign, Sony paid building owners for the rights to paint on their buildings "a collection of dizzy-eyed urban kids playing with the PSP as if it were a skateboard, a paddle, or a rocking horse".
### Advocates.
Marc Ecko, an urban clothing designer, has been an advocate of graffiti as an art form during this period, stating that "Graffiti is without question the most powerful art movement in recent history and has been a driving inspiration throughout my career."
Graffiti have become a common stepping stone for many members of both the art and design communities in North America and abroad. Within the United States graffitists such as Mike Giant, Pursue, Rime, Noah, and countless others have made careers in skateboard, apparel, and shoe design for companies such as DC Shoes, Adidas, Rebel8, Osiris, or Circa Meanwhile, there are many others such as DZINE, Daze, Blade, and The Mac who have made the switch to being gallery artists, often not even using their initial medium, spray paint.
### Global developments.
#### South America.
Tristan Manco wrote that Brazil "boasts a unique and particularly rich, graffiti scene ... [earning] it an international reputation as the place to go for artistic inspiration." Graffiti "flourishes in every conceivable space in Brazil's cities." Artistic parallels "are often drawn between the energy of São Paulo today and 1970s New York." The "sprawling metropolis," of São Paulo has "become the new shrine to graffiti;" Manco alludes to "poverty and unemployment ... [and] the epic struggles and conditions of the country's marginalised peoples," and to "Brazil's chronic poverty," as the main engines that "have fuelled a vibrant graffiti culture." In world terms, Brazil has "one of the most uneven distributions of income. Laws and taxes change frequently." Such factors, Manco argues, contribute to a very fluid society, riven with those economic divisions and social tensions that underpin and feed the "folkloric vandalism and an urban sport for the disenfranchised," that is South American graffiti art.
Prominent Brazilian graffitists include Os Gêmeos, Boleta, Nunca, Nina, Speto, Tikka, and T.Freak. Their artistic success and involvement in commercial design ventures has highlighted divisions within the Brazilian graffiti community between adherents of the cruder transgressive form of "pichação" and the more conventionally artistic values of the practitioners of "grafite".
#### Middle East.
Graffiti in the Middle East has emerged slowly, with taggers operating in Egypt, Lebanon, the Gulf countries like Bahrein or the United Arab Emirates, Israel, and in Iran. The major Iranian newspaper "Hamshahri" has published two articles on illegal writers in the city with photographic coverage of Iranian artist A1one's works on Tehran walls. Tokyo-based design magazine, "PingMag", has interviewed A1one and featured photographs of his work. The Israeli West Bank barrier has become a site for graffiti, reminiscent in this sense of the Berlin Wall. Many graffitists in Israel come from other places around the globe, such as JUIF from Los Angeles and DEVIONE from London. The religious reference "נ נח נחמ נחמן מאומן" ("Na Nach Nachma Nachman Meuman") is commonly seen in graffiti around Israel.
Graffiti has played an important role within the street art scene in the Middle East and North Africa (MENA), especially following the events of the Arab Spring of 2011 or the Sudanese Revolution of 2018/19. Graffiti is a tool of expression in the context of conflict in the region, allowing people to raise their voices politically and socially. Famous street artist Banksy has had an important effect in the street art scene in the MENA area, especially in Palestine where some of his works are located in the West Bank barrier and Bethlehem.
#### Southeast Asia.
There are also a large number of graffiti influences in Southeast Asian countries that mostly come from modern Western culture, such as Malaysia, where graffiti have long been a common sight in Malaysia's capital city, Kuala Lumpur. Since 2010, the country has begun hosting a street festival to encourage all generations and people from all walks of life to enjoy and encourage Malaysian street culture.
## Characteristics of common graffiti.
### Methods and production.
The modern-day graffitists can be found with an arsenal of various materials that allow for a successful production of a piece. This includes such techniques as scribing. However, spray paint in aerosol cans is the number one medium for graffiti. From this commodity comes different styles, technique, and abilities to form master works of graffiti. Spray paint can be found at hardware and art stores and comes in virtually every color.
Stencil graffiti is created by cutting out shapes and designs in a stiff material (such as cardboard or subject folders) to form an overall design or image. The stencil is then placed on the "canvas" gently and with quick, easy strokes of the aerosol can, the image begins to appear on the intended surface.
### Modern experimentation.
Modern graffiti art often incorporates additional arts and technologies. For example, Graffiti Research Lab has encouraged the use of projected images and magnetic light-emitting diodes (throwies) as new media for graffitists. Yarnbombing is another recent form of graffiti. Yarnbombers occasionally target previous graffiti for modification, which had been avoided among the majority of graffitists.
### Tagging.
A number of recent examples of graffiti make use of hashtags.
## Uses.
Theories on the use of graffiti by avant-garde artists have a history dating back at least to the Asger Jorn, who in 1962 painting declared in a graffiti-like gesture "the avant-garde won't give up".
Many contemporary analysts and even art critics have begun to see artistic value in some graffiti and to recognize it as a form of public art. According to many art researchers, particularly in the Netherlands and in Los Angeles, that type of public art is, in fact an effective tool of social emancipation or, in the achievement of a political goal.
In times of conflict, such murals have offered a means of communication and self-expression for members of these socially, ethnically, or racially divided communities, and have proven themselves as effective tools in establishing dialog and thus, of addressing cleavages in the long run. The Berlin Wall was also extensively covered by graffiti reflecting social pressures relating to the oppressive Soviet rule over the GDR.
Many artists involved with graffiti are also concerned with the similar activity of stenciling. Essentially, this entails stenciling a print of one or more colors using spray-paint. Recognized while exhibiting and publishing several of her coloured stencils and paintings portraying the Sri Lankan Civil War and urban Britain in the early 2000s, graffitists Mathangi Arulpragasam, aka M.I.A., has also become known for integrating her imagery of political violence into her music videos for singles "Galang" and "Bucky Done Gun", and her cover art. Stickers of her artwork also often appear around places such as London in Brick Lane, stuck to lamp posts and street signs, she having become a muse for other graffitists and painters worldwide in cities including Seville.
### Personal expression.
Many graffitists choose to protect their identities and remain anonymous or to hinder prosecution.
With the commercialization of graffiti (and hip hop in general), in most cases, even with legally painted "graffiti" art, graffitists tend to choose anonymity. This may be attributed to various reasons or a combination of reasons. Graffiti still remains the one of four hip hop elements that is not considered "performance art" despite the image of the "singing and dancing star" that sells hip hop culture to the mainstream. Being a graphic form of art, it might also be said that many graffitists still fall in the category of the introverted archetypal artist.
Banksy is one of the world's most notorious and popular street artists who continues to remain faceless in today's society. He is known for his political, anti-war stencil art mainly in Bristol, England, but his work may be seen anywhere from Los Angeles to Palestine. In the UK, Banksy is the most recognizable icon for this cultural artistic movement and keeps his identity a secret to avoid arrest. Much of Banksy's artwork may be seen around the streets of London and surrounding suburbs, although he has painted pictures throughout the world, including the Middle East, where he has painted on Israel's controversial West Bank barrier with satirical images of life on the other side. One depicted a hole in the wall with an idyllic beach, while another shows a mountain landscape on the other side. A number of exhibitions also have taken place since 2000, and recent works of art have fetched vast sums of money. Banksy's art is a prime example of the classic controversy: vandalism vs. art. Art supporters endorse his work distributed in urban areas as pieces of art and some councils, such as Bristol and Islington, have officially protected them, while officials of other areas have deemed his work to be vandalism and have removed it.
Pixnit is another artist who chooses to keep her identity from the general public. Her work focuses on beauty and design aspects of graffiti as opposed to Banksy's anti-government shock value. Her paintings are often of flower designs above shops and stores in her local urban area of Cambridge, Massachusetts. Some store owners endorse her work and encourage others to do similar work as well. "One of the pieces was left up above Steve's Kitchen, because it looks pretty awesome"- Erin Scott, the manager of New England Comics in Allston, Massachusetts.
Graffiti artists may become offended if photographs of their art are published in a commercial context without their permission. In March 2020, the Finnish graffiti artist Psyke expressed his displeasure at the newspaper "Ilta-Sanomat" publishing a photograph of a Peugeot 208 in an article about new cars, with his graffiti prominently shown on the background. The artist claims he does not want his art being used in commercial context, not even if he were to receive compensation.
### Radical and political.
Graffiti often has a reputation as part of a subculture that rebels against authority, although the considerations of the practitioners often diverge and can relate to a wide range of attitudes. It can express a political practice and can form just one tool in an array of resistance techniques. One early example includes the anarcho-punk band Crass, who conducted a campaign of stenciling anti-war, anarchist, feminist, and anti-consumerist messages throughout the London Underground system during the late 1970s and early 1980s. In Amsterdam graffiti was a major part of the punk scene. The city was covered with names such as "De Zoot", "Vendex", and "Dr Rat". To document the graffiti a punk magazine was started that was called "Gallery Anus". So when hip hop came to Europe in the early 1980s there was already a vibrant graffiti culture.
The student protests and general strike of May 1968 saw Paris bedecked in revolutionary, anarchistic, and situationist slogans such as "L'ennui est contre-révolutionnaire" ("Boredom is counterrevolutionary") and "Lisez moins, vivez plus" ("Read less, live more"). While not exhaustive, the graffiti gave a sense of the 'millenarian' and rebellious spirit, tempered with a good deal of verbal wit, of the strikers.
The developments of graffiti art which took place in art galleries and colleges as well as "on the street" or "underground", contributed to the resurfacing in the 1990s of a far more overtly politicized art form in the subvertising, culture jamming, or tactical media movements. These movements or styles tend to classify the artists by their relationship to their social and economic contexts, since, in most countries, graffiti art remains illegal in many forms except when using non-permanent paint. Since the 1990s with the rise of Street Art, a growing number of artists are switching to non-permanent paints and non-traditional forms of painting.
Contemporary practitioners, accordingly, have varied and often conflicting practices. Some individuals, such as Alexander Brener, have used the medium to politicize other art forms, and have used the prison sentences enforced on them as a means of further protest.
The practices of anonymous groups and individuals also vary widely, and practitioners by no means always agree with each other's practices. For example, the anti-capitalist art group the Space Hijackers did a piece in 2004 about the contradiction between the capitalistic elements of Banksy and his use of political imagery.
Territorial graffiti marks urban neighborhoods with tags and logos to differentiate certain groups from others. These images are meant to show outsiders a stern look at whose turf is whose. The subject matter of gang-related graffiti consists of cryptic symbols and initials strictly fashioned with unique calligraphies. Gang members use graffiti to designate membership throughout the gang, to differentiate rivals and associates and, most commonly, to mark borders which are both territorial and ideological.
Berlin human rights activist Irmela Mensah-Schramm has received global media attention and numerous awards for her 35-year campaign of effacing neo-Nazi and other right-wing extremist graffiti throughout Germany, often by altering hate speech in humorous ways.
## Gallery.
### As advertising.
Graffiti has been used as a means of advertising both legally and illegally. Bronx-based TATS CRU has made a name for themselves doing legal advertising campaigns for companies such as Coca-Cola, McDonald's, Toyota, and MTV. In the UK, Covent Garden's Boxfresh used stencil images of a Zapatista revolutionary in the hopes that cross referencing would promote their store.
Smirnoff hired artists to use reverse graffiti (the use of high pressure hoses to clean dirty surfaces to leave a clean image in the surrounding dirt) to increase awareness of their product.
### Offensive graffiti.
Graffiti may also be used as an offensive expression. This form of graffiti may be difficult to identify, as it is mostly removed by the local authority (as councils which have adopted strategies of criminalization also strive to remove graffiti quickly). Therefore, existing racist graffiti is mostly more subtle and at first sight, not easily recognized as "racist". It can then be understood only if one knows the relevant "local code" (social, historical, political, temporal, and spatial), which is seen as heteroglot and thus a 'unique set of conditions' in a cultural context.
By making the graffiti less explicit (as adapted to social and legal constraints), these drawings are less likely to be removed, but do not lose their threatening and offensive character.
Elsewhere, activists in Russia have used painted caricatures of local officials with their mouths as potholes, to show their anger about the poor state of the roads. In Manchester, England a graffitists painted obscene images around potholes, which often resulted in their being repaired within 48 hours.
## Decorative and high art.
In the early 1980s, the first art galleries to show graffitists to the public were Fashion Moda in the Bronx, Now Gallery and Fun Gallery, both in the East Village, Manhattan.
A 2006 exhibition at the Brooklyn Museum displayed graffiti as an art form that began in New York's outer boroughs and reached great heights in the early 1980s with the work of Crash, Lee, Daze, Keith Haring, and Jean-Michel Basquiat. It displayed 22 works by New York graffitists, including Crash, Daze, and Lady Pink. In an article about the exhibition in the magazine "Time Out", curator Charlotta Kotik said that she hoped the exhibition would cause viewers to rethink their assumptions about graffiti.
From the 1970s onwards, Burhan Dogancay photographed urban walls all over the world; these he then archived for use as sources of inspiration for his painterly works. The project today known as "Walls of the World" grew beyond even his own expectations and comprises about 30,000 individual images. It spans a period of 40 years across five continents and 114 countries. In 1982, photographs from this project comprised a one-man exhibition titled "Les murs murmurent, ils crient, ils chantent..." (The walls whisper, shout and sing...) at the Centre Georges Pompidou in Paris.
In Australia, art historians have judged some local graffiti of sufficient creative merit to rank them firmly within the arts. Oxford University Press's art history text "Australian Painting 1788–2000" concludes with a long discussion of graffiti's key place within contemporary visual culture, including the work of several Australian practitioners.
Between March and April 2009, 150 artists exhibited 300 pieces of graffiti at the Grand Palais in Paris.
## Environmental effects.
Spray paint has many negative environmental effects. The paint contains toxic chemicals, and the can uses volatile hydrocarbon gases to spray the paint onto a surface.
Volatile organic compound (VOC) leads to ground level ozone formation and most of graffiti related emissions are VOCs. A 2010 paper estimates 4,862 tons of VOCs were released in the United States in activities related to graffiti.
## Government responses.
### Asia.
In China, Mao Zedong in the 1920s used revolutionary slogans and paintings in public places to galvanise the country's communist revolution.
Based on different national conditions, many people believe that China's attitude towards Graffiti is fierce, but in fact, according to Lance Crayon in his film "Spray Paint Beijing: Graffiti in the Capital of China", Graffiti is generally accepted in Beijing, with artists not seeing much police interference. Political and religiously sensitive graffiti, however, is not allowed.
In Hong Kong, Tsang Tsou Choi was known as the "King of Kowloon" for his calligraphy graffiti over many years, in which he claimed ownership of the area. Now some of his work is preserved officially.
In Taiwan, the government has made some concessions to graffitists. Since 2005 they have been allowed to freely display their work along some sections of riverside retaining walls in designated "Graffiti Zones". From 2007, Taipei's department of cultural affairs also began permitting graffiti on fences around major public construction sites. Department head Yong-ping Lee (李永萍) stated, "We will promote graffiti starting with the public sector, and then later in the private sector too. It's our goal to beautify the city with graffiti". The government later helped organize a graffiti contest in Ximending, a popular shopping district. graffitists caught working outside of these designated areas still face fines up to NT$6,000 under a department of environmental protection regulation. However, Taiwanese authorities can be relatively lenient, one veteran police officer stating anonymously, "Unless someone complains about vandalism, we won't get involved. We don't go after it proactively."
In 1993, after several expensive cars in Singapore were spray-painted, the police arrested a student from the Singapore American School, Michael P. Fay, questioned him, and subsequently charged him with vandalism. Fay pleaded guilty to vandalizing a car in addition to stealing road signs. Under the 1966 Vandalism Act of Singapore, originally passed to curb the spread of communist graffiti in Singapore, the court sentenced him to four months in jail, a fine of S$3,500 (US$2,233), and a caning. "The New York Times" ran several editorials and op-eds that condemned the punishment and called on the American public to flood the Singaporean embassy with protests. Although the Singapore government received many calls for clemency, Fay's caning took place in Singapore on 5 May 1994. Fay had originally received a sentence of six strokes of the cane, but the presiding president of Singapore, Ong Teng Cheong, agreed to reduce his caning sentence to four lashes.
In South Korea, Park Jung-soo was fined two million South Korean won by the Seoul Central District Court for spray-painting a rat on posters of the G-20 Summit a few days before the event in November 2011. Park alleged that the initial in "G-20" sounds like the Korean word for "rat", but Korean government prosecutors alleged that Park was making a derogatory statement about the president of South Korea, Lee Myung-bak, the host of the summit. This case led to public outcry and debate on the lack of government tolerance and in support of freedom of expression. The court ruled that the painting, "an ominous creature like a rat" amounts to "an organized criminal activity" and upheld the fine while denying the prosecution's request for imprisonment for Park.
### Europe.
In Europe, community cleaning squads have responded to graffiti, in some cases with reckless abandon, as when in 1992 in France a local Scout group, attempting to remove modern graffiti, damaged two prehistoric paintings of bison in the Cave of Mayrière supérieure near the French village of Bruniquel in Tarn-et-Garonne, earning them the 1992 Ig Nobel Prize in archeology.
In September 2006, the European Parliament directed the European Commission to create urban environment policies to prevent and eliminate dirt, litter, graffiti, animal excrement, and excessive noise from domestic and vehicular music systems in European cities, along with other concerns over urban life.
In Budapest, Hungary, both a city-backed movement called "I Love Budapest" and a special police division tackle the problem, including the provision of approved areas.
### United Kingdom.
The Anti-Social Behaviour Act 2003 became Britain's latest anti-graffiti legislation. In August 2004, the Keep Britain Tidy campaign issued a press release calling for zero tolerance of graffiti and supporting proposals such as issuing "on the spot" fines to graffiti offenders and banning the sale of aerosol paint to anyone under the age of 16. The press release also condemned the use of graffiti images in advertising and in music videos, arguing that real-world experience of graffiti stood far removed from its often-portrayed "cool" or "edgy'" image.
To back the campaign, 123 Members of Parliament (MPs) (including then Prime Minister Tony Blair), signed a charter which stated: "Graffiti is not art, it's crime. On behalf of my constituents, I will do all I can to rid our community of this problem."
In the UK, city councils have the power to take action against the owner of any property that has been defaced under the Anti-social Behaviour Act 2003 (as amended by the Clean Neighbourhoods and Environment Act 2005) or, in certain cases, the Highways Act. This is often used against owners of property that are complacent in allowing protective boards to be defaced so long as the property is not damaged.
In July 2008, a conspiracy charge was used to convict graffitists for the first time. After a three-month police surveillance operation, nine members of the DPM crew were convicted of conspiracy to commit criminal damage costing at least £1 million. Five of them received prison sentences, ranging from eighteen months to two years. The unprecedented scale of the investigation and the severity of the sentences rekindled public debate over whether graffiti should be considered art or crime.
Some councils, like those of Stroud and Loerrach, provide approved areas in the town where graffitists can showcase their talents, including underpasses, car parks, and walls that might otherwise prove a target for the "spray and run".
### Australia.
In an effort to reduce vandalism, many cities in Australia have designated walls or areas exclusively for use by graffitists. One early example is the "Graffiti Tunnel" located at the Camperdown Campus of the University of Sydney, which is available for use by any student at the university to tag, advertise, poster, and create "art". Advocates of this idea suggest that this discourages petty vandalism yet encourages artists to take their time and produce great art, without worry of being caught or arrested for vandalism or trespassing. Others disagree with this approach, arguing that the presence of legal graffiti walls does not demonstrably reduce illegal graffiti elsewhere. Some local government areas throughout Australia have introduced "anti-graffiti squads", who clean graffiti in the area, and such crews as BCW (Buffers Can't Win) have taken steps to keep one step ahead of local graffiti cleaners.
Many state governments have banned the sale or possession of spray paint to those under the age of 18 (age of majority). However, a number of local governments in Victoria have taken steps to recognize the cultural heritage value of some examples of graffiti, such as prominent political graffiti. Tough new graffiti laws have been introduced in Australia with fines of up to A$26,000 and two years in prison.
Melbourne is a prominent graffiti city of Australia with many of its lanes being tourist attractions, such as Hosier Lane in particular, a popular destination for photographers, wedding photography, and backdrops for corporate print advertising. The Lonely Planet travel guide cites Melbourne's street as a major attraction. All forms of graffiti, including sticker art, poster, stencil art, and wheatpasting, can be found in many places throughout the city. Prominent street art precincts include; Fitzroy, Collingwood, Northcote, Brunswick, St. Kilda, and the CBD, where stencil and sticker art is prominent. As one moves farther away from the city, mostly along suburban train lines, graffiti tags become more prominent. Many international artists such as Banksy have left their work in Melbourne and in early 2008 a perspex screen was installed to prevent a Banksy stencil art piece from being destroyed, it has survived since 2003 through the respect of local street artists avoiding posting over it, although it has recently had paint tipped over it.
### New Zealand.
In February 2008 Helen Clark, the New Zealand prime minister at that time, announced a government crackdown on tagging and other forms of graffiti vandalism, describing it as a destructive crime representing an invasion of public and private property. New legislation subsequently adopted included a ban on the sale of paint spray cans to persons under 18 and increases in maximum fines for the offence from NZ$200 to NZ$2,000 or extended community service. The issue of tagging become a widely debated one following an incident in Auckland during January 2008 in which a middle-aged property owner stabbed one of two teenage taggers to death and was subsequently convicted of manslaughter.
### United States.
#### Tracker databases.
Graffiti databases have increased in the past decade because they allow vandalism incidents to be fully documented against an offender and help the police and prosecution charge and prosecute offenders for multiple counts of vandalism. They also provide law enforcement the ability to rapidly search for an offender's moniker or tag in a simple, effective, and comprehensive way. These systems can also help track costs of damage to city to help allocate an anti-graffiti budget. The theory is that when an offender is caught putting up graffiti, they are not just charged with one count of vandalism; they can be held accountable for all the other damage for which they are responsible. This has two main benefits for law enforcement. One, it sends a signal to the offenders that their vandalism is being tracked. Two, a city can seek restitution from offenders for all the damage that they have committed, not merely a single incident. These systems give law enforcement personnel real-time, street-level intelligence that allows them not only to focus on the worst graffiti offenders and their damage, but also to monitor potential gang violence that is associated with the graffiti.
#### Gang injunctions.
Many restrictions of civil gang injunctions are designed to help address and protect the physical environment and limit graffiti. Provisions of gang injunctions include things such as restricting the possession of marker pens, spray paint cans, or other sharp objects capable of defacing private or public property; spray painting, or marking with marker pens, scratching, applying stickers, or otherwise applying graffiti on any public or private property, including, but not limited to the street, alley, residences, block walls, and fences, vehicles or any other real or personal property. Some injunctions contain wording that restricts damaging or vandalizing both public and private property, including but not limited to any vehicle, light fixture, door, fence, wall, gate, window, building, street sign, utility box, telephone box, tree, or power pole.
#### Hotlines and reward programs.
To help address many of these issues, many local jurisdictions have set up graffiti abatement hotlines, where citizens can call in and report vandalism and have it removed. San Diego's hotline receives more than 5,000 calls per year, in addition to reporting the graffiti, callers can learn more about prevention. One of the complaints about these hotlines is the response time; there is often a lag time between a property owner calling about the graffiti and its removal. The length of delay should be a consideration for any jurisdiction planning on operating a hotline. Local jurisdictions must convince the callers that their complaint of vandalism will be a priority and cleaned off right away. If the jurisdiction does not have the resources to respond to complaints in a timely manner, the value of the hotline diminishes. Crews must be able to respond to individual service calls made to the graffiti hotline as well as focus on cleanup near schools, parks, and major intersections and transit routes to have the biggest impact. Some cities offer a reward for information leading to the arrest and prosecution of suspects for tagging or graffiti related vandalism. The amount of the reward is based on the information provided, and the action taken.
#### Search warrants.
When police obtain search warrants in connection with a vandalism investigation, they are often seeking judicial approval to look for items such as cans of spray paint and nozzles from other kinds of aerosol sprays; etching tools, or other sharp or pointed objects, which could be used to etch or scratch glass and other hard surfaces; permanent marking pens, markers, or paint sticks; evidence of membership or affiliation with any gang or tagging crew; paraphernalia including any reference to "(tagger's name)"; any drawings, writing, objects, or graffiti depicting taggers' names, initials, logos, monikers, slogans, or any mention of tagging crew membership; and any newspaper clippings relating to graffiti crime.

</doc>
<doc id="11986" url="https://en.wikipedia.org/wiki?curid=11986" title="Godzilla">
Godzilla

 is a fictional monster, or "kaiju", originating from a series of Japanese films. The character first appeared in the 1954 film "Godzilla" and became a worldwide pop culture icon, appearing in various media, including 32 films produced by Toho, four Hollywood films and numerous video games, novels, comic books and television shows. Godzilla has been dubbed the "King of the Monsters", a phrase first used in "Godzilla, King of the Monsters!" (1956)"," the Americanized version of the original film.
Godzilla is an enormous, destructive, prehistoric sea monster awakened and empowered by nuclear radiation. With the nuclear bombings of Hiroshima and Nagasaki and the "Lucky Dragon 5" incident still fresh in the Japanese consciousness, Godzilla was conceived as a metaphor for nuclear weapons. Others have suggested that Godzilla is a metaphor for the United States, a giant beast woken from its slumber which then takes terrible vengeance on Japan. As the film series expanded, some stories took on less serious undertones, portraying Godzilla as an antihero, or a lesser threat who defends humanity. Later films address themes including Japan's forgetfulness over its imperial past, natural disasters, and the human condition.
Godzilla has featured alongside many supporting characters. It has faced human opponents such as the JSDF, or other monsters, including King Ghidorah, Mechagodzilla and Gigan. Godzilla sometimes has allies, such as Rodan, Mothra and Anguirus, and offspring, such as Minilla and Godzilla Junior. Godzilla has also fought characters from other franchises in crossover media, such as the RKO Pictures/Universal Studios movie monster King Kong, as well as various Marvel Comics characters, including S.H.I.E.L.D., the Fantastic Four and the Avengers.
## Overview.
### Name.
 is a portmanteau of the Japanese words: and , owing to the fact that in one planning stage, Godzilla was described as "a cross between a gorilla and a whale", due to its size, power and aquatic origin. One popular story is that "Gojira" was actually the nickname of a corpulent stagehand at Toho Studio. Kimi Honda, the widow of the director, dismissed this in a 1998 BBC documentary devoted to Godzilla: "The backstage boys at Toho loved to joke around with tall stories."
Godzilla's name was written in ateji as , where the kanji are used for phonetic value and not meaning. The Japanese pronunciation of the name is ; the Anglicized form is , with the first syllable pronounced like the word "god" and the rest rhyming with "gorilla". In the Hepburn romanization system, Godzilla's name is rendered as "Gojira", whereas in the Kunrei romanization system it is rendered as "Gozira".
During the development of the American version of "Godzilla Raids Again" (1955), Godzilla's name was changed to "Gigantis" by producer Paul Schreibman, who wanted to create a character distinct from Godzilla.
### Characteristics.
Within the context of the Japanese films, Godzilla's exact origins vary, but it is generally depicted as an enormous, violent, prehistoric sea monster awakened and empowered by nuclear radiation. Although the specific details of Godzilla's appearance have varied slightly over the years, the overall impression has remained consistent. Inspired by the fictional "Rhedosaurus" created by animator Ray Harryhausen for the film "The Beast from 20,000 Fathoms", Godzilla's character design was conceived as that of an amphibious reptilian monster based around the loose concept of a dinosaur with an erect standing posture, scaly skin, an anthropomorphic torso with muscular arms, lobed bony plates along its back and tail, and a furrowed brow.
Art director Akira Watanabe combined attributes of a "Tyrannosaurus", an "Iguanodon", a "Stegosaurus" and an alligator to form a sort of blended chimera, inspired by illustrations from an issue of "Life" magazine. To emphasise the monster's relationship with the atomic bomb, its skin texture was inspired by the keloid scars seen on the survivors of Hiroshima. The basic design has a reptilian visage, a robust build, an upright posture, a long tail and three rows of serrated plates along the back. In the original film, the plates were added for purely aesthetic purposes, in order to further differentiate Godzilla from any other living or extinct creature. Godzilla is sometimes depicted as green in comics, cartoons and movie posters, but the costumes used in the movies were usually painted charcoal grey with bone-white dorsal plates up until the film "Godzilla 2000: Millennium".
In the original Japanese films, Godzilla and all the other monsters are referred to with gender-neutral pronouns equivalent to "it", while in the English dubbed versions, Godzilla is explicitly described as a male. In his book, Godzilla co-creator Tomoyuki Tanaka suggested that the monster was probably male. In the 1998 film "Godzilla", the monster is referred to as a male and is depicted laying eggs through parthenogenesis. In the Legendary "Godzilla" films, Godzilla is referred to as a male.
Godzilla's allegiance and motivations have changed from film to film to suit the needs of the story. Although Godzilla does not like humans, it will fight alongside humanity against common threats. However, it makes no special effort to protect human life or property and will turn against its human allies on a whim. It is not motivated to attack by predatory instinct: it does not eat people and instead sustains itself on nuclear radiation and an omnivorous diet. When inquired if Godzilla was "good or bad", producer Shōgo Tomiyama likened it to a Shinto "God of Destruction" which lacks moral agency and cannot be held to human standards of good and evil. "He totally destroys everything and then there is a rebirth. Something new and fresh can begin."
#### Abilities.
Godzilla's signature weapon is its "atomic heat beam" (also known as "atomic breath"), nuclear energy that it generates inside of its body, uses electromagnetic force to concentrate it into a laser-like high velocity projectile and unleashes it from its jaws in the form of a blue or red radioactive beam. Toho's special effects department has used various techniques to render the beam, from physical gas-powered flames to hand-drawn or computer-generated fire. Godzilla is shown to possess immense physical strength and muscularity. Haruo Nakajima, the actor who played Godzilla in the original films, was a black belt in judo and used his expertise to choreograph the battle sequences.
Godzilla is amphibious: it has a preference for traversing Earth's hydrosphere when in hibernation or migration, can breathe underwater and is described in the original film by the character Dr. Yamane as a transitional form between a marine and a terrestrial reptile. Godzilla is shown to have great vitality: it is immune to conventional weaponry thanks to its rugged hide and ability to regenerate, and as a result of surviving a nuclear explosion, it cannot be destroyed by anything less powerful. One incarnation possesses an electromagnetic pulse-producing organ in its body which generates an asymmetrical permeable shield, making it impervious to all damage except for a short period when the organ recycles.
Various films, non-canonical television shows, comics and games have depicted Godzilla with additional powers, such as an atomic pulse, magnetism, precognition, fireballs, convert electromagnetic energy into intensive body heat, converting shed blood into temporary tentacle limbs, an electric bite, superhuman speed, laser beams emitted from its eyes and even flight.
#### Roar.
Godzilla has a distinctive disyllabic roar (transcribed in several comics as "Skreeeonk!"), which was created by composer Akira Ifukube, who produced the sound by rubbing a pine tar-resin-coated glove along the string of a contrabass and then slowing down the playback. In the American version of "Godzilla Raids Again" (1955) titled "Gigantis the Fire Monster" (1959), Godzilla's roar was mostly substituted with that of the monster Anguirus. From "The Return of Godzilla" (1984) to "Godzilla vs. King Ghidorah" (1991), Godzilla was given a deeper and more threatening-sounding roar than in previous films, though this change was reverted from "Godzilla vs. Mothra" (1992) onward. For the 2014 American film, sound editors Ethan Van der Ryn and Erik Aadahl refused to disclose the source of the sounds used for their Godzilla's roar. Aadahl described the two syllables of the roar as representing two different emotional reactions, with the first expressing fury and the second conveying the character's soul.
#### Size.
Godzilla's size is inconsistent, changing from film to film and even from scene to scene for the sake of artistic license. The miniature sets and costumes were typically built at a – scale and filmed at 240 frames per second to create the illusion of great size. In the original 1954 film, Godzilla was scaled to be tall. This was done so Godzilla could just peer over the largest buildings in Tokyo at the time. In the 1956 American version, Godzilla is estimated to be tall, because producer Joseph E. Levine felt that 50 m did not sound "powerful enough".
As the series progressed, Toho would rescale the character, eventually making Godzilla as tall as . This was done so that it would not be dwarfed by the newer, bigger buildings in Tokyo's skyline, such as the Tokyo Metropolitan Government Building which Godzilla destroyed in the film "Godzilla vs. King Ghidorah" (1991). Supplementary information, such as character profiles, would also depict Godzilla as weighing between .
In the American film "Godzilla" (2014) from Legendary Pictures, Godzilla was scaled to be and weighing , making it the largest film version at that time. Director Gareth Edwards wanted Godzilla "to be so big as to be seen from anywhere in the city, but not too big that he couldn't be obscured". For "Shin Godzilla" (2016), Godzilla was made even taller than the Legendary version, at . In ' (2017), Godzilla's height was increased further still to , the tallest height for the character to date. In ' (2019), Godzilla's height was increased to from the 2014 incarnation.
### Special effects details.
Godzilla's appearance has traditionally been portrayed in the films by an actor wearing a latex costume, though the character has also been rendered in animatronic, stop-motion and computer-generated form. Taking inspiration from "King Kong", special effects artist Eiji Tsuburaya had initially wanted Godzilla to be portrayed via stop-motion, but prohibitive deadlines and a lack of experienced animators in Japan at the time made suitmation more practical.
The first suit consisted of a body cavity made of thin wires and bamboo wrapped in chicken wire for support and covered in fabric and cushions, which were then coated in latex. The first suit was held together by small hooks on the back, though subsequent Godzilla suits incorporated a zipper. Its weight was in excess of . Prior to 1984, most Godzilla suits were made from scratch, thus resulting in slight design changes in each film appearance. The most notable changes from 1962 to 1975 were the reduction in Godzilla's number of toes and the removal of the character's external ears and prominent fangs, features which would all later be reincorporated in the Godzilla designs from "The Return of Godzilla" (1984) onward. The most consistent Godzilla design was maintained from "Godzilla vs. Biollante" (1989) to "Godzilla vs. Destoroyah" (1995), when the suit was given a cat-like face and double rows of teeth.
Several suit actors had difficulties in performing as Godzilla due to the suits' weight, lack of ventilation and diminished visibility. Kenpachiro Satsuma in particular, who portrayed Godzilla from 1984 to 1995, described how the Godzilla suits he wore were even heavier and hotter than their predecessors because of the incorporation of animatronics. Satsuma himself suffered numerous medical issues during his tenure, including oxygen deprivation, near-drowning, concussions, electric shocks and lacerations to the legs from the suits' steel wire reinforcements wearing through the rubber padding.
The ventilation problem was partially solved in the suit used in 1994's "Godzilla vs. SpaceGodzilla", which was the first to include an air duct that allowed suit actors to last longer during performances. In "The Return of Godzilla" (1984), some scenes made use of a 16-foot high robotic Godzilla (dubbed the "Cybot Godzilla") for use in close-up shots of the creature's head. The Cybot Godzilla consisted of a hydraulically-powered mechanical endoskeleton covered in urethane skin containing 3,000 computer operated parts which permitted it to tilt its head and move its lips and arms.
In "Godzilla" (1998), special effects artist Patrick Tatopoulos was instructed to redesign Godzilla as an incredibly fast runner. At one point, it was planned to use motion capture from a human to create the movements of the computer-generated Godzilla, but it was said to have ended up looking too much like a man in a suit. Tatopoulos subsequently reimagined the creature as a lean, digitigrade bipedal, iguana-like creature that stood with its back and tail parallel to the ground, rendered via CGI.
Several scenes had the monster portrayed by stuntmen in suits. The suits were similar to those used in the Toho films, with the actors' heads being located in the monster's neck region and the facial movements controlled via animatronics. However, because of the creature's horizontal posture, the stuntmen had to wear metal leg extenders, which allowed them to stand off the ground with their feet bent forward. The film's special effects crew also built a scale animatronic Godzilla for close-up scenes, whose size outmatched that of Stan Winston's "T. rex" in "Jurassic Park". Kurt Carley performed the suitmation sequences for the adult Godzilla.
In "Godzilla" (2014), the character was portrayed entirely via CGI. Godzilla's design in the reboot was intended to stay true to that of the original series, though the film's special effects team strove to make the monster "more dynamic than a guy in a big rubber suit." To create a CG version of Godzilla, the Moving Picture Company (MPC) studied various animals such as bears, Komodo dragons, lizards, lions and wolves, which helped the visual effects artists visualize Godzilla's body structure, like that of its underlying bone, fat and muscle structure, as well as the thickness and texture of its scales. Motion capture was also used for some of Godzilla's movements. T. J. Storm provided the performance capture for Godzilla by wearing sensors in front of a green screen. Storm reprised the role of Godzilla in "", portraying the character through performance capture. In "Shin Godzilla", a majority of the character was portrayed via CGI, with Mansai Nomura portraying Godzilla through motion capture.
## Cultural impact.
Godzilla is one of the most recognizable symbols of Japanese popular culture worldwide and remains an important facet of Japanese films, embodying the "kaiju" subset of the "tokusatsu" genre. Godzilla's vaguely humanoid appearance and strained, lumbering movements endeared it to Japanese audiences, who could relate to Godzilla as a sympathetic character, despite its wrathful nature. Audiences respond positively to the character because it acts out of rage and self-preservation and shows where science and technology can go wrong.
In 1967, the Keukdong Entertainment Company of South Korea, with production assistance from Toei Company, produced "Yongary, Monster from the Deep", a reptilian monster who invades South Korea to consume oil. The film and character has often been branded as an imitation of Godzilla.
Godzilla has been considered a filmographic metaphor for the United States, as well as an allegory of nuclear weapons in general. The earlier "Godzilla" films, especially the original, portrayed Godzilla as a frightening nuclear-spawned monster. Godzilla represented the fears that many Japanese held about the atomic bombings of Hiroshima and Nagasaki and the possibility of recurrence.
As the series progressed, so did Godzilla, changing into a less destructive and more heroic character. "Ghidorah" (1964) was the turning point in Godzilla's transformation from villain to hero, by pitting him against a greater threat to humanity, King Ghidorah. Godzilla has since been viewed as an anti-hero. Roger Ebert cites Godzilla as a notable example of a villain-turned-hero, along with King Kong, Jaws ("James Bond"), the Terminator and John Rambo.
Godzilla is considered "the original radioactive superhero" due to his accidental radioactive origin story predating Spider-Man (1962 debut), though Godzilla did not become a hero until "Ghidorah" in 1964. By the 1970s, Godzilla came to be viewed as a superhero, with the magazine "King of the Monsters" in 1977 describing Godzilla as "Superhero of the '70s." Godzilla had surpassed Superman and Batman to become "the most universally popular superhero of 1977" according to Donald F. Glut. Godzilla was also voted the most popular movie monster in "The Monster Times" poll in 1973, beating Count Dracula, King Kong, the Wolf Man, the Mummy, the Creature from the Black Lagoon and the Frankenstein Monster.
In 1996, Godzilla received the MTV Lifetime Achievement Award, as well as being given a star on the Hollywood Walk of Fame in 2004 to celebrate the premiere of the character's 50th anniversary film, "". Godzilla's pop-cultural impact has led to the creation of numerous parodies and tributes, as seen in media such as "Bambi Meets Godzilla", which was ranked as one of the "50 greatest cartoons", two episodes of "Mystery Science Theater 3000" and the song "Godzilla" by Blue Öyster Cult. Godzilla has also been used in advertisements, such as in a commercial for Nike, where Godzilla lost an oversized one-on-one game of basketball to a giant version of NBA player Charles Barkley. The commercial was subsequently adapted into a comic book illustrated by Jeff Butler. Godzilla has also appeared in a commercial for Snickers candy bars, which served as an indirect promo for the 2014 film. Godzilla's success inspired the creation of numerous other monster characters, such as Gamera, Reptilicus of Denmark, Yonggary of South Korea, Pulgasari of North Korea, Gorgo of the United Kingdom and the Cloverfield monster of the United States.
"Dakosaurus" is an extinct sea crocodile of the Jurassic Period, which researchers informally nicknamed "Godzilla". Paleontologists have written tongue-in-cheek speculative articles about Godzilla's biology, with Ken Carpenter tentatively classifying it as a ceratosaur based on its skull shape, four-fingered hands and dorsal scutes and paleontologist Darren Naish expressing skepticism, while commenting on Godzilla's unusual morphology.
Godzilla's ubiquity in pop-culture has led to the mistaken assumption that the character is in the public domain, resulting in litigation by Toho to protect their corporate asset from becoming a generic trademark. In April 2008, Subway depicted a giant monster in a commercial for their Five Dollar Footlongs sandwich promotion. Toho filed a lawsuit against Subway for using the character without permission, demanding $150,000 in compensation. In February 2011, Toho sued Honda for depicting a fire-breathing monster in a commercial for the Honda Odyssey. The monster was never mentioned by name, being seen briefly on a video screen inside the minivan. The Sea Shepherd Conservation Society christened a vessel the "MV Gojira". Its purpose is to target and harass Japanese whalers in defense of whales in the Southern Ocean Whale Sanctuary. The "MV Gojira" was renamed the in May 2011, due to legal pressure from Toho. Gojira is the name of a French death metal band, formerly known as Godzilla; legal problems forced the band to change their name. In May 2015, Toho launched a lawsuit against Voltage Pictures over a planned picture starring Anne Hathaway. Promotional material released at the Cannes Film Festival used images of Godzilla.
Steven Spielberg cited "Godzilla" as an inspiration for "Jurassic Park" (1993), specifically "Godzilla, King of the Monsters!" (1956), which he grew up watching. Spielberg described "Godzilla" as "the most masterful of all the dinosaur movies because it made you believe it was really happening." "Godzilla" also influenced the Spielberg film "Jaws" (1975). "Godzilla" has also been cited as an inspiration by filmmakers Martin Scorsese and Tim Burton.
The main-belt asteroid 101781 Gojira, discovered by American astronomer Roy Tucker at the Goodricke-Pigott Observatory in 1999, was named in honor of the creature. The official naming citation was published by the Minor Planet Center on 11 July 2018 ().
### Cultural ambassador.
In April 2015, the Shinjuku ward of Tokyo named Godzilla a special resident and official tourism ambassador to encourage tourism. During an unveiling of a giant Godzilla bust at Toho headquarters, Shinjuku mayor Kenichi Yoshizumi stated "Godzilla is a character that is the pride of Japan." The mayor extended a residency certificate to an actor in a rubber suit representing Godzilla, but as the suit's hands were not designed for grasping, it was accepted on Godzilla's behalf by a Toho executive. Reporters noted that Shinjuku ward has been flattened by Godzilla in three Toho movies.

</doc>
<doc id="11987" url="https://en.wikipedia.org/wiki?curid=11987" title="Gigantis the Fire Monster">
Gigantis the Fire Monster



</doc>
<doc id="11988" url="https://en.wikipedia.org/wiki?curid=11988" title="King Kong vs. Godzilla">
King Kong vs. Godzilla

 is a 1962 Japanese "kaiju" film directed by Ishirō Honda, with special effects by Eiji Tsuburaya. Produced and distributed by Toho Co., Ltd, it is the third film in both the "Godzilla" franchise, and "King Kong franchise", plus the first of two Toho-produced films featuring King Kong. It is also the first time that each character appeared on film in color and widescreen. The film stars Tadao Takashima, Kenji Sahara, Yū Fujiki, Ichirō Arishima, and Mie Hama, with Shoichi Hirose as King Kong and Haruo Nakajima as Godzilla. In the film, as Godzilla is reawakened by an American submarine, a pharmaceutical company captures King Kong for promotional uses, which culminates into a battle on Mount Fuji.
The project began with a story outline devised by "King Kong" stop motion animator Willis H. O'Brien around 1960, in which Kong battles a giant Frankenstein Monster; O'Brien gave the outline to producer John Beck for development. Behind O'Brien's back and without his knowledge, Beck gave the project to Toho to produce the film, replacing the giant Frankenstein Monster with Godzilla and scrapping O'Brien's original story.
"King Kong vs. Godzilla" was released theatrically in Japan on August 11, 1962. The film remains the most attended "Godzilla" film in Japan to date, and is credited with encouraging Toho to prioritize the continuation of the "Godzilla" series after seven years of dormancy. A heavily edited version was released by Universal International Inc. theatrically in the United States on June 26, 1963.
The film was followed by "Mothra vs. Godzilla", released April 29, 1964.
## Plot.
Mr. Tako, head of Pacific Pharmaceuticals, is frustrated with the television shows his company is sponsoring and wants something to boost his ratings. When a doctor tells Tako about a giant monster he discovered on the small Faro Island, Tako believes that it would be a brilliant idea to use the monster to gain publicity. Tako immediately sends two men, Osamu Sakurai and Kinsaburo Furue, to find and bring back the monster. Meanwhile, the American nuclear submarine "Seahawk" gets caught in an iceberg. The iceberg collapses, unleashing Godzilla, who had been trapped within it since 1955. Godzilla then destroys the submarine and makes his way towards Japan, attacking a military base as he journeys southward.
On Faro Island, a gigantic octopus crawls ashore and attacks the native village in search of Farolacton juice, taken from a species of red berry native to the island. The mysterious Faro monster, revealed to be King Kong, arrives and defeats the octopus. Kong then drinks several vases full of the juice while the islanders perform a ceremony, which both cause him to fall asleep. Sakurai and Furue place Kong on a large raft and begin to transport him back to Japan. Mr. Tako arrives on the ship transporting Kong, but a JSDF ship stops them and orders them to return Kong to Faro Island. Meanwhile, Godzilla arrives in Japan and begins terrorizing the countryside. Kong wakes up and breaks free from the raft. Reaching the mainland, Kong confronts Godzilla and proceeds to throw giant rocks at Godzilla. Godzilla is not fazed by King Kong's rock attack and uses his atomic heat ray to burn him. Kong retreats after realizing that he is not yet ready to take on Godzilla and his atomic heat ray.
The JSDF digs a large pit laden with explosives and poison gas and lures Godzilla into it, but Godzilla is unharmed. They next string up a barrier of power lines around the city filled with 1,000,000 volts of electricity, which proves effective against Godzilla. Kong then approaches Tokyo and tears through the power lines, feeding off the electricity, which seems to make him stronger. Kong then enters Tokyo and captures Fumiko, Sakurai's sister, taking her to the National Diet Building which he then scales. The JSDF launches capsules full of vaporised Farolacton juice, which puts Kong to sleep, and are able to rescue Fumiko. The JSDF then decides to transport Kong via balloons to Godzilla, in hopes that they will kill each other.
The next morning, Kong is deployed by helicopter next to Godzilla at the summit of Mount Fuji and the two engage in a final battle. Godzilla initially has the advantage dazing Kong with a devastating dropkick and repeated tail blows to his head. Godzilla then attempts to burn Kong to death by using his Atomic Breath to set fire to the foliage around Kong's body. Suddenly, a bolt of lightning from thunder clouds strikes Kong, reviving him and charging him up, and the battle resumes. Godzilla and King Kong fight their way down the mountain and into Atami, where the two monsters destroy Atami Castle while trading blows, before falling off a cliff together into Sagami Bay. After a brief underwater battle, only Kong resurfaces from the water, victorious, and he begins to swim back toward his home island. There is no sign of Godzilla, but the JSDF speculates that it is possible he survived.
## Cast.
### American version.
Cast taken from "Japan's Favorite Mon-star".
## Production.
### Crew.
Personnel taken from "Japan's Favorite Mon-star".
### Conception.
The film had its roots in an earlier concept for a new "King Kong" feature developed by Willis O'Brien, animator of the original stop-motion Kong. Around 1958, O'Brien came up with a proposed treatment, "King Kong Meets Frankenstein", where Kong would fight against a giant Frankenstein Monster in San Francisco. O'Brien took the project (which consisted of some concept art and a screenplay treatment) to RKO to secure permission to use the King Kong character. During this time, the story was renamed "King Kong vs. the Ginko" when it was believed that Universal had the rights to the Frankenstein name (it actually only had the rights to the monster's makeup design by Jack Pierce). O'Brien was introduced to producer John Beck, who promised to find a studio to make the film (at this point in time, RKO was no longer a production company). Beck took the story treatment and had George Worthing Yates flesh it out into a screenplay. The story was slightly altered and the title changed to "King Kong vs. Prometheus", returning the name to the original Frankenstein concept ("The Modern Prometheus" was the alternate title of the original novel). Unfortunately, the cost of stop-motion animation discouraged potential studios from putting the film into production. After shopping the script around overseas, Beck eventually attracted the interest of the Japanese studio Toho, which had long wanted to make a "King Kong" film. After purchasing the script, they decided to replace the giant Frankenstein Monster with Godzilla to be King Kong's opponent and would have Shinichi Sekizawa rewrite Yates' script. The studio thought that it would be the perfect way to celebrate its 30th year in production. It was one of five big banner releases for the company to celebrate the anniversary alongside "Sanjuro", "", "Lonely Lane", and "Born in Sin". John Beck's dealings with Willis O'Brien's project were done behind his back, and O'Brien was never credited for his idea. Merian C. Cooper was bitterly opposed to the project, stating in a letter addressed to his friend Douglas Burden, "I was indignant when some Japanese company made a belittling thing, to a creative mind, called "King Kong vs. Godzilla". I believe they even stooped so low as to use a man in a gorilla suit, which I have spoken out against so often in the early days of "King Kong"". In 1963, he filed a lawsuit to enjoin distribution of the movie against John Beck, as well as Toho and Universal (the film's U.S. copyright holder) claiming that he outright owned the King Kong character, but the lawsuit never went through, as it turned out he was not Kong's sole legal owner as he had previously believed.
### Themes.
Ishiro Honda wanted the theme of the movie to be a satire of the television industry in Japan. In April 1962, TV networks and their various sponsors started producing outrageous programming and publicity stunts to grab audiences' attention after two elderly viewers reportedly died at home while watching a violent wrestling match on TV. The various rating wars between the networks and banal programming that followed this event caused widespread debate over how TV would affect Japanese culture with Soichi Oya stating TV was creating "a nation of 100 million idiots". Honda stated "People were making a big deal out of ratings, but my own view of TV shows was that they did not take the viewer seriously, that they took the audience for granted...so I decided to show that through my movie" and "the reason I showed the monster battle through the prism of a ratings war was to depict the reality of the times". Honda addressed this by having a pharmaceutical company sponsor a TV show and going to extremes for a publicity stunt for ratings by capturing a giant monster stating "All a medicine company would have to do is just produce good medicines you know? But the company doesn't think that way. They think they will get ahead of their competitors if they use a monster to promote their product.". Honda would work with screenwriter Shinichi Sekizawa on developing the story stating that "Back then Sekizawa was working on pop songs and TV shows so he really had a clear insight into television".
### Filming.
Special effects director Eiji Tsuburaya was planning on working on other projects at this point in time such as a new version of a fairy tale film script called "Kaguyahime" ("Princess Kaguya"), but he postponed those to work on this project with Toho instead since he was such a huge fan of King Kong. He stated in an early 1960s interview with the Mainichi Newspaper, "But my movie company has produced a very interesting script that combined King Kong and Godzilla, so I couldn't help working on this instead of my other fantasy films. The script is special to me; it makes me emotional because it was "King Kong" that got me interested in the world of special photographic techniques when I saw it in 1933."
Early drafts of the script were sent back with notes from the studio asking that the monster antics be made as "funny as possible". This comical approach was embraced by Tsuburaya, who wanted to appeal to children's sensibilities and broaden the genre's audience. Much of the monster battle was filmed to contain a great deal of humour but the approach was not favoured by most of the effects crew, who "couldn't believe" some of the things Tsuburaya asked them to do, such as Kong and Godzilla volleying a giant boulder back and forth. With the exception of the next film, "Mothra vs. Godzilla", this film began the trend to portray Godzilla and the monsters with more and more anthropomorphism as the series progressed, to appeal more to younger children. Ishirō Honda was not a fan of the dumbing down of the monsters. Years later, Honda stated in an interview. "I don't think a monster should ever be a comical character." "The public is more entertained when the great King Kong strikes fear into the hearts of the little characters." The decision was also taken to shoot the film in a (2.35:1) scope ratio (Tohoscope) and to film in color (Eastman Color), marking both monsters' first widescreen and color portrayals.
Toho had planned to shoot this film on location in Sri Lanka, but had to forgo that (and scale back on production costs) because it ended up paying RKO roughly ¥80 million ($220,000) for the rights to the King Kong character. The bulk of the film was shot on the Japanese island of Izu Ōshima instead. The movie's production budget came out to ().
Suit actors Shoichi Hirose (King Kong) and Haruo Nakajima (Godzilla) were given mostly free rein by Eiji Tsuburaya to choreograph their own moves. The men would rehearse for hours and would base their moves on that from professional wrestling (a sport that was growing in popularity in Japan), in particular the movies of Toyonobori.
During pre-production, Eiji Tsuburaya had toyed with the idea of using Willis O'Brien's stop-motion technique instead of the suitmation process used in the first two "Godzilla" films, but budgetary concerns prevented him from using the process, and the more cost-efficient suitmation was used instead. However, some brief stop motion was used in a couple of quick sequences. One of these sequences was animated by Koichi Takano, who was a member of Eiji Tsuburaya's crew.
A brand new Godzilla suit was designed for this film and some slight alterations were done to its overall appearance. These alterations included the removal of its tiny ears, three toes on each foot rather than four, enlarged central dorsal fins, and a bulkier body. These new features gave Godzilla a more reptilian/dinosaurian appearance. Outside of the suit, a meter-high model and a small puppet were also built. Another puppet (from the waist up) was also designed that had a nozzle in the mouth to spray out liquid mist simulating Godzilla's atomic breath. However the shots in the film where this prop was employed (far away shots of Godzilla breathing its atomic breath during its attack on the Arctic Military base) were ultimately cut from the film. These cut scenes can be seen in the Japanese theatrical trailer. Finally, a separate prop of Godzilla's tail was also built for close-up practical shots when its tail would be used (such as the scene where Godzilla trips Kong with its tail). The tail prop would be swung offscreen by a stage hand.
Sadamasa Arikawa (who worked with Eiji Tsuburaya) said that the sculptors had a hard time coming up with a King Kong suit that appeased Tsuburaya. The first suit was rejected for being too fat with long legs giving Kong what the crew considered an almost cute look. A few other designs were done before Tsuburaya would approve the final look that was ultimately used in the film. The suit's body design was a team effort by brothers Koei Yagi and Kanji Yagi and was covered with expensive yak hair, which Eizo Kaimai hand-dyed brown. Because RKO instructed that the face must be different from the original's design, sculptor Teizo Toshimitsu based Kong's face on the Japanese macaque rather than a gorilla, and designed two separate masks. As well, two separate pairs of arms were also created. One pair were extended arms that were operated by poles inside the suit to better give Kong a gorilla-like illusion, while the other pair were at normal arms-length and featured gloves that were used for scenes that required Kong to grab items and wrestle with Godzilla. Suit actor Hirose had to be sewn into the suit in order to hide the zipper. This would force him to be trapped inside the suit for large amounts of time and would cause him much physical discomfort. In the scene where Kong drinks the berry juice and falls asleep, he was trapped in the suit for three hours. Hirose stated in an interview "Sweat came pouring out like a flood and it got into my eyes too. When I came out, I was pale all over". Besides the suit with the two separate arm attachments, a meter-high model and a puppet of Kong (used for closeups) were also built. As well, a huge prop of Kong's hand was built for the scene where he grabs Mie Hama (Fumiko) and carries her off.
For the attack of the giant octopus, four live octopuses were used. They were forced to move among the miniature huts by having hot air blown onto them. After the filming of that scene was finished, three of the four octopuses were released. The fourth became special effects director Eiji Tsuburaya's dinner. These sequences were filmed on a miniature set outdoors on the Miura Coast. Along with the live animals, two rubber octopus props were built, with the larger one being covered with plastic wrap to simulate mucous. Some stop-motion tentacles were also created for the scene where the octopus grabs a native and tosses him. These sequences were shot indoors at Toho Studios.
Since King Kong was seen as the bigger draw and since Godzilla was still a villain at this point in the series, the decision was made to not only give King Kong top billing but also to present him as the winner of the climactic fight. While the ending of the film does look somewhat ambiguous, Toho confirmed that King Kong was indeed the winner in their 1962–63 English-language film program "Toho Films Vol. 8", which states in the film's plot synopsis, "A spectacular duel is arranged on the summit of Mt. Fuji and King Kong is victorious. But after he has won..."
## American version.
When John Beck sold the "King Kong vs Prometheus" script to Toho (which became "King Kong vs. Godzilla"), he was given exclusive rights to produce a version of the film for release in non-Asian territories. He was able to line up a couple of potential distributors in Warner Bros. and Universal-International even before the film began production. Beck, accompanied by two Warner Bros. representatives, attended at least two private screenings of the film on the Toho Studios lot before it was released in Japan.
John Beck enlisted the help of two Hollywood writers, Paul Mason and Bruce Howard, to write a new screenplay. After discussions with Beck, the two wrote the American version and worked with editor Peter Zinner to remove scenes, recut others, and change the sequence of several events. To give the film more of an American feel, Mason and Howard decided to insert new footage that would convey the impression that the film was actually a newscast. The television actor Michael Keith played newscaster Eric Carter, a United Nations reporter who spends much of the time commenting on the action from the U.N. Headquarters via an International Communications Satellite (ICS) broadcast. Harry Holcombe was cast as Dr. Arnold Johnson, the head of the Museum of Natural History in New York City, who tries to explain Godzilla's origin and his and Kong's motivations. The new footage, directed by Thomas Montgomery, was shot in three days.
Beck and his crew were able to obtain library music from a host of older films (music tracks that had been composed by Henry Mancini, Hans J. Salter, and even a track from Heinz Roemheld). These films include "Creature from the Black Lagoon", "Bend of the River", "Untamed Frontier", "The Golden Horde", "Frankenstein Meets the Wolf Man", "Man Made Monster", "Thunder on the Hill", "While the City Sleeps", "Against All Flags", "The Monster That Challenged the World", "The Deerslayer" and music from the TV series "Wichita Town". Cues from these scores were used to almost completely replace the original Japanese score by Akira Ifukube and give the film a more Western sound. They also obtained stock footage from the film "The Mysterians" from RKO (the film's U.S. copyright holder at the time) which was used not only to represent the ICS, but which was also utilized during the film's climax. Stock footage of a massive earthquake from "The Mysterians" was employed to make the earthquake caused by Kong and Godzilla's plummet into the ocean much more violent than the tame tremor seen in the Japanese version. This added footage features massive tidal waves, flooded valleys, and the ground splitting open swallowing up various huts.
Beck spent roughly $15,500 making his English version and sold the film to Universal-International for roughly $200,000 on April 29, 1963. The film opened in New York on June 26 of that year.
Starting in 1963, Toho's international sales booklets began advertising an English dub of "King Kong vs. Godzilla" alongside Toho-commissioned, unedited international dubs of movies such as "Giant Monster Varan" and "The Last War". By association, it is thought that this "King Kong vs. Godzilla" dub is an unedited English-language international version not known to have been released on home video.
## Release.
### Theatrical.
In Japan, the film was released on August 11, 1962, where it played alongside "Myself and I" for a two week period, afterward, it was extended by one more week and screened alongside the anime film "Touring the World". The film was re-released twice as part of the "Toho Champion Festival", a film festival that ran from 1969 through 1978 that featured numerous films packaged together and aimed at children, first in 1970, and then again in 1977, to coincide with the Japanese release of the 1976 version of "King Kong".
After its theatrical re-releases, the film was screened two more times at specialty festivals. In 1979, to celebrate Godzilla's 25th anniversary, the film was reissued as part of a triple bill festival known as "The Godzilla Movie Collection" ("Gojira Eiga Zenshu"). It played alongside "Invasion of Astro-Monster" and "Godzilla vs. Mechagodzilla". This release is known among fans for its exciting and dynamic movie poster featuring all the main kaiju from these three films engaged in battle. Then in 1983, the film was screened as part of "The Godzilla Resurrection Festival" ("Gojira no Fukkatsu"). This large festival featured 10 Godzilla/kaiju films in all ("Godzilla", "King Kong vs. Godzilla", "Mothra vs. Godzilla", "Ghidorah, the Three-Headed Monster", "Invasion of Astro-Monster", "Godzilla vs. Mechagodzilla", "Rodan", "Mothra", "Atragon", and "King Kong Escapes").
In North America, "King Kong vs. Godzilla" premiered in New York City on June 26, 1963. The film was also released in many international markets. In Germany, it was known as "Die Rückkehr des King Kong" ("The Return of King Kong") and in Italy as "Il trionfo di King Kong" ("The triumph of King Kong"). In France, it was released in 1976.
### Home media.
The Japanese version of this film was released numerous times through the years by Toho on different home video formats. The film was first released on VHS in 1985 and again in 1991. It was released on LaserDisc in 1986 and 1991, and then again in 1992 in its truncated 74-minute form as part of a laserdisc box set called the "Godzilla Toho Champion Matsuri". Toho then released the film on DVD in 2001. They released it again in 2005 as part of the "Godzilla Final Box" DVD set, and again in 2010 as part of the Toho Tokusatsu DVD Collection. This release was volume #8 of the series and came packaged with a collectible magazine that featured stills, behind-the-scenes photos, interviews, and more. In the summer of 2014, the film was released for the first time on Blu-ray as part of the company releasing the entire series on the Blu-ray format for Godzilla's 60th anniversary. The 4K Ultra High Definition remaster of the film was released on Blu-Ray in both a two disc deluxe box set and a standard one disc in May 2021.
The American version was released on VHS by GoodTimes Entertainment (which acquired the license to some of Universal's film catalogue) in 1987, and then on DVD to commemorate the 35th anniversary of the film's U.S release in 1998. Both of these releases were full frame. Universal Pictures released the English-language version of the film on DVD in widescreen as part of a two-pack bundle with "King Kong Escapes" in 2005, and then on its own as an individual release on September 15, 2009. They then re-released the film on Blu-ray on April 1, 2014, along with "King Kong Escapes". This release sold $749,747 worth of Blu-rays. FYE released an exclusive Limited Edition Steelbook version of this Blu-ray on September 10, 2019.
In 2019, the Japanese and American versions were included in a Blu-ray box set released by The Criterion Collection, which included all 15 films from the franchise's Shōwa era.
## Reception.
### Box office.
In Japan, this film has the highest box office attendance figures of all of the "Godzilla" films to date. It sold 11.2 million tickets during its initial theatrical run, accumulating in distribution rental earnings. The film was the fourth highest-grossing film in Japan that year, behind "The Great Wall (Shin no shikōtei)", "Sanjuro", and "" and was Toho's second biggest moneymaker. At an average 1962 Japanese ticket price, ticket sales were equivalent to estimated gross receipts of approximately ().
Including re-releases, the film accumulated a lifetime figure of 12.6 million tickets sold in Japan, with distribution rental earnings of . The 1970 re-release sold 870,000 tickets, equivalent to estimated gross receipts of approximately (). The 1977 re-release sold 480,000 tickets, equivalent to estimated gross receipts of approximately (). This adds up to total estimated Japanese gross receipts of approximately (). In the United States, the film grossed $2.7 million, accumulating a profit (via rentals) of $1.25 million. In France, where it released in 1976, the film sold 554,695 tickets, equivalent to estimated gross receipts of approximately ($1,667,650). This adds up to total estimated gross receipts of approximately worldwide.
## Preservation.
The original Japanese version of "King Kong vs. Godzilla" is infamous for being one of the most poorly-preserved "tokusatsu" films. In 1970, director Ishiro Honda prepared an edited version of the film for the Toho Champion Festival, a children's matinee program that showcased edited re-releases of older kaiju films along with cartoons and then-new kaiju films. Honda cut 24 minutes from the film's original negative and, as a result, the highest quality source for the cut footage was lost. For years, all that was thought to remain of the uncut 1962 version was a faded, heavily damaged 16mm element from which rental prints had been made. 1980s restorations for home video integrated the 16mm deleted scenes into the 35mm Champion cut, resulting in wildly inconsistent picture quality.
In 1991, Toho issued a restored laserdisc incorporating the rediscovery of a reel of 35mm trims of the deleted footage from the original negative. The resultant quality was far superior to previous reconstructions, but not perfect; an abrupt cut caused by missing frames at the beginning or end of a trim is evident whenever the master switches between the Champion cut and a 35mm trim within the same shot. This laserdisc master was utilized for Toho's 2001 DVD release with few changes.
In 2014, Toho released a new restoration of the film on Blu-Ray, which utilized the 35mm edits once again, but only those available for reels 2-7 of the film were able to be located. The remainder of video for the deleted portions was sourced from the earlier Blu-Ray of the U.S. version, in addition to the previous 480i 1991 laserdisc master. On July 14, 2016, a 4K restoration of a completely 35mm sourced version of the film aired on "The Godzilla First Impact", a series of 4K broadcasts of Godzilla films on the Nihon Eiga Senmon Channel.
## Legacy.
Due to the great box office success of this film, Toho wanted to produce a sequel immediately. Shinichi Sekizawa was brought back to write the screenplay tentatively called "Continuation King Kong vs Godzilla". Sekizawa revealed that Kong had killed Godzilla during their underwater battle in Sagami Bay with a line of dialogue stating "Godzilla, who sank and died in the waters off Atami". As the story progressed, Godzilla's body is salvaged from the Ocean by a group of entrepreneurs who hope to display the remains at a planned resort. Meanwhile King Kong is found in Africa where he had been protecting a baby (the sole survivor of a plane crash). After the baby is rescued by investigators, and is taken back to Japan, Kong follows the group and rampages through the country looking for the infant. Godzilla is then revived with hopes of driving off Kong. The story ends with both monsters plummeting into a volcano. The project was ultimately cancelled.
A couple of years later, Toho conceived the idea to pit Godzilla against a giant Frankenstein Monster and assigned Takeshi Kimura in 1964 to write a screenplay titled "Frankenstein vs. Godzilla". However, Toho would cancel this project as well and instead decided to match Mothra against Godzilla in "Mothra vs. Godzilla". This began a formula where "kaiju" from past Toho films would be added into the Godzilla franchise. 
Toho was interested in producing a series around their version of King Kong, but were refused by RKO. However, Toho would handle the character once more in 1967 to help Rankin/Bass co-produce their film "King Kong Escapes", which was loosely based on a cartoon series Rankin/Bass had produced.
Henry G. Saperstein was impressed with the giant octopus scene and requested a giant octopus to appear in "Frankenstein Conquers the World" and "The War of the Gargantuas". The giant octopus appeared in an alternate ending for "Frankenstein Conquers the World" that was intended for overseas markets, but went unused. As a result, the octopus instead appeared in the opening of "The War of the Gargantuas". The film's Godzilla suit was reused for certain scenes in "Mothra vs. Godzilla" The film's Godzilla design also formed the basis for some early merchandise in the U.S. in the 1960s, such as a model kit by Aurora Plastics Corporation, and a board game by Ideal Toys. This game was released alongside a King Kong game in 1963 to coincide with the U.S. theatrical release of the film. The film's King Kong suit was recycled and altered for the second episode of "Ultra Q" and the water scenes for "King Kong Escapes". Scenes of the film's giant octopus attack were recycled for the 23rd episode of "Ultra Q".
In 1992, to coincide with the company's 60th anniversary, Toho expressed interest in remaking the film as "Godzilla vs. King Kong". However, producer Tomoyuki Tanaka stated that obtaining the rights to King Kong proved difficult. Toho then considered producing "Godzilla vs. Mechani-Kong" but effects director Koichi Kawakita confirmed that obtaining the likeness of King Kong also proved difficult. Mechani-Kong was replaced by Mechagodzilla, and the project was developed into "Godzilla vs. Mechagodzilla II" in 1993. During the production of "", animation director Hal Hickel instructed his team to watch "King Kong vs. Godzilla", specifically the giant octopus scene, to use as a reference when animating the Kraken's tentacles.
The film has been referenced in pop culture through various media. It was referenced in Da Lench Mob's 1992 single "Guerillas in tha Mist". It was spoofed in advertising for a Bembos burger commercial from Peru, for Ridsect Lizard Repellant, and for the board game Connect 4. It was paid homage to in comic books by DC Comics, Bongo Comics, and Disney Comics. It was spoofed in "The Simpsons" episode "Wedding for Disaster".
In 2015, Legendary Entertainment announced plans for a King Kong vs Godzilla film of their own (unrelated to Toho's version), which was released on March 26, 2021.
### Dual ending myth.
For many years, a popular myth has persisted that in the Japanese version of this film, Godzilla emerges as the winner. The myth originated in the pages of "Spacemen" magazine, a 1960s sister magazine to the influential publication "Famous Monsters of Filmland". In an article about the film, it is incorrectly stated that there were two endings and "If you see "King Kong vs Godzilla" in Japan, Hong Kong or some Oriental sector of the world, Godzilla wins!" The article was reprinted in various issues of "Famous Monsters of Filmland" in the years following, such as in issues #51 and #114. This misinformation would be accepted as fact and persist for decades. For example, a question in the "Genus III" edition of the popular board game "Trivial Pursuit" asked, "Who wins in the Japanese version of "King Kong vs. Godzilla"?" and stated that the correct answer was "Godzilla". Various media have repeated this falsehood, including the "Los Angeles Times".
With the rise of home video, Westerners have increasingly been able to view the original version and the myth has been dispelled. The only differences between the two endings of the film are minor:
In 1993, comic book artist Arthur Adams wrote and drew a one-page story that appeared in the anthology "Urban Legends" #1, published by Dark Horse Comics, which dispels the popular misconception about the two versions of "King Kong vs. Godzilla".

</doc>
<doc id="11989" url="https://en.wikipedia.org/wiki?curid=11989" title="Godzilla vs The Thing">
Godzilla vs The Thing



</doc>
<doc id="11990" url="https://en.wikipedia.org/wiki?curid=11990" title="Ghidorah the Three Headed Monster">
Ghidorah the Three Headed Monster



</doc>
<doc id="11991" url="https://en.wikipedia.org/wiki?curid=11991" title="Monster Zero">
Monster Zero



</doc>
<doc id="11992" url="https://en.wikipedia.org/wiki?curid=11992" title="Ebirah, Horror of the Deep">
Ebirah, Horror of the Deep

 is a 1966 Japanese " kaiju" film directed by Jun Fukuda and produced and distributed by Toho Co., Ltd. The film stars Akira Takarada, Kumi Mizuno, Akihiko Hirata and Eisei Amamoto, and features the fictional monster characters Godzilla, Mothra, and Ebirah. It is the seventh film in the " Godzilla" franchise, and features special effects by Sadamasa Arikawa, under the supervision of Eiji Tsuburaya. In the film, Godzilla and Ebirah are portrayed by Haruo Nakajima and Hiroshi Sekita, respectively.
During its development, "Ebirah, Horror of the Deep" was intended to feature King Kong, but the character was replaced by Godzilla. The film was released to theaters in Japan on December 17, 1966, and was released directly to television in the United States in 1968 under the title "Godzilla versus the Sea Monster".
## Plot.
After Yota is lost at sea, his brother Ryota steals a yacht with his two friends and a bank robber. However, the crew runs afoul of Ebirah, a giant lobster-like creature, and washes ashore on Letchi Island. There, the Red Bamboo, a terrorist organization, manufactures heavy water for selling weapons of mass destruction and a yellow liquid that keeps Ebirah at bay, presumably controlling him. The Red Bamboo has enslaved natives from nearby Infant Island to create the yellow liquid, while the natives hope that Mothra will awaken in her winged, adult form and rescue them.
In their efforts to avoid capture, Ryota and his friends, aided by Daiyo, a native girl, come across Godzilla, who previously fought Ghidorah and is now sleeping within a cliffside cavern. The group devises a plan to defeat the Red Bamboo and escape the island. In the process, they awaken Godzilla using a makeshift lightning rod. Godzilla fights Ebirah, but the huge crustacean escapes. Godzilla is then attacked by a giant condor and a squadron of Red Bamboo fighter jets. Using his atomic ray, Godzilla destroys the jets and kills the giant bird.
The humans retrieve the missing Yata and free the enslaved natives as Godzilla begins to destroy the Red Bamboo's base of operations, smashing a tower that causes a countdown that will destroy the island in a nuclear explosion. Godzilla fights Ebirah and defeats him, ripping his claws off, forcing him to retreat into the sea. The natives await for Mothra to carry them off in a large net. However, when she gets to the island, Mothra is challenged by Godzilla due to a previous confrontation. Mothra manages to repel Godzilla and save her people and the human heroes. Godzilla also escapes just before the bomb detonates and destroys the island.
## Production.
### Development.
The film was originally written to feature King Kong rather than Godzilla. The film's working title was Operation Robinson Crusoe: King Kong vs. Ebirah, and the project was rejected by Rankin/Bass Productions before being accepted by Toho, after which King Kong's role in the film was replaced by Godzilla. Even though Eiji Tsuburaya was given directorial credit for the special effects, Sadamasa Arikawa actually directed the special effects under the supervision of Tsuburaya, who had his own company, Tsuburaya Productions, at the time. Toho had decided to set the film on an island to cut back on special effects costs. Arikawa has cited the film as a frustrating experience, stating, "There were major limitations on the budget from the studio. Toho couldn't have made too many demands about the budget if Mr. Tsuburaya had been in charge. The studio knew I was also doing TV work then, so they must have figured I could produce the movie cheaply."
### Special effects.
The underwater sequences were filmed on an indoor soundstage where the Godzilla and Ebirah suits were filmed through the glass of a water-filled aquarium, with some scenes of the Godzilla suit shot separately underwater as well. Haruo Nakajima (the suit performer for Godzilla) wore a wet suit under the Godzilla suit for every scene that required him to be in the water, which took a week to complete the water scenes, Nakajima stated, "I worked overtime until about eight o'clock every day. Even though I wore a wet suit under the costume, I got cold. But I never got sick, because I was so tense during the filming."
### Filming.
This is the first of two "Godzilla" films in which a Pacific island is the primary setting, rather than a location inside Japan. The second and final one is "Son of Godzilla" (1967).
## Release.
"Ebirah, Horror of the Deep" was released theatrically in Japan on December 17, 1966, where it was distributed by Toho.
The American version of the film was released directly to television by Continental Distributing in 1968 under the title "Godzilla versus the Sea Monster". The film may have received theatrical distribution in the United States as a Walter Reade, Jr. Presentation, but this has not been confirmed.
### Home media.
The film was released on DVD on February 8, 2005 by Sony Pictures Home Entertainment. The film was released on Blu-ray on May 6, 2014 by Kraken Releasing. In 2019, the Japanese version was included in a Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era.

</doc>
<doc id="11993" url="https://en.wikipedia.org/wiki?curid=11993" title="Son of Godzilla">
Son of Godzilla

 is a 1967 Japanese "kaiju" film directed by Jun Fukuda, with special effects by Sadamasa Arikawa, under the supervision of Eiji Tsuburaya. Produced and distributed by Toho Co., Ltd, it is the eighth film in the "Godzilla" franchise. It stars Tadao Takashima, Akira Kubo, Akihiko Hirata, and Beverly Maeda, with Hiroshi Sekita, Seiji Onaka, and Haruo Nakajima as Godzilla, and Marchan the Dwarf as Minilla.
"Son of Godzilla" received a theatrical release in Japan on December 16, 1967, and was released directly to television in the United States in 1969 through the Walter Reade Organization.
## Plot.
A team of scientists are trying to perfect a weather-controlling system. Their efforts are hampered by the arrival of a nosy reporter and by the sudden presence of giant praying mantises. The first test of the weather control system goes awry when the remote control for a radioactive balloon is jammed by an unexplained signal coming from the center of the island. The balloon detonates prematurely, creating a radioactive storm that causes the giant mantises to grow to enormous sizes. Investigating the mantises, which are named Kamacuras (Gimantis in the English-dubbed version), the scientists find the monstrous insects digging an egg out from under a pile of earth. The egg hatches, revealing a baby Godzilla. The scientists realize that the baby's telepathic cries for help were the cause of the interference that ruined their experiment. Shortly afterwards, Godzilla arrives on the island in response to the infant's cries, demolishing the scientist's base while rushing to defend the baby. Godzilla kills two of the Kamacuras during the battle while one manages to fly away to safety, Godzilla then adopts the baby.
The baby Godzilla, named Minilla, quickly grows to about half the size of the adult Godzilla and Godzilla instructs it on the important monster skills of roaring and using its atomic ray. At first, Minilla has difficulty producing anything more than atomic smoke rings, but Godzilla discovers that stressful conditions (i.e. stomping on his tail) or motivation produces a true radioactive blast. Minilla comes to the aid of Saeko when she is attacked by a Kamacuras, but inadvertently awakens Kumonga (Spiga in the English-dubbed version), a giant spider that was sleeping in a valley. Kumonga attacks the caves where the scientists are hiding and Minilla stumbles into the fray.
Kumonga traps Minilla and the final Kamacuras with its webbing, but as Kumonga begins to feed on the deceased Kamacuras, Godzilla arrives. Godzilla saves Minilla and they work together to defeat Kumonga by using their atomic rays on the giant spider. Hoping to keep the monsters from interfering in their attempt to escape the island, the scientists finally use their perfected weather altering device on the island and the once tropical island becomes buried in snow and ice. As the scientists are saved by an American submarine, Godzilla and Minilla begin to hibernate as they wait for the island to become tropical again.
## Production.
For the second "Godzilla" film in a row, Toho produced an island themed adventure with a smaller budget than most of their monster films from this time period. While the a-list crew of talent was hired to work on that year's "King Kong Escapes", (Ishirō Honda, Eiji Tsuburaya, and Akira Ifukube), the second string crew of cheaper talent was once again tapped to work on this project as they had done with "Ebirah, Horror of the Deep". This included Jun Fukuda (director), Sadamasa Arikawa (special effects), and Masaru Sato (composer). This was the first film where Arikawa was officially listed as the director of Special Effects, although he did receive some supervision from Tsuburaya when he was available.
Toho wanted to create a baby Godzilla to appeal to the "date crowd" (a genre of films that were very popular among young couples during this time period), with the idea that girls would like a "cute" baby monster. For the idea behind Minilla, Fukuda stated, "We wanted to take a new approach, so we gave Godzilla a child. We thought it would be a little strange if we gave Godzilla a daughter, so instead we gave him a son". Fukuda also wanted to portray the monsters almost as people in regards to the father-son relationship between Godzilla and Minilla, as Fukuda stated "We focused on the relationship between Godzilla and his son throughout the course of "Son of Godzilla".
Minilla was designed to incorporate features of not only a baby Godzilla but a human baby was well. "Marchan the Dwarf" was hired to play the character due to his ability to play-act and to give the character a childlike ambiance. He was also hired because of his ability to perform athletic rolls and flips inside the thick rubber suit.
The Godzilla suit built for this film was the biggest in terms of size and girth. This was done in order to give Godzilla a "maternal" appearance and to give a parent-like stature in contrast next to Minilla. Because of the size of the suit, seasoned Godzilla suit actor Haruo Nakajima was only hired to play Godzilla in two scenes because the suit was much too big for him to wear. The smaller suit he had worn for the films "Ebirah, Horror of the Deep" and "Invasion of Astro-Monster" was used for these sequences. The much larger Seji Onaka instead played Godzilla in the film, although he was replaced midway through filming by Hiroshi Sekita after he broke his fingers.
Outside of the two monster suits, various marionettes and puppets were used to portray the Island's gigantic inhabitants. The various giant preying mantises known as Kamacuras and the huge spider Kumonga. Arikawa would usually have 20 puppeteers at a time working on the various marionettes. The massive Kumonga puppet needed 2 to 3 people at a time to operate each leg. Filming took place in Guam and areas in Japan including Gotemba, Lake Yamana, the Fuji Five Lakes region, and Oshima. A sequence that shows Godzilla leaving Minilla behind on the freezing Sollgel Island and making it to shore before turning back was cut from the final film's ending. A portion of this sequence has been preserved in both the trailer and an outtake reel included with the Godzilla Final Box DVD collection as supplemental material.
## Release.
### Theatrical.
"Son of Godzilla" was distributed theatrically in Japan by Toho on December 16, 1967. The film was released theatrically in the United Kingdom in August of 1969, as a double feature with "Ebirah, Horror of the Deep". "Son of Godzilla" was never released theatrically in the United States, instead being released directly to television by Walter Reade Sterling as well as American International Pictures (AIP-TV) in some markets in 1969. The American television version was cut to 84 minutes.
### Home media.
In 2005, the film was released on DVD by Sony Pictures in its original uncut length with the original Japanese audio and Toho's international English dub. In 2019, the Japanese version and export English version was included in a Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era.
## Reception.
In a contemporary review, the "Monthly Film Bulletin" declared the film to be "out of the top drawer of the Toho Company's monster file, with the special effects department achieving their best results in monster locomotion" and that the film "has the advantage of a more soundly constructed story than most of its predecessors and a delightful vein of humor that allows for a gentle parody of the genre."
According to the Polish writer Aleksandra Ziółkowska-Boehm, the film appealed to Polish journalist Melchior Wańkowicz: "On August 9, Tomuś's birthday, we all went to see "Son of Godzilla". I was afraid [Melchior] would be irritated by this film's type. I was again surprised, I watched with what interest he looked at the picture. Later he said that he had never seen this genre, but he was delighted with the technique of realization."

</doc>
<doc id="11994" url="https://en.wikipedia.org/wiki?curid=11994" title="Destroy All Monsters">
Destroy All Monsters

 is a 1968 Japanese "kaiju" film directed by Ishirō Honda, with special effects by Eiji Tsuburaya. The film, which was produced and distributed by Toho Co., Ltd, is the ninth film in the "Godzilla" franchise, and features eleven monster characters, including Godzilla, Mothra, Rodan, King Ghidorah, Anguirus, and Minilla. The film stars Akira Kubo, Jun Tazaki, Yukiko Kobayashi and Yoshio Tsuchiya.
In the film, humans have achieved world peace by the year 1999, and various giant monsters are confined to an area known as Monsterland. The monsters are freed from the area and are mind-controlled by aliens known as Kilaaks, who send them to attack major cities. When the monsters are freed from the Kilaaks' influence, the aliens send King Ghidorah to challenge the other monsters.
"Destroy All Monsters" was released theatrically in Japan on August 1, 1968. The film was released by American International Pictures with an English-language dub in the United States on May 23, 1969. Contemporary American reviews were mixed, with praise mainly held for the climactic monster battle. Retrospectively, the film has received more praise, and is considered a favorite among "Godzilla" fans for its "audacious and simple story", "innovative action sequences", and a "memorably booming" score by Akira Ifukube.
## Plot.
At the close of the 20th century, all of the Earth's kaiju have been collected by the United Nations Science Committee and confined in an area known as Monster Island, located in the Ogasawara island chain. A special control center is constructed underneath the island to ensure that the monsters stay secure and to serve as a research facility to study them.
When communications with Monster Island are suddenly and mysteriously severed, and all of the monsters begin attacking world capitals, Dr. Yoshida of the UNSC orders Captain Yamabe and the crew of his spaceship, Moonlight SY-3, to investigate Ogasawara. There, they discover that the scientists, led by Dr. Otani, have become mind-controlled slaves of a feminine alien race identifying themselves as the Kilaaks, who reveal that they are in control of the monsters. Their leader demands that the human race surrender, or face total annihilation.
Godzilla attacks New York City, Rodan invades Moscow, Mothra lays waste to Beijing, Gorosaurus destroys Paris (although Baragon was credited for its destruction), and Manda attacks London. These attacks were set in to motion to draw attention away from Japan, so that the aliens can establish an underground stronghold near Mount Fuji in Japan. The Kilaaks then turn their next major attack onto Tokyo and, without serious opposition, become arrogant in their aims until the UNSC discover, after recovering the Kilaaks' monster mind-control devices from around the world, that they have switched to broadcasting the control signals from their base under the Moon's surface. In a desperate battle, the crew of the SY-3 destroys the Kilaak's lunar outpost and returns the alien control system to Earth.
With all of the monsters under the control of the UNSC, the Kilaaks call King Ghidorah. The three-headed space dragon is dispatched to protect the alien stronghold at Mount Fuji, and battles Godzilla, Minilla, Mothra, Rodan, Gorosaurus, Anguirus, and Kumonga. While seemingly invincible, King Ghidorah is eventually overpowered by the combined strength of the Earth monsters and is killed. Refusing to admit defeat, the Kilaaks produce their ace, a burning monster they call the Fire Dragon, which begins to torch Tokyo and destroys the control center on Ogasawara. Suddenly, Godzilla attacks and destroys the Kilaaks' underground base, revealing that the Earth's monsters instinctively know who their enemies are. Captain Yamabe then pursues the Fire Dragon in the SY-3 and narrowly achieves victory for the human race. The Fire Dragon is revealed to be a flaming Kilaak saucer and is destroyed. With the Kilaaks defeated, Godzilla and the other monsters eventually return to Monster Island to live in peace.
## Production.
Per the waning popularity of the "Godzilla" series, special effects director Sadamasa Arikawa noted that Toho were going to potentially end the "Godzilla" series as "Producer Tanaka figured that all the ideas had just run out."
The film was written by Takeshi Kimura and Ishirō Honda, making it the first "Godzilla" film since "Godzilla Raids Again" not written by Shinichi Sekizawa. Takeshi Kimura is credited to the pen name Kaoru Mabuchi in the film's credits. Kimura and Honda's script developed the concept of Monsterland (referred to as Monster Island in future films). 
The earliest screenplay was titled, Monster Chushingura (Chushingura refers to a famous historical story in Japan about the rebellion of 47 samurai who took revenge after their master was unjustly forced to commit suicide.) Written in 1967 by Kimura, this version of the film was to include “all of the monsters”, according to Ishiro Honda in an interview. The story called for Godzilla, Minilla, Anguirus, Rodan, Mothra, Gorosaurus, Manda, Baragon, Kumonga, Varan, Magma, Kamacuras, Gaira, Sanda, and King Kong to appear in the film. When it was decided to adapt "Two Godzillas!: Japan SOS" (an earlier version of "Son of Godzilla") instead, the script was shelved for next year, by then the rights to Kong had expired. Ishiro Honda also wanted to show lunar colonies and brand new hybrid monsters, the results of interbreeding and genetic splicing. He also wanted to delve more deeply into undersea farming to feed the monsters. But because of budget constraints he couldn't show all this. In later scripts, the number of monsters was cut as well.
As the film has several monsters who continuously return in the films, the location was developed to be a faraway island where the monsters are pacified. This tied other films not related to the "Godzilla" series within its universe, as creatures such as Manda (from "Atragon") and Varan ("Varan the Unbelievable") exist. The film features footage from "Ghidorah, the Three-Headed Monster" (1964), specifically King Ghidorah's fiery birth scene.
New monster suits for Godzilla and Anguirus were constructed for the film, while Rodan, Kumonga, Minilla, Gorosaurus, Manda, Baragon, Mothra, and King Ghidorah suits were modified from previous films, with King Ghidorah having less detail than he had in previous films.
## Release.
"Destroy All Monsters" was released in Japan on 1 August 1968 where it was distributed by Toho. It was released on a double bill with a reissue of the film "Atragon". The film was reissued theatrically in Japan in 1972 where it was re-edited by Honda to a 74-minute running time and released with the title "Gojira: Dengeki Taisakusen" ( "Godzilla: Lightning Fast Strategy"). "Destroy All Monsters" continued the decline in ticket sales in Japan for the "Godzilla" series, earning 2.6 million in ticket sales. In comparison, "Invasion of Astro-Monster" brought in 3.8 million and "Son of Godzilla" collected 2.5 million.
The film was released in the United States by American International Pictures with an English-language dub on 23 May 1969. The film premiered in the United States in Cincinnati. American International Pictures hired Titra Studios to dub the film into English. The American version of the film remains relatively close to the Japanese original. Among the more notable removed elements include Akira Ifukube's title theme and a brief shot of Minilla shielding his eyes and ducking when King Ghidorah drops Anguirus from the sky. "Destroy All Monsters" was shown on American television until the early 1980s. It resurfaced on cable broadcast on the Sci-Fi Channel in 1996.
### Home media.
"Destroy All Monsters" was released on VHS by ADV Films in 1998 which featured English-dubbed dialogue from Toho's own international version of the film. In 2011, Tokyo Shock released the film on DVD and Blu-ray and in 2014 the company re-released it on DVD and Blu-ray. In 2019, the Japanese version and export English version were included in a Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era.
## Critical reception.
From contemporary reviews, both "Variety" and "Monthly Film Bulletin" noted the film's best scenes involved the monsters together, while criticising the filmmaking. "Variety" reviewed the English-dubbed version of the film stating that it may appeal to "Sci-fi addicts and monster fans" while stating that the "plot is on comic strip level, special effects depend on obvious miniatures and acting (human) is from school of "Flash Gordon"" and that the film's strength relied on its "monster rally". The "Monthly Film Bulletin" opined that "the model work is poor, and as usual the script is junior comic-strip". Both reviews mentioned the monsters' final scene with "Variety" commenting that it was "clever" and the "Monthly Film Bulletin" stating that "apart from [the monsters] statutory devastation of world capitals [...] the monsters have disappointingly little to do until they get together in the last reel for a splendid battle" The "Monthly Film Bulletin" commented that the film was "almost worth sitting through the banalities for the final confrontation on Mount Fuji" noting the son of Godzilla "endearingly applauding from a safe distance" and "the victorious monsters performing a celebratory jig".
From retrospective reviews, Steve Biodrowski of "Cinefantastique" commented that the film "is too slim in its storyline, too thin in its characterizations, to be considered a truly great film [...] But for the ten-year-old living inside us all, it is entertainment of the most awesome sort." Matt Paprocki of "Blogcritics" said the film is "far from perfect" and "can be downright boring at times" but felt that "the destruction scenes make up for everything else" and "the final battle is an epic that simply can't be matched".
The film is considered a cult favorite among fans of the "Godzilla" franchise. In Steve Ryfle and Ed Godziszewski's 2017 book covering Ishiro Honda's filmography, they expressed that "Destroy All Monsters" is now seen as the "last truly spirited entry" in Toho's initial series of "kaiju" films, due to "its audacious and simple story, a bounty of monsters and destruction, and a memorably booming soundtrack from Akira Ifukube".
"Godzilla" director Gareth Edwards previously expressed interest in making a sequel to his 2014 movie inspired by "Destroy All Monsters".

</doc>
<doc id="11995" url="https://en.wikipedia.org/wiki?curid=11995" title="Godzilla's Revenge">
Godzilla's Revenge



</doc>
<doc id="11996" url="https://en.wikipedia.org/wiki?curid=11996" title="Godzilla/Godzilla vs Gigan">
Godzilla/Godzilla vs Gigan



</doc>
<doc id="11997" url="https://en.wikipedia.org/wiki?curid=11997" title="Godzilla vs The Smog Monster">
Godzilla vs The Smog Monster



</doc>
<doc id="11998" url="https://en.wikipedia.org/wiki?curid=11998" title="Godzilla vs. Megalon">
Godzilla vs. Megalon

 is a 1973 Japanese "kaiju" film directed by Jun Fukuda, written by Fukuda and Shinichi Sekizawa, and produced by Tomoyuki Tanaka, with special effects by Teruyoshi Nakano. Distributed by Toho and produced under their effects subsidiary Toho–Eizo, it is the 13th film in the "Godzilla" franchise, and features the fictional monster characters Godzilla, Megalon, and Gigan, along with the mecha character Jet Jaguar. The film stars Katsuhiko Sasaki, Hiroyuki Kawase, Yutaka Hayashi, and Robert Dunham, alongside Shinji Takagi as Godzilla, Hideto Date as Megalon, Kenpachiro Satsuma as Gigan, and Tsugutoshi Komada as Jet Jaguar.
"Godzilla vs. Megalon" was released theatrically in Japan on March 17, 1973. It received a theatrical release in the United States in the summer of 1976 by Cinema Shares.
## Plot.
In the first part of 1971 (197X in the Japanese version), the most recent underground nuclear test, set off near the Aleutians, sends shockwaves as far across the globe as Monster Island in the South Pacific, severely damaging the island paradise and sending Rodan and Anguirus plummeting into the depths of the Earth, with Godzilla narrowly escaping the fissure which his friends tumbled into.
For years, Seatopia, an opulent undersea civilisation that resides in vast cities reminiscent of those of Ancient Greece and Rome, has existed in relative peace, ruled by Emperor Antonio, but nuclear tests in recent years have severely affected the cities via the earthquakes the tests produced. With the Seatopian capital badly affected by the most recent test, the Seatopians plan to unleash their civilization's beetle-styled god, Megalon, to destroy the surface world out of vengeance.
On the surface, an inventor named Goro Ibuki, his little brother Rokuro, and Goro's friend Hiroshi Jinkawa are off on an outing near a lake when Seatopia makes itself known to the Earth by drying up the lake the trio was relaxing nearby and using it as a base of operation. As they return home they are ambushed by agents of Seatopia who are trying to steal Jet Jaguar, a humanoid robot under construction by the trio of inventors. However the agents' first attempt is botched and they are forced to flee to safety.
Some time later, Jet Jaguar is completed but the trio of inventors are knocked unconscious by the returning Seatopian agents. The agents' plan is to use Jet Jaguar to guide and direct Megalon to destroy whatever city Seatopia commands him to do. Goro and Rokuro are sent to be killed, while Hiroshi is taken hostage. Megalon is finally released to the surface while Jet Jaguar is put under the control of the Seatopians and is used to guide Megalon to attack Tokyo with the Japan Self Defense Forces failing to defeat the monster. Eventually, the trio of heroes manage to escape their situation with the Seatopians and reunite to devise a plan to send Jet Jaguar to get Godzilla's help using Jet Jaguar's secondary control system.
After uniting with Japan's Defense Force, Goro manages to regain control of Jet Jaguar and sends the robot to Monster Island to bring Godzilla to fight Megalon. Without a guide to control its actions, Megalon flails around relentlessly and aimlessly fighting with the Defense Force and destroying the outskirts of Tokyo. The Seatopians learn of Jet Jaguar's turn and thus send out a distress call to their allies, the Space Hunter Nebula M aliens (from the previous film) to send the alien monster Gigan to assist their allies.
As Godzilla journeys to fight Megalon, Jet Jaguar starts acting on its own and ignoring commands to the surprise of its inventors, and grows to gigantic proportions to face Megalon himself until Godzilla arrives. The battle is roughly at a standstill between robot and cyborg, until Gigan arrives and both Megalon and Gigan double team against Jet Jaguar. Godzilla finally arrives to assist Jet Jaguar and the odds become even. After a long and brutal fight, Gigan and Megalon both retreat and Godzilla and Jet Jaguar shake hands on a job well done. Jet Jaguar bids Godzilla farewell and Godzilla returns to its home on Monster Island. Jet Jaguar turns back to its human size, and returns home with Goro and Rokuro.
## Production.
### Development.
The origins of Megalon can be traced back to 1969's "All Monsters Attack", as the original working idea for the film's antagonist Gabara was initially envisioned as a giant mole cricket called Gebara. The character was later reworked into Kaoru Mabuchi's 1971 treatment for "Godzilla vs. the Space Monsters: Earth Defense Directive", a precursor to 1972's "Godzilla vs. Gigan". The proposal called for Megalon to be paired with Gigan and King Ghidorah under the command of the hostile alien invader Miko, only to be defeated and driven off by the combined might of Godzilla, Anguirus, and a brand new monster called Majin Tuol. The next draft of the script, titled "The Return of King Ghidorah!", retained the core villain cast of Gigan, King Ghidorah, and Megalon, but replaced Anguirus and Majin Tuol with Varan and Rodan. However, most of the proposed monsters were cut, leading to the final version of "Godzilla vs. Gigan".
Contrary to popular belief, there is no evidence "Godzilla vs. Megalon" was originally planned as a Jet Jaguar solo film, and no Japanese sources have surfaced which claim otherwise. Rather, the creation of Jet Jaguar was the result of a contest Toho had for children in mid-to-late 1972. The winner of the contest was an elementary school student, who submitted the drawing of a robot called Red Arone. Red Arone was turned into a monster suit, but when the child was shown the suit, he became upset because the suit did not resemble his original design. The boy's original design was white but the costume was colored red, blue and yellow. Red Arone was used for publicity, but Toho had renamed the character Jet Jaguar and had special effects director Teruyoshi Nakano redesign the character, only keeping the colors from the Red Arone suit. The Red Arone suit had a different head and wings.
According to Teruyoshi Nakano, "Godzilla vs. Megalon" was a replacement project for another film that was cancelled at the last minute, and evidence suggests this cancelled film was "Godzilla vs. Red Moon", slated for 1973. As a result, the project was postponed during pre-production. Screenwriter Shinichi Sekizawa had no time to write out a full script, and instead thought out a general story. Director Jun Fukuda ultimately ended up writing the screenplay. To make up for lost production time, the film was shot in a hasty three weeks. The production time totaled nearly six months from planning to finish.
The film had three early treatments, each written by Shinichi Sekizawa, one was titled "Godzilla vs. The Megalon Brothers: The Undersea Kingdom's Annihilation Strategy" which was completed in September 1972. The second was titled "Insect Monster Megalon vs. Godzilla: Undersea Kingdom's Annihilation Strategy", which was turned in on September 5, 1972, and the third draft was submitted on September 7, 1972.
### Creature design.
According to Teruyoshi Nakano, the Godzilla suit used in this film (nicknamed "MegaroGoji" メガロゴジ ) was made in a week, making it the fastest Godzilla suit ever made to date. They did not have time to make the eyes work correctly, something they had more time to fix for Godzilla's five appearances on Toho's superhero TV series "Zone Fighter" (1973), which was produced around the same time.
The Megalon suit was one of the heaviest suits produced since the 1954 "Godzilla" suit, which made it even more difficult to raise the Megalon suit via wires in certain scenes up to the point where Nakano almost decided to scrap those scenes altogether. Since the film was shot in the winter, Katsuhiko Sasaki stated that director Jun Fukuda gave him and Yutaka Hayashi a shot of whiskey to warm them up.
The Gigan suit is similar to the previous design, but the suit was made thinner, less bulky, the horn on the head was less pointed, and the buzzsaw didn't move, since it was made of static pieces. This suit also has different-sized back fins, a more circular visor, scales running up the back/sides of the neck and longer legs compared to the original version.
Teruyoshi Nakano recalls how the film was rushed and that it took three weeks to shoot, stating, "It went into productions without enough preparation. There was no time to ask Mr. Sekizawa to write the script, so Mr. Sekizawa kind of thought up the general story and director Fukuda wrote the screenplay. The screenplay was completed right before crank-in".
### Filming.
Like previous Godzilla films, "Godzilla vs. Megalon" heavily employs stock footage from previous films such as "Mothra vs. Godzilla" (1964), "The War of the Gargantuas" (1966), "Ebirah, Horror of the Deep" (1966), "Destroy All Monsters" (1968), "Godzilla vs. Hedorah" (1971), and "Godzilla vs. Gigan" (1972).
## English versions.
In 1976, Cinema Shares gave "Godzilla vs. Megalon" a wide theatrical release in the United States and launched a massive marketing campaign for the film, along with the poster, buttons with one of the four monsters' faces on them were released. Given away at theatrical showings was a comic that told a simplified version of the film, which incorrectly named Jet Jaguar as "Robotman" and Gigan as "Borodan". These incorrect names were also featured in the U.S. trailer.
Initially, Cinema Shares screened Toho's international English version but to ensure a G rating, several cuts were made, which resulted in the film running three minutes shorter than the original version.
"Godzilla vs. Megalon" is the first Godzilla film to receive an American prime time network television premiere, where it was broadcast nationwide at 9:00 PM on NBC on March 15, 1977. However, to accommodate commercials, the film was only shown in a one-hour time slot, which resulted in the film being cut down to 48 minutes. John Belushi hosted the broadcast where he did some skits, all in a Godzilla suit.
Mel Maron (who was president of Cinema Shares at the time) chose to release "Godzilla vs. Megalon" because he saw Godzilla as a heroic figure by that point and felt the timing was right to show children a hero who was a friendly monster and not Superman.
The U.S. rights for the film eventually fell into the public domain in the late 80s, which resulted in companies releasing poorly-cropped, fullscreen VHS tapes mastered from pan and scan sources. This also led to the film being featured in "Mystery Science Theater 3000". In 1988, New World Video intended to release the original uncut version of the English dub but, declined the project, due to a lack of budget that was required for a full release. However, despite this, the film was released uncut and in widescreen in 1992 by UK company Polygram Ltd as a double feature with "Godzilla vs. Gigan". In 1998 the film was again released by UK company, 4 Front Video. As of now it appears those are the only two VHS tapes on the film that are unedited and in high quality. It was also released on DVD by Power Multimedia in 1999 in Taiwan. Originally the Sci-Fi Channel (now SyFy) showed the cut version, until finally in 2002 as Toho regained ownership of that title alongside "Godzilla vs. Gigan" and "Godzilla vs. Mechagodzilla" (both of which also were released by Cinema Shares) and broadcast the film fully uncut for the first time in the U.S.
## Release.
### Box office.
In Japan, "Godzilla vs. Megalon" sold approximately 980,000 tickets. It was the first "Godzilla" film to sell less than one million admissions. It earned ¥220 million in Japan distribution income (rentals).
The film was a success in American theaters, earning $383,744 in its first three days in Texas and Louisiana alone. The film grossed about worldwide.
### Critical reception.
"Godzilla vs. Megalon" was released theatrically in America on May 9, 1976, though the "San Francisco Chronicle" indicates that it opened there in June, and "The New York Times" indicates that it opened in New York City on July 11. "The New York Times" film critic Vincent Canby, who a decade before had given a negative review to "Ghidorah, the Three-Headed Monster", gave "Godzilla vs. Megalon" a generally positive review. In his review on July 12, 1976, Canby said, ""Godzilla vs. Megalon" completes the canonization of Godzilla...It's been a remarkable transformation of character - the dragon has become St. George...It's wildly preposterous, imaginative and funny (often intentionally). It demonstrates the rewards of friendship, between humans as well as monsters, and it is gentle."
"Godzilla vs. Megalon" has attracted the ire of many "Godzilla" fans in the decades since its original release. The film contributed to the reputation of "Godzilla" films in the United States as cheap children's entertainment that should not be taken seriously. It has been described as "incredibly, undeniably, mind-numbingly bad" and one of the "poorer moments" in the history of kaiju films.
Author Stephen Mark Rainey's critique of the film was strongly negative, published in Japanese Giants, issue four. 1977. Edited and published by Bradford G. Boyle.
In particular, the special effects of the film have been heavily criticized. One review described the Godzilla costume as appearing to be "crossed with Kermit the Frog" and another sneeringly compared it to "Godzilla vs. Gigan", stating that it did "everything wrong that "Gigan" did, and then some." However, most of the criticism is of the lack of actual special effects work, as most of it consists of stock footage from previous films, including "Godzilla vs. Gigan" and "Ghidorah, the Three-Headed Monster", but a few pieces of effects work have garnered praise, specifically a scene where Megalon breaks through a dam and the draining of the lake.
The other aspects of the film have been similarly skewered. The acting is usually described as flat and generally poor, and as not improving, or sometimes, worsening, the already weak script. One part of the film, on the other hand, has garnered almost universal praise: Godzilla's final attack on Megalon, a flying kick. It has been called the saving grace of the film, and was made famous by the mock exclamations of shock and awe displayed on "Godzilla vs. Megalon"'s appearance on "Mystery Science Theater 3000". Through the end of season three to the middle of season five, that clip would be shown at the opening of each show.
Despite all this, the film is also one of the most widely seen "Godzilla "films in the United States — it was popular in its initial theatrical release, largely due to an aggressive marketing campaign, including elaborate posters of the two title monsters battling atop New York City's World Trade Center towers, presumably to capitalize on the hype surrounding the Dino De Laurentiis remake of "King Kong", which used a similar image for its own poster.
### Home media.
The film was released numerous times in the VHS format, mostly as videos from bargain basement studios that featured the edited TV version (which was wrongly assumed to be in the public domain for many years), while PolyGram and 4 Front released the unedited version of the film in 1992 and 1998, respectively. Some rumors have circulated that the film's original VHS releases in the States were uncut, but there is no evidence confirming or denying this.  
Media Blasters acquired the DVD rights to both "Godzilla vs. Megalon" and "Destroy All Monsters". Both films were released under one of the company's divisions, Tokyo Shock. Media Blasters originally planned to release "Godzilla vs. Megalon" on DVD and Blu-ray on December 20, 2011; however, due to technical difficulties with the dubbing and Toho having yet to give its approval for the release, the DVD/Blu-ray release was delayed. Media Blasters finally released the film on August 14, 2012, but only on a bare-bones DVD and Blu-ray. Despite this, a manufacturing error led to several copies of the originally planned version featuring bonus content to be released by accident. These special features versions are incredibly rare and are not labelled differently from the standard version, making them nearly impossible to find. This release was commercially the first to remaster the film to its original full-length version. In 2019, the Japanese version and export English dub were included in a Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era.

</doc>
<doc id="11999" url="https://en.wikipedia.org/wiki?curid=11999" title="Godzilla vs The Cosmic Monster">
Godzilla vs The Cosmic Monster



</doc>
<doc id="12000" url="https://en.wikipedia.org/wiki?curid=12000" title="Godzilla vs. Biollante">
Godzilla vs. Biollante

 is a 1989 Japanese "kaiju" film written and directed by Kazuki Ōmori, with special effects by Koichi Kawakita. Distributed by Toho and produced under their subsidiary Toho Pictures, it is the 17th film in the "Godzilla" franchise and the second film in the franchise's Heisei period. The film stars Kunihiko Mitamura, Yoshiko Tanaka, Masanobu Takashima, Megumi Odaka, Toru Minegishi, Yasuko Sawaguchi, Toshiyuki Nagashima, Yoshiko Kuga, Ryunosuke Kaneda and Kōji Takahashi.
In the film, Godzilla battles a monster born from the cells of a plant and a woman, as corporations struggle for control over Godzilla cells. The idea originated from a public story-writing contest, and set a trend common to all Heisei era movies, in which Godzilla faces off against opponents capable of metamorphosing into new, progressively more powerful forms.
"Godzilla vs. Biollante" was released theatrically in Japan on December 16, 1989. It received a direct-to-video release in the United States on November 25, 1992 through HBO Video. Although it received generally positive reviews, the film was a disappointment at the Japanese box office. In Japan, it was followed by "Godzilla vs. King Ghidorah" in 1991.
## Plot.
In the aftermath of Godzilla's attack on Tokyo and later imprisonment at Mount Mihara, the monster's cells are secretly delivered to the Saradia Institute of Technology and Science, where they are to be merged with genetically modified plants in the hope of transforming Saradia's deserts into fertile land and ending the country's economic dependence on oil wells. Dr. Genshiro Shiragami and his daughter, Erika, are enlisted to aid with the project. However, a terrorist bombing destroys the institute's laboratory, ruining the cells and killing Erika.
In 1989, Shiragami has returned to Japan and merged some of Erika's cells with those of a rose in an attempt to preserve her soul. Scientist Kazuhito Kirishima and Lieutenant Goro Gondo of the Japan Self-Defense Forces (JSDF) are using the Godzilla cells they collected to create "Anti-Nuclear Energy Bacteria", hoping it can serve as a weapon against Godzilla should it return. They attempt to recruit Shiragami to aid them, but are rebuffed. Meanwhile, international tensions increase over the Godzilla cells, as they are coveted by both the Saradia Institute of Technology and Science and the American Bio-Major organization. An explosion from Mount Mihara causes tremors across the area, including Shiragami's home, badly damaging the roses. Shiragami agrees to join the JSDF's effort and is given access to the Godzilla cells, which he secretly merges with one of the roses. A night later, rival Bio-Major and Saradian agents break into Shiragami's lab, but are attacked by a large plant-like creature which later escapes to Lake Ashi and is named "Biollante" by Shiragami.
Bio-Major agents plant explosives around Mount Mihara and blackmails the Diet of Japan, warning the explosives will be detonated and thus free Godzilla if the cells are not handed over. Kirishima and Gondo attempt to trade, but Saradian agent SSS9 thwarts the attempt and escapes with the cells. The explosives are detonated, and Godzilla is released. Godzilla attempts to reach the nearest power plant to replenish its supply of nuclear energy, but Biollante calls out to Godzilla. Godzilla arrives at the lake to engage Biollante in a vicious battle, and emerges as the victor. Godzilla then proceeds toward the power plant at Tsuruga, but psychic Miki Saegusa uses her powers to divert it toward Osaka instead. The city is quickly evacuated before Godzilla makes landfall. A team led by Gondo meet Godzilla at the central district and fire rockets infused with the anti-nuclear bacteria into its body. Gondo is killed in the process, and an unharmed Godzilla leaves.
Kirishima recovers the cells and returns them to the JSDF. Shiragami theorizes that if Godzilla's body temperature is increased, the bacteria should work against him. The JSDF erects microwave-emitting plates during an artificial thunderstorm, hitting Godzilla with lightning and heating up his body temperature during a battle near the shores of Wakasa Bay. Godzilla is only moderately affected, but Biollante arrives to engage Godzilla in battle once again. After a long battle, the fight ends after Godzilla fires an atomic heat ray inside Biollante's mouth, severely injuring her. An exhausted Godzilla collapses on the beach as the bacterial infection finally takes hold, and Biollante splits apart into glowing spores which rise into the sky, forming an image of Erika among the stars. Shiragami, watching the scene, is killed by SSS9. Kirishima chases the assassin and, after a brief scuffle, SSS9 is killed by a microwave-emitting plate activated by Sho Kuroki. Godzilla reawakens and leaves for the ocean.
## Production.
### Pre-production.
Tomoyuki Tanaka announced a sequel to "The Return of Godzilla" in 1985, but was skeptical of its possibilities, as the film had been of little financial benefit to Toho, and the failure of "King Kong Lives" following year convinced him that audiences were not ready for a continuation of the "Godzilla" series. He relented after the success of "Little Shop of Horrors", and proceeded to hold a public story contest for a possible script. In consideration of "The Return of Godzilla"'s marginal success in Japan, Tanaka insisted that the story focus on a classic monster vs. monster theme. Tanaka handed the five finalist entries to director Kazuki Ōmori, despite the two's initially hostile relationship; the latter had previously held Tanaka responsible for the decline in the "Godzilla" series' quality during the 1970s. Ōmori chose the entry of dentist Shinichiro Kobayashi, who wrote his story with the hypothetical death of his daughter in mind.
Kobayashi's submission was notable for its emphasis on dilemmas concerning biotechnology rather than nuclear energy, and revolved around a scientist grieving for his deceased daughter and attempting to keep her soul alive by merging her genes with those of a plant. The scientist's initial experiments would have resulted in the creation of a giant rat-like amphibian called Deutalios, which would have landed in Tokyo Bay and been killed by Godzilla. A female reporter investigating the scientist's activities would have suffered from psychic visions of plants with humanoid faces compelling her to infiltrate the scientist's laboratory. The scientist would have later confessed his intentions, and the finale would have had Godzilla battling a human-faced Biollante who defeats him by searing his flesh with acid.
Ōmori proceeded to modify the story into a workable script over a period of three years, using his background as a biologist to create a plausible plot involving genetic engineering and botany. In order to preserve the series' anti-nuclear message, he linked the creation of Biollante to the use of Godzilla cells, and replaced Kobayashi's journalist character with Miki Saegusa. He openly admitted that directing a "Godzilla" film was secondary to his desire to make a James Bond movie, and thus added elements of the spy film genre into the plot. Unlike the case with later, more committee-driven "Godzilla" films, Ōmori was given considerable leeway in writing and directing the film, which Toho staff later judged to have been an error resulting in a movie with a very narrow audience.
### Special effects.
Koichi Kawakita, who had previously worked for Tsuburaya Productions, replaced Teruyoshi Nakano as head of the series' special effects unit after Toho became impressed at his work in "Gunhed". Kawakita made use of "Gunhed"'s special effects team Studio OX, and initially wanted to make Godzilla more animal-like, using crocodiles as references, but was berated by Tanaka, who declared Godzilla to be "a monster" rather than an animal. Kenpachiro Satsuma returned to portray Godzilla, hoping to improve his performance by making it less anthropomorphic than in previous films. Suitmaker Noboyuki Yasamaru created a Godzilla suit made specifically with Satsuma's measurements in mind, unlike the previous one which was initially built for another performer and caused Satsuma discomfort. The resulting 242 lb suit proved more comfortable than the last, having a lower center of gravity and more mobile legs. A second 176 lb suit was built for outdoor underwater scenes. The head's size was reduced, and the whites around the eyes removed. On the advice of story finalist Shinichiro Kobayashi, a double row of teeth was incorporated in the jaws. As with the previous film, animatronic models were used for close-up shots. These models were an improvement over the last, as they were made from the same molds used for the main costume, and included an articulated tongue and intricate eye motion. The suit's dorsal plates were filled with light bulbs for scenes in which Godzilla uses his atomic ray, thus lessening reliance on optical animation, though they electrocuted Satsuma the first time they were activated. Satsuma was also obliged to wear protective goggles when in the suit during scenes in which Godzilla battles the JSDF, as real explosives were used on set. The film was mainly shot at the Toho lot, although some filming occued on location at the East Fuji Maneuver Area.
Designing and building the Biollante props proved problematic, as traditional suitmation techniques made realizing the requested design of the creature's first form difficult, and the resulting cumbersome model for Biollante's final form was met with disbelief from the special effects team. Biollante's first form was performed by Masao Takegami, who sat within the model's trunk area on a platform just above water level. While the creature's head movements were simple to operate, its vines were controlled by an intricate array of overhead wires which proved difficult for Satsuma to react to during combat scenes as they offered no tension, thus warranting Satsuma to feign receiving blows from them, despite not being able to perceive them. Biollante's final form was even more difficult to operate, as its vine network took hours to rig up on set. Visibility in both the Godzilla and final form Biollante suits was poor, thus causing difficulties for Takegami in aiming the creature's head when firing sap, which permanently stained anything it landed on.
While it was initially decided to incorporate stop motion animation into the film, the resulting sequences were scrapped, as Kawakita felt they failed to blend in with the live-action footage effectively. The film however became the first of its kind to use CGI, though its usage was limited to scenes involving computer generated schematics. The original cut of the movie had the first battle culminating in Biollante's spores falling around the hills surrounding Lake Ashino and blooming into fields of flowers, though this was removed as the flowers were out of scale.
### Music.
Unlike the previous film, "Godzilla vs. Biollante" incorporates themes from Akira Ifukube's original "Godzilla" theme, though the majority of the soundtrack was composed of original themes by Koichi Sugiyama. The score was orchestrated by conductor David Howell through the Kansai Philarmonic, though Howell himself had never viewed the movie, and thus was left to interpret what the scenes would consist of when conducting the orchestra.
## English version.
After the film was released in Japan, Toho commissioned a Hong Kong company named Omni Productions to dub the film into English.
In early 1990, Toho entered discussions with Miramax to distribute the film. When talks broke off, Toho filed a lawsuit in Los Angeles Federal Court, accusing Miramax of entering an oral agreement in June to pay Toho $500,000 to distribute the film. This lawsuit delayed the film's release for two years. An out of court settlement was reached with Miramax buying the rights to the film for an unreported figure. Miramax would have entertained thoughts of releasing the film in theaters, but in the end it was decided to release the film straight to home video instead. HBO released the film on VHS in 1992 and Laserdisc in 1993. Miramax utilized the uncut English international version of the film for this release.
## Release.
### Home media.
"Godzilla vs. Biollante" was released on VHS by HBO Home Video on November 25, 1992. It was later released on Blu-ray and DVD by Miramax Echo Bridge on December 4, 2012. It was released as a double feature and 8-disk movie pack on both Blu-ray and DVD with "Mega Shark Versus Giant Octopus" (2009) by Echo Bridge Home Entertainment in 2013. It was last released by Lionsgate on Blu-ray and DVD on October 7, 2014. Sometime afterwards, the future of the film's availability remains uncertain.
## Reception.
### Box office.
In Japan, the film sold approximately 2 million tickets, grossing .
### Critical reaction.
"Godzilla vs. Biollante" has received positive reviews, with praise for the story, music and visuals.
Ed Godziszewski of Monster Zero said the film is "by no means a classic" but felt that "for the first time in well over 20 years, a [Godzilla] script is presented with some fresh, original ideas and themes." Joseph Savitski of Beyond Hollywood said the film's music is "a major detraction", but added that it's "not only one of the most imaginative films in the series, but also the most enjoyable to watch." Japan Hero said, "[T]his is definitely a Godzilla movie not to be missed."
In their scholarly book "Japan's Green Monsters" on kaiju cinema, Rhoads and McCorkle offer an ecocritical assessment of "Godzilla vs. Biollante". The scholars focus on the film's critique of genetic engineering and biotechnology years before the subject appeared in more popular Hollywood blockbusters like Steven Spielberg's 1993 blockbuster "Jurassic Park". Rhoads and McCorkle counter prior reviews of the film and argue that "Godzilla vs. Biollante" possesses far deeper environmental messages than the obvious ones present on the film's surface.
In July 2014, in a poll reported by the , "Godzilla vs. Biollante" was selected as the best "Godzilla" film by a group of fans and judges.
Composer Akira Ifukube, who had refused to compose the film's score, stated on interview that he disliked the way Koichi Sugiyama had modernized his Godzilla theme, and defined the Saradia theme as "ridiculous", on account of it sounding more European than Middle Eastern.

</doc>
<doc id="12001" url="https://en.wikipedia.org/wiki?curid=12001" title="Terror of Mechagodzilla">
Terror of Mechagodzilla

 is a 1975 Japanese "kaiju" film directed by Ishirō Honda, written by Yukiko Takayama, and produced by Tomoyuki Tanaka and Henry G. Saperstein, with special effects by Teruyoshi Nakano. Distributed by Toho and produced under their effects subsidiary Toho–Eizo, it is the 15th film in the "Godzilla" franchise, serving as a direct sequel to the 1974 film "Godzilla vs. Mechagodzilla".
"Terror of Mechagodzilla" stars Katsuhiko Sasaki, Tomoko Ai, Akihiko Hirata, and Gorō Mutsumi, and features Toru Kawai, Kazunari Mori, and Tatsumi Nikamoto as the fictional monster characters Godzilla, Mechagodzilla 2, and Titanosaurus, respectively. The film was released theatrically in Japan on March 15, 1975. It received a limited release in the United States in 1978 by Bob Conn Enterprises under the title The Terror of Godzilla. The film remains the least financially successful entry in the "Godzilla" franchise to this day.
## Plot.
Following the events of "Godzilla vs. Mechagodzilla", Interpol agents search for Mechagodzilla's remains at the bottom of the Okinawan Sea in the hopes of gathering information on the robot's builders, the alien Simeons. However, their submarine is attacked by a giant, aquatic dinosaur called Titanosaurus and the crew vanishes.
Interpol launches an investigation into the incident. With the help of marine biologist Akira Ichinose, they trace Titanosaurus to a reclusive, mad scientist named Shinzô Mafune, who wants to destroy mankind. While the group is visiting the scientist's old home, they meet Mafune's daughter, Katsura, who claims her father is dead and that she burned his notes about Titanosaurus at his request. Unbeknownst to Interpol, the living Mafune is visited by Tsuda, aide to the Simeon leader Mugal, who is leading a project to rebuild Mechagodzilla. Mugal offers the Simeons' services to Mafune so that their respective monsters can wipe out mankind and allow them to rebuild the world for themselves.
Complicating matters, Ichinose falls in love with Katsura and unwittingly gives her Interpol's information on the Simeons, Mechagodzilla, and Titanosaurus. She is also revealed to be a cyborg, having undergone cybernetic surgery after she was nearly killed during one of her father's experiments as a child, and implanted with Mechagodzilla's control device. Additionally, an impatient Mafune releases Titanosaurus on Yokosuka without the aliens' permission. While Interpol discovers the dinosaur is vulnerable to supersonic waves, Katsura destroys their supersonic wave oscillator. However, Godzilla arrives and easily defeats Titanosaurus, causing the latter to retreat.
When Ichinose visits Katsura, the Simeons capture him and force him to watch as they unleash Mechagodzilla 2 and Titanosaurus on Tokyo while Interpol struggles to repair their wave oscillator and the Japanese armed forces struggle to fend off the monsters. Godzilla arrives, but is initially outmatched until Interpol distracts Titanosaurus with the repaired wave oscillator, allowing Godzilla to focus on Mechagodzilla 2. Interpol agents infiltrate the aliens' hideout, rescue Ichinose, and kill Mafune and many of the aliens. The remaining Simeons attempt to escape, but Godzilla shoots down their ships with its atomic breath. The wounded Katsura shoots herself to destroy Mechagodzilla 2's control device and dies in Ichinose's arms. With the robot non-functional, Godzilla tosses it into a chasm before blasting it with its atomic breath, causing it to explode and get buried. With help from Interpol, Godzilla then defeats Titanosaurus, who returns to the sea.
## Production.
### Development.
The original screenplay that Yukiko Takayama created after winning Toho's story contest for the next installment in the Godzilla series was picked by assistant producer Kenji Tokoro and was submitted for approval on July 1, 1974, less than four months after "Godzilla vs. Mechagodzilla" was released.
The original concept is similar to the finished version of "Terror of Mechagodzilla", with many of the changes being budgetary in nature. The most obvious alteration is the removal of the two dinosaurs called the Titans, which merged to become Titanosaurus in the first draft. It was an interesting concept, although something that was also under-explained, considering the magnitude of such an occurrence of the creatures merging. Another noticeable change to the script is that of the final battle, which does not move to the countryside but instead would have reduced Tokyo to rubble during the ensuing conflict between the three monsters.
After her initial draft, Takayama submitted a revised version on October 14, 1974. This went through a third revision on December 4, and then yet another on December 28 of that same year before it was met with approval and filming began.
### Filming.
This film is one of two "Godzilla" films with brief nudity (the other being 1994's "Godzilla vs. SpaceGodzilla"). The scene occurs when Katsura undergoes an operation to have Mechagodzilla 2's control device placed inside her body, at which point her breasts are exposed. While she was portrayed by a mannequin in the scene, the scene was cut when the film was released in the U.S., both from the theatrical and TV versions of the film.
Director Ishiro Honda laments not being able to work with the story's writer, Yukiko Takayama, on other films, enjoying that a "woman's perspective was especially fresh" for the genre.
Kensho Yamashita was the chief assistant director on the project. He notes, though, that Honda never actually assigned any of the shooting to him, possibly because he was happy to be directing again after a long gap in his career and wanted to do the work himself.
## English version.
Toho titled its English version of the film "Terror of Mechagodzilla" and had it dubbed into English in Hong Kong. This “international version” has never seen wide release in the United States, but has been issued on VHS in the United Kingdom by PolyGram Video Ltd. and on DVD in Taiwan by Power Multimedia.
The film was given a North American theatrical release in March 1978 by independent distributor Bob Conn Enterprises under the title "The Terror of Godzilla". Just as Cinema Shares had done with the previous three "Godzilla" movies, Bob Conn Enterprises chose to utilize the Toho-commissioned English dub instead of hiring a new crew to re-dub the film. "The Terror of Godzilla" was heavily edited to obtain a "G" rating from the MPAA. Several scenes with violent content were entirely removed, disrupting the flow of the narrative.
Henry G. Saperstein, who sold the theatrical rights to Bob Conn Enterprises, also released the film to television in late 1978, this time under Toho's international title, "Terror of Mechagodzilla". Unlike "The Terror of Godzilla", the television version remained mostly uncut, with only the shot of Katsura's naked breasts excised. Saperstein's editors also added a 10-minute prologue that served as a brief history of Godzilla, with footage from Saperstein's English versions of "Invasion of Astro-Monster" and "All Monsters Attack" (the latter of which utilized stock footage from both "Ebirah, Horror of the Deep" and "Son of Godzilla").
In the mid-1980s, the U.S. television version, "Terror of Mechagodzilla", was replaced by the theatrical edit, "The Terror of Godzilla", on television and home video. For some reason, the title was also changed to "Terror of Mechagodzilla". The 1994 Paramount release of "Terror of Mechagodzilla" listed a running time of 89 minutes on the slipcase, implying that this release would be the longer version first shown on American TV. The actual video cassette featured the edited theatrical version. In a 1995 interview with "G-Fan" magazine, Saperstein was surprised to hear about this mistake. In 1997 on Channel 4 in the U.K., three Godzilla movies were shown back to back late at night, starting with "Godzilla vs. Megalon", "Godzilla vs. Gigan" and then "Terror of Mechagodzilla"; all were dubbed versions. This showing was uncut, including the Katsura nudity scene, but it did not have the Western-made prologue.
In the mid-2000s, the television version showed up again on Monsters HD, and in 2007, it made its home video debut as the U.S. version on the Classic Media DVD. Although the added prologue was originally framed for fullscreen television, it was cropped and shown in widescreen on the disc. The rest of the movie featured the audio from Saperstein's television version synced to video from the Japanese version.
The first article about the movie's storyline was published in Japanese Giants #4 in 1977, edited and published by Bradford G. Boyle, and was written by Richard H. Campbell, creator of "The Godzilla Fan News Letter" (a.k.a. "The Gang").
## Box office.
In Japan, the film sold 980,000 tickets. Despite earning positive reviews, it would be the least-attended "Godzilla" film in Japan and also one of only two "Godzilla" films to sell less than 1 million tickets. This was part of a decline in attendance for monster movies as a whole and Toho put the production of monster movies on hold. Toho had no intention of permanently ending the "Godzilla" series. Throughout the remainder of the 1970s, several new Godzilla stories were submitted by various writers and producers. None of these films, however, were ultimately made. It was not until 1984 and "Godzilla"'s 30th anniversary that Toho would start production on a new Godzilla movie.
## Home media.
The film has been released several times on DVD in the United States. The first release, by Simitar Entertainment, was on May 6, 1998 in a fullscreen version under the title "The Terror of Godzilla". The second release, by First Classic Media and distributed by Sony Music Entertainment, was on September 17, 2002. It was released both individually and as part of the "Ultimate Godzilla DVD Collection" box set, the latter being released on the same day.
It was then re-released by Second Classic Media, this time distributed by Genius Entertainment, on November 20, 2007 both individually and as part of the "Godzilla Collection" box set on April 29, 2008.
In 2019, both the Japanese version and the export English version were included in a Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era.

</doc>
<doc id="12002" url="https://en.wikipedia.org/wiki?curid=12002" title="Godzilla vs. King Ghidorah">
Godzilla vs. King Ghidorah

 is a 1991 Japanese "kaiju" film written and directed by Kazuki Ōmori and produced by Shōgo Tomiyama. The film, produced and distributed by Toho Studios, is the 18th film in the "Godzilla" franchise, and is the third film in the franchise's Heisei period. The film features the fictional monster characters Godzilla and King Ghidorah, and stars Kōsuke Toyohara, Anna Nakagawa, Megumi Odaka, Katsuhiko Sasaki, Akiji Kobayashi, Yoshio Tsuchiya, and Robert Scott Field. In the film, time-travelers' from the future warn Japan to prevent Godzilla's mutation, only to reveal their true motives via unleashed a three-headed dragon that terrorizes the city.
The production crew of "Godzilla vs. King Ghidorah" remained largely unchanged from that of the previous film in the series, "Godzilla vs. Biollante". Because the previous installment was a box office disappointment, due to a lack of child viewership and alleged competition with the "Back to the Future" franchise, the producers of "Godzilla vs. King Ghidorah" were compelled to create a film with more fantasy elements, along with time travel.
"Godzilla vs. King Ghidorah" was the first "Godzilla" film since 1975's "Terror of Mechagodzilla" to feature a newly orchestrated score by Akira Ifukube. The film was released theatrically in Japan on December 14, 1991, and was followed by "Godzilla vs. Mothra" the following year. It was released direct-to-video in North America in 1998 by Columbia TriStar Home Entertainment. Though "Godzilla vs. King Ghidorah" was more financially successful than "Godzilla vs. Biollante", the film attracted controversy outside Japan due to its perceived Japanese nationalist themes.
## Plot.
In 1991, science fiction writer Kenichiro Terasawa is writing a book about Godzilla and learns of a group of Japanese soldiers stationed on Lagos Island during the Gilbert and Marshall Islands campaign. In February 1944, while threatened by American soldiers, the Japanese soldiers were saved by a mysterious dinosaur. He theorizes that the dinosaur was subsequently mutated into Godzilla in 1954 after a hydrogen bomb test on the island. Yasuaki Shindo, a wealthy businessman who commanded the Japanese soldiers on Lagos Island, confirms that the dinosaur did indeed exist.
Meanwhile, a UFO lands on Mount Fuji. When the Japanese army investigates, they are greeted by Wilson, Grenchiko, Emmy Kano, and the android M-11. The visitors, known as the "Futurians", explain that they are humans from the year 2303, where Godzilla has completely destroyed Japan. The Futurians plan to travel back in time to 1944 and remove the dinosaur from Lagos Island before the island is irradiated in 1954, thus preventing the mutation of the creature into Godzilla. As proof of their story, Emmy presents a copy of Terasawa's book, which has not yet been completed in the present.
The Futurians, Terasawa, Miki Saegusa, and Professor Mazaki, board a time shuttle and travel back to 1944 to Lagos Island. There, as American forces land and engage the Japanese forces commanded by Shindo, the dinosaur attacks and kills the American soldiers. The American navy then bombs the dinosaur from the sea and gravely wounds it. After Shindo and his men leave the island, M-11 teleports the dinosaur from Lagos Island to the Bering Strait. Before returning to 1991, the Futurians secretly leave three small creatures called Dorats on Lagos Island, which are exposed to radiation from the hydrogen bomb test in 1954 and merge to become King Ghidorah, which then appears in present-day Japan. After returning to 1991, the Futurians use King Ghidorah to subjugate Japan and issue an ultimatum, but Japan refuses to surrender.
Feeling sympathy for the Japanese people, Emmy reveals to Terasawa the truth behind the Futurians' mission: in the future, Japan is an economic superpower that has surpassed the United States, Russia, and China. The Futurians traveled back in time in order to change history and prevent Japan's future economic dominance by creating King Ghidorah and using it to destroy present-day Japan. At the same time, they also planned to erase Godzilla from history so that it would not pose a threat to their plans. After M-11 brings Emmy back to the UFO, she reprograms the android so it will help her.
Terasawa discovers that a Russian nuclear submarine sank in the Bering Strait in the 1970s and released enough radiation to mutate the dinosaur into Godzilla. Shindo plans to use his nuclear submarine to rejuvenate Godzilla. En route to the Bering Strait, Shindo's submarine is destroyed by Godzilla, who absorbs its radiation and becomes larger and more powerful. Godzilla arrives in Japan and is met by King Ghidorah. They fight at equal strength, each immune to the other's attacks. With M-11 and Terasawa's aid, Emmy sabotages the UFO's control over King Ghidorah, causing the three-headed monster to lose focus during the battle. Godzilla eventually ends the battle by blasting off Ghidorah's middle head. Before sending King Ghidorah crashing into the ocean, Godzilla destroys the UFO, killing Wilson and Grenchiko before turning its attention on Tokyo, destroying the city and killing Shindo.
Emmy travels to the future with M-11 and returns to the present day with Mecha-King Ghidorah, a cybernetic version of King Ghidorah. The cybernetic Ghidorah blasts Godzilla with beams, which proves useless. Godzilla then counters by relentlessly blasting Ghidorah with its atomic breath before Ghidorah launches clamps to restrain Godzilla. Ghidorah carries Godzilla out of Japan, but Godzilla breaks from its restraints and causes Ghidorah to send both crashing into the ocean. Emmy then returns to the future but not before informing Terasawa that she is his descendant.
At the bottom of the ocean, Godzilla awakens and roars over Mecha-King Ghidorah's remains before swimming away.
## Production.
### Conception.
Although the previously filmed "Godzilla vs. Biollante" had been the most expensive "Godzilla" film produced at the time, its low audience attendance and loss of revenue convinced executive producer and "Godzilla" series creator Tomoyuki Tanaka to revitalize the series by bringing back iconic monsters from pre-1984 "Godzilla" movies, specifically Godzilla's archenemy King Ghidorah.
"Godzilla vs. Biollante" director and writer Kazuki Ōmori had initially hoped to start a standalone series centered on Mothra, and was in the process of rewriting a 1990 script for the unrealized film "Mothra vs. Bagan". The film was ultimately scrapped by Toho, under the assumption that, unlike Godzilla, Mothra would have been a difficult character to market overseas. The planning stages for a sequel to "Godzilla vs. Biollante" were initially hampered by Tanaka's deteriorating health, thus prompting the takeover of Shōgo Tomiyama as producer. The new producer felt that the financial failure of "Godzilla vs. Biollante" was due to the plot being too sophisticated for child audiences, and thus intended to return some of the fantasy elements of the pre-1984 "Godzilla" films to the series. Ōmori himself blamed the lackluster performance of "Godzilla vs. Biollante" on competition with "Back to the Future Part II", and thus concluded that audiences wanted plots involving time travel. His approach to the film also differed from "Godzilla vs. Biollante" in his greater emphasis on developing the personalities of the monsters rather than the human characters.
Akira Ifukube agreed to compose the film's score on the insistence of his daughter, after as he was dissatisfied with the way his compositions had been treated in "Godzilla vs. Biollante".
### Special effects.
The Godzilla suits used in "Godzilla vs. Biollante" were reused in "Godzilla vs. King Ghidorah", though with slight modifications. The original suit used for land-based and full body shots had its head replaced with a wider and flatter one, and the body cut in half. The upper half was used in scenes where Godzilla emerges from the sea and during close-ups during the character's first fight with King Ghidorah. The suit used previously for scenes set at sea was modified with rounder shoulders, a more prominent chest, and an enhanced face, and was used throughout the majority of the film's Godzilla scenes.
The redesigned King Ghidorah featured much more advanced wirework puppetry than its predecessors, and effects team leader Koichi Kawakita designed the "Godzillasaurus" as a more paleontologically accurate-looking dinosaur than Godzilla itself as a nod to American filmmakers aspiring to direct their own "Godzilla" films with the intention of making the monster more realistic. Ōmori's original draft specified that the dinosaur that would become Godzilla was a "Tyrannosaurus", though this was rejected by creature designer Shinji Nishikawa, who stated that he "couldn't accept that a tyrannosaur could become Godzilla". The final suit combined features of "Tyrannosaurus" with Godzilla, and real octopus blood was used during the bombardment scene. Because the Godzillasaurus' arms were much smaller than Godzilla's, suit performer Wataru Fukuda had to operate them with levers within the costume. The creature's distress calls were recycled Gamera cries.
## Home media.
The Columbia/TriStar Home Video DVD version was released in 1998 as a single disc double feature with "Godzilla vs. Mothra". The picture was full frame (1.33:1) [NTSC] and the audio in English (2.0). There were no subtitles. Extras included the trailer for "Godzilla vs. King Ghidorah" and "Godzilla vs. Mothra".
The Sony Blu-ray version was released on May 6, 2014 as a two-disc double feature with "Godzilla vs. Mothra". The picture was MPEG-4 AVC (1.85:1) [1080p] and the audio was in Japanese and English (DTS-HD Master Audio 2.0). Subtitles were added in English, English SDH and French. Extras included the theatrical trailer and three teasers in HD with English subtitles.
## Reception.
Joseph Savitski of "Beyond Hollywood" said "This entry in the popular monster series is a disappointing and flawed effort unworthy of the “Godzilla” name." Film historian and critic David Kalat wrote "Despite its shortcomings, illogic, and overpopulated cast, "Godzilla vs. King Ghidorah" is crammed full of ideas, richly visualized innovations, a genuine spirit of fun, and some of the most complex emotional manipulation ever to grace the series."
### Controversy.
The film was considered controversial at the time of its release, being contemporary to a period of between America and Japan, but mainly due to its fictional World War II depictions. Gerald Glaubitz of the Pearl Harbor Survivors Association appeared alongside director Kazuki Ōmori on "Entertainment Tonight" and condemned the film as being in "very poor taste" and detrimental to American-Japanese relations. Ishirō Honda also criticized Ōmori, stating that the scene in which Godzilla attacks and crushes American G.I.s went "too far". Conversely, Godzilla historian Steve Ryfle said American media reports of supposed anti-Americanism "weren't really thought-provoking or insightful." Ōmori has denied all such allegations, stating that the American extras in the film had been "happy about being crushed and squished by Godzilla." Commenting on the controversy in 2006, Ōmori stated: 

</doc>
<doc id="12003" url="https://en.wikipedia.org/wiki?curid=12003" title="Godzilla vs. Mothra">
Godzilla vs. Mothra

 is a 1992 Japanese "kaiju" film directed by Takao Okawara, written by Kazuki Ōmori, and produced by Shogo Tomiyama. Produced and distributed by Toho Studios, it is the 19th film in the "Godzilla" franchise, and is the fourth film in the franchise's Heisei era. The film features the fictional monster characters Godzilla, Mothra, and Battra, and stars Tetsuya Bessho, Satomi Kobayashi, Takehiro Murata, Megumi Odaka, Shiori Yonezawa, Makoto Otake, Akiji Kobayashi, Koichi Ueda, Shinya Owada, Keiko Imamura, Sayaka Osawa, Saburo Shinoda and Akira Takarada, with Kenpachiro Satsuma as Godzilla. The plot follows Battra and Mothra's attempts to stop Godzilla from attacking Yokohama.
Originally conceived as a standalone Mothra film entitled "Mothra vs. Bagan", the film is notable for its return to a more fantasy-based, family-oriented atmosphere, evocative of older "Godzilla" films. Although he did not return as director, Ōmori continued his trend of incorporating Hollywood elements into his screenplay, in this case nods to the "Indiana Jones" franchise.
"Godzilla vs. Mothra" was released theatrically in Japan on December 12, 1992, and was followed by "Godzilla vs. Mechagodzilla II" the following year. "Godzilla vs. Mothra" was released direct-to-video in the United States in 1998 by Columbia Tristar Home Video under the title "Godzilla and Mothra: The Battle for Earth". The film was the second highest-grossing film in Japan in 1993, with "Jurassic Park" being the highest-grossing.
## Plot.
In mid-1992, following the events of "Godzilla vs. King Ghidorah", a meteoroid crashes in the Ogasawara Trench and awakens Godzilla. Six months later, explorer Takuya Fujito is detained after stealing an ancient artifact. Later, a representative of the Japanese Prime Minister offers to have Takuya's charges dropped if he explores Infant Island with his ex-wife, Masako Tezuka and Kenji Ando, the secretary of the rapacious Marutomo company. After the trio arrives on the island, they find a cave containing a depiction of two giant insects in battle. Further exploration leads them to a giant egg and a pair of diminutive humanoids called the Cosmos, who identify the egg as belonging to Mothra.
The Cosmos tell of an ancient civilization that tried to control the Earth's climate 12,000 years ago, thus provoking the Earth into creating Battra. Battra, a male divine moth similar to Mothra, but much more fearsome in appearance, destroyed the civilisation and their weather-controlling device but then became uncontrollable, and started to harm the very planet that created him. Mothra was then sent by the Earth to fight Battra, who eventually lost. The Cosmos explain how the meteoroid uncovered Mothra's egg, and may have awoken Battra, who is still embittered over humanity's interference in the Earth's natural order.
The Marutomo company sends a freighter to Infant Island to pick up the egg, ostensibly to protect it. As they are sailing, Godzilla surfaces and heads toward the newly hatched Mothra larva. Battra, also as a larva, soon appears and joins the fight, allowing Mothra to retreat. The battle between Godzilla and Battra is eventually taken underwater, where the force of the battle causes a giant crack on the Philippine Sea Plate that swallows the two.
Masako and Takuya later discover Ando's true intentions when he kidnaps the Cosmos and takes them to Marutomo headquarters, where the CEO intends to use them for publicity purposes. Mothra enters Tokyo in an attempt to rescue the Cosmos, but is attacked by the JSDF. The wounded Mothra heads for the National Diet Building and starts constructing a cocoon around herself. Meanwhile, Godzilla surfaces from Mount Fuji, while Battra frees himself from the Earth's crust and continues towards Japan.
Both Mothra and Battra attain their imago forms and converge at Yokohama Cosmo World where they begin to fight once more. Godzilla interrupts the battle and attacks Mothra, but Battra comes to her aid and briefly incapacitates Godzilla. Regrouping, the two moths decide to join forces against Godzilla, determining him to be the greater threat to the planet. Eventually, Mothra and Battra overwhelm Godzilla and carry it over the ocean. Godzilla bites Battra's neck and fires its atomic breath into the wound, killing him. A tired Mothra drops Godzilla and the lifeless Battra into the water below, sealing Godzilla below the surface by creating a mystical glyph with scales from her wings. The next morning, the Cosmos explain that Battra had been waiting many years to destroy an even larger asteroid that would threaten the Earth in 1999. Mothra had promised she would stop the future collision if Battra were to die, and she and the Cosmos leave Earth as the humans bid farewell.
## Production.
The idea of shooting a movie featuring a revamped Mothra dated back to a screenplay written in 1980 by Akira Murao entitled "Mothra vs. Bagan", which revolved around a vengeful dragon called Bagan who sought to destroy humanity for its abuse of the Earth's resources, only to be defeated by Mothra, the goddess of peace. The screenplay was revised by Kazuki Ōmori after the release of "Godzilla vs. Biollante", though the project was ultimately scrapped by Toho, under the assumption that Mothra was a character born purely out of Japanese culture, and thus would have been difficult to market overseas unlike the more internationally recognized Godzilla.
After the success of "Godzilla vs. King Ghidorah", producer Shōgo Tomiyama and "Godzilla" series creator Tomoyuki Tanaka proposed resurrecting King Ghidorah in a film entitled "Ghidorah's Counterattack", but relented when polls demonstrated that Mothra was more popular with women, who comprised the majority of Japan's population. Tomiyama replaced Ōmori with Takao Okawara as director, but maintained Ōmori as screenwriter. Hoping to maintain as much of "Mothra vs. Bagan" as possible, Ōmori reconceptualized Bagan as Badora, a dark twin to Mothra. The character was later renamed Battra (a portmanteau of "battle" and "Mothra"), as the first name was disharmonious in Japanese. Tomiyama had intended to feature "Mothra" star Frankie Sakai, but was unable to because of scheduling conflicts. The final battle between Godzilla, Mothra and Battra was originally meant to have a more elaborate conclusion; as in the final product, Godzilla would have been transported to sea, only to kill Battra and plunge into the ocean. However, the site of their fall would have been the submerged, Stonehenge-like ruins of the Cosmos civilization, which would have engulfed and trapped Godzilla with a forcefield activated by Mothra.
Ishirō Honda, who directed the first "Godzilla" film and many others, visited the set shortly before dying.
### Special effects.
Koichi Kawakita continued his theme of giving Godzilla's opponents the ability to metamorphose, and had initially intended to have Mothra killed off, only to be reborn as the cybernetic moth "MechaMothra", though this was scrapped early in production, thus making "Godzilla vs. Mothra" the first post-1984 "Godzilla" movie to not feature a mecha contraption. The underwater scenes were filmed through an aquarium filled with fish set between the performers and the camera. Kawakita's team constructed a new Godzilla suit from previously used molds, though it was made slimmer than previous suits, the neck given more prominent ribbing, and the arrangement of the character's dorsal plates was changed so that the largest plate was placed on the middle of the back. The arms were more flexible at the biceps, and the face was given numerous cosmetic changes; the forehead was reduced and flattened, the teeth scaled down, and the eyes given a golden tint. The head was also electronically modified to allow more vertical mobility. Filming the Godzilla scenes was hampered when the suit previously used for "Godzilla vs. Biollante" and "Godzilla vs. King Ghidorah", which was needed for some stunt-work, was stolen from Toho studios, only to be recovered at Lake Okutama in bad condition. The remains of the suit were recycled for the first battle sequence. Godzilla's roar was reverted to the high-pitched shriek from pre-1984 "Godzilla" films, while Battra's sound effects were recycled from those of Rodan. In designing Battra, which the script described as a "black Mothra", artist Shinji Nishikawa sought to distance its design from Mothra's by making its adult form more similar to its larval one than is the case with Mothra, and combining Mothra's two eyes into one.
## Release.
"Godzilla vs. Mothra" was released in Japan on December 12, 1992 where it was distributed by Toho. The film sold approximately 4,200,000 tickets in Japan, becoming the number one Japanese film on the domestic market in the period that included the year 1993. It earned ¥2.22 billion in distribution income, and grossed in total.
The film was released in the United States as "Godzilla and Mothra: The Battle for Earth" on April 28, 1998 on home video by Columbia TriStar Home Video.
## Critical reaction.
Review aggregation website Rotten Tomatoes has a 75% approval rating from critics, based on 8 reviews with an average score of 6.3/10. Ed Godziszewski of Monster Zero said, "Rushed into production but a few months after "Godzilla vs. King Ghidorah", this film is unable to hide its hurried nature [but] effects-wise, the film makes up for the story's shortcomings and then some." Japan Hero said, "While this movie is not the best of the Heisei series, it is still a really interesting movie. The battles are cool, and Battra was an interesting idea. If you have never seen this movie, I highly recommend it."
Stomp Tokyo said the film is "one of the better "Godzilla" movies in that the scenes in which monsters do not appear actually make some sort of sense. And for once, they are acted with some gusto, so that we as viewers can actually come to like the characters on screen, or at least be entertained by them." Mike Bogue of American Kaiju said the film "[does] not live up to its potential", but added that "[its] colorful and elaborate spectacle eventually won [him] over" and "the main story thread dealing with the eventual reconciliation of the divorced couple adequately holds the human plot together."
## Home media.
The film was released by Sony on Blu-ray in "The Toho Godzilla Collection" on May 6, 2014.

</doc>
<doc id="12004" url="https://en.wikipedia.org/wiki?curid=12004" title="Godzilla (1954 film)">
Godzilla (1954 film)

 is a 1954 Japanese "kaiju" film directed by Ishirō Honda, with special effects by Eiji Tsuburaya. Produced and distributed by Toho Co., Ltd, it is the first film in the "Godzilla" franchise and the Shōwa era. The film stars Akira Takarada, Momoko Kōchi, Akihiko Hirata, and Takashi Shimura, with Haruo Nakajima and Katsumi Tezuka as Godzilla. In the film, Japan's authorities deal with the sudden appearance of a giant monster, whose attacks trigger fears of nuclear holocaust during post-war Japan.
"Godzilla" entered production after a Japanese-Indonesian co-production collapsed. Tsuburaya originally proposed for a giant octopus before the filmmakers decided on a dinosaur-inspired creature. "Godzilla" pioneered a form of special effects called suitmation, in which a stunt performer wearing a suit interacts with miniature sets. Principal photography ran 51 days, and special effects photography ran 71 days.
"Godzilla" was theatrically released in Japan on November 3, 1954, and grossed during its original theatrical run. In 1956, a heavily re-edited "Americanized" version, titled "Godzilla, King of the Monsters!" was released in the United States. The film spawned a multimedia franchise, being recognized by "Guinness World Records" as the longest-running film franchise in history. The character Godzilla has since become an international pop culture icon. The film and Tsuburaya have been largely credited for establishing the template for "tokusatsu" media. Since its release, the film has been regarded as a cinematic achievement and one of the best monster films ever made.
The film was followed by "Godzilla Raids Again", released on April 24, 1955.
## Plot.
When the Japanese freighter "Eiko-maru" is destroyed near Odo Island, another ship—the "Bingo-maru"—is sent to investigate, only to meet the same fate with few survivors. A fishing boat from Odo is also destroyed, with one survivor. Fishing catches mysteriously drop to zero, blamed by an elder on the ancient sea creature known as "Godzilla". Reporters arrive on Odo Island to further investigate. A villager tells one of the reporters that something in the sea is ruining the fishing. That evening, a storm strikes the island, destroying the reporters' helicopter, and Godzilla, briefly seen, destroys 17 homes and kills nine people and 20 of the villagers' livestock.
Odo residents travel to Tokyo to demand disaster relief. The villagers' and reporters' evidence describes damage consistent with something large crushing the village. The government sends paleontologist Kyohei Yamane to lead an investigation on the island, where giant radioactive footprints and a trilobite are discovered. The village alarm bell is rung and Yamane and the villagers rush to see the monster, retreating after seeing that it is a giant dinosaur. Yamane presents his findings in Tokyo, estimating that Godzilla is 50 m tall and is evolved from an ancient sea creature becoming a terrestrial creature. He concludes that Godzilla has been disturbed by underwater hydrogen bomb testing. Debate ensues about notifying the public about the danger of the monster. Meanwhile, 17 ships are lost at sea.
Ten frigates are dispatched to attempt to kill the monster using depth charges. The mission disappoints Yamane, who wants Godzilla to be studied. When Godzilla survives the attack, officials appeal to Yamane for ideas to kill the monster, but Yamane tells them that Godzilla is unkillable, having survived H-bomb testing, and must be studied. Yamane's daughter, Emiko, decides to break off her arranged engagement to Yamane's colleague, Daisuke Serizawa, because of her love for Hideto Ogata, a salvage ship captain. When a reporter arrives and asks to interview Serizawa, Emiko escorts the reporter to Serizawa's home. After Serizawa refuses to divulge his current work to the reporter, he gives Emiko a demonstration of his recent project on the condition that she must keep it a secret. The demonstration horrifies her and she leaves without mentioning the engagement. Shortly after she returns home, Godzilla surfaces from Tokyo Bay and attacks Shinagawa. After attacking a passing train, Godzilla returns to the ocean.
After consulting international experts, the Japanese Self-Defense Forces construct a 30 m tall and 50,000 volt electrified fence along the coast and deploy forces to stop and kill Godzilla. Dismayed that there is no plan to study Godzilla for its resistance to radiation, Yamane returns home, where Emiko and Ogata await, hoping to get his consent for them to wed. When Ogata disagrees with Yamane, arguing that the threat that Godzilla poses outweighs any potential benefits from studying the monster, Yamane tells him to leave. Godzilla resurfaces and breaks through the fence to Tokyo with its atomic breath, unleashing more destruction across the city. Further attempts to kill the monster with tanks and fighter jets fail and Godzilla returns to the ocean. The day after, hospitals and shelters are crowded with the maimed and the dead, with some survivors suffering from radiation sickness.
Distraught by the devastation, Emiko tells Ogata about Serizawa's research, a weapon called the "Oxygen Destroyer", which disintegrates oxygen atoms and causes organisms to die of a rotting asphyxiation. Emiko and Ogata go to Serizawa to convince him to use the Oxygen Destroyer but he initially refuses, explaining that if he uses the device, the superpowers of the world will surely force him to construct more Oxygen Destroyers for use as a superweapon. After watching a program displaying the nation's current tragedy, Serizawa finally accepts their pleas. As Serizawa burns his notes, Emiko breaks down crying.
A navy ship takes Ogata and Serizawa to plant the device in Tokyo Bay. After finding Godzilla, Serizawa unloads the device and cuts off his air support, taking the secret of the Oxygen Destroyer to his grave. Godzilla is destroyed, but many mourn Serizawa's death. Yamane believes that if nuclear weapons testing continues, another Godzilla may rise in the future.
## Cast.
Cast taken from "Japan's Favorite Mon-star".
## Themes.
In the film, Godzilla symbolizes nuclear holocaust from Japan's perspective and has since been culturally identified as a strong metaphor for nuclear weapons. Producer Tomoyuki Tanaka stated that, "The theme of the film, from the beginning, was the terror of the bomb. Mankind had created the bomb, and now nature was going to take revenge on mankind." Director Ishirō Honda filmed Godzilla's Tokyo rampage to mirror the atomic bombings of Hiroshima and Nagasaki, stating, "If Godzilla had been a dinosaur or some other animal, he would have been killed by just one cannonball. But if he were equal to an atomic bomb, we wouldn't know what to do. So, I took the characteristics of an atomic bomb and applied them to Godzilla."
On March 1, 1954, just a few months before the film was made, the Japanese fishing vessel "Daigo Fukuryū Maru" ("Lucky Dragon No. 5") had been showered with radioactive fallout from the U.S. military's 15-megaton "Castle Bravo" hydrogen bomb test at nearby Bikini Atoll. The boat's catch was contaminated, spurring a panic in Japan about the safety of eating fish, and the crew was sickened, with one crew member eventually dying from radiation sickness. This event led to the emergence of a large and enduring anti-nuclear movement that gathered 30 million signatures on an anti-nuclear petition by August 1955 and eventually became institutionalized as the Japan Council against Atomic and Hydrogen Bombs. The film's opening scene of Godzilla destroying a Japanese vessel is a direct reference to these events, and had a strong impact on Japanese viewers with this recent event still fresh in the mind of the public.
Academics Anne Allison, Thomas Schnellbächer, and Steve Ryfle have said that "Godzilla" contains political and cultural undertones that can be attributed to what the Japanese had experienced in World War II and that Japanese audiences were able to connect emotionally to the monster. They theorized that these viewers saw Godzilla as a victim and felt that the creature's backstory reminded them of their experiences in World War II. These academics have also claimed that as the atomic bomb testing that woke Godzilla was carried out by the United States, the film in a way can be seen to blame the United States for the problems and struggles that Japan experienced after World War II had ended. They also felt that the film could have served as a cultural coping method to help the people of Japan move on from the events of the war.
Brian Merchant from "Motherboard" called the film "a bleak, powerful metaphor for nuclear power that still endures today" and on its themes, he stated: "It's an unflinchingly bleak, deceptively powerful film about coping with and taking responsibility for incomprehensible, manmade tragedy. Specifically, nuclear tragedies. It's arguably the best window into post-war attitudes towards nuclear power we've got—as seen from the perspective of its greatest victims." Terrence Rafferty from "The New York Times" said Godzilla was "an obvious gigantic, unsubtle, grimly purposeful metaphor for the atomic bomb" and felt the film was "extraordinarily solemn, full of earnest discussions".
Mark Jacobson from the website of "New York" magazine said that Godzilla "transcends humanist prattle. Very few constructs have so perfectly embodied the overriding fears of a particular era. He is the symbol of a world gone wrong, a work of man that once created cannot be taken back or deleted. He rears up out of the sea as a creature of no particular belief system, apart from even the most elastic version of evolution and taxonomy, a reptilian id that lives inside the deepest recesses of the collective unconscious that cannot be reasoned with, a merciless undertaker who broaches no deals." Regarding the film, Jacobson stated, "Honda's first Godzilla... is in line with these inwardly turned post-war films and perhaps the most brutally unforgiving of them. Shame-ridden self-flagellation was in order, and who better to supply the rubber-suited psychic punishment than the Rorschach-shaped big fella himself?"
Tim Martin from "The Daily Telegraph" (London) said that the original 1954 film was "a far cry from its B-movie successors. It was a sober allegory of a film with ambitions as large as its thrice-normal budget, designed to shock and horrify an adult audience. Its roster of frightening images—cities in flames, overstuffed hospitals, irradiated children—would have been all too familiar to cinemagoers for whom memories of Hiroshima and Nagasaki were still less than a decade old, while its script posed deliberately inflammatory questions about the balance of postwar power and the development of nuclear energy." Martin also commented how the film's themes were omitted in the American version, stating, "Its thematic preoccupation with nuclear energy proved even less acceptable to the American distributors who, after buying the film, began an extensive reshoot and recut for Western markets."
## Production.
### Crew.
Personnel taken from "Japan's Favorite Mon-star".
### Development.
In 1954, Toho originally planned to produce , a Japanese-Indonesian co-production about the aftermath of the Japanese occupation of Indonesia. However, anti-Japanese sentiment in Indonesia forced political pressure on the government to deny visas for the Japanese filmmakers. The film was to be co-produced with Perfini, filmed on location in Jakarta in color (a first for a major Toho production), and was to open markets for Japanese films in Southeast Asia.
Producer Tomoyuki Tanaka flew to Jakarta to renegotiate with the Indonesian government but was unsuccessful and on the flight back to Japan, conceived the idea for a giant monster film inspired by the 1953 film "The Beast from 20,000 Fathoms" and the "Daigo Fukuryū Maru" incident that happened in March 1954. The film's opening sequence is a direct reference to the incident. Tanaka felt the film had potential due to nuclear fears generating news and monster films becoming popular, due to the financial success of "The Beast from 20,000 Fathoms" and the 1952 re-release of "King Kong", the latter of which earned more money than previous releases.
During his flight, Tanaka wrote an outline with the working title "The Giant Monster from 20,000 Miles Beneath the Sea" and pitched it to executive producer Iwao Mori. Mori approved the project in mid–April 1954 after special effects director Eiji Tsuburaya agreed to do the film's effects and confirmed that the film was financially feasible. Mori also felt the project was a perfect vehicle for Tsuburaya and to test the storyboarding system that he instituted at the time. Mori also approved Tanaka's choice to have Ishirō Honda direct the film and shortened the title of the production to "Project G" (G for Giant), as well as giving the production classified status and ordered Tanaka to minimize his attention on other films and mainly focus on "Project G".
Toho originally intended for Senkichi Taniguchi to direct the film, as he was originally attached to direct "In the Shadow of Glory", however, Taniguchi declined the assignment. Honda was not Toho's first choice for the film's director, however, his war-time experience made him an ideal candidate for the film's anti-nuclear themes. Several other directors passed on the project, feeling the idea was "stupid", however, Honda accepted the assignment due to this interest in science and "unusual things", stating, "I had no problem taking it seriously." It was during the production of "Godzilla" that Honda worked with assistant director Kōji Kajita for the first time. Afterwards, Kajita would go on to collaborate with Honda as his chief assistant director for 17 films over the course of 10 years. Due to sci-fi films lacking respect from film critics, Honda, Tanaka, and Tsuburaya agreed on depicting a monster attack as if it were a real event, with the serious tone of a documentary.
### Writing.
Tsuburaya submitted an outline of his own, written three years prior to "Godzilla"; it featured a giant octopus attacking ships in the Indian Ocean. In May 1954, Tanaka hired sci-fi writer Shigeru Kayama to write the story. Only 50 pages long and written in 11 days, Kayama's treatment depicted Dr. Yamane wearing dark shades, a cape and living in a European-style house from which he only emerged at night. Godzilla was portrayed as more animal-like by coming ashore to feed on animals, with an ostensibly gorilla-like interest in females. Kayama's story also featured less destruction and borrowed a scene from "The Beast from 20,000 Fathoms" by having Godzilla attack a lighthouse.
Takeo Murata and Honda co-wrote the screenplay in three weeks, confining themselves in a Japanese inn in Tokyo's Shibuya ward. On writing the script, Murata stated, "Director Honda and I... racked our brains to make Mr. Kayama's original treatment into a full, working vision." Murata said that Tsuburaya and Tanaka pitched their ideas as well. Tanaka requested that they do not spend too much money, while Tsuburaya encouraged them to "do whatever it takes to make it work". Murata and Honda redeveloped key characters and elements by adding Emiko's love triangle. In Kayama's story, Serizawa was depicted as merely a colleague of Dr. Yamane's. Godzilla's full appearance was to be revealed during the Odo Island hurricane but Honda and Murata opted to show parts of the creature as the film built up to his full reveal. Honda and Murata also introduced the characters Hagiwara and Dr. Tanabe in their draft but the role of Shinkichi, who had a substantial role in Kayama's story, was cut down.
A novelization, written by Kayama, was published on October 25, 1954 by Iwatani Bookstore as .
### Creature design.
Godzilla was designed by Teizō Toshimitsu and Akira Watanabe under Eiji Tsuburaya's supervision. Early on, Tanaka contemplated having the monster be gorilla-like or whale-like in design, due to the name "Gojira" (a combination of the Japanese words for "gorilla", , and "whale", ), but eventually settled on a dinosaur-like design. Kazuyoshi Abe was hired earlier to design Godzilla but his ideas were later rejected due to Godzilla looking too humanoid and mammalian, with a head shaped like a mushroom cloud; however, Abe was retained to help draw the film's storyboards.
Toshimitsu and Watanabe decided to base Godzilla's design on dinosaurs and, by using dinosaur books and magazines as a reference, combined elements of a Tyrannosaurus, Iguanodon and the dorsal fins of a Stegosaurus. Despite wanting to have utilized stop motion animation, Tsuburaya reluctantly settled on suitmation. Toshimitsu sculpted three clay models on which the suit would be based. The first two were rejected but the third was approved by Tsuburaya, Tanaka, and Honda.
The Godzilla suit was constructed by Kanji Yagi, Koei Yagi, and Eizo Kaimai, who used thin bamboo sticks and wire to build a frame for the interior of the suit and added metal mesh and cushioning over it to bolster its structure and finally applied coats of latex. Coats of molten rubber were additionally applied, followed by carved indentations and strips of latex glued onto the surface of the suit to create Godzilla's scaly hide. This first version of the suit weighed 100 kilograms (220 pounds). For close-ups, Toshimitsu created a smaller scale, mechanical, hand-operated puppet that sprayed streams of mist from its mouth to act as Godzilla's atomic breath.
Haruo Nakajima and Katsumi Tezuka were chosen to perform in the Godzilla suit, due to their strength and endurance. At the first costume fitting, Nakajima fell down while inside the suit, due to the heavy latex and inflexible materials used to create the suit. This first version of the suit was cut in half and used for scenes requiring only partial shots of Godzilla or close-ups, with the lower-half fitted with rope suspenders for Nakajima to wear. For full-body shots, a second identical suit was created which was made lighter than the first suit, but Nakajima was still only able to be inside for three minutes before passing out. Nakajima lost 20 pounds during the production of the film. Nakajima would go on to portray Godzilla and other monsters until his retirement in 1972. Tezuka filmed scenes in the Godzilla suit but, due to his older body, he was unable to fully commit to the physical demands required by the role. As a result, few of his scenes made it to the final cut as very few scenes were considered usable. Tezuka filled in for Nakajima when he was unavailable or needed relief from the physically demanding role.
Godzilla's name was also a source of consternation for the filmmakers. Because the monster had no name, the first draft of the film was not called "Gojira" but rather titled "G", also known as "Kaihatsu keikaku G" ("Development Plan G"), the "G" of the title stood for "Giant", however. Nakajima confirmed that Toho held a contest to name the monster. The monster was eventually named "Gojira". One explanation that is chalked up to legend is that a hulking Toho Studios employee's physical attributes led him to be nicknamed "Gojira". In a 1998 BBC documentary on Godzilla, Kimi Honda, the widow of the director, dismissed the employee-name story as a tall tale, believing that Honda, Tanaka, and Tsuburaya gave "considerable thought" to the name of the monster, stating, "the backstage boys at Toho loved to joke around with tall stories, but I don't believe that one". In 2003, a Japanese television special claimed to have identified the anonymous hulking Toho employee as Shiro Amikura, a Toho contract actor from the 1950s.
### Special effects.
The film's special effects were directed by Eiji Tsuburaya. In order for the effects footage to sync with the live-action footage, Honda and Tsuburaya would develop plans early during development and briefly meet prior to the day's shoot. Kajita would shuttle Tsuburaya to Honda's set to observe how a scene was being shot and where the actors were being positioned. Kajita also ushered Honda to the effects stage to observe how Tsuburaya was shooting certain effects. While Honda edited the live-action footage, he left blank leaders for Tsuburaya to insert the effects footage. At times, Honda had to cut out certain effects footage. Tsuburaya disapproved of these decisions due to Honda's cuts not matching the effects; however, Honda had final say in these matters.
Tsuburaya originally wanted to use stop motion for the film's special effects but realized it would have taken seven years to complete based on the then-current staff and infrastructure at Toho. Settling on suitmation and miniature effects, Tsuburaya and his crew scouted the locations Godzilla was to destroy and were nearly arrested after a security guard overheard their plans for destruction but were released after showing police their Toho business cards. Kintaro Makino, the chief of miniature construction, was given blueprints by Akira Watanabe for the miniatures and assigned 30 to 40 workers from the carpentry department to build them, which took a month to build the scaled down version of Ginza. A majority of the miniatures were built at 1:25 scale but the Diet building was scaled down to a 1:33 scale to look smaller than Godzilla. While it proved to be too expensive to use stop-motion extensively throughout the picture, the final film did include a stop-motion scene of Godzilla's tail destroying the Nichigeki Theater building.
The buildings' framework were made of thin wooden boards reinforced with a mixture of plaster and white chalk. Explosives were installed inside miniatures that were to be destroyed by Godzilla's atomic breath while some were sprayed with gasoline to make them burn more easily; others included small cracks so they could crumble easily. Optical animation techniques were used for Godzilla's glowing dorsal fins by having hundreds of cells drawn frame-by-frame. Haruo Nakajima perspired inside the suit so much that the Yagi brothers had to dry out the cotton lining every morning and sometimes re-line the interior of the suit and repair damages.
The typhoon waves were created by stagehands who overturned barrels of water into a water tank where the miniature Odo Island shoreline was built. Multiple composition shots were used for the Odo Island scenes. Most of the Odo Island scenes were filmed near rice fields. Toho hired en masse part-time employees to work on the film's optical effects. Half of the 400 hired staff were mostly part-timers with little to no experience. An early version of Godzilla's full reveal was filmed that featured Godzilla, via hand-operated puppet, devouring a cow. Sadamasa Arikawa thought the scene was too gruesome and convinced Tsuburaya to re-film it. Optical effects were utilized for Godzilla's footprints on the beach by painting them onto glass and inserting it onto an area of the live-action footage. Special effects photography lasted for 71 days.
### Filming.
On the first day of filming, Honda addressed a crew of 30 to read the script and leave the project if they did not feel convinced, wanting only to work with those who had confidence in him and the film. Most of the film was shot in the Toho lot. Honda's team also filmed on location in the Shima Peninsula in Mie Prefecture to film the Odo Island scenes, which used 50 Toho extras and Honda's team establishing their base in the town of Toba. Local villagers were also used as extras for the Odo Island scenes. The dance ritual scene was filmed on location in Mie Prefecture, with local villagers performing as the dancers. The cast and crew commuted every morning by boat to Toba, Mie, working under harsh weather temperatures. Honda worked shirtless and as a result, suffered blistering sunburn on his back that left permanent scars.
Toho had negotiated with the Japan Self-Defense Forces (JSDF) to film scenes requiring the military and filmed target practices and drills for the film; Honda's team followed a convoy of JSDF vehicles for the convoy dispatch scene. Two thousand girls were used from an all-girls high school for the prayer for peace scene. The filmmakers had little cooperation from the JSDF and had to rely on World War II stock footage, provided by the Japanese military, for certain scenes. The stock footage was sourced from 16mm prints. Honda's team spent 51 days shooting the film.
## Music and sound effects.
The film's score was composed by Akira Ifukube. After meeting with Tanaka, Tsuburaya, and Honda, Ifukube enthusiastically accepted the job after learning that the main character was a monster, Ifukube said, "I couldn't sit still when I heard that in this movie the main character was a reptile that would be rampaging through the city." Ifukube was not shown the final film and only had a week to compose his music. Within that time, he was only shown a model of Godzilla and the screenplay. Tsuburaya briefly showed Ifukube some footage, albeit with the effects missing and Tsuburaya attempting to describe how the scene would unfold, Ifukube recalled, "I was very confused. So I tried to make music that would remind you of something enormous." Ifukube used low-pitch brass and string instruments.
It was Honda's idea to make Godzilla roar, despite the fact that reptiles do not have vocal cords. Shimonaga and Minawa were originally tasked with creating the roar, however, Ifukube became involved after taking interest in creating sound effects. Ifukube discussed with Honda regarding what type of sounds were going to be used in certain scenes and other details concerning sounds. Minawa went to the zoo and recorded various animal roars that were played back at certain speeds. However, these sounds proved unsatisfactory and went unused. Ifukube borrowed a contrabass from the Japan Art University's music department and created Godzilla's roar by loosening the strings and rubbing them with a leather glove. The sound was recorded and played at a reduced speed, which achieved the effect of the roar used in the film. This technique would be adopted by Toho as a standard method in creating monster roars in the following years.
There are conflicting reports as to how Godzilla's footsteps were created. One claim states that the roar was created with a knotted rope hitting a kettle drum that was recorded and processed through an echo box. However, Ifukube told "Cult Movies" that the footsteps were created using a primitive amplifier that made a loud clap when struck. Some Japanese texts claim that the footsteps were sourced from an explosion with the ending clipped off and processed through an electronic reverb unit. The optical recording equipment contained four audio tracks: one for principal dialogue, one for background chatter, ambient noises, tanks, planes, and one for the roars and footsteps. An independent audio track was used to prevent bleeding over other audio.
The music and sound effects of Godzilla's rampage were recorded live simultaneously. While Ifukube conducted the NHK Philharmonic orchestra, a foley artists watched Godzilla's rampage projected on a screen and used tin, concrete debris, wood, and other equipment to simulate sounds that would sync with the footage. A new take would be needed if the foley artist had missed a cue. Many of Ifukube's themes and motifs associated with Godzilla were introduced in the film, such as the March, the Horror theme, and the Requiem. The "Self Defense Force March" had become synonymous with Godzilla that Ifukube later referred to it as "Godzilla's theme." Ifukube considers his music for the film his finest film score.
## Release.
### Marketing.
During production, Mori devised promotional strategies to generate public interest. Amongst these strategies was a radio play titled 
. 11 episodes were produced based on the screenplay, and aired on Saturdays on the NHK radio network from July 17, 1954 to September 25, 1954. In an attempt to build mystery, Mori banned reporters from the set, kept the special effects techniques and other behind the scenes crafts secret. Nakajima's suit performance as Godzilla would not be revealed until the 1960s. However, Godzilla's image was widely publicized. Godzilla's image was added to the company stationary, cut-out pictures and posters were displayed in theaters and stores, large advertisement balloons were flown to major Japanese cities, and a Godzilla doll was mounted onto a truck and driven around Tokyo. The film's theatrical trailer debuted in theaters on October 20, 1954.
### Theatrical.
"Godzilla" was first released in Nagoya on October 27, 1954, and released nationwide on November 3, 1954. At the time of the film's release, it set a new opening day record for any Toho film, selling 33,000 tickets at Toho's cinemas in Tokyo and selling out at Nichigeki Theater. As a result, Toho's CEO personally called Honda to congratulate him. Honda's wife, Kimi, noted "that sort of thing didn't usually happen."
From 1955 into the 1960s, "Godzilla" played in theaters catering to Japanese-Americans in predominantly Japanese neighborhoods in the United States. An English subtitled version was shown at film festivals in New York, Chicago, and other cities in 1982. An 84-minute cut of the Japanese version was theatrically released in West Germany on April 10, 1956, as "Godzilla". This version removes the Japanese Parliament argument, acknowledgement of Godzilla as a "child of the H-bomb", references to Hiroshima and Nagasaki, and an altered translation of the mother holding her children. The film was re-released theatrically in Japan on November 21, 1982, to commemorate Toho's 50th anniversary. Since its release, the 1954 film remained unavailable officially in the United States until 2004.
To coincide with "Godzilla"s 50th anniversary, art-house distributor Rialto Pictures gave the film a traveling tour-style limited release, coast-to-coast, across the United States, on May 7, 2004. It ran uncut with English subtitles until December 19, 2004. The film never played on more than six screens at any given point during its limited release. The film played in roughly sixty theaters and cities across the United States during its -month release. On April 18, 2014, Rialto re-released the film in the United States, coast-to-coast, using another limited-style traveling tour. This coincided with not only Godzilla's 60th anniversary, but also celebrated the American "Godzilla" film which was released that same year. To avoid confusion with the Hollywood feature, the Rialto release was subtitled "The Japanese Original". It was screened in 66 theaters in 64 cities from April 18 to October 31, 2014.
For its 67th anniversary, a 4K remaster of the film, along with other "Godzilla" films, was screened in Alamo Drafthouse Cinema locations on November 3, 2021.
### American version.
Following the film's success in Japan, Toho sold the American rights to Joseph E. Levine for $25,000. A heavily altered version of the film was released in the United States and worldwide as "Godzilla, King of the Monsters!" on April 27, 1956. This version trimmed the original down to 80 minutes and featured new footage with Canadian actor Raymond Burr interacting with body doubles mixed with Honda's footage to make it seem like he was part of the original Japanese production. Many of the film's political themes were trimmed or removed completely. It was this version of the original "Godzilla" film that introduced audiences worldwide to the character and franchise and the only version that critics and scholars had access to until 2004 when the 1954 film was released in select theaters in North America. "Godzilla, King of the Monsters!" grossed $2 million during its theatrical run, more than what the 1954 film grossed in Japan.
Honda was unaware that "Godzilla" had been re-edited until Toho released "Godzilla, King of the Monsters!" in Japan in May 1957 as "Monster King Godzilla". Toho converted the entire film from its original scope to a widescreen 2.35:1 scope, which resulted in an awkward crop for the entire film. Japanese subtitles were given to the Japanese actors since their original dialogue differed greatly from the original script and were dubbed in English. Since the release of the film, Toho had adopted the moniker "King of the Monsters" for Godzilla, which has since appeared in official marketing, advertisement, and promotional materials.
### Home media.
The 1956 "Godzilla, King of the Monsters!" version of the film was released on DVD by Simitar in 1998 and Classic Media in 2002. In 2005, BFI released the original Japanese version in the UK theatrically, and later in the same year on DVD. The DVD includes the original mono track and several extra features, such as documentaries and commentary tracks by Steve Ryfle, Ed Godziszewski, and Keith Aiken. The DVD also includes a documentary about the "Daigo Fukuryū Maru", a Japanese fishing boat that was caught in an American nuclear blast and partially inspired the creation of the film.
In 2006, Classic Media and Sony BMG Music Entertainment Home Entertainment released a two-disc DVD set titled "Gojira: The Original Japanese Masterpiece". This release features both the 1954 Japanese version and the 1956 American version, making the Japanese version of the film available on DVD in North America for the first time. This release features theatrical trailers for both films, audio commentary tracks on both films with Godzilla scholars Steve Ryfle (author of "Japan's Favorite Mon-Star: The Unauthorized Biography of the Big G") and Ed Godziszewski (editor of "Japanese Giants Magazine"), two 13-minute documentaries titled "Godzilla Story Development" and "Making of the Godzilla Suit", and a 12-page essay booklet by Steve Ryfle. This release also restores the original ending credits of the American film which, until recently, were thought to have been lost.
In 2009, Classic Media released "Godzilla" on Blu-ray. This release includes the same special features from the 2006 Classic Media DVD release, but does not feature the 1956 American version. In 2012, the Criterion Collection released a "new high-definition digital restoration" of "Godzilla" on Blu-ray and DVD. This release includes a remaster of the 1956 American version, "Godzilla, King of the Monsters!", as well as other special features such as interviews with Akira Ikufube, Japanese film critic Tadao Sato, actor Akira Takarada, Godzilla performer Haruo Nakajima, effects technicians Yoshio Irie and Eizo Kaimai and audio commentaries on both films by David Kalat, author of "A Critical History and Filmography of Toho's Godzilla Series".
In 2014, Classic Media reissued "Godzilla" and "Godzilla, King of the Monsters!" on DVD, to commemorate the release of Legendary's "Godzilla" film. This release retained the same specs and features as the 2006 DVD release. In 2017, Janus Films and the Criterion Collection acquired the film, as well as other Godzilla titles, to stream on Starz and FilmStruck. In 2019, the film and the American version were included in the "Godzilla: The Showa Era Films" Blu-ray box set released by the Criterion Collection, which included all 15 films from the franchise's Shōwa era. In May 2020, the film became available on HBO Max upon its launch.
## Reception.
### Box office.
During its initial Japanese theatrical run, the film sold approximately tickets and was the eighth best-attended film in Japan that year. The film earned a distribution rental income of , unadjusted for inflation. During its 2004 limited theatrical release in North America, the film grossed $38,030 on its opening weekend and grossed $412,520 by the end of its limited run. For the 2014 limited re-release in North America, it grossed $10,903 after playing in one theater in New York and grossed $150,191 at the end of its run. In the United Kingdom, the film sold 3,643 tickets from limited releases during 20052006 and 20162017.
### Critical response in Japan.
Prior to the release of the film, skeptics predicted the film would flop. At the time of the film's release, Japanese reviews were mixed. Japanese critics accused the film of exploiting the widespread devastation that the country had suffered in World War II, as well as the "Daigo Fukuryū Maru" incident that occurred a few months before filming began. Ishiro Honda lamented years later in the "Tokyo Journal", "They called it grotesque junk, and said it looked like something you'd spit up. I felt sorry for my crew because they had worked so hard!"
Others said that depicting a fire breathing organism was strange. Honda also believed Japanese critics began to change their minds after the good reviews the film received in the United States. He stated "The first film critics to appreciate "Godzilla" were those in the U.S. When "Godzilla" was released there as "Godzilla, King of the Monsters!" in 1956, the critics said such things as, 'For the start, this film frankly depicts the horrors of the Atomic Bomb', and by these evaluations, the assessment began to impact critics in Japan and has changed their opinions over the years."
As time went on, the film gained more respect in its home country. In 1984, "Kinema Junpo" magazine listed "Godzilla" as one of the top 20 Japanese films of all time, while a survey of 370 Japanese film critics published in "Nihon Eiga Besuto 150" ("Best 150 Japanese Films"), had "Godzilla" ranked as the 27th best Japanese film ever made. The film was nominated for two Japanese Movie Association awards. One for best special effects and the other for best film. It won best special effects but lost best picture to Akira Kurosawa's "Seven Samurai".
### Critical response internationally.
"Godzilla" received generally positive reviews from critics. On review aggregator Rotten Tomatoes, the film has an approval rating of 93% based on 74 reviews, with an average score of 7.60/10. The site's consensus states, "More than straight monster-movie fare, "Gojira" offers potent, sobering postwar commentary". On Metacritic, the film has a score of 78/100, based on 20 critics, indicating "generally favorable reviews".
Owen Gleiberman from "Entertainment Weekly" noted the film is more "serious" than the 1956 American cut yet "its tone just veers closer to that of solemn American B-horror cheese like "Them!" The real difference is that the film's famous metaphor for the bombing of Hiroshima and Nagasaki looks more nuttily masochistic than ever." Luke Y. Thompson from "Dallas Observer" defended the film's effects as products of their time and felt that viewers would be "surprised by what they see", stating, "This ain't your standard goofy monster rampage." Peter Bradshaw from "The Guardian" awarded the film four stars out of five, praising the storytelling as "muscular" and the nuclear themes as "passionate and fascinatingly ambiguous", stating, "the sheer fervency of this film takes it beyond the crash-bang entertainment of most blockbusters, ancient and modern." David Nusair from Reel Film Reviews awarded the film one and a half stars out of four, saying the film turns into a "terminally erratic narrative that's more dull than engrossing." Nusair criticized Honda for his "inability to offer up even a single compelling human character" and found the film's ending as "anticlimactic and pointless", concluding, "the film is entirely lacking in elements designed to capture and hold the viewer's ongoing attention."
Roger Ebert from the "Chicago Sun-Times" awarded the film one and a half stars out of four, stating, "regaled for 50 years by the stupendous idiocy of the American version of "Godzilla", audiences can now see the original Japanese version, which is equally idiotic, but, properly decoded, was the "Fahrenheit 9/11" of its time." Ebert criticized the effects as looking "crude", feeling the effects of the 1933 film "King Kong" were "more convincing" and concluded that "This is a bad movie, but it has earned its place in history."
Keith Uhlich from "Time Out" awarded the film four stars out of five, calling the film "Pop Art as purge", and praising the film's characters, themes, and Godzilla as a "potent and provocative metaphor, a lumbering embodiment of atomic-age anxieties birthed from mankind's own desire to destroy." Desson Thomson from the "Washington Post" called the film's effects "pretty extraordinary" and "amazingly credible" for their time. Thomson felt some of the acting was "ham-handed" but said "there's a surprisingly powerful thrust to this film." Mick LaSalle from the "San Francisco Chronicle" called the film a "classic", stating, "Such moments go beyond spectacle. "Godzilla" is a collective metaphor and a collective nightmare, a message film that says more than its message, that captures, with a horrified poetry, the terrors that stomped through the minds of people 50 years ago."
Since its release, "Godzilla" has been regarded as one of the best giant monster films ever made: critic Allen Perkins called the film "not just a classic monster movie, but also an important cinematic achievement." In 2010, the film was ranked No. 31 in "Empire" magazine's "100 Best Films Of World Cinema". In 2013, "Rolling Stone" ranked the film No. 1 on their "Best Monster Movies of All Time" list. In 2015, "Variety" listed the film amongst their "10 Best Monster Movies of All-Time" list. In 2019, "Time Out Film" ranked the film No. 9 on their "50 best monster movies" list.
### Accolades.
In 1954, Eiji Tsuburaya won the "Japanese Film Technique" award for the film's special effects. In 2007, Classic Media's DVD release of the film won "Best DVD of 2006" by the Rondo Hatton Classic Horror Awards and Best DVD Classic Film Release by the Saturn Awards.
## Legacy.
The film spawned a multimedia franchise consisting of 33 films in total, video games, books, comics, toys and other media. The "Godzilla" franchise has been recognized by "Guinness World Records" as being the longest-running film franchise in history. Since his debut, Godzilla became an international pop culture icon, inspiring countless rip-offs, imitations, parodies and tributes. The 1954 film and its special effects director Eiji Tsuburaya have been largely credited for establishing the template for "tokusatsu", a technique of practical special effects filmmaking that would become essential in Japan's film industry since the release of "Godzilla". Critic and scholar Ryusuke Hikawa said: "Disney created the template for American animation, In the same way, (special-effects studio) Tsubaraya created the template for the Japanese movie business. It was their use of cheap but craftsman-like approaches to movie-making that made tokusatsu unique." Steven Spielberg cited "Godzilla" as an inspiration for "Jurassic Park" (1993), specifically "Godzilla, King of the Monsters!" (1956), which he grew up watching.
### American films.
In 1998, TriStar Pictures released a reimagining, titled "Godzilla", directed by Roland Emmerich. Emmerich wanted his "Godzilla" to have nothing to do with Toho's "Godzilla" but chose to retain key elements from the 1954 film, stating, "We took part of [the original movie's] basic storyline, in that the creature becomes created by radiation and it becomes a big challenge. But that's all we took."
In 2014, Warner Bros. and Legendary Pictures released a reboot, also titled "Godzilla", directed by Gareth Edwards. Edwards stated that his film was inspired by the 1954 film, and attempted to retain some of its themes, stating, "Godzilla is a metaphor for Hiroshima in the original movie. We tried to keep that, and there are a lot of themes from the '54 movie that we've kept."

</doc>
<doc id="12005" url="https://en.wikipedia.org/wiki?curid=12005" title="The Return of Godzilla">
The Return of Godzilla

 is a 1984 Japanese "kaiju" film directed by Koji Hashimoto, with special effects by Teruyoshi Nakano. The film features the fictional monster character Godzilla. Distributed by Toho and produced under their subsidiary Toho Pictures, it is the 16th film in the "Godzilla" franchise, and is the last film to be produced in the Showa era. In Japan, the film was followed by "Godzilla vs. Biollante" in 1989.
"The Return of Godzilla" stars Ken Tanaka, Yasuko Sawaguchi, Yosuke Natsuki, and Keiju Kobayashi, with Kenpachiro Satsuma as Godzilla. The film serves as both a sequel to the original 1954 film and a reboot of the franchise that ignores the events of every Shōwa era film aside from the original "Godzilla", placing itself in line with the darker tone and themes of the original film and returning Godzilla to his destructive, antagonistic roots. The film was released theatrically in Japan on December 15, 1984. The following year, in the United States, New World Pictures released "Godzilla 1985", a heavily re-edited American adaptation of the film which includes additional footage, and features Raymond Burr reprising his role from the 1956 film "Godzilla, King of the Monsters!".
## Plot.
The Japanese fishing vessel "Yahata-Maru" is caught in strong currents off the shores of Daikoku Island. As the boat drifts into shore, the island begins to erupt, and a giant monster lifts itself out of the volcano. A few days later, reporter Goro Maki is sailing in the area and finds the vessel intact but deserted. As he explores the vessel, he finds all the crew dead except for Hiroshi Okumura, who has been badly wounded. Suddenly a giant "Shockirus" sea louse attacks him but he is saved by Okumura.
In Tokyo, Okumura realizes by looking at pictures that the monster he saw was a new Godzilla. Maki writes an article about the account, but the news of Godzilla's return is kept secret and his article is withheld. Maki visits Professor Hayashida, whose parents were lost in the 1954 Godzilla attack. Hayashida describes Godzilla as a living, invincible nuclear weapon able to cause mass destruction. At Hayashida's laboratory, Maki meets Okumura's sister, Naoko, and informs her that her brother is alive and at the police hospital.
A Soviet submarine is destroyed in the Pacific. The Soviets believe the attack was perpetrated by the Americans, and a diplomatic crisis ensues, which threatens to escalate into nuclear war. The Japanese intervene and reveal that Godzilla was behind the attacks. The Japanese cabinet meets to discuss Japan's defense. A new weapon is revealed, the Super X, a specially-armored flying fortress that will defend the capital. The Japanese military is put on alert.
Godzilla attacks the Ihama nuclear power plant in Shizuoka Prefecture. While feeding off the reactor, he is distracted by a flock of birds and leaves the facility. Hayashida believes that Godzilla was distracted instinctively by a homing signal from the birds. Hayashida, together with geologist Minami, propose to the Japanese Cabinet, that Godzilla could be lured back to Mount Mihara on Ōshima Island by a similar signal, and a volcanic eruption could be started, capturing Godzilla.
Prime Minister Mitamura meets with Soviet and American envoys and declares that nuclear weapons will not be used on Godzilla, even if he were to attack the Japanese mainland. Meanwhile, the Soviets have their own plans to counter the threat posed by Godzilla, and a Soviet control ship disguised as a freighter in Tokyo Harbor prepares to launch a nuclear missile from one of their orbiting satellites should Godzilla attack.
Godzilla is sighted at dawn in Tokyo Bay heading towards Tokyo, causing mass evacuations. The JASDF attacks Godzilla but fails to stop his advance on the city. Godzilla soon emerges and makes short work of the JSDF stationed there. The battle causes damage to the Soviet ship and starts a missile launch countdown. The captain dies as he attempts to stop the missile from launching. Godzilla proceeds towards Shinjuku, wreaking havoc along the way. Godzilla is confronted by four laser-armed trucks and the Super X. Because Godzilla's heart is similar to a nuclear reactor, the cadmium shells that are fired into his mouth by the Super X seal and slow down his heart, knocking Godzilla unconscious.
The countdown ends and the Soviet missile is launched, but it is destroyed by an American counter-missile. Hayashida and Okumura are extracted from Tokyo via helicopter and taken to Mt. Mihara to set up the homing device before the two missiles collide above Tokyo. The destruction of the nuclear missile produces an electrical storm and an EMP, which revives Godzilla once more and temporarily disables the Super X.
An enraged Godzilla bears down on the Super X just as it manages to get airborne again. The Super X's weapons prove ineffective against the kaiju, resulting in even more destruction in the city as Godzilla chases it through several skyscrapers. Godzilla finally destroys the Super X by dropping a skyscraper on top of it and continues his rampage, until Hayashida uses the homing device to distract him. Godzilla leaves Tokyo and swims across Tokyo Bay, following the homing device to Mount Mihara. There, Godzilla follows the device and falls into the mouth of the volcano. Okumura activates detonators at the volcano, creating a controlled eruption that traps Godzilla inside.
## Production.
### Development.
After the box office failure of "Terror of Mechagodzilla", Toho attempted to reinvigorate the franchise several times during the late 1970s and early 1980s. The first attempt was the announcement of a color remake of the original 1954 film entitled "The Rebirth of Godzilla" in 1977, but the project was shelved. A year later, it was announced that Toho would develop a film jointly with UPA studios entitled "Godzilla vs. the Devil", though this, along with UPA producer Henry G. Saperstein's proposed "Godzilla vs. Gargantua", also never materialized.
"Godzilla" series creator Tomoyuki Tanaka took charge of reviving the franchise in 1979, Godzilla's 25th anniversary, intending to return the series to its dark, anti-nuclear roots in the wake of the Three Mile Island accident. Hoping to win back adult audiences alienated by the fantastical approach to "Godzilla" films taken during the 1970s, Tanaka was further encouraged in his vision by the contemporary success of adult-oriented horror and science fiction movies like "King Kong", "Invasion of the Body Snatchers", "Alien" and "The Thing". A draft story entitled "The Resurrection of Godzilla" was submitted by Akira Murao in 1980, and had Godzilla pitted against a shape-shifting monster called Bakan in the backdrop of an illegal nuclear waste disposal site, though the project was cancelled due to budgetary concerns. In 1983, American director Steve Miner proposed directing a "Godzilla" film at his own expense. Toho approved of the project, and Miner hired Fred Dekker to write the screenplay and paleosculptor Steve Czerkas to redesign the monster. The project was however hampered by Miner's insistence on using prohibitively costly stop-motion animation and shooting the film in 3D, and was thus rejected by major American movie studios. Under pressure from a 10,000-member group of Japanese "Godzilla" fans calling themselves the "Godzilla Resurrection Committee", Tanaka decided to helm a Japanese film for "strictly domestic consumption" to be released jointly alongside Miner's movie.
In an effort to disavow Godzilla's increasingly heroic and anthropomorphic depiction in previous films, Tanaka insisted on making a direct sequel to the original 1954 movie. He hired screenwriter Shuichi Nagahara, who wrote a screenplay combining elements of the previously cancelled "The Resurrection of Godzilla" and Miner's still unproduced film, including an intensification of hostilities during the Cold War and a flying fortress which fires missiles into Godzilla's mouth. Koji Hashimoto was hired as director after Ishirō Honda declined the offer, as he was assisting Akira Kurosawa with "Kagemusha" and "Ran", and felt that the franchise should have been discontinued after the death of Eiji Tsuburaya.
Composer Akira Ifukube was offered to score the film but respectfully declined. At the time, it was rumored that Ifukube refused to participate in the film due to the changes made to Godzilla, stating, "I do not write music for 80-meter monsters". However, this quote was later clarified, by Ifukube's biographer Erik Homenick and "Japanese Giants" editor Ed Godziszewski, as a joke spread by fans which was later misinterpreted as fact. Ifukube declined to score the film due to his priorities, at the time, teaching composition at the Tokyo College of Music.
### Special effects.
The special effects were again directed by Teruyoshi Nakano, who had directed the special effects of several previous "Godzilla" films. The decision was made by Tanaka to increase the apparent height of Godzilla from to so that Godzilla would not be dwarfed by the contemporary skyline of Tokyo. This meant that the miniatures had to be built to a th scale, and this contributed to an increase in the budget of the film to $6.25 million. Tanaka and Nakano supervised suit-maker Noboyuki Yasumaru in constructing a new Godzilla design, incorporating ears and four toes, features not seen since "Godzilla Raids Again". Nakano insisted on infusing elements into the design that suggested sadness, such as downward-slanting eyes and sloping shoulders.
Suit construction took two months, and consisted of separately casting body-part molds with urethane on a pre-built, life-size statue of the final design. Yasumaru personally took charge of all phases of suit-building, unlike in previous productions wherein the different stages of suit-production were handled by different craftsmen. The final suit was constructed to accommodate stuntman Hiroshi Yamawaki, but he declined suddenly, and was replaced by veteran suit actor Kenpachiro Satsuma, who had portrayed Hedorah and Gigan in the Showa Era. Because the suit wasn't built to his measurements, Satsuma had difficulty performing, being able to last only ten minutes within it, and losing 12 pounds during filming. Hoping to avoid having Godzilla move in an overly human fashion, Nakano instructed Satsuma to base his actions on Noh, a traditional Japanese dance.
Taking inspiration from the publicity surrounding the 40-foot tall King Kong model from Dino De Laurentiis's 1976 film of the same name, Toho spent a reported ¥52,146 (approximately $475.00) on a 16-foot high robotic Godzilla (dubbed "Cybot") for use in close-up shots of the creature's head. The Cybot consisted of a hydraulically-powered mechanical endoskeleton covered in urethane skin containing 3,000 computer operated parts which permitted it to tilt its head, and move its lips and arms. Unlike previous Godzilla suits, whose lower jaws consisted of wire-operated flaps, the Cybot's jaws were hinged like those of an actual animal, and slid back as they opened. A life-size, crane operated foot was also built for close-up shots of city destruction scenes. Part of the film was shot on location on Izu Ōshima, where the climax of the story takes place.
## Release.
### Theatrical.
"The Return of Godzilla" was released on December 15, 1984 in Japan where it was distributed by Toho. The film sold 3.2 million tickets, and grossed at the Japanese box office.
### Reception.
Despite its American re-edit receiving negative reviews, the original Japanese cut of the film has been much more well-received, with critics and fans praising the film's score, practical effects, and its darker tone. In 1985, the film won the "Japan Academy Award" for Special Effects.
### Home video.
In May 2016, Kraken Releasing revealed plans to release the original Japanese version of "The Return of Godzilla" and its international English dub on DVD and Blu-ray in North America on September 13, 2016. However, it was also revealed that the Americanized version of the film, "Godzilla 1985" would not be featured in the release due to ongoing copyright issues concerning music cues that New World Pictures borrowed from "Def-Con 4" for use in "Godzilla 1985".
## Alternate English versions.
### Exported English dub.
Shortly after the film's completion, Toho's foreign sales division, Toho International Co., Ltd, had the film dubbed into English by an unidentified firm in Hong Kong. No cuts were made, though credits and other titles were accordingly rendered in English. The international English dub features the voice of news anchor and radio announcer John Culkin in the role of Goro Maki, and actor Barry Haigh as Prime Minister Mitamura. The English version fully dubs all dialogue into English, including that of the Soviet and American characters. The international English dub was released on VHS in the U.K. by Carlton Home Entertainment on July 24, 1998.
In 2016, the international English dub was included on the U.S. DVD and Blu-Ray releases from Kraken, though the audio mix was not the original monaural track that was originally heard on Toho's English language prints. The English dialogue was originally mixed with an alternate music and effects track that contained different music edits and sound effects from the Japanese theatrical version, most notably a distinct "cry" produced by Godzilla during the film's ending. The U.S. home video version instead uses the conventional music and effects track used for the regular Japanese version mixed in DTS 5.1 surround sound instead of mono.
### "Godzilla 1985".
After the film's lackluster performance in the Japanese box office and the ultimate shelving of Steve Miner's "Godzilla 3D" project, Toho decided to distribute the film overseas in order to regain lost profits. New World Pictures acquired "The Return of Godzilla" for distribution in North America, and changed the title to "Godzilla 1985", bringing back Raymond Burr in order to commemorate the 30th anniversary of "". Originally, New World reportedly planned to re-write the dialogue in order to turn the film into a tongue-in-cheek comedy starring Leslie Nielsen (à la "What's Up, Tiger Lily?"), but this plan was reportedly scrapped because Raymond Burr expressed displeasure at the idea, taking the idea of Godzilla as a nuclear metaphor seriously. The only dialogue left over from that script was "That's quite an urban renewal program they've got going on over there," said by Major McDonahue. All of Burr's scenes were filmed in one day to suit his schedule. He was paid US$50,000. The reverse shots, of the actors he was speaking to, were filmed the next day, and the American filming was completed in three days. One of the most controversial changes done on the film was having Soviet Colonel Kashirin deliberately launch the nuclear missile rather than die in attempting to prevent its launch. Director R. J. Kizer later attributed this to New World's management's conservative leanings.
The newly edited film also contained numerous product placements for Dr Pepper, which had twice used Godzilla in its commercials. Dr Pepper's marketing director at one point insisted that Raymond Burr drink Dr Pepper during a scene, and the suggestion was put to the actor by Kizer. Burr reportedly responded by "[fixing] me with one of those withering glares and just said nothing."
Roger Ebert and Vincent Canby gave the film negative reviews.

</doc>
<doc id="12006" url="https://en.wikipedia.org/wiki?curid=12006" title="Godzilla on Monster Island">
Godzilla on Monster Island



</doc>
<doc id="12007" url="https://en.wikipedia.org/wiki?curid=12007" title="Johann Gottlieb Fichte">
Johann Gottlieb Fichte

Johann Gottlieb Fichte (; ; 19 May 1762 – 29 January 1814) was a German philosopher who became a founding figure of the philosophical movement known as German idealism, which developed from the theoretical and ethical writings of Immanuel Kant. Recently, philosophers and scholars have begun to appreciate Fichte as an important philosopher in his own right due to his original insights into the nature of self-consciousness or self-awareness. Fichte was also the originator of "thesis–antithesis–synthesis", an idea that is often erroneously attributed to Hegel. Like Descartes and Kant before him, Fichte was motivated by the problem of subjectivity and consciousness. Fichte also wrote works of political philosophy; he has a reputation as one of the fathers of German nationalism.
## Biography.
### Origins.
Fichte was born in Rammenau, Upper Lusatia. The son of a ribbon weaver, he came of peasant stock which had lived in the region for many generations. The family was noted in the neighborhood for its probity and piety. Christian Fichte, Johann Gottlieb's father, married somewhat above his station. It has been suggested that a certain impatience which Fichte himself displayed throughout his life was an inheritance from his mother.
He received a rudimentary education from his father. He showed remarkable ability from an early age, and it was owing to his reputation among the villagers that he gained the opportunity for a better education than he otherwise would have received. The story runs that the Freiherr von Militz, a country landowner, arrived too late to hear the local pastor preach. He was, however, informed that a lad in the neighborhood would be able to repeat the sermon almost "verbatim". As a result, the baron took Fichte into his protection and paid for his tuition.
### Early schooling.
Fichte was placed in the family of Pastor Krebel at Niederau near Meissen, and there received a thorough grounding in the classics. From this time onward, Fichte saw little of his parents. In October 1774, he attended the celebrated foundation-school at Pforta near Naumburg. This school is associated with the names of Novalis, August Wilhelm Schlegel, Friedrich Schlegel and Nietzsche. The spirit of the institution was semi-monastic and, while the education was excellent, it is doubtful whether there was enough social life and contact with the world for Fichte's temperament and antecedents. Perhaps his education strengthened a tendency toward introspection and independence, characteristics which appear strongly in his doctrines and writings.
### Theological studies and private tutoring.
In 1780, Fichte began study at the University of Jena's theology seminary. He was transferred a year later to study at the Leipzig University. Fichte seems to have supported himself during this period of bitter poverty and hard struggle. Freiherr von Militz continued to support him, but when he died in 1784, Fichte had to end his studies without completing his degree.
From 1784 to 1788, Fichte precariously supported himself as tutor for various Saxon families. In early 1788, he returned to Leipzig in the hope of finding a better employment, but eventually he had to settle for a less promising position with the family of an innkeeper in Zurich. He lived in Zurich for the next two years (1788–1790), which was a time of great contentment for him. There he met his future wife, Johanna Rahn, and Johann Heinrich Pestalozzi. He also became, in 1793, a member of the Freemasonry lodge "Modestia cum Libertate" with which Johann Wolfgang Goethe was also connected. In the spring of 1790, he became engaged to Johanna. Fichte began to study the works of Kant in the summer of 1790. This occurred initially because one of Fichte's students wanted to know about Kant's writings. They had a lasting effect on his life and thought. However, while Fichte was studying Kantian philosophy, the Rahn family suffered financial reverses. His impending marriage had to be postponed.
### Kant.
From Zurich, Fichte returned to Leipzig in May 1790. In early 1791, he obtained a tutorship in Warsaw in the house of a Polish nobleman. The situation, however, quickly proved disagreeable and he was released. He then got a chance to see Kant at Königsberg. After a disappointing interview on 4 July of the same year, he shut himself in his lodgings and threw all his energies into the composition of an essay which would attract Kant's attention and interest. This essay, completed in five weeks, was the "Versuch einer Critik aller Offenbarung" ("Attempt at a Critique of All Revelation", 1792). In this book, according to Henrich, Fichte investigated the connections between divine revelation and Kant's critical philosophy. The first edition was published without Kant's or Fichte's knowledge and without Fichte's name or signed preface. It was thus believed by the public to be a new work by Kant.
When Kant cleared the confusion and openly praised the work and author, Fichte's reputation skyrocketed. In a letter to Karl Reinhold, Jens Baggeson wrote that it was "...the most shocking and astonishing news... [since] nobody but Kant could have written this book. This amazing news of a third sun in the philosophical heavens has set me into such confusion". Kant waited seven years to make public statement about the incident; after considerable external pressure he dissociated himself from Fichte. In his statement, he inscribed, "May God protect us from our friends. From our enemies, we can try to protect ourselves."
### Jena.
In October 1793, Fichte was married in Zurich, where he remained the rest of the year. Stirred by the events and principles of the French Revolution, he wrote and anonymously published two pamphlets which led to him to be seen as a devoted defender of liberty of thought and action and an advocate of political changes. In December of the same year, he received an invitation to fill the position of extraordinary professor of philosophy at the University of Jena. He accepted and began his lectures in May 1794. With extraordinary zeal, he expounded his system of "transcendental idealism". His success was immediate. He excelled as a lecturer due to the earnestness and force of his personality. These lectures were later published under the title "The Vocation of the Scholar" ("Einige Vorlesungen über die Bestimmung des Gelehrten"). He gave himself up to intense production, and a succession of works soon appeared.
### Atheism dispute.
After weathering several academic storms, Fichte was finally dismissed from the University of Jena in 1799 for atheism. He had been accused of this in 1798 after publishing the essay "Ueber den Grund unsers Glaubens an eine göttliche Weltregierung" ("On the Ground of Our Belief in a Divine World-Governance"), written in response to Friedrich Karl Forberg's essay "Development of the Concept of Religion", in his "Philosophical Journal". For Fichte, God should be conceived primarily in moral terms: "The living and efficaciously acting moral order is itself God. We require no other God, nor can we grasp any other" ("On the Ground of Our Belief in a Divine World-Governance"). Fichte's intemperate "Appeal to the Public" ("Appellation an das Publikum", 1799) provoked F. H. Jacobi to publish an open letter in which he equated philosophy in general and Fichte's transcendental philosophy in particular with nihilism.
### Berlin.
Since all the German states except Prussia had joined in the cry against Fichte, he was forced to go to Berlin. There he associated himself with the Schlegels, Schleiermacher, Schelling and Tieck. In April 1800, through the introduction of Hungarian writer Ignaz Aurelius Fessler, he was initiated into Freemasonry in the Lodge Pythagoras of the Blazing Star where he was elected minor warden. At first Fichte was a warm admirer of Fessler, and was disposed to aid him in his proposed Masonic reform. But later he became Fessler's bitter opponent. Their controversy attracted much attention among Freemasons. Fichte presented two lectures on the philosophy of Masonry during the same period as part of his work on the development of various higher degrees for the lodge in Berlin. Johann Karl Christian Fischer, a high official of the Grand Orient, published those lectures in 1802/03 in two volumes under the title "Philosophy of Freemasonry: Letters to Konstant" ("Philosophie der Maurerei. Briefe an Konstant"), where Konstant referred to a fictitious non-Mason.
In November 1800, Fichte published "The Closed Commercial State: A Philosophical Sketch as an Appendix to the Doctrine of Right and an Example of a Future Politics" ("Der geschlossene Handelsstaat. Ein philosophischer Entwurf als Anhang zur Rechtslehre und Probe einer künftig zu liefernden Politik"), a philosophical statement of his property theory, a historical analysis of European economic relations, and a political proposal for reforming them. In 1805, he was appointed to a professorship at the University of Erlangen. The Battle of Jena-Auerstedt in 1806, in which Napoleon completely crushed the Prussian army, drove him to Königsberg for a time, but he returned to Berlin in 1807 and continued his literary activity.
After the collapse of the Holy Roman Empire, where German southern principalities resigned as member states and became part of a French protectorship, Fichte delivered the famous "Addresses to the German Nation" ("Reden an die deutsche Nation", 1807-1808) which attempted to define the German Nation, and guided the uprising against Napoleon. He became a professor at the new University of Berlin, founded in 1810. By the votes of his colleagues Fichte was unanimously elected its rector in the succeeding year. But, once more, his impetuosity and reforming zeal led to friction, and he resigned in 1812. The campaign against Napoleon began, and the hospitals at Berlin were soon full of patients. Fichte's wife devoted herself to nursing and caught a virulent fever. Just as she was recovering, he became sick with typhus and died in 1814 at the age of 51.
His son, Immanuel Hermann Fichte (18 July 1796 – 8 August 1879), also made contributions to philosophy.
## Philosophical work.
Fichte's critics argued that his mimicry of Kant's difficult style produced works that were barely intelligible. "He made no hesitation in pluming himself on his great skill in the shadowy and obscure, by often remarking to his pupils, that 'there was only one man in the world who could fully understand his writings; and even he was often at a loss to seize upon his real meaning. On the other hand, Fichte acknowledged the difficulty, but argued that his works were clear and transparent to those who made the effort to think without preconceptions and prejudices.
Fichte did not endorse Kant's argument for the existence of noumena, of "things in themselves", the supra-sensible reality beyond direct human perception. Fichte saw the rigorous and systematic separation of "things in themselves" (noumena) and things "as they appear to us" (phenomena) as an invitation to skepticism. Rather than invite skepticism, Fichte made the radical suggestion that we should throw out the notion of a noumenal world and accept that consciousness does not have a grounding in a so-called "real world". In fact, Fichte achieved fame for originating the argument that consciousness is not grounded in outside of itself. The phenomenal world as such, arises from consciousness; the activity of the I; and moral awareness. His student (and critic), Arthur Schopenhauer, wrote:
Søren Kierkegaard was also a student of the writings of Fichte:
### Central theory.
In "Foundations of Natural Right" (1797), Fichte argued that self-consciousness was a social phenomenon — an important step and perhaps the first clear step taken in this direction by modern philosophy. For Fichte, a necessary condition of every subject's self-awareness is the existence of other rational subjects. These others call or summon ("fordern auf") the subject or self out of its unconsciousness and into an awareness of itself as a free individual.
Fichte proceeds from the general principle that the I ("das Ich") must posit itself as an individual in order to posit ("setzen") itself at all, and that in order to posit itself as an individual, it must recognize itself to a calling or summons ("Aufforderung") by other free individual(s) — called to limit its own freedom out of respect for the freedom of the others. The same condition applies to the others in development. Mutual recognition ("gegenseitig anerkennen") of rational individuals is a condition necessary for the individual I. The argument for intersubjectivity is central to the conception of selfhood developed in the "Foundations of the Science of Knowledge" ("Grundlage der gesamten Wissenschaftslehre", 1794/1795).
Fichte's consciousness of the self depends upon resistance or a check by something that is understood as not part of the self yet is not immediately ascribable to a particular sensory perception. In his later 1796–99 lectures (his "Nova methodo"), Fichte incorporated this into his revised presentation of the foundations of his system, where the summons takes its place alongside original feeling, which takes the place of the earlier "Anstoss" (see below) as a limit on the absolute freedom and a condition for the positing of the I.
The I posits this situation for itself. To posit does not mean to 'create' the objects of consciousness. The principle in question simply states that the essence of an I lies in the assertion of self-identity, i.e., that consciousness presupposes self-consciousness. Such immediate self-identity cannot be understood as a psychological fact, or an act or accident of some previously existing substance or being. It is an action of the I, but one that is identical with the very existence of this same I. In Fichte's technical terminology, the original unity of self-consciousness is an action and the product of the same I, as a "fact and/or act" ("Thathandlung"; Modern German: "Tathandlung"), a unity that is presupposed by and contained within every fact and every act of empirical consciousness, although it never appears as such.
The I can posit itself only as limited. Moreover, it cannot even posit its own limitations, in the sense of producing or creating these limits. The finite I cannot be the ground of its own passivity. Instead, for Fichte, if the I is to posit itself, it must simply discover itself to be limited, a discovery that Fichte characterizes as an "impulse," "repulse," or "resistance" ("Anstoss"; Modern German: "Anstoß") to the free practical activity of the I. Such an original limitation of the I is, however, a limit for the I only insofar as the I posits it out as a limit. The I does this, according to Fichte's analysis, by positing its own limitation, first, as only a feeling, then as a sensation, then as an intuition of a thing, and finally as a summons of another person.
The "Anstoss" thus provides the essential impetus that first posits in motion the entire complex train of activities that finally result in our conscious experience both of ourselves and others as empirical individuals and of the world around us. Although "Anstoss" plays a similar role as the thing in itself does in Kantian philosophy, unlike Kant, Fichte's "Anstoss" is not something foreign to the I. Instead, it denotes the original encounter of the I with its own finitude. Rather than claim that the not-I ("das Nicht-Ich") is the cause or ground of the "Anstoss", Fichte argues that not-I is posited by the I in order to explain to itself the "Anstoss" in order to become conscious of "Anstoss". The "Wissenschaftslehre" demonstrates that "Anstoss" must occur if self-consciousness is to come about but is unable to explain the actual occurrence of "Anstoss". There are limits to what can be expected from an a priori deduction of experience, and this, for Fichte, equally applies to Kant's transcendental philosophy. According to Fichte, transcendental philosophy can explain that the world must have space, time, and causality, but it can never explain why objects have the particular sensible properties they happen to have or why I am this determinate individual rather than another. This is something that the I simply has to discover at the same time that it discovers its own freedom, and indeed, is a condition for the latter.
Dieter Henrich (1966) proposed that Fichte was able to move beyond a "reflective theory of consciousness". According to Fichte, the self must already have some prior acquaintance with itself, independent of the act of reflection ("no object comes to consciousness except under the condition that I am aware of myself, the conscious subject ["jedes Object kommt zum Bewusstseyn lediglich unter der Bedingung, dass ich auch meiner selbst, des bewusstseyenden Subjects mir bewusst sey"]"). This idea is what Henrich called Fichte's original insight.
### Nationalism.
Between December 1807 and March 1808, Fichte gave a series of lectures concerning the "German nation" and its culture and language, projecting the kind of national education he hoped would raise it from the humiliation of its defeat at the hands of the French. Having been a supporter of Revolutionary France, Fichte became disenchanted by 1804 as Napoleon's armies advanced through Europe, occupying German territories, stripping them of their raw materials and subjugating them to foreign rule. He came to believe Germany would be responsible to carry the virtues of the French Revolution into the future. Furthermore, his nationalism was not aroused by Prussian military defeat and humiliation, for these had not yet occurred, but resulted from his own humanitarian philosophy. Disappointed in the French, he turned to the German nation as the instrument of fulfilling it.
These lectures, entitled the "Addresses to the German Nation", coincided with a period of reform in the Prussian government, under the chancellorship of Baron vom Stein. The "Addresses" display Fichte's interest during that period in language and culture as vehicles of human spiritual development. Fichte built upon earlier ideas of Johann Gottfried Herder and attempted to unite them with his approach. The aim of the German nation, according to Fichte, was to "found an empire of spirit and reason, and to annihilate completely the crude physical force that rules of the world." Like Herder's German nationalism, Fichte's was cultural, and grounded in the aesthetic, literary, and moral. However, Fichte's belief in a "Closed Commercial State", a state dominated economy and society, should be noted – as should its kinship with certain 20th-century governments in Germany and elsewhere.
The nationalism propounded by Fichte in the "Addresses" would be used over a century later by the Nazi Party in Germany, which saw in Fichte a forerunner to its own nationalist ideology. Like Nietzsche, the association of Fichte with the Nazi regime came to colour readings of Fichte's German nationalism in the post-war period. This reading of Fichte was often bolstered through reference to an unpublished letter from 1793, "Contributions to the Correction of the Public's Judgment concerning the French Revolution", wherein Fichte expressed anti-semitic sentiments, such as arguing against extending civil rights to Jews and calling them a "state within a state" that could "undermine" the German nation.&lt;ref name="Gesamtausgabe I/1 pp. 292"&gt;"Gesamtausgabe", I/1, pp. 292–93&lt;/ref&gt;
However, attached to the letter is a footnote in which Fichte provides an impassioned plea for permitting Jews to practice their religion without hindrance. Furthermore, the final act of Fichte's academic career was to resign as rector of the University of Berlin in protest when his colleagues refused to punish the harassment of Jewish students. While recent scholarship has sought to dissociate Fichte's writings on nationalism with their adoption by the Nazi Party, the association continues to blight his legacy, although Fichte, as if to exclude all ground of doubt, clearly and distinctly prohibits,  in his reworked version of "The Science of Ethics as Based on the Science of Knowledge" (see § Final period in Berlin) genocide and other crimes against humanity:
### Economics.
Fichte's 1800 economic treatise "The Closed Commercial State" had a profound influence on the economic theories of German Romanticism. In it, Fichte argues the need for the strictest, purely guild-like regulation of industry.
The "exemplary rational state" ("Vernunftstaat"), Fichte argues, should not allow any of its "subjects" to engage in this or that production, failing to pass the preliminary test, not certifying government agents in their professional skills and agility. According to Vladimir Mikhailovich Shulyatikov, "this kind of demand was typical of "Mittelstund", the German petty middle class, the class of artisans, hoping by creating artificial barriers to stop the victorious march of big capital and thus save themselves from inevitable death. The same demand was imposed on the state, as is evident from Fichte's treatise, by the German "factory" ("Fabrike"), more precisely, the manufacture of the early 19th century".
Fichte opposed free trade and unrestrained capitalist industrial growth, stating: "There is an endless war of all against all ... And this war is becoming more fierce, unjust, more dangerous in its consequences, the more the world's population grows, the more acquisitions the trading state makes, the more production and art (industry) develops and, together with thus, the number of circulating goods increases, and with them the needs become more and more diversified. What, with the simple way of life of nations, was done before without great injustices and oppression, turns, thanks to increased needs, into flagrant injustice, into a source of great evils. The buyer tries to take the goods away from the seller; therefore he demands freedom of trade, i.e. freedom for the seller to wander around the markets, freedom not to find a sale for goods and sell them significantly below their value. Therefore, he requires strong competition between manufacturers ("Fabrikanten") and merchants."
The only means that could save the modern world, which would destroy evil at the root, is, according to Fichte, to split the "world state" (the global market) into separate self-sufficient bodies. Each such body, each "closed trading state" will be able to regulate its internal economic relations. It will be able to both extract and process everything that is needed to meet the needs of its citizens. It will carry out the ideal organization of production. Fichte argued for government regulation of industrial growth, writing "Only by limitation does a certain industry become the property of the class that deals with it".
Vladimir Mikhailovich Shulyatikov considers the economics of German idealists and Romantics as representing the compromise of the German bourgeoisie of the early 19th century with the monarchical State:
The French physiocrats proclaimed the principle: "Laissez faire!" On the other hand, the German capitalists of the 1800s, whose ideologists were the objective idealists, professed a belief in the saving effect of government tutelage.
### Women.
Fichte believed that "active citizenship, civic freedom and even property rights should be withheld from women, whose calling was to subject themselves utterly to the authority of their fathers and husbands."
## Final period in Berlin.
Fichte gave a wide range of public and private lectures in Berlin from the last decade of his life. These form some of his best known work, and are the basis of a revived German-speaking scholarly interest in his work.
The lectures include two works from 1806. In "The Characteristics of the Present Age" ("Die Grundzüge des gegenwärtigen Zeitalters"), Fichte outlines his theory of different historical and cultural epochs. His mystic work "The Way Towards the Blessed Life" ("Die Anweisung zum seligen Leben oder auch die Religionslehre") gave his fullest thoughts on religion. In 1807-1808 he gave a series of speeches in French-occupied Berlin, "Addresses to the German Nation".
In 1810, the new University of Berlin was established, designed along ideas put forward by Wilhelm von Humboldt. Fichte was made its rector and also the first Chair of Philosophy. This was in part because of educational themes in the "Addresses", and in part because of his earlier work at Jena University.
Fichte lectured on further versions of his "Wissenschaftslehre". Of these, he only published a brief work from 1810, "The Science of Knowledge in its General Outline" ("Die Wissenschaftslehre, in ihrem allgemeinen Umrisse dargestellt"; also translated as "Outline of the Doctrine of Knowledge"). His son published some of these thirty years after his death. Most only became public in the last decades of the twentieth century, in his collected works. This included reworked versions of the "Doctrine of Science" ("Wissenschaftslehre", 1810–1813), "The Science of Rights" ("Das System der Rechtslehre", 1812), and "The Science of Ethics as Based on the Science of Knowledge" ("Das System der Sittenlehre nach den Principien der Wissenschaftslehre", 1812; 1st ed. 1798).
## Bibliography.
### Collected works in German.
The new standard edition of Fichte's works in German, which supersedes all previous editions, is the "Gesamtausgabe" ("Collected Works" or "Complete Edition", commonly abbreviated as "GA"), prepared by the Bavarian Academy of Sciences: "Gesamtausgabe der Bayerischen Akademie der Wissenschaften", 42 volumes, edited by , Hans Gliwitzky, Erich Fuchs and Peter Schneider, Stuttgart-Bad Cannstatt: Frommann-Holzboog, 1962–2012.
It is organized into four parts:
Fichte's works are quoted and cited from "GA", followed by a combination of Roman and Arabic numbers, indicating the series and volume, respectively, and the page number(s).
Another edition is "Johann Gottlieb Fichtes sämmtliche Werke" (abbrev. "SW"), ed. I. H. Fichte. Berlin: de Gruyter, 1971.

</doc>
<doc id="12010" url="https://en.wikipedia.org/wiki?curid=12010" title="Great Lakes">
Great Lakes

The Great Lakes also called the Great Lakes of North America or the Laurentian Great Lakes, is a series of large interconnected freshwater lakes in the mid-east region of North America that connect to the Atlantic Ocean via the Saint Lawrence River. They are Lakes Superior, Michigan, Huron, Erie, and Ontario and are in general on or near the Canada–United States border. Hydrologically, there are four lakes, because lakes Michigan and Huron join at the Straits of Mackinac. The Great Lakes Waterway enables travel by water among the lakes. 
The Great Lakes are the largest group of freshwater lakes on Earth by total area and are second-largest by total volume, containing 21% of the world's surface fresh water by volume. The total surface is , and the total volume (measured at the low water datum) is , slightly less than the volume of Lake Baikal (, 22–23% of the world's surface fresh water). Because of their sea-like characteristics, such as rolling waves, sustained winds, strong currents, great depths, and distant horizons, the five Great Lakes have long been called inland seas. By surface area, Lake Superior is the second-largest lake in the world, and is the largest freshwater lake. Lake Michigan is the largest lake that is entirely within one country.
The Great Lakes began to form at the end of the Last Glacial Period around 14,000 years ago, as retreating ice sheets exposed the basins they had carved into the land, which then filled with meltwater. The lakes have been a major source for transportation, migration, trade, and fishing, serving as a habitat to many aquatic species in a region with much biodiversity. The surrounding region is called the Great Lakes region, which includes the Great Lakes Megalopolis.
## Geography.
Though the five lakes lie in separate basins, they form a single, naturally interconnected body of fresh water, within the Great Lakes Basin. As a chain of lakes and rivers, they connect the east-central interior of North America to the Atlantic Ocean. From the interior to the outlet at the Saint Lawrence River, water flows from Superior to Huron and Michigan, southward to Erie, and finally northward to Lake Ontario. The lakes drain a large watershed via many rivers and contain approximately 35,000 islands. There are also several thousand smaller lakes, often called "inland lakes", within the basin. The surface area of the five primary lakes combined is roughly equal to the size of the United Kingdom, while the surface area of the entire basin (the lakes and the land they drain) is about the size of the UK and France combined. Lake Michigan is the only one of the Great Lakes that is entirely within the United States; the others form a water boundary between the United States and Canada. The lakes are divided among the jurisdictions of the Canadian province of Ontario and the U.S. states of Michigan, Wisconsin, Minnesota, Illinois, Indiana, Ohio, Pennsylvania, and New York. Both the province of Ontario and the state of Michigan include in their boundaries portions of four of the lakes: The province of Ontario does not border Lake Michigan, and the state of Michigan does not border Lake Ontario. New York and Wisconsin's jurisdictions extend into two lakes, and each of the remaining states into one of the lakes.
### Bathymetry.
As the surfaces of Lakes Superior, Huron, Michigan, and Erie are all approximately the same elevation above sea level, while Lake Ontario is significantly lower, and because the Niagara Escarpment precludes all natural navigation, the four upper lakes are commonly called the "upper great lakes". This designation is not universal. Those living on the shore of Lake Superior often refer to all the other lakes as "the lower lakes", because they are farther south. Sailors of bulk freighters transferring cargoes from Lake Superior and northern Lake Michigan and Lake Huron to ports on Lake Erie or Ontario commonly refer to the latter as the lower lakes and Lakes Michigan, Huron, and Superior as the upper lakes. This corresponds to thinking of lakes Erie and Ontario as "down south" and the others as "up north". Vessels sailing north on Lake Michigan are considered "upbound" even though they are sailing toward its effluent current.
### Lake Michigan–Huron.
Lakes Huron and Michigan are sometimes considered a single lake, called Lake Michigan–Huron, because they are one hydrological body of water connected by the Straits of Mackinac. The straits are wide and deep; the water levels rise and fall together, and the flow between Michigan and Huron frequently reverses direction.
### Islands.
Dispersed throughout the Great Lakes are approximately 35,000 islands. The largest among them is Manitoulin Island in Lake Huron, the largest island in any inland body of water in the world. The second-largest island is Isle Royale in Lake Superior. Both of these islands are large enough to contain multiple lakes themselves—for instance, Manitoulin Island's Lake Manitou is the world's largest lake on a freshwater island. Some of these lakes even have their own islands, like Treasure Island in Lake Mindemoya in Manitoulin Island
### Peninsulas.
The Great Lakes also have several peninsulas between them, including the Door Peninsula, the Peninsulas of Michigan, and the Ontario Peninsula. Some of these peninsulas even contain smaller peninsulas, such as the Keweenaw Peninsula, the Thumb Peninsula, the Bruce Peninsula, and the Niagara Peninsula. Population centers on the peninsulas include Grand Rapids, Flint, and Detroit in Michigan along with London, Hamilton, Brantford, and Toronto in Ontario.
### Shipping connection to the ocean.
Although the Saint Lawrence Seaway and Great Lakes Waterway make the Great Lakes accessible to ocean-going vessels, shifts in shipping to wider ocean-going container ships—which do not fit through the locks on these routes—have limited container shipping on the lakes. Most Great Lakes trade is of bulk material, and bulk freighters of Seawaymax-size or less can move throughout the entire lakes and out to the Atlantic. Larger ships are confined to working within the lakes. Only barges can access the Illinois Waterway system providing access to the Gulf of Mexico via the Mississippi River. Despite their vast size, large sections of the Great Lakes freeze over in winter, interrupting most shipping from January to March. Some icebreakers ply the lakes, keeping the shipping lanes open through other periods of ice on the lakes.
The Great Lakes are connected by the Chicago Sanitary and Ship Canal to the Gulf of Mexico by way of the Illinois River (from the Chicago River) and the Mississippi River. An alternate track is via the Illinois River (from Chicago), to the Mississippi, up the Ohio, and then through the Tennessee–Tombigbee Waterway (a combination of a series of rivers and lakes and canals), to Mobile Bay and the Gulf of Mexico. Commercial tug-and-barge traffic on these waterways is heavy.
Pleasure boats can enter or exit the Great Lakes by way of the Erie Canal and Hudson River in New York. The Erie Canal connects to the Great Lakes at the east end of Lake Erie (at Buffalo, New York) and at the south side of Lake Ontario (at Oswego, New York).
### Water levels.
The lakes were originally fed by both precipitation and meltwater from glaciers which are no longer present. In modern times, only about 1% of volume per year is "new" water, originating from rivers, precipitation, and groundwater springs. In the post-glacial period, evaporation, and drainage have generally been balanced, making the levels of the lakes relatively constant.
Intensive human population growth began in the region in the 20th century and continues today. At least two human water use activities have been identified as having the potential to affect the lakes' levels: diversion (the transfer of water to other watersheds) and consumption (substantially done today by the use of lake water to power and cool electric generation plants, resulting in evaporation). Outflows through the Chicago Sanitary and Ship Canal is more than balanced by artificial inflows via the Ogoki River and Long Lake/Kenogami River diversions. 
Fluctuation of the water levels in the lakes has been observed since records began in 1918. The water level of Lake Michigan–Huron had remained fairly constant over the 20th century Recent lake levels include record low levels in 2013 in Lakes Superior, Erie, and Michigan-Huron, followed by record high levels in 2020 in the same lakes. The water level in Lake Ontario has remained relatively constant in the same time period, hovering around the historical average level.
The lake levels are affected primarily by changes in regional meteorology and climatology. The outflows from lakes Superior and Ontario are regulated, while the outflows of Michigan-Huron and Erie are not regulated at all. Ontario is the most tightly regulated, with its outflow controlled by the Moses-Saunders Power Dam, which explains its consistent historical levels.
## Statistics.
The Great Lakes contain 21% of the world's surface fresh water: , or 6.0×1015 U.S. gallons, that is 6 quadrillion U.S gallons, (2.3×1016 liters). The lakes contain about 84% of the surface freshwater of North America; if the water were evenly distributed over the entire continent's land area, it would reach a depth of 5 feet (1.5 meters). This is enough water to cover the 48 contiguous U.S. states to a uniform depth of . Although the lakes contain a large percentage of the world's fresh water, the Great Lakes supply only a small portion of U.S. drinking water on a national basis.
The total surface area of the lakes is approximately —nearly the same size as the United Kingdom, and larger than the U.S. states of New York, New Jersey, Connecticut, Rhode Island, Massachusetts, Vermont, and New Hampshire combined.&lt;ref name="Taylor/Schechter/Wolfson"&gt;&lt;/ref&gt; The Great Lakes coast measures approximately ;, but the length of a coastline is impossible to measure exactly and is not a well-defined measure. Canada borders approximately of coastline, while the remaining are bordered by the United States. Michigan has the longest shoreline of the United States, bordering roughly of lakes, followed by Wisconsin (), New York (), and Ohio (). Traversing the shoreline of all the lakes would cover a distance roughly equivalent to travelling half-way around the world at the equator.
A notable modern phenomenon is the formation of ice volcanoes over the lakes during wintertime. Storm-generated waves carve the lakes' ice sheet and create conical mounds through the eruption of water and slush. The process is only well-documented in the Great Lakes, and has been credited with sparing the southern shorelines from worse rocky erosion.
## Geology.
It has been estimated that the foundational geology that created the conditions shaping the present day upper Great Lakes was laid from 1.1 to 1.2 billion years ago, when two previously fused tectonic plates split apart and created the Midcontinent Rift, which crossed the Great Lakes Tectonic Zone. A valley was formed providing a basin that eventually became modern day Lake Superior. When a second fault line, the Saint Lawrence rift, formed approximately 570 million years ago, the basis for Lakes Ontario and Erie was created, along with what would become the Saint Lawrence River.
The Great Lakes are estimated to have been formed at the end of the Last Glacial Period (the Wisconsin glaciation ended 10,000 to 12,000 years ago), when the Laurentide Ice Sheet receded. The retreat of the ice sheet left behind a large amount of meltwater (Lake Algonquin, Lake Chicago, Glacial Lake Iroquois, and Champlain Sea) that filled up the basins that the glaciers had carved, thus creating the Great Lakes as we know them today. Because of the uneven nature of glacier erosion, some higher hills became Great Lakes islands. The Niagara Escarpment follows the contour of the Great Lakes between New York and Wisconsin. Land below the glaciers "rebounded" as it was uncovered. Since the glaciers covered some areas longer than others, this glacial rebound occurred at different rates.
## Climate.
The Great Lakes have a humid continental climate,
Köppen climate classification Dfa (in southern areas) and Dfb (in northern parts) with varying influences from air masses from other regions including dry, cold Arctic systems, mild Pacific air masses from the west, and warm, wet tropical systems from the south and the Gulf of Mexico. The lakes have a moderating effect on the climate; they can also increase precipitation totals and produce lake effect snowfall.
### Lake effect.
The Great Lakes can have an effect on regional weather called "lake-effect snow", which is sometimes very localized. Even late in winter, the lakes often have no icepack in the middle. The prevailing winds from the west pick up the air and moisture from the lake surface, which is slightly warmer in relation to the cold surface winds above. As the slightly warmer, moist air passes over the colder land surface, the moisture often produces concentrated, heavy snowfall that sets up in bands or "streamers". This is similar to the effect of warmer air dropping snow as it passes over mountain ranges. During freezing weather with high winds, the "snowbelts" receive regular snow fall from this localized weather pattern, especially along the eastern shores of the lakes. Snowbelts are found in Wisconsin, Michigan, Ohio, Pennsylvania, New York, and Ontario. Related to the lake effect is the regular occurrence of fog, particularly along the shorelines of the lakes. This is most noticeable along Lake Superior's shores.
The lakes tend to moderate seasonal temperatures to some degree but not with as large an influence as do large oceans; they absorb heat and cool the air in summer, then slowly radiate that heat in autumn. They protect against frost during transitional weather and keep the summertime temperatures cooler than further inland. This effect can be very localized and overridden by offshore wind patterns. This temperature buffering produces areas known as "fruit belts", where fruit can be produced that is typically grown much farther south. For instance, western Michigan has apple orchards, and cherry orchards are cultivated adjacent to the lake shore as far north as the Grand Traverse Bay. Near Collingwood, Ontario, commercial fruit orchards, including a few wineries, exist near the shoreline of southern Nottawasaga Bay. The eastern shore of Lake Michigan and the southern shore of Lake Erie have many successful wineries because of the lakes' moderating effects, as do the large commercial fruit and wine growing areas of the Niagara Peninsula located between Lake Erie and Lake Ontario. A similar phenomenon allows wineries to flourish in the Finger Lakes region of New York, as well as in Prince Edward County, Ontario, on Lake Ontario's northeast shore.
The Great Lakes have been observed to help intensify storms, such as Hurricane Hazel in 1954, and the 2011 Goderich, Ontario tornado, which moved onshore as a tornadic waterspout. In 1996, a rare tropical or subtropical storm was observed forming in Lake Huron, dubbed the 1996 Lake Huron cyclone. Rather large severe thunderstorms covering wide areas are well known in the Great Lakes during mid-summer; these Mesoscale convective complexes or MCCs can cause damage to wide swaths of forest and shatter glass in city buildings. These storms mainly occur during the night, and the systems sometimes have small embedded tornadoes, but more often straight-line winds accompanied by intense lightning.
## Ecology.
Historically, the Great Lakes, in addition to their lake ecology, were surrounded by various forest ecoregions (except in a relatively small area of southeast Lake Michigan where savanna or prairie occasionally intruded). Logging, urbanization, and agriculture uses have changed that relationship. In the early 21st century, Lake Superior's shores are 91% forested, Lake Huron 68%, Lake Ontario 49%, Lake Michigan 41%, and Lake Erie, where logging and urbanization has been most extensive, 21%. Some of these forests are second or third growth (i.e. they have been logged before, changing their composition). At least 13 wildlife species are documented as becoming extinct since the arrival of Europeans, and many more are threatened or endangered. Meanwhile, exotic and invasive species have also been introduced.
### Fauna.
While the organisms living on the bottom of shallow waters are similar to those found in smaller lakes, the deep waters contain organisms found only in deep, cold lakes of the northern latitudes. These include the delicate opossum shrimp (order mysida), the deepwater scud (a crustacean of the order amphipoda), two types of copepods, and the deepwater sculpin (a spiny, large-headed fish).
The Great Lakes are an important source of fishing. Early European settlers were astounded by both the variety and quantity of fish; there were 150 different species in the Great Lakes. Throughout history, fish populations were the early indicator of the condition of the Lakes and have remained one of the key indicators even in the current era of sophisticated analyses and measuring instruments. According to the bi-national (U.S. and Canadian) resource book, "The Great Lakes: An Environmental Atlas and Resource Book": "The largest Great Lakes fish harvests were recorded in 1889 and 1899 at some [147 million pounds]."
By 1801, the New York Legislature found it necessary to pass regulations curtailing obstructions to the natural migrations of Atlantic salmon from Lake Erie into their spawning channels. In the early 19th century, the government of Upper Canada found it necessary to introduce similar legislation prohibiting the use of weirs and nets at the mouths of Lake Ontario's tributaries. Other protective legislation was passed, but enforcement remained difficult.
On both sides of the Canada–United States border, the proliferation of dams and impoundments have multiplied, necessitating more regulatory efforts. Concerns by the mid-19th century included obstructions in the rivers which prevented salmon and lake sturgeon from reaching their spawning grounds. The Wisconsin Fisheries Commission noted a reduction of roughly 25% in general fish harvests by 1875. The states have removed dams from rivers where necessary.
Overfishing has been cited as a possible reason for a decrease in population of various whitefish, important because of their culinary desirability and, hence, economic consequence. Moreover, between 1879 and 1899, reported whitefish harvests declined from some 24.3 million pounds (11 million kg) to just over 9 million pounds (4 million kg). By 1900, commercial fishermen on Lake Michigan were hauling in an average of 41 million pounds of fish annually. By 1938, Wisconsin's commercial fishing operations were motorized and mechanized, generating jobs for more than 2,000 workers, and hauling 14 million pounds per year. The population of giant freshwater mussels was eliminated as the mussels were harvested for use as buttons by early Great Lakes entrepreneurs. 
"The Great Lakes: An Environmental Atlas and Resource Book" (1972) notes: "Only pockets remain of the once large commercial fishery." Water quality improvements realized during the 1970s and 1980s, combined with successful salmonid stocking programs, have enabled the growth of a large recreational fishery. The last commercial fisherman left Milwaukee in 2011 because of overfishing and anthropogenic changes to the biosphere.
### Invasive species.
Since the 19th century, an estimated 160 new species have found their way into the Great Lakes ecosystem; many have become invasive; the overseas ship ballast and ship hull parasitism are causing severe economic and ecological impacts. According to the Inland Seas Education Association, on average a new species enters the Great Lakes every eight months. Introductions into the Great Lakes include the zebra mussel, which was first discovered in 1988, and quagga mussel in 1989. Since 2000, the invasive quagga mussel has smothered the bottom of Lake Michigan almost from shore to shore, and their numbers are estimated at 900 trillion. The mollusks are efficient filter feeders, competing with native mussels and reducing available food and spawning grounds for fish. In addition, the mussels may be a nuisance to industries by clogging pipes. The U.S. Fish and Wildlife Service estimated in 2007 that the economic impact of the zebra mussel could be about $5 billion over the next decade.
The alewife first entered the system west of Lake Ontario via 19th-century canals. By the 1960s, the small silver fish had become a familiar nuisance to beach goers across Lakes Michigan, Huron, and Erie. Periodic mass die-offs result in vast numbers of the fish washing up on shore; estimates by various governments have placed the percentage of Lake Michigan's biomass, which was made up of alewives in the early 1960s, as high as 90%. In the late 1960s, the various state and federal governments began stocking several species of salmonids, including the native lake trout as well as non-native chinook and coho salmon; by the 1980s, alewife populations had dropped drastically. The ruffe, a small percid fish from Eurasia, became the most abundant fish species in Lake Superior's Saint Louis River within five years of its detection in 1986. Its range, which has expanded to Lake Huron, poses a significant threat to the lower lake fishery. Five years after first being observed in the St. Clair River, the round goby can now be found in all of the Great Lakes. The goby is considered undesirable for several reasons: it preys upon bottom-feeding fish, overruns optimal habitat, spawns multiple times a season, and can survive poor water quality conditions.
The influx of parasitic lamprey populations after the development of the Erie Canal and the much later Welland Canal led to the two federal governments of the U.S. and Canada working on joint proposals to control it. By the mid-1950s, the lake trout populations of Lakes Michigan and Huron were reduced, with the lamprey deemed largely to blame. This led to the launch of the bi-national Great Lakes Fishery Commission.
Several species of exotic water fleas have accidentally been introduced into the Great Lakes, such as the spiny waterflea, "Bythotrephes longimanus", and the fishhook waterflea, "Cercopagis pengoi", potentially having an effect on the zooplankton population. Several species of crayfish have also been introduced that may contend with native crayfish populations. More recently an electric fence has been set up across the Chicago Sanitary and Ship Canal in order to keep several species of invasive Asian carp out of the lakes. These fast-growing planktivorous fish have heavily colonized the Mississippi and Illinois river systems. Invasive species, particularly zebra and quagga mussels, may be at least partially responsible for the collapse of the deepwater demersal fish community in Lake Huron, as well as drastic unprecedented changes in the zooplankton community of the lake.
### Microbiology.
Scientists understand that the micro-aquatic life of the lakes is abundant but know very little about some of the most plentiful microbes and their environmental effects in the Great Lakes. Although a drop of lake water may contain 1 million bacteria cells and 10 million viruses, only since 2012 has there been a long-term study of the lakes' micro-organisms. Between 2012 and 2019 more than 160 new species have been discovered.
### Flora.
Native habitats and ecoregions in the Great Lakes region include:
Plant lists include:
Logging
Logging of the extensive forests in the Great Lakes region removed riparian and adjacent tree cover over rivers and streams, which provide shade, moderating water temperatures in fish spawning grounds. Removal of trees also destabilized the soil, with greater volumes washed into stream beds causing siltation of gravel beds, and more frequent flooding.
Running cut logs down the tributary rivers into the Great Lakes also dislocated sediments. In 1884, the New York Fish Commission determined that the dumping of sawmill waste (chips and sawdust) had impacted fish populations.
### Pollution.
The first U.S. Clean Water Act, passed by a Congressional override after being vetoed by U.S. President Richard Nixon in 1972, was a key piece of legislation, along with the bi-national Great Lakes Water Quality Agreement signed by Canada and the U.S. A variety of steps taken to process industrial and municipal pollution discharges into the system greatly improved water quality by the 1980s, and Lake Erie in particular is significantly cleaner. Discharge of toxic substances has been sharply reduced. Federal and state regulations control substances like PCBs. The first of 43 "Great Lakes Areas of Concern" to be formally "de-listed" through successful cleanup was Ontario's Collingwood Harbour in 1994; Ontario's Severn Sound followed in 2003. Presque Isle Bay in Pennsylvania is formally listed as in recovery, as is Ontario's Spanish Harbour. Dozens of other Areas of Concern have received partial cleanups such as the Rouge River (Michigan) and Waukegan Harbor (Illinois).
Phosphate detergents were historically a major source of nutrient to the Great Lakes algae blooms in particular in the warmer and shallower portions of the system such as Lake Erie, Saginaw Bay, Green Bay, and the southernmost portion of Lake Michigan. By the mid-1980s, most jurisdictions bordering the Great Lakes had controlled phosphate detergents. Blue-green algae, or cyanobacteria blooms, have been problematic on Lake Erie since 2011. "Not enough is being done to stop fertilizer and phosphorus from getting into the lake and causing blooms," said Michael McKay, executive director of the Great Lakes Institute for Environmental Research (GLIER) at the University of Windsor. The largest Lake Erie bloom to date occurred in 2015, exceeding the severity index at 10.5 and in 2011 at a 10. In early August 2019, satellite images depicted a bloom stretching up to 1,300 square kilometres on Lake Erie, with the heaviest concentration near Toledo, Ohio. A large bloom does not necessarily mean the cyanobacteria ... will produce toxins", said Michael McKay, of the University of Windsor. Water quality testing was underway in August 2019.
#### Mercury.
Until 1970, mercury was not listed as a harmful chemical, according to the United States Federal Water Quality Administration. In the 21st century, mercury has become more apparent in water tests. Mercury compounds have been used in paper mills to prevent slime from forming during their production, and chemical companies have used mercury to separate chlorine from brine solutions. Studies conducted by the Environmental Protection Agency have shown that when the mercury comes in contact with many of the bacteria and compounds in the fresh water, it forms the compound methyl mercury, which has a much greater impact on human health than elemental mercury due to a higher propensity for absorption. This form of mercury is not detrimental to a majority of fish types, but is very detrimental to people and other wildlife animals who consume the fish. Mercury has been known for health related problems such as birth defects in humans and animals, and the near extinction of eagles in the Great Lakes region.
#### Sewage.
The amount of raw sewage dumped into the waters was the primary focus of both the first Great Lakes Water Quality Agreement and federal laws passed in both countries during the 1970s. Implementation of secondary treatment of municipal sewage by major cities greatly reduced the routine discharge of untreated sewage during the 1970s and 1980s. The International Joint Commission in 2009 summarized the change: "Since the early 1970s, the level of treatment to reduce pollution from waste water discharges to the Great Lakes has improved considerably. This is a result of significant expenditures to date on both infrastructure and technology, and robust regulatory systems that have proven to be, on the whole, quite effective." The commission reported that all urban sewage treatment systems on the U.S. side of the lakes had implemented secondary treatment, as had all on the Canadian side except for five small systems.
Though contrary to federal laws in both countries, those treatment system upgrades have not yet eliminated combined sewer overflow events. This describes when older sewerage systems, which combine storm water with sewage into single sewers heading to the treatment plant, are temporarily overwhelmed by heavy rainstorms. Local sewage treatment authorities then must release untreated effluent, a mix of rainwater and sewage, into local water bodies. While enormous public investments such as the Deep Tunnel projects in Chicago and Milwaukee have greatly reduced the frequency and volume of these events, they have not been eliminated. The number of such overflow events in Ontario, for example, is flat according to the International Joint Commission. Reports about this issue on the U.S. side highlight five large municipal systems (those of Detroit, Cleveland, Buffalo, Milwaukee and Gary) as being the largest current periodic sources of untreated discharges into the Great Lakes.
### Impacts of climate change on algae.
Algae such as diatoms, along with other phytoplankton, are photosynthetic primary producers supporting the food web of the Great Lakes, and have been affected by global warming. The changes in the size or in the function of the primary producers may have a direct or an indirect impact on the food web. Photosynthesis carried out by diatoms constitutes about one fifth of the total photosynthesis. By taking out of the water to photosynthesize, diatoms help to stabilize the pH of the water, as would react with water to produce carbonic acid. 
Diatoms acquire inorganic carbon through passive diffusion of and , and use carbonic anhydrase mediated active transport to speed up this process. Large diatoms require more carbon uptake than smaller diatoms. There is a positive correlation between the surface area and the chlorophyll concentration of diatom cells.
## History.
Several Native American populations (Paleo-indians) inhabited the region around 10,000 BC, after the end of the Wisconsin glaciation. The peoples of the Great Lakes traded with the Hopewell culture from around 1000 AD, as copper nuggets have been extracted from the region and fashioned into ornaments and weapons in the mounds of Southern Ohio. 
The Rush–Bagot Treaty signed in 1818, after the War of 1812 and the later Treaty of Washington eventually led to a complete disarmament of naval vessels in the Great Lakes. Nonetheless, both nations maintained coast guard vessels in the Great Lakes.
The brigantine "Le Griffon", which was commissioned by René-Robert Cavelier, Sieur de La Salle, was built at Cayuga Creek, near the southern end of the Niagara River, and became the first known sailing ship to travel the upper Great Lakes on August 7, 1679. During settlement, the Great Lakes and its rivers were the only practical means of moving people and freight. Barges from middle North America were able to reach the Atlantic Ocean from the Great Lakes when the Welland Canal opened in 1824 and the later Erie Canal opened in 1825. By 1848, with the opening of the Illinois and Michigan Canal at Chicago, direct access to the Mississippi River was possible from the lakes. With these two canals an all-inland water route was provided between New York City and New Orleans.
The main business of many of the passenger lines in the 19th century was transporting immigrants. Many of the larger cities owe their existence to their position on the lakes as a freight destination as well as for being a magnet for immigrants. After railroads and surface roads developed, the freight and passenger businesses dwindled and, except for ferries and a few foreign cruise ships, have now vanished.
The immigration routes still have an effect today. Immigrants often formed their own communities, and some areas have a pronounced ethnicity, such as Dutch, German, Polish, Finnish, and many others. Since many immigrants settled for a time in New England before moving westward, many areas on the U.S. side of the Great Lakes also have a New England feel, especially in home styles and accent.
Since general freight these days is transported by railroads and trucks, domestic ships mostly move bulk cargoes, such as iron ore, coal and limestone for the steel industry. The domestic bulk freight developed because of the nearby mines. It was more economical to transport the ingredients for steel to centralized plants rather than to make steel on the spot. Grain exports are also a major cargo on the lakes. In the 19th and early 20th centuries, iron and other ores such as copper were shipped south on (downbound ships), and supplies, food, and coal were shipped north (upbound). Because of the location of the coal fields in Pennsylvania and West Virginia, and the general northeast track of the Appalachian Mountains, railroads naturally developed shipping routes that went due north to ports such as Erie, Pennsylvania and Ashtabula, Ohio.
Because the lake maritime community largely developed independently, it has some distinctive vocabulary. Ships, no matter the size, are called "boats". When the sailing ships gave way to steamships, they were called "steamboats"—the same term used on the Mississippi. The ships also have a distinctive design; ships that primarily trade on the lakes are known as "lakers". Foreign boats are known as "salties". One of the more common sights on the lakes has been since about 1950 the 1,000‑by‑105-foot (305-by-32-meter), self-unloader. This is a laker with a conveyor belt system that can unload itself by swinging a crane over the side. Today, the Great Lakes fleet is much smaller in numbers than it once was because of the increased use of overland freight, and a few larger ships replacing many small ones.
During World War II, the risk of submarine attacks against coastal training facilities motivated the United States Navy to operate two aircraft carriers on the Great Lakes, and . Both served as training ships to qualify naval aviators in carrier landing and takeoff. Lake Champlain briefly became the sixth Great Lake of the United States on March 6, 1998, when President Clinton signed Senate Bill 927. This bill, which reauthorized the National Sea Grant Program, contained a line declaring Lake Champlain to be a Great Lake. Not coincidentally, this status allows neighboring states to apply for additional federal research and education funds allocated to these national resources. Following a small uproar, the Senate voted to revoke the designation on March 24 (although New York and Vermont universities would continue to receive funds to monitor and study the lake).
Alan B. McCullough has written that the fishing industry of the Great Lakes got its start "on the American side of Lake Ontario in Chaumont Bay, near the Maumee River on Lake Erie, and on the Detroit River at about the time of the War of 1812". Although the region was sparsely populated until the 1830s, so there was not much local demand and transporting fish was prohibitively costly, there were economic and infrastructure developments that were promising for the future of the fishing industry going into the 1830s. Particularly, the 1825 opening of the Erie Canal and the Welland Canal a few years later. The fishing industry expanded particularly in the waters associated with the fur trade that connect Lake Erie and Lake Huron. In fact, two major suppliers of fish in the 1830s were the fur trading companies Hudson's Bay Company and the American Fur Company.
The catch from these waters was sent to the growing market for salted fish in Detroit, where merchants involved in the fur trade had already gained some experience handling salted fish. One such merchant was John P. Clark, a shipbuilder and merchant who began selling fish in the area of Manitowoc, Wisconsin where whitefish was abundant. Another operation cropped up in Georgian Bay, Canadian waters plentiful with trout as well as whitefish. In 1831, Alexander MacGregor from Goderich, Ontario found whitefish and herring in abundant supply around the Fishing Islands. A contemporary account by Methodist missionary John Evans describes the fish as resembling a "bright cloud moving rapidly through the water".
From 1844 through 1857, palace steamers carried passengers and cargo around the Great Lakes. In the first half of the 20th century large luxurious passenger steamers sailed the lakes in opulence. The Detroit and Cleveland Navigation Company had several vessels at the time and hired workers from all walks of life to help operate these vessels. Several ferries currently operate on the Great Lakes to carry passengers to various islands. As of 2007, four car ferry services cross the Great Lakes, two on Lake Michigan: a steamer from Ludington, Michigan, to Manitowoc, Wisconsin, and a high speed catamaran from Milwaukee to Muskegon, Michigan, one on Lake Erie: a boat from Kingsville, Ontario, or Leamington, Ontario, to Pelee Island, Ontario, then onto Sandusky, Ohio, and one on Lake Huron: the M.S. "Chi-Cheemaun" runs between Tobermory and South Baymouth, Manitoulin Island, operated by the Owen Sound Transportation Company. An international ferry across Lake Ontario from Rochester, New York, to Toronto ran during 2004 and 2005 but is no longer in operation.
### Shipwrecks.
The large size of the Great Lakes increases the risk of water travel; storms and reefs are common threats. The lakes are prone to sudden and severe storms, in particular in the autumn, from late October until early December. Hundreds of ships have met their end on the lakes. The greatest concentration of shipwrecks lies near Thunder Bay (Michigan), beneath Lake Huron, near the point where eastbound and westbound shipping lanes converge. The Lake Superior shipwreck coast from Grand Marais, Michigan, to Whitefish Point became known as the "Graveyard of the Great Lakes". More vessels have been lost in the Whitefish Point area than any other part of Lake Superior. The Whitefish Point Underwater Preserve serves as an underwater museum to protect the many shipwrecks in this area.
The first ship to sink in Lake Michigan was "Le Griffon", also the first ship to sail the Great Lakes. Caught in a 1679 storm while trading furs between Green Bay and Michilimacinac, she was lost with all hands aboard. Its wreck may have been found in 2004, but a wreck subsequently discovered in a different location was also claimed in 2014 to be "Le Griffon". The largest and last major freighter wrecked on the lakes was the , which sank on November 10, 1975, just over offshore from Whitefish Point on Lake Superior. The largest loss of life in a shipwreck out on the lakes may have been that of , wrecked in 1860 with the loss of around 400 lives on Lake Michigan. In an incident at a Chicago dock in 1915, the rolled over while loading passengers, killing 841.
In 2007, the Great Lakes Shipwreck Historical Society announced that it had found the wreckage of "Cyprus", a long, century-old ore carrier. "Cyprus" sank during a Lake Superior storm on October 11, 1907, during its second voyage while hauling iron ore from Superior, Wisconsin, to Buffalo, New York. The entire crew of 23 drowned, except one, Charles Pitz, who floated on a life raft for almost seven hours. In 2008, deep sea divers in Lake Ontario found the wreck of the 1780 Royal Navy warship in what has been described as an "archaeological miracle". There are no plans to raise her as the site is being treated as a war grave. In 2010, "L.R. Doty" was found in Lake Michigan by an exploration diving team led by dive boat Captain Jitka Hanakova from her boat "Molly V". The ship sank in October 1898, probably attempting to rescue a small schooner, "Olive Jeanette", during a terrible storm.
Still missing are the two last warships to sink in the Great Lakes, the French minesweepers, "Inkerman" and "Cerisoles", which vanished in Lake Superior during a blizzard in 1918. 78 lives were lost making it the largest loss of life in Lake Superior and the greatest unexplained loss of life in the Great Lakes.
## Economy.
### Shipping.
Except when the water is frozen during winter, more than 100 lake freighters operate continuously on the Great Lakes, which remain a major water transport corridor for bulk goods. The Great Lakes Waterway connects all the lakes; the smaller Saint Lawrence Seaway connects the lakes to the Atlantic oceans. Some lake freighters are too large to use the Seaway and operate only on the Waterway and lakes. In 2002, 162 million net tons of dry bulk cargo were moved on the Lakes. This was, in order of volume: iron ore, grain and potash. The iron ore and much of the stone and coal are used in the steel industry. There is also some shipping of liquid and containerized cargo.
Only four bridges are on the Great Lakes other than Lake Ontario because of the cost of building structures high enough for ships to pass under. The Blue Water Bridge is, for example, more than 150 feet high and more than a mile long. Major ports on the Great Lakes include Duluth-Superior, Chicago, Detroit, Cleveland, Twin Harbors, Hamilton and Thunder Bay.
### Recreation.
Tourism and recreation are major industries on the Great Lakes. A few small cruise ships operate on the Great Lakes including some sailing ships. Sport fishing, commercial fishing, and Native American fishing represent a U.S.$4 billion a year industry with salmon, whitefish, smelt, lake trout, bass and walleye being major catches. Many other water sports are practiced on the lakes such as yachting, sea kayaking, diving, kitesurfing, powerboating, and lake surfing. The Great Lakes Circle Tour is a designated scenic road system connecting all of the Great Lakes and the Saint Lawrence River.
## Legislation.
In 1872, a treaty gave access to the St. Lawrence River to the United States and access to Lake Michigan to the Dominion of Canada. The International Joint Commission was established in 1909 to help prevent and resolve disputes relating to the use and quality of boundary waters, and to advise Canada and the United States on questions related to water resources. Concerns over diversion of Lake water are of concern to both Americans and Canadians. Some water is diverted through the Chicago River to operate the Illinois Waterway, but the flow is limited by treaty. Possible schemes for bottled water plants and diversion to dry regions of the continent raise concerns. Under the U.S. "Water Resources Development Act", diversion of water from the Great Lakes Basin requires the approval of all eight Great Lakes governors through the Great Lakes Commission, which rarely occurs. International treaties regulate large diversions.
In 1998, the Canadian company Nova Group won approval from the Province of Ontario to withdraw of Lake Superior water annually to ship by tanker to Asian countries. Public outcry forced the company to abandon the plan before it began. Since that time, the eight Great Lakes Governors and the Premiers of Ontario and Quebec have negotiated the Great Lakes-Saint Lawrence River Basin Sustainable Water Resources Agreement and the Great Lakes-St. Lawrence River Basin Water Resources Compact that would prevent most future diversion proposals and all long-distance ones. The agreements strengthen protection against abusive water withdrawal practices within the Great Lakes basin. On December 13, 2005, the Governors and Premiers signed these two agreements, the first of which is between all ten jurisdictions. It is somewhat more detailed and protective, though its legal strength has not yet been tested in court. The second, the Great Lakes Compact, has been approved by the state legislatures of all eight states that border the Great Lakes as well as the U.S. Congress, and was signed into law by President George W. Bush on October 3, 2008.
The Great Lakes Restoration Initiative, described as "the largest investment in the Great Lakes in two decades", was funded at $475 million in the U.S. federal government's Fiscal Year 2011 budget, and $300 million in the Fiscal Year 2012 budget. Through the program a coalition of federal agencies is making grants to local and state entities for toxics cleanups, wetlands and coastline restoration projects, and invasive species-related projects. The Great Lakes Restoration Initiative Act of 2019 passed as Public Law on January 5, 2021.

</doc>
<doc id="12012" url="https://en.wikipedia.org/wiki?curid=12012" title="German">
German

German(s) may refer to:

</doc>
<doc id="12013" url="https://en.wikipedia.org/wiki?curid=12013" title="Girth (graph theory)">
Girth (graph theory)

In graph theory, the girth of an undirected graph is the length of a shortest cycle contained in the graph. If the graph does not contain any cycles (that is, it is a forest), its girth is defined to be infinity.
For example, a 4-cycle (square) has girth 4. A grid has girth 4 as well, and a triangular mesh has girth 3. A graph with girth four or more is triangle-free.
## Cages.
A cubic graph (all vertices have degree three) of girth that is as small as possible is known as a -cage (or as a (3,)-cage). The Petersen graph is the unique 5-cage (it is the smallest cubic graph of girth 5), the Heawood graph is the unique 6-cage, the McGee graph is the unique 7-cage and the Tutte eight cage is the unique 8-cage. There may exist multiple cages for a given girth. For instance there are three nonisomorphic 10-cages, each with 70 vertices: the Balaban 10-cage, the Harries graph and the Harries–Wong graph.
## Girth and graph coloring.
For any positive integers and , there exists a graph with girth at least and chromatic number at least ; for instance, the Grötzsch graph is triangle-free and has chromatic number 4, and repeating the Mycielskian construction used to form the Grötzsch graph produces triangle-free graphs of arbitrarily large chromatic number. Paul Erdős was the first to prove the general result, using the probabilistic method. More precisely, he showed that a random graph on vertices, formed by choosing independently whether to include each edge with probability has, with probability tending to 1 as goes to infinity, at most cycles of length or less, but has no independent set of size Therefore, removing one vertex from each short cycle leaves a smaller graph with girth greater than in which each color class of a coloring must be small and which therefore requires at least colors in any coloring.
Explicit, though large, graphs with high girth and chromatic number can be constructed as certain Cayley graphs of linear groups over finite fields. These remarkable "Ramanujan graphs" also have large expansion coefficient.
## Related concepts.
The odd girth and even girth of a graph are the lengths of a shortest odd cycle and shortest even cycle respectively. 
The of a graph is the length of the "longest" (simple) cycle, rather than the shortest.
Thought of as the least length of a non-trivial cycle, the girth admits natural generalisations as the 1-systole or higher systoles in systolic geometry.
Girth is the dual concept to edge connectivity, in the sense that the girth of a planar graph is the edge connectivity of its dual graph, and vice versa. These concepts are unified in matroid theory by the girth of a matroid, the size of the smallest dependent set in the matroid. For a graphic matroid, the matroid girth equals the girth of the underlying graph, while for a co-graphic matroid it equals the edge connectivity.

</doc>
<doc id="12015" url="https://en.wikipedia.org/wiki?curid=12015" title="Gun safety">
Gun safety

Gun safety is the study and practice of using, transporting, storing and disposing of firearms and ammunition, including the training of gun users, the design of weapons, and formal and informal regulation of gun production, distribution, and usage, for the purpose of avoiding unintentional injury, illness, or death. This includes mishaps like accidental discharge, negligent discharge, and firearm malfunctions, as well as secondary risks like hearing loss, lead poisoning from bullets, and pollution from other hazardous materials in propellants and cartridges. There were 47,000 unintentional firearm deaths worldwide in 2013. 
## History.
Accidental explosions of stored gunpowder date to the 13th century in Yangzhou, China. Early handheld muskets using matchlock or wheel lock mechanisms were limited by poor reliability and the risk of accidental discharge, which was improved somewhat by the introduction of the flintlock, though unintentional firing continued to be a serious drawback. Percussion caps, introduced in the 1820s were more reliable, and by 1830 inventors added security pins to their designs to prevent accidental discharges. Trigger guards and grip safetys were further steps leading to the various safeties built into modern firearms.
## Storage.
Proper storage prevents unauthorized use or theft of firearms and ammunition, or damage to them. A gun safe or gun cabinet is commonly used to physically prevent access to a firearm. Local laws may require particular standards for the lock, for the strength and burglar resistance of the cabinet, and may even require weapons and ammunition to be stored separately. Rifles or shotgun safes that are a lighter version of true safes are generally the norm for hunters or multiple firearm owners. Various safety standards like the RSC standard and CDOJ safety standard in US exists for the minimum requirement to qualify a container as firearm safety storage device. Similarly small handgun safes of different sizes and capacity are preferred for storing small number of handguns although most of them are found to be not very reliable by independent researchers and professional hackers. Locking mechanism plays important role in overall safety of the small safe. Generally simplex mechanical locks are found to be most secure and reliable.
For ammunition some experts recommend storing in secure locations away from firearms. Ammunition should be kept in cool, dry conditions free from contaminating vapors to prevent deterioration of the propellant and cartridge. Handloaders must take special precautions for storing primers and loose gunpowder.
## Training, habits and mindset.
Gun safety training teaches a safety mindset, habits, and rules. The mindset is that firearms are inherently dangerous and must always be stored carefully and handled with care. Handlers are taught to treat firearms with respect for their destructive capabilities, and strongly discouraged from playing or toying with firearms, a common cause of accidents. The rules of gun safety follow from this mindset.
In 1902, the English politician and game shooting enthusiast Mark Hanbury Beaufoy wrote some much-quoted verses on gun safety, meant to instill the safety mindset. Various similar sayings have since been popularized. Jeff Cooper, an influential figure in modern firearms training, formalized and popularized "Four Rules" of safe firearm handling. Prior lists of gun safety rules included as few as three basic safety rules or as many as ten rules including gun safety and sporting etiquette rules. In addition to Cooper, other influential teachers of gun safety include Massad Ayoob, Clint Smith, Chuck Taylor, Jim Crews, Bob Munden and Ignatius Piazza. The National Rifle Association and other public safety websites provides a similar set of rules.
### Locks.
There are several types of locks that serve to make it difficult to discharge a firearm. Locks are considered less effective than keeping firearms stored in a lockable safe since locks are more easily defeated than approved safes. An unauthorized handler can bypass the locked firearm at their leisure. Some manufacturers, such as Taurus, build locks into the firearm itself.
California effected regulations in 2000 that forced locks to be approved by a firearm safety device laboratory via California Penal Code Section 12088. All locks under this code must receive extensive tests including saw, pick, pull, and many other tests in order to be approved for the state of California. If a lock passes the requirements then it is said to be California Department of Justice (CADOJ) approved.
### Trigger lock.
There is controversy surrounding manufacturing standards, usage, and legislation of trigger locks. While supporters of trigger locks argue that they will save children by preventing accidents, critics point to demonstrations that some models can be removed by children with very little force and common household tools. Many firearms can discharge when dropped. Firearms that fully disengage the hammer when the safety is on pose less of a risk. A former senior product manager at Master Lock, a trigger lock manufacturer, was quoted as saying "If it is a loaded gun, there isn't a lock out there that will keep it from being fired... If you put a trigger lock on any loaded gun, you are making the gun more dangerous." Critics also point out that a trigger lock will increase the time it takes an owner to respond to a self-defense emergency. In 2008, the U.S. Supreme Court overturned a Washington, D.C. law that required handguns to be locked or otherwise kept inoperative within the home, saying that this "makes it impossible for citizens to use them for the core lawful purpose of self-defense."
### Chamber locks.
Chamber locks aim to block ammunition from being chambered, since most firearms typically cannot be discharged unless the ammunition is in the correct position. They are used to prevent live ammunition from being loaded into a firearm by blocking the chamber with a dummy cartridge or a chamber plug, which is sometimes wedged into place with the use of a tool, in essence jamming the firearm. Another type is one in which a steel rod locked into the safety cartridge with a key. As long as the rod and safety cartridge are engaged, the dummy round cannot eject nor can live ammunition be loaded into the firearm. Chamber locks work with most firearm types including revolvers, pistols, rifles and shotguns. They are available in any caliber and length, and may include such features as unique keying, rapid removal, and rigorous testing and certification by major state departments such as the California Department of Justice.
Some shooting ranges require the handler to insert a temporary chamber plug which often has a brightly colored external tag, to signal the chamber being devoid of ammunition and blocked, whenever the firearm is being unused. These are called empty chamber indicators, or chamber flags.
### Cable locks.
Cable locks are a popular type of lock that usually threads into the receiver through the ejection port of repeating firearms. These locks physically obstruct the movements of the bolt, thereby preventing the cycling of the action, and deny the return to "battery" and the closure of the breech. In many designs of pistol and rifle, they also thread through the magazine well of the firearm to prevent the proper insertion of a magazine.
### Smart gun.
Personalized firearms, or smart guns, are intended to prevent unauthorized use with built-in locks that are released by RFID chips or other proximity devices, fingerprint recognition, magnetic rings, or a microchip implant.
## Secondary dangers.
While a firearm's primary danger lies in the discharge of ammunition, there are other ways a firearm may be detrimental to the health of the handler and bystanders.
### Noise.
When a firearm is discharged it emits a very loud noise, typically close to the handler's ears. This can cause temporary or permanent hearing damage such as tinnitus. Hearing protection such as earplugs, or earmuffs, or both, can reduce the risk of hearing damage. Some earmuffs or headphones made for shooting and similar loud situations use active noise control. Firearms may also have silencers which reduce the sound intensity from the barrel.
### Hot gases and debris.
A firearm emits hot gases, powder, and other debris when discharged. Some firearms, such as semi-automatic and fully automatic firearms, typically eject spent cartridge casings at high speed. Casings are also dangerously hot when ejected. Revolvers store spent casings in the chamber, but may emit a stream of hot gases and possible fine particulate debris laterally from the interface between the revolving chamber and the barrel. Any of these may hurt the handler or bystanders through burning or impact damage. Because eyes are particularly vulnerable to this type of damage, eye protection should be worn to reduce the risk of injury. Prescription lenses and various tints to suit different light conditions are available. Some eye protection products are rated to withstand impact from birdshot loads, which offers protection against irresponsible firearms use by other game bird shooters.
### Toxins and pollutants.
In recent years the toxic effects of ammunition and firearm cleaning agents have been highlighted.
Indoor ranges require good ventilation to remove pollutants such as powder, smoke, and lead dust from the air around the shooters. Indoor and outdoor ranges typically require extensive decontamination when they are decommissioned to remove all traces of lead, copper, and powder residues from the area.
Lead, copper and other metals will also be released when a firearm is cleaned. Highly aggressive solvents and other agents used to remove lead and powder fouling may also present a hazard to health. Installing good ventilation, washing hands after handling firearms, and cleaning the space where the firearm was handled lessens the risk of unnecessary exposure.
## Unsafe users.
### Impaired users.
Firearms should never be handled by persons who are under the influence of alcohol or any drugs which may affect their judgment. Gun safety teachers advocate zero tolerance of their use. In the United States, this recommendation is codified in many states' penal codes as a crime of "carrying under the influence", with penalties similar to DWI/DUI. Other sources of temporary impairment include exhaustion, dehydration, and emotional stress. These can affect reaction time, cognitive processing, sensory perception, and judgment.
Many jurisdictions prohibit the possession of firearms by people deemed generally incapable of using them safely, such as the mentally ill or convicted felons.
### Children.
The National Rifle Association's the Eddie Eagle program for preschoolers through 6th graders is intended to teach children to avoid firearm accidents when they encounter guns that have not been securely stored out of their reach.
Whether programs like Eddie Eagle are effective has not been conclusively determined. Some studies published in peer-reviewed journals have shown that it is very difficult for young children to control their curiosity even when they have been taught not to touch firearms. Gun access is also a major risk factor for youth suicide. The American Academy of Pediatrics (AAP) advises that keeping a gun in the home, especially a handgun increases the risk of injury and death for children and youth in the home.

</doc>
<doc id="12018" url="https://en.wikipedia.org/wiki?curid=12018" title="Gun/Politics">
Gun/Politics



</doc>
<doc id="12021" url="https://en.wikipedia.org/wiki?curid=12021" title="Go Down Moses">
Go Down Moses

"Go Down Moses" is a spiritual phrase that describes events in the Old Testament of the Bible, specifically Exodus 5:1: "And the LORD spake unto Moses, Go unto Pharaoh, and say unto him, Thus saith the LORD, Let my people go, that they may serve me", in which God commands Moses to demand the release of the Israelites from bondage in Egypt. This phrase is the title of the one of the most well known African American spirituals of all time. The song discusses themes of freedom, a very common occurrence in spirituals. In fact, the song actually had multiple messages, discussing not only the metaphorical freedom of Moses but also the physical freedom of runaway slaves, and many slave holders outlawed this song because of those very messages. The opening verse as published by the Jubilee Singers in 1872:
The lyrics of the song represent liberation of the ancient Jewish people from Egyptian slavery, a story recounted in the Old Testament. For enslaved African Americans, the story was very powerful because they could relate to the experiences of Moses and the Israelites who were enslaved by the pharaoh, representing the slave holders, and it holds the hopeful message that God will help those who are persecuted. The song also makes references to the Jordan River, which was often referred to in spirituals to describe finally reaching freedom because such an act of running away often involved crossing one or more rivers.
Going "down" to Egypt is derived from the Bible; the Old Testament recognizes the Nile Valley as lower than Jerusalem and the Promised Land; thus, going to Egypt means going "down" while going away from Egypt is "up". In the context of American slavery, this ancient sense of "down" converged with the concept of "down the river" (the Mississippi), where slaves' conditions were notoriously worse, a situation which led to the idiom "sell [someone] down the river" in present-day English. 
## "Oh! Let My People Go".
Although usually thought of as a spiritual, the earliest written record of the song was as a rallying anthem for the Contrabands at Fort Monroe sometime before July 1862. White people who reported on the song presumed it was composed by them. This became the first ever spiritual to be recorded in sheet music that is known of, by Reverend Lewis Lockwood. While visiting Fortress Monroe in 1861, he heard runaway slaves singing this song, transcribed what he heard, and then eventually published it in the "National Anti-Slavery Standard." Sheet music was soon after published, titled "Oh! Let My People Go: The Song of the Contrabands", and arranged by Horace Waters. L.C. Lockwood, chaplain of the Contrabands, stated in the sheet music that the song was from Virginia, dating from about 1853. However, the song was not included in "Slave Songs of the United States," despite it being a very prominent spiritual among slaves. Furthermore, the original version of the song sung by slaves almost definitely sounded very different from what Lockwood transcribed by ear, especially following an arrangement by a person who had never before heard the song how it was originally sung. The opening verse, as recorded by Lockwood, is:
Sarah Bradford's authorized biography of Harriet Tubman, "Scenes in the Life of Harriet Tubman" (1869), quotes Tubman as saying she used "Go Down Moses" as one of two code songs fugitive slaves used to communicate when fleeing Maryland. Tubman began her underground railroad work in 1850 and continued until the beginning of the Civil War, so it's possible Tubman's use of the song predates the origin claimed by Lockwood. Some people even hypothesize that she herself may have written the spiritual. Although others claim Nat Turner, who led one of the most well-known slave revolts in history, either wrote or was the inspiration for the song. 

</doc>
